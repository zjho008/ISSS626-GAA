[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS626-Geospatial Analytics and Applications Homepage",
    "section": "",
    "text": "Hello there I am Zi Jun. Welcome to my ISSS626 Geospatial Analytics and Applications webpage. In this website, you will find my coursework prepared for this course under the tutelage of Assoc. Professor Kam Tin Seong\nHere is the webpage link for my Visual Analytics and Application course\nA Feature of My Latest Works:\n\n\n\n\n\n\n\n\n\n\nPreparing HDB data\n\n\n\n\n\n\nDr. Kam Tin Seong\n\n\n\n\n\n\n\n\n\n\n\n\nPreparing HDB data\n\n\n\n\n\n\nDr. Kam Tin Seong\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 10a: Processing and Visualising Flow Data\n\n\n\n\n\n\nHo Zi Jun\n\n\nOct 31, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 10b: Calibrating Spatial Interaction Models with R\n\n\n\n\n\n\nHo Zi Jun\n\n\nOct 31, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nModelling Geographic of Accessibility\n\n\n\n\n\n\nHo Zi Jun\n\n\nOct 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 9: Modelling Geographical Accessibility\n\n\n\n\n\n\nHo Zi Jun\n\n\nOct 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 8: Geographically Weighted Predictive Modelling\n\n\n\n\n\n\nHo Zi Jun\n\n\nOct 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nTake-home Exercise 3b: Geospatial Analytics\n\n\n\n\n\n\nHo Zi Jun\n\n\nOct 16, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn-class Exercise 7: Geographically Weighted Regression (GWR)\n\n\n\n\n\n\nHo Zi Jun\n\n\nOct 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 7: Geographically Weighted Regression (GWR)\n\n\n\n\n\n\nHo Zi Jun\n\n\nOct 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn-class Exercise 6\n\n\n\n\n\n\nHo Zi Jun\n\n\nSep 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nTake-home Exercise 2: Geospatial Analytics in Thailand Tourism Sector (Pre, During, Post COVID-19)\n\n\n\n\n\n\nHo Zi Jun\n\n\nSep 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 6: Geographic Segmentation with Spatially Constrained Cluster Analysis\n\n\n\n\n\n\nHo Zi Jun\n\n\nSep 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn-class Exercise 5: Global and Local Measures of Spatial Autocorrelation\n\n\n\n\n\n\nHo Zi Jun\n\n\nSep 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 5a: Spatial Weights and Applications\n\n\n\n\n\n\nHo Zi Jun\n\n\nSep 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 5b: Local Measures of Spatial Autocorrelation\n\n\n\n\n\n\nHo Zi Jun\n\n\nSep 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn-class Exercise 4\n\n\n\n\n\n\nHo Zi Jun\n\n\nSep 16, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 4: Spatial Weights and Applications\n\n\n\n\n\n\nHo Zi Jun\n\n\nSep 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn-class Exercise 3\n\n\n\n\n\n\nHo Zi Jun\n\n\nSep 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nTake-home Exercise 1: Geospatial Analytics for Public Good\n\n\n\n\n\n\nHo Zi Jun\n\n\nSep 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 3: Network Constrained Spatial Point Patterns Analysis\n\n\n\n\n\n\nHo Zi Jun\n\n\nSep 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn-class Exercise 2\n\n\n\n\n\n\nHo Zi Jun\n\n\nSep 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 2b: 2nd Order Spatial Point Patterns Analysis Methods\n\n\n\n\n\n\nHo Zi Jun\n\n\nSep 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 2a: 1st Order Spatial Point Patterns Analysis Methods\n\n\n\n\n\n\nHo Zi Jun\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html",
    "title": "In-class Exercise 1",
    "section": "",
    "text": "THe following 4 R packages will be used for this in-class exercise:\n\nsf for importing, managing, and processing geospatial data,\ntidyverse for performing data science tasks such as importing, wrangling and visualising data,\ntmap to plot functional and truthful choropleth maps, and\nggstatsplot for creating graphics with details from statistical tests.\n\nTidyverse consists of a family of R packages. In this hands-on exercise, the following packages will be used:\n\nreadr for importing csv data,\nreadxl for importing Excel worksheet,\ntidyr for manipulating data,\ndplyr for transforming data, and\nggplot2 for visualising data\n\n\n\n\n\n\n\nNote\n\n\n\nThie code chunk below uses p_load() of pacman package to check if sf and tidyverse packages are installed in the computer. If they are, then they will be launched into R.\n\n\n\n\n\n\npacman::p_load(sf, tidyverse, tmap, ggstatsplot)\n\n\n\n\n\n\nthe st_read() function of sf package is used to import MP14_SUBZONE_WEB_PL shapefile into R as a polygon feature data frame.\n\nmpsz14_shp = st_read(dsn = \"data/\", \n  layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\zjho008\\ISSS626-GAA\\In-class_Ex\\In-class_Ex01\\data' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nUsing the class() function, the code chunk below tells us that it is a simple feature data frame.\n\nclass(mpsz14_shp)\n\n[1] \"sf\"         \"data.frame\"\n\n\nThis code chunk imports the kml file\n\n# mpsz14_kml &lt;- st_read(\"data/MasterPlan2014SubzoneBoundaryWebKML.kml\")\n\n\n\n\n\n\n\nWarning\n\n\n\nAfter running the code, an error message is shown stating that the file cannot be opened. This is likely due to an issue with file structure resulting in file being unable to be opened.\n\n\n\n\n\n\nst_write()\n\nst_write(mpsz14_shp,\n         \"data/MP14_SUBZONE_WEB_PL.kml\",\n          delete_dsn = TRUE)\n\nDeleting source `data/MP14_SUBZONE_WEB_PL.kml' using driver `KML'\nWriting layer `MP14_SUBZONE_WEB_PL' to data source \n  `data/MP14_SUBZONE_WEB_PL.kml' using driver `KML'\nWriting 323 features with 15 fields and geometry type Multi Polygon.\n\n\n\n\n\n\n\n\nNote\n\n\n\nWith the code chunk above the file in kml format is created. The delete_dsn argument is to overwrite the old file and replace with the new file with same file name.\n\n\n\n\n\n\nmpsz19_kml &lt;- st_read(\"data/MasterPlan2019SubzoneBoundaryNoSeaKML.kml\")\n\nReading layer `URA_MP19_SUBZONE_NO_SEA_PL' from data source \n  `C:\\zjho008\\ISSS626-GAA\\In-class_Ex\\In-class_Ex01\\data\\MasterPlan2019SubzoneBoundaryNoSeaKML.kml' \n  using driver `KML'\nSimple feature collection with 332 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY, XYZ\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nUpon some initial observation - kml version is not very tidy\n\n\n\n\n\nFor this section an updated version of the data published in 2019 will be used.\n\nmpsz19_shp = st_read(dsn = \"data/\", \n                     layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `C:\\zjho008\\ISSS626-GAA\\In-class_Ex\\In-class_Ex01\\data' using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\n\n\n\nThe Master Plan 2019 Subzone Boundary Data was in the Geographical Coordinate System - WGS84.\nA viable option to check the geometry if its is in: 0 - 180 / 0 - 360 likely in WGS coordinate system.\nFor the code chunk above, pipe is utilised since we are using sf.\nAfter transformation (re-projection) observed from geometry that now it is in metres\n\n\n\n\n\nComparing excel(due to heading & blank spaces & asteris) vs csv file (better for analysis). CSV seems to be the more viable option for analysis as it has no un-necessary structure.\n\n\n\n\nThe Task: To visit and extract the latest Singapore Residents by Planning Area / Subzone, Age, Group, Sex and Type of Dwelling from Singstat.\n\n\npopdata &lt;- read_csv(\"data/respopagesextod2023.csv\")\n\nRows: 100928 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWrangling of data to be done in order to derive the groups: YOUNG, ACTIVE, ECONOMY ACTIVE\n\npopdata2023 &lt;- popdata %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from = AG,\n              values_from = POP)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\n\nCode was split to observe the steps - one at a time. Will aggregate does not differentiate male/female.\npivot wider portion - will compute and bring multiple columns based on age.\n\ncolnames(popdata2023)\n\n [1] \"PA\"          \"SZ\"          \"0_to_4\"      \"10_to_14\"    \"15_to_19\"   \n [6] \"20_to_24\"    \"25_to_29\"    \"30_to_34\"    \"35_to_39\"    \"40_to_44\"   \n[11] \"45_to_49\"    \"50_to_54\"    \"55_to_59\"    \"5_to_9\"      \"60_to_64\"   \n[16] \"65_to_69\"    \"70_to_74\"    \"75_to_79\"    \"80_to_84\"    \"85_to_89\"   \n[21] \"90_and_Over\"\n\n\n\n\n\n\npopdata2023 &lt;- popdata2023 %&gt;%\n  mutate(YOUNG = rowSums(.[, 3:6]) + rowSums(.[, 14])) %&gt;%  # Aged 0-24, 10-24 + Aged 5-9\n  mutate(`ECONOMY ACTIVE` = rowSums(.[, 7:13]) + rowSums(.[, 15])) %&gt;%  # Aged 25-59 + Aged 60-64\n  mutate(AGED = rowSums(.[, 16:21])) %&gt;%  # Aged 65 and above\n  mutate(TOTAL = rowSums(.[, 3:21])) %&gt;%  # Total population\n  mutate(DEPENDENCY = (YOUNG + AGED) / `ECONOMY ACTIVE`) %&gt;%  # Dependency ratio\n  select(PA, SZ, YOUNG, `ECONOMY ACTIVE`, AGED, TOTAL, DEPENDENCY)\n\n+rowSums should not be 12 (as attempted in Hands-On Exercise) but its 14.\nWe use glimpse() function take a look at the updated popdata2023 data-frame.\n\nglimpse(popdata2023)\n\nRows: 332\nColumns: 7\n$ PA               &lt;chr&gt; \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo Kio…\n$ SZ               &lt;chr&gt; \"Ang Mo Kio Town Centre\", \"Cheng San\", \"Chong Boon\", …\n$ YOUNG            &lt;dbl&gt; 1240, 5150, 4620, 4320, 1840, 3810, 1870, 3750, 0, 10…\n$ `ECONOMY ACTIVE` &lt;dbl&gt; 2830, 15600, 14120, 12400, 3670, 9600, 4320, 11090, 0…\n$ AGED             &lt;dbl&gt; 890, 6580, 7060, 5640, 1420, 4320, 1790, 5390, 0, 880…\n$ TOTAL            &lt;dbl&gt; 4960, 27330, 25800, 22360, 6930, 17730, 7980, 20230, …\n$ DEPENDENCY       &lt;dbl&gt; 0.7526502, 0.7519231, 0.8271955, 0.8032258, 0.8882834…"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#getting-started",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#getting-started",
    "title": "In-class Exercise 1",
    "section": "",
    "text": "THe following 4 R packages will be used for this in-class exercise:\n\nsf for importing, managing, and processing geospatial data,\ntidyverse for performing data science tasks such as importing, wrangling and visualising data,\ntmap to plot functional and truthful choropleth maps, and\nggstatsplot for creating graphics with details from statistical tests.\n\nTidyverse consists of a family of R packages. In this hands-on exercise, the following packages will be used:\n\nreadr for importing csv data,\nreadxl for importing Excel worksheet,\ntidyr for manipulating data,\ndplyr for transforming data, and\nggplot2 for visualising data\n\n\n\n\n\n\n\nNote\n\n\n\nThie code chunk below uses p_load() of pacman package to check if sf and tidyverse packages are installed in the computer. If they are, then they will be launched into R."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#the-code",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#the-code",
    "title": "In-class Exercise 1",
    "section": "",
    "text": "pacman::p_load(sf, tidyverse, tmap, ggstatsplot)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#the-data",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#the-data",
    "title": "In-class Exercise 1",
    "section": "",
    "text": "the st_read() function of sf package is used to import MP14_SUBZONE_WEB_PL shapefile into R as a polygon feature data frame.\n\nmpsz14_shp = st_read(dsn = \"data/\", \n  layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\zjho008\\ISSS626-GAA\\In-class_Ex\\In-class_Ex01\\data' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nUsing the class() function, the code chunk below tells us that it is a simple feature data frame.\n\nclass(mpsz14_shp)\n\n[1] \"sf\"         \"data.frame\"\n\n\nThis code chunk imports the kml file\n\n# mpsz14_kml &lt;- st_read(\"data/MasterPlan2014SubzoneBoundaryWebKML.kml\")\n\n\n\n\n\n\n\nWarning\n\n\n\nAfter running the code, an error message is shown stating that the file cannot be opened. This is likely due to an issue with file structure resulting in file being unable to be opened."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#working-with-master-plan-2014-subzone-boundary-web-file---attempt",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#working-with-master-plan-2014-subzone-boundary-web-file---attempt",
    "title": "In-class Exercise 1",
    "section": "",
    "text": "st_write()\n\nst_write(mpsz14_shp,\n         \"data/MP14_SUBZONE_WEB_PL.kml\",\n          delete_dsn = TRUE)\n\nDeleting source `data/MP14_SUBZONE_WEB_PL.kml' using driver `KML'\nWriting layer `MP14_SUBZONE_WEB_PL' to data source \n  `data/MP14_SUBZONE_WEB_PL.kml' using driver `KML'\nWriting 323 features with 15 fields and geometry type Multi Polygon.\n\n\n\n\n\n\n\n\nNote\n\n\n\nWith the code chunk above the file in kml format is created. The delete_dsn argument is to overwrite the old file and replace with the new file with same file name."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#working-with-master-plan-2019-subzone-boundary-data",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#working-with-master-plan-2019-subzone-boundary-data",
    "title": "In-class Exercise 1",
    "section": "",
    "text": "mpsz19_kml &lt;- st_read(\"data/MasterPlan2019SubzoneBoundaryNoSeaKML.kml\")\n\nReading layer `URA_MP19_SUBZONE_NO_SEA_PL' from data source \n  `C:\\zjho008\\ISSS626-GAA\\In-class_Ex\\In-class_Ex01\\data\\MasterPlan2019SubzoneBoundaryNoSeaKML.kml' \n  using driver `KML'\nSimple feature collection with 332 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY, XYZ\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nUpon some initial observation - kml version is not very tidy"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#handling-coordinate-systems",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#handling-coordinate-systems",
    "title": "In-class Exercise 1",
    "section": "",
    "text": "For this section an updated version of the data published in 2019 will be used.\n\nmpsz19_shp = st_read(dsn = \"data/\", \n                     layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `C:\\zjho008\\ISSS626-GAA\\In-class_Ex\\In-class_Ex01\\data' using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\n\n\n\nThe Master Plan 2019 Subzone Boundary Data was in the Geographical Coordinate System - WGS84.\nA viable option to check the geometry if its is in: 0 - 180 / 0 - 360 likely in WGS coordinate system.\nFor the code chunk above, pipe is utilised since we are using sf.\nAfter transformation (re-projection) observed from geometry that now it is in metres"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#in-class-sharing",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#in-class-sharing",
    "title": "In-class Exercise 1",
    "section": "",
    "text": "Comparing excel(due to heading & blank spaces & asteris) vs csv file (better for analysis). CSV seems to be the more viable option for analysis as it has no un-necessary structure."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#working-with-population-data",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#working-with-population-data",
    "title": "In-class Exercise 1",
    "section": "",
    "text": "The Task: To visit and extract the latest Singapore Residents by Planning Area / Subzone, Age, Group, Sex and Type of Dwelling from Singstat.\n\n\npopdata &lt;- read_csv(\"data/respopagesextod2023.csv\")\n\nRows: 100928 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWrangling of data to be done in order to derive the groups: YOUNG, ACTIVE, ECONOMY ACTIVE\n\npopdata2023 &lt;- popdata %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from = AG,\n              values_from = POP)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\n\nCode was split to observe the steps - one at a time. Will aggregate does not differentiate male/female.\npivot wider portion - will compute and bring multiple columns based on age.\n\ncolnames(popdata2023)\n\n [1] \"PA\"          \"SZ\"          \"0_to_4\"      \"10_to_14\"    \"15_to_19\"   \n [6] \"20_to_24\"    \"25_to_29\"    \"30_to_34\"    \"35_to_39\"    \"40_to_44\"   \n[11] \"45_to_49\"    \"50_to_54\"    \"55_to_59\"    \"5_to_9\"      \"60_to_64\"   \n[16] \"65_to_69\"    \"70_to_74\"    \"75_to_79\"    \"80_to_84\"    \"85_to_89\"   \n[21] \"90_and_Over\""
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#data-processing",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#data-processing",
    "title": "In-class Exercise 1",
    "section": "",
    "text": "popdata2023 &lt;- popdata2023 %&gt;%\n  mutate(YOUNG = rowSums(.[, 3:6]) + rowSums(.[, 14])) %&gt;%  # Aged 0-24, 10-24 + Aged 5-9\n  mutate(`ECONOMY ACTIVE` = rowSums(.[, 7:13]) + rowSums(.[, 15])) %&gt;%  # Aged 25-59 + Aged 60-64\n  mutate(AGED = rowSums(.[, 16:21])) %&gt;%  # Aged 65 and above\n  mutate(TOTAL = rowSums(.[, 3:21])) %&gt;%  # Total population\n  mutate(DEPENDENCY = (YOUNG + AGED) / `ECONOMY ACTIVE`) %&gt;%  # Dependency ratio\n  select(PA, SZ, YOUNG, `ECONOMY ACTIVE`, AGED, TOTAL, DEPENDENCY)\n\n+rowSums should not be 12 (as attempted in Hands-On Exercise) but its 14.\nWe use glimpse() function take a look at the updated popdata2023 data-frame.\n\nglimpse(popdata2023)\n\nRows: 332\nColumns: 7\n$ PA               &lt;chr&gt; \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo Kio…\n$ SZ               &lt;chr&gt; \"Ang Mo Kio Town Centre\", \"Cheng San\", \"Chong Boon\", …\n$ YOUNG            &lt;dbl&gt; 1240, 5150, 4620, 4320, 1840, 3810, 1870, 3750, 0, 10…\n$ `ECONOMY ACTIVE` &lt;dbl&gt; 2830, 15600, 14120, 12400, 3670, 9600, 4320, 11090, 0…\n$ AGED             &lt;dbl&gt; 890, 6580, 7060, 5640, 1420, 4320, 1790, 5390, 0, 880…\n$ TOTAL            &lt;dbl&gt; 4960, 27330, 25800, 22360, 6930, 17730, 7980, 20230, …\n$ DEPENDENCY       &lt;dbl&gt; 0.7526502, 0.7519231, 0.8271955, 0.8032258, 0.8882834…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "title": "Hands-on Exercise 3: Network Constrained Spatial Point Patterns Analysis",
    "section": "",
    "text": "Network constrained Spatial Point Patterns Analysis (NetSPAA) is a collection of spatial point patterns analysis methods specially developed for analysing spatial point events occurring on or alongside networks. The spatial point event can be locations of traffic accidents or childcare centres for example. The network, on the other hand can be a road network or river network.\nIn this hands-on exercise, it will help to gain hands-on experience on using appropriate functions of spNetwork package, mainly:\n\nto derive network kernel density estimation (NKDE), and\nto perform network G-function and K-function analysis\n\n\n\n\nIn this study, the spatial distribution of childcare centres in Punggol Planning Area will be analysed. For the purpose of this study, two geospatial data sets will be used. They are:\n\nPunggol_St, a line feature geospatial data which stores the road network within Punggol Planning Area.\nPunggol_CC, a point feature geospatial data which stores the location of childcare centres within Punggol Planning Area.\n\nBoth data sets are in ESRI shapefile format.\n\n\n\nIn this hands-on exercise, four R packages will be used, they are:\n\nspNetwork, which provides functions to perform Spatial Point Patterns Analysis such as kernel density estimation (KDE) and K-function on network. It also can be used to build spatial matrices (‘listw’ objects like in ‘spdep’ package) to conduct any kind of traditional spatial analysis with spatial weights based on reticular distances.\nsf package provides functions to manage, process, and manipulate Simple Features, in a formal geospatial data standard that specifies a storage and access model of spatial geometries such as points, lines, and polygons.\ntmap which provides functions for plotting cartographic quality static point patterns maps or interactive maps by using leaflet API.\ntidyverse for performing data science tasks such as importing, wrangling and visualising data.\n\nThe code chunk below is used to install and launch the four R packages.\n\npacman::p_load(spNetwork, sf, tmap, tidyverse)\n\n\n\n\nThe code chunk below uses st_read() of sf package to important Punggol_St and Punggol_CC geospatial data sets into RStudio as sf data frames.\n\nnetwork &lt;- st_read(dsn = \"data/geospatial\",\n                   layer = \"Punggol_St\")\n\nReading layer `Punggol_St' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2642 features and 2 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 34038.56 ymin: 40941.11 xmax: 38882.85 ymax: 44801.27\nProjected CRS: SVY21 / Singapore TM\n\nchildcare &lt;- st_read(dsn = \"data/geospatial\",\n                     layer = \"Punggol_CC\")\n\nReading layer `Punggol_CC' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 61 features and 1 field\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 34423.98 ymin: 41503.6 xmax: 37619.47 ymax: 44685.77\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\n\n\nThe structure of the output simple features data tables can be examined in RStudio. Alternatively, the code chunk below can be used to print the contents of network and childcare simple feature objects.\n\nNetworkChildcare\n\n\n\nnetwork\n\nSimple feature collection with 2642 features and 2 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 34038.56 ymin: 40941.11 xmax: 38882.85 ymax: 44801.27\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n     LINK_ID                   ST_NAME                       geometry\n1  116130894                PUNGGOL RD LINESTRING (36546.89 44574....\n2  116130897 PONGGOL TWENTY-FOURTH AVE LINESTRING (36546.89 44574....\n3  116130901   PONGGOL SEVENTEENTH AVE LINESTRING (36012.73 44154....\n4  116130902   PONGGOL SEVENTEENTH AVE LINESTRING (36062.81 44197....\n5  116130907           PUNGGOL CENTRAL LINESTRING (36131.85 42755....\n6  116130908                PUNGGOL RD LINESTRING (36112.93 42752....\n7  116130909           PUNGGOL CENTRAL LINESTRING (36127.4 42744.5...\n8  116130910               PUNGGOL FLD LINESTRING (35994.98 42428....\n9  116130911               PUNGGOL FLD LINESTRING (35984.97 42407....\n10 116130912            EDGEFIELD PLNS LINESTRING (36200.87 42219....\n\n\n\nst_crs(network)\n\nCoordinate Reference System:\n  User input: SVY21 / Singapore TM \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\n\nchildcare\n\nSimple feature collection with 61 features and 1 field\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 34423.98 ymin: 41503.6 xmax: 37619.47 ymax: 44685.77\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n      Name                      geometry\n1   kml_10 POINT Z (36173.81 42550.33 0)\n2   kml_99 POINT Z (36479.56 42405.21 0)\n3  kml_100 POINT Z (36618.72 41989.13 0)\n4  kml_101 POINT Z (36285.37 42261.42 0)\n5  kml_122  POINT Z (35414.54 42625.1 0)\n6  kml_161 POINT Z (36545.16 42580.09 0)\n7  kml_172 POINT Z (35289.44 44083.57 0)\n8  kml_188 POINT Z (36520.56 42844.74 0)\n9  kml_205  POINT Z (36924.01 41503.6 0)\n10 kml_222 POINT Z (37141.76 42326.36 0)\n\n\n\nst_crs(childcare)\n\nCoordinate Reference System:\n  User input: SVY21 / Singapore TM \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\n\nUpon exploration of the simple feature data table, spNetwork is expecting the geospatial data to contain complete CRS information.\n\n\n\n\n\n\nNote\n\n\n\nWhen using the spNetwork package in R, ensuring that the geospatial data contains complete Coordinate Reference System (CRS) information is crucial for accurate spatial analysis.\n\nFor instance,verifying the CRS with functions like st_crs() for sf objects and doing transformation if necessary with functions like like st_transform()to reproject it into a suitable system\n\n\n\n\nHence, in the steps above st_crs() is used to ensure the correct EPSG code is in place while looking atthe data as well.\n\n\n\n\nBefore performing analysis, it is a good practice to visualise the geospatial data. There are at least two ways to visualise the geospatial data. One way is by using plot() of Base R as shown in the code chunk below.\n\nplot(st_geometry(network))\nplot(childcare, add = T, col = 'red', pch = 19)\n\n\n\n\n\n\n\n\nThe second way to visualise the geospatial data does so with high cartographic quality and in an interactive manner. The mapping function of tmap package can be used as shown in the code chunk below.\n\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\ntm_shape(childcare) +\n  tm_dots() +\n  tm_shape(network) +\n  tm_lines()\n\n\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\n\nUsage of tmap allows us to plot highly customisable and interactive maps.\n\n\n\nIn this section, NKDE analysis will be performed by using appropriate functions provided in spNetwork package.\n\n\nBefore computing NKDE, the Spatial Lines object needs to be cut into lixels with a specified minimal distance. This task can be performed by using lixelize_lines() of spNetwork as shown in the code chunk below.\n\nlixels &lt;- lixelize_lines(network,\n                         700,\n                         mindist = 375)\n\n\n\n\n\n\nThe length of a lixel, lx_length is set to 700m, and\nThe minimum length of a lixel, mindist is set to 375m.\n\nAfter cut, if the length of the final lixel is shorter than the minimum distance, then it is added to the previous lixel. If NULL, then mindist = maxdist/10. Also note that the segments that are already shorter than the minimum distance are not modified.\n\nNote: There is another function called lixelize_lines.mc() which provides multicore support.\n\n\n\n\nNext, lines_center() of spNetwork will be used to generate a SpatialPointsDataFrame (i.e. samples) with line centre points as shown in the code chunk below.\n\nsamples &lt;- lines_center(lixels)\n\nThe points are located at center of the line based on the length of the line.\n\n\n\nNow, to compute the NKDE by using the code chunk below.\n\ndensities &lt;- nkde(network,\n                  events = childcare,\n                  w = rep(1, nrow(childcare)),\n                  samples = samples,\n                  kernel_name = \"quartic\",\n                  bw = 300,\n                  div = \"bw\",\n                  method = \"simple\",\n                  digits = 1,\n                  tol = 1,\n                  grid_shape = c(1,1),\n                  max_depth = 8,\n                  agg = NULL,\n                  sparse = TRUE,\n                  verbose = FALSE)\n\n\n\n\n\n\n\nThing to learn from the code chunk above\n\n\n\n\nkernel_name argument indicates that quartic kernel is used. The available kernel methods supported by spNetwork are: triangle, gaussian, scaled gaussian, tricube, cosine ,triweight, epanechnikov or uniform.\nThe method argument indicates that simple method is used to calculate the NKDE. Currently, spNetwork support three popular methods, they are:\n\nsimple (method =\"simple\"): This first method was presented by Xie et al. (2008) and proposes an intuitive solution. The distances between events and sampling points are replaced by network distances, and the formula of the kernel is adapted to calculate the density over a linear unit instead of an areal unit.\ndiscontinous (method = \"discontinuous\"): This method was proposed by Okabe et al (2008), which equally “divides” the mass density of an event at intersections of lixels.\ncontinous (method = \"continuous\"). If the discontinuous method is unbiased, it leads to a discontinuous kernel function which is a bit counter-intuitive. Okabe et al (2008) proposed another version of the kernel, that divides the mass of the density at intersection but adjusts the density before the intersection to make the function continuous.\n\n\n\n\n\n\nBefore we can visualise the NKDE values, thr code chunk below will be used to insert the computed density values (i.e. densities) into samples and lixels objects as density field.\n\nsamples$density &lt;- densities\nlixels$density &lt;- densities\n\nSince the svy21 projection system is in metres, the computed density values are very small i.e. 0.0000005. The code chunk below is used to rescale the density values from number of events per metre to number of events per kilometre.\n\n# rescaling\n\nsamples$density &lt;- samples$density*1000\nlixels$density &lt;- lixels$density*1000\n\nThe code below uses appropriate functions of tmap package to prepare interactive and high cartographic quality map visualisation.\n\ntmap_mode(mode = c(\"view\"))\n\ntmap mode set to interactive viewing\n\ntm_shape(lixels) +\n  tm_lines(col = \"density\") +\n  tm_shape(childcare) +\n  tm_dots()\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\n\nThe interactive map above effectively reveals road segments (darker colour) with relatively higher density of childcare centres than road segments with relatively lower density of childcare centres (lighter colour)\n\n\n\n\nIn this section, a complete spatial randomness (CSR) test will be carried out by using kfunctions() of spNetwork package. The null hypothesis is defined as:\nHo: The observed spatial point events (i.e distribution of childcare centres) are uniformly distributed over a street network in Punggol Planning Area.\nThe CSR test is based on the assumption of the binomial point process which implies the hypothesis that the childcare centres are randomly and independently distributed over the street network.\nIf this hypothesis is rejected, we may infer that the distribution of childcare centres is spatially interacting and dependent on each other; as a result, they may form non-random patterns, meaning that childcare centres are not randomly distributed.\n\n\n\n\n\n\nNote\n\n\n\nK-function measures the number of events found up to a given distance of any particular event.\n\n\n\nkfun_childcare &lt;- kfunctions(network,\n                             childcare,\n                             start = 0,\n                             end = 1000,\n                             step = 50,\n                             width = 50,\n                             nsim = 99,\n                             resolution = 50,\n                             verbose = FALSE,\n                             conf_int = 0.05)\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nlines: A SpatialLinesDataFrame with the sampling points. The geometries must be in a SpatialLinesDataFrame (it may crash if some geometries are invalid).\npoints: A SpatialPointsDataFrame representing the points on the network. These points will be stamped on the network.\nstart: A double, the start value for evaluating the k and g functions.\nend: A double, the last value for evaluating the k and g functions.\nstep: A double, the jump between two evaluations of the k and g function.\nwidth: The width of each donut for the g-function.\nnsim: An integer indicating the number of Monte Carlo simulations required. In the above example, 50 simulation was performed. Note: most of the time, more simulations are required for inference\nresolution: When simulating random points on the network, selecting a resolution will greatly reduce the calculation time. When resolution is null the random points can occur everywhere on the graph. If a value is specified, the edges are split according to this value and the random points are selected vertices on the new network.\nconf_int: A double indicating the width confidence interval (default = 0.05).\n\n\n\nThe output of kfunctions() is a list with the following values:\n\nplotkA, a ggplot2 object representing the values of the k-function\nplotgA, a ggplot2 object representing the values of the g-function\nvaluesA, a DataFrame with the values used to build the plots\n\nVisualising the ggplot2 object of k-function by using the code chunk below.\n\nK-FunctionG-Function\n\n\n\nkfun_childcare$plotk\n\n\n\n\n\n\n\n\nThe blue line is the empirical network K-function of the childcare centres in the Punggol planning area.\nThe grey envelope in the plot represents the confidence bounds (typically from random simulations) for the K-function under a null hypothesis, such as complete spatial randomness (CSR).The grey envelop represents the results of the 50 simulations in the interval 2.5% - 97.5%, meaning 95% of the simulated K-functions fall within this envelope.\nBased on observations of the blue line, between the distance of 250m-400m are below the grey area, which suggests a deviation from the expected pattern under the null hypothesis.\nWe can infer that the childcare centres in Punggol planning area resembles regular patterns at the distance of 250m-400m.\n\n\n\nkfun_childcare$plotg\n\n\n\n\n\n\n\n\nThe observations suggest that the G-function generally supports the hypothesis of randomness, with some signs of regularity at certain distances (150m & 500m mark) where the blue line dips slightly below the lower bound of the grey envelope, indicating that at these specific distances, the childcare centres might exhibit a more regular (dispersed) pattern than expected. No significant clustering is observed.\n\n\n\n\n\n\n\nKam, T.S. (2024). Network Constrained Spatial Point Patterns Analysis\nspNetwork: Spatial Analysis on Network\nNetwork Kernel Density Estimate\nDetails about NKDE\nNetwork k Functions"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#overview",
    "title": "Hands-on Exercise 3: Network Constrained Spatial Point Patterns Analysis",
    "section": "",
    "text": "Network constrained Spatial Point Patterns Analysis (NetSPAA) is a collection of spatial point patterns analysis methods specially developed for analysing spatial point events occurring on or alongside networks. The spatial point event can be locations of traffic accidents or childcare centres for example. The network, on the other hand can be a road network or river network.\nIn this hands-on exercise, it will help to gain hands-on experience on using appropriate functions of spNetwork package, mainly:\n\nto derive network kernel density estimation (NKDE), and\nto perform network G-function and K-function analysis"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#the-data",
    "title": "Hands-on Exercise 3: Network Constrained Spatial Point Patterns Analysis",
    "section": "",
    "text": "In this study, the spatial distribution of childcare centres in Punggol Planning Area will be analysed. For the purpose of this study, two geospatial data sets will be used. They are:\n\nPunggol_St, a line feature geospatial data which stores the road network within Punggol Planning Area.\nPunggol_CC, a point feature geospatial data which stores the location of childcare centres within Punggol Planning Area.\n\nBoth data sets are in ESRI shapefile format."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#installing-and-launching-the-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#installing-and-launching-the-r-packages",
    "title": "Hands-on Exercise 3: Network Constrained Spatial Point Patterns Analysis",
    "section": "",
    "text": "In this hands-on exercise, four R packages will be used, they are:\n\nspNetwork, which provides functions to perform Spatial Point Patterns Analysis such as kernel density estimation (KDE) and K-function on network. It also can be used to build spatial matrices (‘listw’ objects like in ‘spdep’ package) to conduct any kind of traditional spatial analysis with spatial weights based on reticular distances.\nsf package provides functions to manage, process, and manipulate Simple Features, in a formal geospatial data standard that specifies a storage and access model of spatial geometries such as points, lines, and polygons.\ntmap which provides functions for plotting cartographic quality static point patterns maps or interactive maps by using leaflet API.\ntidyverse for performing data science tasks such as importing, wrangling and visualising data.\n\nThe code chunk below is used to install and launch the four R packages.\n\npacman::p_load(spNetwork, sf, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#data-import-and-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#data-import-and-preparation",
    "title": "Hands-on Exercise 3: Network Constrained Spatial Point Patterns Analysis",
    "section": "",
    "text": "The code chunk below uses st_read() of sf package to important Punggol_St and Punggol_CC geospatial data sets into RStudio as sf data frames.\n\nnetwork &lt;- st_read(dsn = \"data/geospatial\",\n                   layer = \"Punggol_St\")\n\nReading layer `Punggol_St' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2642 features and 2 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 34038.56 ymin: 40941.11 xmax: 38882.85 ymax: 44801.27\nProjected CRS: SVY21 / Singapore TM\n\nchildcare &lt;- st_read(dsn = \"data/geospatial\",\n                     layer = \"Punggol_CC\")\n\nReading layer `Punggol_CC' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 61 features and 1 field\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 34423.98 ymin: 41503.6 xmax: 37619.47 ymax: 44685.77\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\n\n\nThe structure of the output simple features data tables can be examined in RStudio. Alternatively, the code chunk below can be used to print the contents of network and childcare simple feature objects.\n\nNetworkChildcare\n\n\n\nnetwork\n\nSimple feature collection with 2642 features and 2 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 34038.56 ymin: 40941.11 xmax: 38882.85 ymax: 44801.27\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n     LINK_ID                   ST_NAME                       geometry\n1  116130894                PUNGGOL RD LINESTRING (36546.89 44574....\n2  116130897 PONGGOL TWENTY-FOURTH AVE LINESTRING (36546.89 44574....\n3  116130901   PONGGOL SEVENTEENTH AVE LINESTRING (36012.73 44154....\n4  116130902   PONGGOL SEVENTEENTH AVE LINESTRING (36062.81 44197....\n5  116130907           PUNGGOL CENTRAL LINESTRING (36131.85 42755....\n6  116130908                PUNGGOL RD LINESTRING (36112.93 42752....\n7  116130909           PUNGGOL CENTRAL LINESTRING (36127.4 42744.5...\n8  116130910               PUNGGOL FLD LINESTRING (35994.98 42428....\n9  116130911               PUNGGOL FLD LINESTRING (35984.97 42407....\n10 116130912            EDGEFIELD PLNS LINESTRING (36200.87 42219....\n\n\n\nst_crs(network)\n\nCoordinate Reference System:\n  User input: SVY21 / Singapore TM \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\n\nchildcare\n\nSimple feature collection with 61 features and 1 field\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 34423.98 ymin: 41503.6 xmax: 37619.47 ymax: 44685.77\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n      Name                      geometry\n1   kml_10 POINT Z (36173.81 42550.33 0)\n2   kml_99 POINT Z (36479.56 42405.21 0)\n3  kml_100 POINT Z (36618.72 41989.13 0)\n4  kml_101 POINT Z (36285.37 42261.42 0)\n5  kml_122  POINT Z (35414.54 42625.1 0)\n6  kml_161 POINT Z (36545.16 42580.09 0)\n7  kml_172 POINT Z (35289.44 44083.57 0)\n8  kml_188 POINT Z (36520.56 42844.74 0)\n9  kml_205  POINT Z (36924.01 41503.6 0)\n10 kml_222 POINT Z (37141.76 42326.36 0)\n\n\n\nst_crs(childcare)\n\nCoordinate Reference System:\n  User input: SVY21 / Singapore TM \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\n\nUpon exploration of the simple feature data table, spNetwork is expecting the geospatial data to contain complete CRS information.\n\n\n\n\n\n\nNote\n\n\n\nWhen using the spNetwork package in R, ensuring that the geospatial data contains complete Coordinate Reference System (CRS) information is crucial for accurate spatial analysis.\n\nFor instance,verifying the CRS with functions like st_crs() for sf objects and doing transformation if necessary with functions like like st_transform()to reproject it into a suitable system\n\n\n\n\nHence, in the steps above st_crs() is used to ensure the correct EPSG code is in place while looking atthe data as well."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#visualising-the-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#visualising-the-geospatial-data",
    "title": "Hands-on Exercise 3: Network Constrained Spatial Point Patterns Analysis",
    "section": "",
    "text": "Before performing analysis, it is a good practice to visualise the geospatial data. There are at least two ways to visualise the geospatial data. One way is by using plot() of Base R as shown in the code chunk below.\n\nplot(st_geometry(network))\nplot(childcare, add = T, col = 'red', pch = 19)\n\n\n\n\n\n\n\n\nThe second way to visualise the geospatial data does so with high cartographic quality and in an interactive manner. The mapping function of tmap package can be used as shown in the code chunk below.\n\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\ntm_shape(childcare) +\n  tm_dots() +\n  tm_shape(network) +\n  tm_lines()\n\n\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\n\nUsage of tmap allows us to plot highly customisable and interactive maps."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#network-kde-nkde-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#network-kde-nkde-analysis",
    "title": "Hands-on Exercise 3: Network Constrained Spatial Point Patterns Analysis",
    "section": "",
    "text": "In this section, NKDE analysis will be performed by using appropriate functions provided in spNetwork package.\n\n\nBefore computing NKDE, the Spatial Lines object needs to be cut into lixels with a specified minimal distance. This task can be performed by using lixelize_lines() of spNetwork as shown in the code chunk below.\n\nlixels &lt;- lixelize_lines(network,\n                         700,\n                         mindist = 375)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#things-to-learn-from-the-code-chunk-above",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#things-to-learn-from-the-code-chunk-above",
    "title": "Hands-on Exercise 3: Network Constrained Spatial Point Patterns Analysis",
    "section": "",
    "text": "The length of a lixel, lx_length is set to 700m, and\nThe minimum length of a lixel, mindist is set to 375m.\n\nAfter cut, if the length of the final lixel is shorter than the minimum distance, then it is added to the previous lixel. If NULL, then mindist = maxdist/10. Also note that the segments that are already shorter than the minimum distance are not modified.\n\nNote: There is another function called lixelize_lines.mc() which provides multicore support."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#network-constrained-g--and-k-function-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#network-constrained-g--and-k-function-analysis",
    "title": "Hands-on Exercise 3: Network Constrained Spatial Point Patterns Analysis",
    "section": "",
    "text": "In this section, a complete spatial randomness (CSR) test will be carried out by using kfunctions() of spNetwork package. The null hypothesis is defined as:\nHo: The observed spatial point events (i.e distribution of childcare centres) are uniformly distributed over a street network in Punggol Planning Area.\nThe CSR test is based on the assumption of the binomial point process which implies the hypothesis that the childcare centres are randomly and independently distributed over the street network.\nIf this hypothesis is rejected, we may infer that the distribution of childcare centres is spatially interacting and dependent on each other; as a result, they may form non-random patterns, meaning that childcare centres are not randomly distributed.\n\n\n\n\n\n\nNote\n\n\n\nK-function measures the number of events found up to a given distance of any particular event.\n\n\n\nkfun_childcare &lt;- kfunctions(network,\n                             childcare,\n                             start = 0,\n                             end = 1000,\n                             step = 50,\n                             width = 50,\n                             nsim = 99,\n                             resolution = 50,\n                             verbose = FALSE,\n                             conf_int = 0.05)\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nlines: A SpatialLinesDataFrame with the sampling points. The geometries must be in a SpatialLinesDataFrame (it may crash if some geometries are invalid).\npoints: A SpatialPointsDataFrame representing the points on the network. These points will be stamped on the network.\nstart: A double, the start value for evaluating the k and g functions.\nend: A double, the last value for evaluating the k and g functions.\nstep: A double, the jump between two evaluations of the k and g function.\nwidth: The width of each donut for the g-function.\nnsim: An integer indicating the number of Monte Carlo simulations required. In the above example, 50 simulation was performed. Note: most of the time, more simulations are required for inference\nresolution: When simulating random points on the network, selecting a resolution will greatly reduce the calculation time. When resolution is null the random points can occur everywhere on the graph. If a value is specified, the edges are split according to this value and the random points are selected vertices on the new network.\nconf_int: A double indicating the width confidence interval (default = 0.05).\n\n\n\nThe output of kfunctions() is a list with the following values:\n\nplotkA, a ggplot2 object representing the values of the k-function\nplotgA, a ggplot2 object representing the values of the g-function\nvaluesA, a DataFrame with the values used to build the plots\n\nVisualising the ggplot2 object of k-function by using the code chunk below.\n\nK-FunctionG-Function\n\n\n\nkfun_childcare$plotk\n\n\n\n\n\n\n\n\nThe blue line is the empirical network K-function of the childcare centres in the Punggol planning area.\nThe grey envelope in the plot represents the confidence bounds (typically from random simulations) for the K-function under a null hypothesis, such as complete spatial randomness (CSR).The grey envelop represents the results of the 50 simulations in the interval 2.5% - 97.5%, meaning 95% of the simulated K-functions fall within this envelope.\nBased on observations of the blue line, between the distance of 250m-400m are below the grey area, which suggests a deviation from the expected pattern under the null hypothesis.\nWe can infer that the childcare centres in Punggol planning area resembles regular patterns at the distance of 250m-400m.\n\n\n\nkfun_childcare$plotg\n\n\n\n\n\n\n\n\nThe observations suggest that the G-function generally supports the hypothesis of randomness, with some signs of regularity at certain distances (150m & 500m mark) where the blue line dips slightly below the lower bound of the grey envelope, indicating that at these specific distances, the childcare centres might exhibit a more regular (dispersed) pattern than expected. No significant clustering is observed."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#references",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#references",
    "title": "Hands-on Exercise 3: Network Constrained Spatial Point Patterns Analysis",
    "section": "",
    "text": "Kam, T.S. (2024). Network Constrained Spatial Point Patterns Analysis\nspNetwork: Spatial Analysis on Network\nNetwork Kernel Density Estimate\nDetails about NKDE\nNetwork k Functions"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html",
    "title": "Hands-on_Exercise 2a: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "Spatial Point Pattern Analysis is the evaluation of the pattern or distribution, of a set of points on a surface. The point can be locations of:\n\nevents such as crime, traffic accidents and disease onset, or\nbusiness services (coffee and fast food outlets) or facilities such as childcare and elder care centres.\n\nBy using appropriate functions of spatstat, this hands-on exercise aims to discover the spatial point processes of childcare centres in Singapore.\nThe specific questions that will be answered in this hands-on exercise are as follows:\n\nare the childcare centres in Singapore randomly distributed throughout the country?\n\nif the answer is no, then the next logical question is where are the locations with higher a concentration of childcare centres?\n\n\n\n\nTo investigate for the answers for questions above, three data sets will be used. They are:\n\nCHILDCARE, a point feature data providing both location and attribute information of childcare centres. It is downloaded from Data.gov.sg and is in geojson format.\nMP14_SUBZONE_WEB_PL, a polygon feature data providing information of URA 2014 Master Plan Planning Subzone boundary data. It is in ESRI shapefile format. This data set is also downloaded from Data.gov.sg.\nCostalOutline, a polygon feature data showing the national boundary of Singapore. It is provided by SLA and is in ESRI shapefile format.\n\n\n\n\nIn this hands-on exercise, five R packages will be used, they are:\n\nsf, a relatively new R package specially designed to import, manage and process vector-based geospatial data in R.\nspatstat, which has a wide range of useful functions for point pattern analysis. In this hands-on exercise, it will be used to perform 1st- and 2nd-order spatial point patterns analysis and derive kernel density estimation (KDE) layer.\nraster which reads, writes, manipulates, analyses and model of gridded spatial data (i.e. raster). In this hands-on exercise, it will be used to convert image output generate by spatstat into raster format.\nmaptools which provides a set of tools for manipulating geographic data (Note: Package ‘maptools’ was removed from the CRAN repository). In this hands-on exercise, we mainly use it to convert Spatial objects into ppp format of spatstat.\ntmap which provides functions for plotting cartographic quality static point patterns maps or interactive maps by using leaflet API.\n\nThe code chunk below is used to install and launch the five R packages.\n\npacman::p_load(sf, sp, raster, spatstat, tmap, tidyverse)\n\n\n\n\n\n\nIn this section, st_read() of sf package will be used to import these three geospatial data sets into R.\n\nchildcare_sf &lt;- st_read(\"data/child-care-services-geojson.geojson\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `child-care-services-geojson' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nsg_sf &lt;- st_read(dsn = \"data\", layer = \"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data' using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\n\nmpsz_sf &lt;- st_read(dsn = \"data\",\n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nBefore using these data for analysis, it is important to ensure that they are projected in the same projection system.\n\nDIY: Using the appropriate sf functions in previous Hands-on Exercise, the code chunk below retrieves the referencing system information of these geospatial data.\n\n\nst_crs(childcare_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\nst_crs(sg_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\nst_crs(mpsz_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nFrom the results above: Notice that except childcare_sf - EPSG:3414, both mpsz_sf and sg_sf - “EPSG”,9001 do not have the proper crs information.\n\nDIY: Using the method learnt in previous hands-on exercise, attempt to assign the correct crs to mpsz_sf and sg_sf simple feature data frames.\n\n\nDIY: If necessary, changing the referencing system to Singapore national projected coordinate system in context of the question.\n\n\n\nst_set_crs() of sf is used as shown in the code chunk below to assign the correct EPSG code to mpsz_sf and sg_sf data frame.\n\nsg_sf &lt;- st_set_crs(sg_sf, 3414)\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\n\nChecking the CSR again by using the code chunk below.\n\nst_crs(childcare_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\nmpsz_sf &lt;- st_set_crs(mpsz_sf, 3414)\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\n\n\nst_crs(mpsz_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\n\n\nAfter checking the referencing system of each geospatial data data frame, it is also useful for us to plot a map to show their spatial patterns.\n\ntm_shape(sg_sf) +\n  tm_polygons() +\ntm_shape(mpsz_sf) +\n  tm_polygons() +\ntm_shape(childcare_sf) +\n  tm_dots()\n\n\n\n\n\n\n\n\nNotice that all the geospatial layers are within the same map extend. This shows that their referencing system and coordinate values are referring to similar spatial context. This is very important in any geospatial analysis.\nAlternatively, a pin map cna be prepared by using the code chunk below:\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\ntm_shape(childcare_sf) +\n  tm_dots()\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\n\nNotice that in the interactive mode, tmap is using leaflet for R API. The advantage of this interactive pin map is that it allows user to navigate and zoom around the map freely. We can also query the information of each simple feature (i.e. the point) by clicking of them. Last but not least, we can also change the background of the internet map layer. Currently, three internet map layers are provided. They are: ESRI.WorldGrayCanvas, OpenStreetMap, and ESRI.WorldTopoMap. The default is ESRI.WorldGrayCanvas.\n\nReminder: Always remember to switch back to plot mode after the interactive map. This is because, each interactive mode will consume a connection. Displaying excessive numbers of interactive maps (i.e. not more than 10) in one RMarkdown document when publishing on Netlify should be avoided.\n\n\n\n\n\nAlthough simple feature data frame is gaining popularity again - sp’s Spatial classes, there are, however, many geospatial analysis packages requiring the input of geospatial data in sp’s Spatial classes. In this section, we will learn how to convert simple feature data frame to sp’s Spatial class.\n\n\nThe code chunk below uses as_Spatial() of sf package to convert the three geospatial data from simple feature data frame to sp’s Spatial class.\n\nchildcare &lt;- as_Spatial(childcare_sf)\nmpsz &lt;- as_Spatial(mpsz_sf)\nsg &lt;- as_Spatial(sg_sf)\n\nInformation on the three Spatial classes are shown in the code chunk below:\n\nchildcare\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 2\nnames       :    Name,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Description \nmin values  :   kml_1, &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;018989&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;1, MARINA BOULEVARD, #B1 - 01, ONE MARINA BOULEVARD, SINGAPORE 018989&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;THE LITTLE SKOOL-HOUSE INTERNATIONAL PTE. LTD.&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;08F73931F4A691F4&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt; \nmax values  : kml_999,                  &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;829646&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;200, PONGGOL SEVENTEENTH AVENUE, SINGAPORE 829646&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;Child Care Services&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;RAFFLES KIDZ @ PUNGGOL PTE LTD&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;379D017BF244B0FA&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt; \n\n\n\nmpsz\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 323 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 15\nnames       : OBJECTID, SUBZONE_NO, SUBZONE_N, SUBZONE_C, CA_IND, PLN_AREA_N, PLN_AREA_C,       REGION_N, REGION_C,          INC_CRC, FMEL_UPD_D,     X_ADDR,     Y_ADDR,    SHAPE_Leng,    SHAPE_Area \nmin values  :        1,          1, ADMIRALTY,    AMSZ01,      N, ANG MO KIO,         AM, CENTRAL REGION,       CR, 00F5E30B5C9B7AD8,      16409,  5092.8949,  19579.069, 871.554887798, 39437.9352703 \nmax values  :      323,         17,    YUNNAN,    YSSZ09,      Y,     YISHUN,         YS,    WEST REGION,       WR, FFCCF172717C2EAF,      16409, 50424.7923, 49552.7904, 68083.9364708,  69748298.792 \n\n\n\nsg\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 4\nnames       : GDO_GID, MSLINK, MAPID,              COSTAL_NAM \nmin values  :       1,      1,     0,             ISLAND LINK \nmax values  :      60,     67,     0, SINGAPORE - MAIN ISLAND \n\n\nNotice that the geospatial data have been converted into their respective sp’s Spatial classes.\n\n\n\nspatstat requires the analytical data in ppp object form. There is no direct way to convert a Spatial class into ppp object. First, the Spatial classes needs to be converted into Spatial object first.\nThe codes chunk below converts the Spatial classes into generic sp objects.\n\nchildcare_sp &lt;- as(childcare, \"SpatialPoints\")\nsg_sp &lt;- as(sg, \"SpatialPolygons\")\n\nNext, the sp objects properties are displayed as shown below.\n\nchildcare_sp\n\nclass       : SpatialPoints \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\n\nsg_sp\n\nclass       : SpatialPolygons \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\n\nChallenge: What are the differences between Spatial* classes and generic sp object?\n\n\nNote: Class Hierarchy:Spatial: Specific classes like SpatialPoints, SpatialLines, SpatialPolygons, etc., representing different types of spatial data. sp object: A more generic object from the sp package, can be used for broader purposes without specific geometric constraints\n\n\n\n\nNow, we will use as.ppp() function of spatstat to convert the spatial data into spatstat’s ppp object format.\n\nchildcare_ppp &lt;- as.ppp(childcare_sf)\n\nWarning in as.ppp.sf(childcare_sf): only first attribute column is used for\nmarks\n\nchildcare_ppp\n\nMarked planar point pattern: 1545 points\nmarks are of storage type  'character'\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n\n\nNow, to plot childcare_ppp and examine the difference.\n\nplot(childcare_ppp)\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 1545 symbols are shown in the symbol map\n\n\n\n\n\n\n\n\n\nWe take a quick look at the summary statistics of the newly created ppp object by using the code chunk below.\n\nsummary(childcare_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1545 character character \n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\n\nNotice the warning message about duplicates. In spatial point patterns analysis an issue of significance is the presence of duplicates. The statistical methodology used for spatial point patterns processes is based largely on the assumption that process are simple, that is, that the points cannot be coincident.\n\n\n\nWe can check the duplication in a ppp object by using the code chunk below.\n\nany(duplicated(childcare_ppp))\n\n[1] FALSE\n\n\nTo count the number of co-incidence points, we will use the multiplicity() function as shown in the code chunk below.\n\nmultiplicity(childcare_ppp)\n\n   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [75] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [112] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [149] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [186] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [223] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [260] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [297] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [334] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [371] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [408] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [445] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [482] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [519] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [556] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [593] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [630] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [667] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [704] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [741] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [778] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [815] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [852] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [889] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [926] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [963] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1000] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1037] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1074] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1111] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1148] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1185] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1222] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1259] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1296] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1333] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1370] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1407] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1444] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1481] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1518] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n\n\nTo know how many locations have more than one point event, we can use the code chunk below.\n\nsum(multiplicity(childcare_ppp) &gt; 1)\n\n[1] 0\n\n\nTo view the locations of any duplicate point events, we will plot childcare data by using the code chunk below.\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\ntm_shape(childcare) +\n  tm_dots(alpha = 0.4,\n          size = 0.05)\n\n\n\n\n\n\nChallenge: How to spot the duplicate points from the map shown above?\n\nManual Checking (Visual): If the dataset is small, zoom in on clusters to check for over-plotting. Duplicates will appear as darker points due to overlaid symbols.\nFor duplicates, there are three ways to overcome this problem. The easiest way is to delete the duplicates. But, that will also mean that some useful point events will be lost.\nThe second solution is to use jittering, which will add a small perturbation to the duplicate points so that they do not occupy the exact same space.\nThe third solution is to make each point “unique” and then attach the duplicates of the points to the patterns as marks, as attributes of the points. Then you would need analytical techniques that take into account these marks.\nThe code chunk below implements the jittering approach.\n\nchildcare_ppp_jit &lt;- rjitter(childcare_ppp,\n                             retry = TRUE,\n                             nsim = 1,\n                             drop = TRUE)\n\n\nany(duplicated(childcare_ppp_jit))\n\n[1] FALSE\n\n\nCode chunk result from above shows no duplciated points.\n\n\n\nWhen analysing spatial point patterns, it is a good practice to confine the analysis with a geographical area like Singapore boundary. In spatstat, an object called owin is specially designed to represent this polygonal region.\nThe code chunk below is used to covert sg SpatialPolygon object into owin object of spatstat.\n\nsg_owin &lt;- as.owin(sg_sf)\n\nThe ouput object can be displayed by using the plot() function\n\nplot(sg_owin)\n\n\n\n\n\n\n\n\nand using the summary() function of Base R.\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\n\n\n\nIn this last step of geospatial data wrangling, we will extract childcare events that are located within Singapore by using the code chunk below.\n\nchildcareSG_ppp &lt;- childcare_ppp[sg_owin]\n\nThe output object combined both the point and polygon feature in one ppp object class as shown below.\n\nsummary(childcareSG_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 2.129929e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1545 character character \n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\nPlotting the newly derived childcareSG_ppp\n\nplot(childcareSG_ppp)\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 1545 symbols are shown in the symbol map\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn this section, it will be on learning how to perform first-order Spatial Point Patterns Analysis (SPPA) by using spatstat package. The hands-on exercise will focus on:\n\nderiving kernel density estimation (KDE) layer for visualising and exploring the intensity of point processes,\nperforming Confirmatory Spatial Point Patterns Analysis by using Nearest Neighbour statistics.\n\n\n\nIn this section, it encompasses learnign how to compute the kernel density estimation (KDE) of childcare services in Singapore.\n\n\nThe code chunk below computes a kernel density by using the following configurations of density() of spatstat:\n\nbw.diggle() automatic bandwidth selection method. Other recommended methods are bw.CvL(), bw.scott() or bw.ppl().\n\nThe smoothing kernel used is gaussian, which is the default. Other smoothing methods are: “epanechnikov”, “quartic” or “disc”.\n\nThe intensity estimate is corrected for edge effect bias by using method described by Jones (1993) and Diggle (2010, equation 18.9). The default is FALSE.\n\n\nkde_childcareSG_bw &lt;- density(childcareSG_ppp,\n                              sigma = bw.diggle,\n                              edge = TRUE,\n                            kernel = \"gaussian\")\n\nThe plot() function of Base R is then used to display the kernel density derived.\n\nplot(kde_childcareSG_bw)\n\n\n\n\n\n\n\n\nThe density values of the output ranges from 0 to 0.000035 which is way too small to comprehend. This is because the default unit of measurement of svy21 is in metres. As a result, the density values computed is in “number of points per square meter”.\nBefore moving on to the next section, it is good to know that we can retrieve the bandwidth used to compute the kde layer by using the code chunk below.\n\nbw &lt;- bw.diggle(childcareSG_ppp)\nbw\n\n   sigma \n298.4095 \n\n\n\n\n\nIn the code chunk below, rescale.ppp() is used to covert the unit of measurement from metres to kilometres.\n\nchildcareSG_ppp.km &lt;- rescale.ppp(childcareSG_ppp, 1000, \"km\")\n\nNow, an attempt to re-run density() using the rescaled data set and plot the output kde map.\n\nkde_childcareSG.bw &lt;- density(childcareSG_ppp.km,\n                              sigma = bw.diggle,\n                              edge = TRUE,\n                            kernel = \"gaussian\")\n\n\nplot(kde_childcareSG.bw)\n\n\n\n\n\n\n\n\nNotice that output image looks identical to the earlier version, the only changes are in the data values from the legend.\n\n\n\n\nBesides bw.diggle(), there are three other spatstat functions which can be used to determine the bandwidth, they are: bw.CvL(), bw.scott(), and bw.ppl().\nThis section will attempt to explore the bandwidth return with these automatic bandwidth calculation methods by using the code chunk below.\n\nbw.CvL(childcareSG_ppp.km)\n\n   sigma \n4.543278 \n\n\n\nbw.scott(childcareSG_ppp.km)\n\n sigma.x  sigma.y \n2.224898 1.450966 \n\n\n\nbw.ppl(childcareSG_ppp.km)\n\n    sigma \n0.3897114 \n\n\n\nbw.diggle(childcareSG_ppp.km)\n\n    sigma \n0.2984095 \n\n\nBaddeley et. (2016) suggested the use of the bw.ppl() algorithm because in their experience it tends to produce the more appropriate values when the pattern consists predominantly of tight clusters. But they also insist that if the purpose of one’s study is to detect a single tight cluster in the midst of random noise then the bw.diggle() method seems to work best.\nThe code chunk beow will be used to compare the output of using bw.diggle and bw.ppl methods.\n\nkde_childcareSG.ppl &lt;- density(childcareSG_ppp.km,\n                               sigma = bw.ppl,\n                               edge = TRUE,\n                               kernel = \"gaussian\")\npar(mfrow = c(1,2))\nplot(kde_childcareSG.bw, main = \"bw.diggle\")\nplot(kde_childcareSG.ppl, main = \"bw.ppl\")\n\n\n\n\n\n\n\n\n\n\n\nAs stated earlier the smoothing kernel used is gaussian as a default.\nBy default, the kernel method used in density.ppp() is gaussian. But there are three other options, namely: Epanechnikov, Quartic and Dics.\nThe code chunk below will be used to compute three more kernel density estimations by using these three kernel functions.\n\npar(mfrow = c(2,2))\nplot(density(childcareSG_ppp.km,\n             sigma = bw.ppl,\n             edge = TRUE,\n             kernel = \"gaussian\"),\n     main = \"Gaussian\")\nplot(density(childcareSG_ppp.km,\n             sigma = bw.ppl,\n             edge = TRUE,\n             kernel = \"epanechnikov\"),\n     main = \"Epanechnikov\")\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel\n\nplot(density(childcareSG_ppp.km,\n             sigma = bw.ppl,\n             edge = TRUE,\n             kernel = \"quartic\"),\n     main = \"Quartic\")\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel\n\nplot(density(childcareSG_ppp.km,\n             sigma = bw.ppl,\n             edge = TRUE,\n             kernel = \"disc\"),\n     main = \"Disc\")\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNext, will be an attempt to compute a KDE layer by defining a bandwidth of 600 metres. Notice that in the code chunk below, the sigma value used is 0.6. This is because the unit of measurement of childcareSG_ppp.km object is in kilometres, hence the 600m translates to 0.6km.\n\nkde_childcareSG_600 &lt;- density(childcareSG_ppp.km,\n                               sigma = 0.6,\n                               edge = TRUE,\n                              kernel = \"gaussian\")\n\n\nplot(kde_childcareSG_600)\n\n\n\n\n\n\n\n\n\n\n\nFixed bandwidth method is very sensitive to highly skewed distributions of spatial point patterns over geographical units for example urban versus rural. One way to overcome this problem is by using adaptive bandwidth instead.\nIn this section, the objective is learning to derive adaptive kernel density estimation by using density.adaptive() of spatstat.\n\nkde_childcareSG_adaptive &lt;- adaptive.density(childcareSG_ppp.km,\n                                             method = \"kernel\")\n\n\nplot(kde_childcareSG_adaptive)\n\n\n\n\n\n\n\n\nWe can compare the fixed and adaptive kernel density estimation outputs by using the code chunk below.\n\npar(mfrow = c(1,2))\nplot(kde_childcareSG.bw, main = \"Fixed bandwidth\")\nplot(kde_childcareSG_adaptive, main = \"Adaptive bandwidth\")\n\n\n\n\n\n\n\n\n\n\n\nThe results are the same, conversion will be done so that it is suitable for mapping purposes\n\nkde_df &lt;- as.data.frame(kde_childcareSG.bw)\n\ncoordinates(kde_df) &lt;- ~x+y\ngridded(kde_df) &lt;- TRUE\n\nWarning in points2grid(points, tolerance, round): grid has empty column/rows in\ndimension 2\n\nkde_spdf &lt;- as(kde_df, \"SpatialPixelsDataFrame\")\n\nspplot(kde_spdf)\n\n\n\n\n\n\n\n\n\n\nThe gridded kernal density objects will be converted into RasterLayer object by using raster() of raster package.\n\nkde_childcareSG_bw_raster &lt;- raster(kde_childcareSG.bw)\n\nThe properties of kde_childcareSG_bw_raster RasterLayer are shown using the code chunk below:\n\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : layer \nvalues     : -8.476185e-15, 28.51831  (min, max)\n\n\nNotice that the crs property is a NA value.\n\n\n\nThe code chunk below will be used to include the CRS information on kde_childcareSG_bw_raster RasterLayer.\n\nprojection(kde_childcareSG_bw_raster) &lt;- CRS(\"+init=EPSG:3414\")\n\n\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +units=m +no_defs \nsource     : memory\nnames      : layer \nvalues     : -8.476185e-15, 28.51831  (min, max)\n\n\nNotice that the CRS property is completed.\n\n\n\n\nFinally, the code chunk below is used to display the raster in cartographic quality map using tmap package.\n\ntm_shape(kde_childcareSG_bw_raster) + \n  tm_raster(\"layer\", palette = \"viridis\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)\n\nlegend.postion is used for plot mode. Use view.legend.position in tm_view to set the legend position in view mode.\n\n\n\n\n\n\nNotice that the raster values are encoded explicitly onto the raster pixel using the values in “v”” field.\n\n\n\nIn this section, we will learn how to compare KDE of childcares at Punggol, Tampines, Chua Chu Kang and Jurong West planning areas.\n\n\nThe code chunk below will be used to extract the target planning areas.\n\npg &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"PUNGGOL\")\ntm &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"TAMPINES\")\nck &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"CHOA CHU KANG\")\njw &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"JURONG WEST\")\n\nPlotting target planning areas\n\npar(mfrow = c(2,2))\nplot(pg, main = \"Punggol\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\nplot(tm, main = \"Tampines\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\nplot(ck, main = \"Choa Chu Kang\")\n\nWarning: plotting the first 10 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\nplot(jw, main = \"Jurong West\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\n\n\nThese sf objects will be converted into owin objects that is required by spatstat.\n\npg_owin = as.owin(pg)\ntm_owin = as.owin(tm)\nck_owin = as.owin(ck)\njw_owin = as.owin(jw)\n\n\n\n\nBy using the code chunk below, we are able to extract childcare that are within the specific regions to do our analysis later on.\n\nchildcare_pg_ppp = childcare_ppp_jit[pg_owin]\nchildcare_tm_ppp = childcare_ppp_jit[tm_owin]\nchildcare_ck_ppp = childcare_ppp_jit[ck_owin]\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\n\nNext, rescale.ppp() function is used to transform the unit of measurement from metre to kilometre.\n\nchildcare_pg_ppp.km = rescale.ppp(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale.ppp(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale.ppp(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale.ppp(childcare_jw_ppp, 1000, \"km\")\n\nThe code chunk below is then used to plot these four study areas and the locations of the childcare centres.\n\npar(mfrow = c(2,2))\nplot(childcare_pg_ppp.km, main = \"Punggol\")\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 60 symbols are shown in the symbol map\n\nplot(childcare_tm_ppp.km, main = \"Tampines\")\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 89 symbols are shown in the symbol map\n\nplot(childcare_ck_ppp.km, main = \"Choa Chu Kang\")\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 61 symbols are shown in the symbol map\n\nplot(childcare_jw_ppp.km, main = \"Jurong West\")\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 87 symbols are shown in the symbol map\n\n\n\n\n\n\n\n\n\n\n\n\nThe code chunk below will be used to compute the KDE of these four planning areas. bw.diggle method is used to derive the bandwidth of each plot.\n\npar(mfrow = c(2,2))\nplot(density(childcare_pg_ppp.km,\n             sigma = bw.diggle,\n             edge = TRUE,\n             kernel = \"gaussian\"),\n     main = \"Punggol\")\nplot(density(childcare_tm_ppp.km,\n             sigma = bw.diggle,\n             edge = TRUE,\n             kernel = \"gaussian\"),\n     main = \"Tampines\")\nplot(density(childcare_ck_ppp.km,\n             sigma = bw.diggle,\n             edge = TRUE,\n             kernel = \"gaussian\"),\n     main = \"Choa Chu Kang\")\nplot(density(childcare_jw_ppp.km,\n             sigma = bw.diggle,\n             edge = TRUE,\n             kernel = \"gaussian\"),\n     main = \"Jurong West\")\n\n\n\n\n\n\n\n\n\n\n\nFor comparison purposes, 250m bandwidth will be used.\n\npar(mfrow = c(2,2))\nplot(density(childcare_ck_ppp.km,\n             sigma = 0.25,\n             edge = TRUE,\n             kernel = \"gaussian\"),\n     main = \"Choa Chu Kang\")\nplot(density(childcare_jw_ppp.km,\n             sigma = 0.25,\n             edge = TRUE,\n             kernel = \"gaussian\"),\n     main = \"Jurong West\")\nplot(density(childcare_pg_ppp.km,\n             sigma = 0.25,\n             edge = TRUE,\n             kernel = \"gaussian\"),\n     main = \"Punggol\")\nplot(density(childcare_tm_ppp.km,\n             sigma = 0.25,\n             edge = TRUE,\n             kernel = \"gaussian\"),\n     main = \"Tampines\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn this section, the Clark-Evans test of aggregation will be performed for a spatial point pattern by using clarkevans.test() of statspat.\nThe test hypotheses are:\nHo = The distribution of childcare services are randomly distributed.\nH1 = The distribution of childcare services are not randomly distributed.\nThe 95% confident interval will be used.\n\n\n\nclarkevans.test(childcareSG_ppp,\n                correction = \"none\",\n                clipregion = \"sg_owin\",\n                alternative = c(\"clustered\"),\n                nsim = 99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcareSG_ppp\nR = 0.55631, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\nConclusions that can be drawn from the test result:\n\nR = 0.55631: This value of R is significantly less than 1, indicating that the distribution of childcare services is clustered rather than random.\np-value &lt; 2.2e-16: The extremely small p-value indicates that the observed clustering is statistically significant. In other words, there is a very strong evidence against the null hypothesis (Ho) of random distribution.\n\n\n\n\n\n\n\nConclusion\n\n\n\nGiven the test result (R = 0.55631) and the very small p-value, we reject the null hypothesis (Ho) at the 95% confidence level. The conclusion is that the distribution of childcare services is not randomly distributed; instead, the services are significantly clustered in certain areas.\nThis suggests that childcare services are more likely to be found near other childcare services, potentially due to factors: like population density, demand for services, or urban planning considerations.\n\n\n\n\n\nIn the code chunk below, clarkevans.test() of spatstat is used to perform the Clark-Evans test of aggregation for childcare centre in Choa Chu Kang planning area.\n\nclarkevans.test(childcare_ck_ppp,\n                correction = \"none\",\n                clipregion = NULL,\n                alternative = c(\"two.sided\"),\n                nsim = 999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_ck_ppp\nR = 0.9587, p-value = 0.5372\nalternative hypothesis: two-sided\n\n\n\n\n\nIn the code chunk below, the similar test is used to analyse the spatial point patterns of childcare centre in Tampines planning area.\n\nclarkevans.test(childcare_tm_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_tm_ppp\nR = 0.7902, p-value = 0.0001529\nalternative hypothesis: two-sided"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#overview",
    "title": "Hands-on_Exercise 2a: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "Spatial Point Pattern Analysis is the evaluation of the pattern or distribution, of a set of points on a surface. The point can be locations of:\n\nevents such as crime, traffic accidents and disease onset, or\nbusiness services (coffee and fast food outlets) or facilities such as childcare and elder care centres.\n\nBy using appropriate functions of spatstat, this hands-on exercise aims to discover the spatial point processes of childcare centres in Singapore.\nThe specific questions that will be answered in this hands-on exercise are as follows:\n\nare the childcare centres in Singapore randomly distributed throughout the country?\n\nif the answer is no, then the next logical question is where are the locations with higher a concentration of childcare centres?"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#the-data",
    "title": "Hands-on_Exercise 2a: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "To investigate for the answers for questions above, three data sets will be used. They are:\n\nCHILDCARE, a point feature data providing both location and attribute information of childcare centres. It is downloaded from Data.gov.sg and is in geojson format.\nMP14_SUBZONE_WEB_PL, a polygon feature data providing information of URA 2014 Master Plan Planning Subzone boundary data. It is in ESRI shapefile format. This data set is also downloaded from Data.gov.sg.\nCostalOutline, a polygon feature data showing the national boundary of Singapore. It is provided by SLA and is in ESRI shapefile format."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#installing-and-loading-the-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#installing-and-loading-the-r-packages",
    "title": "Hands-on_Exercise 2a: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "In this hands-on exercise, five R packages will be used, they are:\n\nsf, a relatively new R package specially designed to import, manage and process vector-based geospatial data in R.\nspatstat, which has a wide range of useful functions for point pattern analysis. In this hands-on exercise, it will be used to perform 1st- and 2nd-order spatial point patterns analysis and derive kernel density estimation (KDE) layer.\nraster which reads, writes, manipulates, analyses and model of gridded spatial data (i.e. raster). In this hands-on exercise, it will be used to convert image output generate by spatstat into raster format.\nmaptools which provides a set of tools for manipulating geographic data (Note: Package ‘maptools’ was removed from the CRAN repository). In this hands-on exercise, we mainly use it to convert Spatial objects into ppp format of spatstat.\ntmap which provides functions for plotting cartographic quality static point patterns maps or interactive maps by using leaflet API.\n\nThe code chunk below is used to install and launch the five R packages.\n\npacman::p_load(sf, sp, raster, spatstat, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#spatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#spatial-data-wrangling",
    "title": "Hands-on_Exercise 2a: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "In this section, st_read() of sf package will be used to import these three geospatial data sets into R.\n\nchildcare_sf &lt;- st_read(\"data/child-care-services-geojson.geojson\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `child-care-services-geojson' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nsg_sf &lt;- st_read(dsn = \"data\", layer = \"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data' using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\n\nmpsz_sf &lt;- st_read(dsn = \"data\",\n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nBefore using these data for analysis, it is important to ensure that they are projected in the same projection system.\n\nDIY: Using the appropriate sf functions in previous Hands-on Exercise, the code chunk below retrieves the referencing system information of these geospatial data.\n\n\nst_crs(childcare_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\nst_crs(sg_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\nst_crs(mpsz_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nFrom the results above: Notice that except childcare_sf - EPSG:3414, both mpsz_sf and sg_sf - “EPSG”,9001 do not have the proper crs information.\n\nDIY: Using the method learnt in previous hands-on exercise, attempt to assign the correct crs to mpsz_sf and sg_sf simple feature data frames.\n\n\nDIY: If necessary, changing the referencing system to Singapore national projected coordinate system in context of the question.\n\n\n\nst_set_crs() of sf is used as shown in the code chunk below to assign the correct EPSG code to mpsz_sf and sg_sf data frame.\n\nsg_sf &lt;- st_set_crs(sg_sf, 3414)\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\n\nChecking the CSR again by using the code chunk below.\n\nst_crs(childcare_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\nmpsz_sf &lt;- st_set_crs(mpsz_sf, 3414)\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\n\n\nst_crs(mpsz_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\n\n\nAfter checking the referencing system of each geospatial data data frame, it is also useful for us to plot a map to show their spatial patterns.\n\ntm_shape(sg_sf) +\n  tm_polygons() +\ntm_shape(mpsz_sf) +\n  tm_polygons() +\ntm_shape(childcare_sf) +\n  tm_dots()\n\n\n\n\n\n\n\n\nNotice that all the geospatial layers are within the same map extend. This shows that their referencing system and coordinate values are referring to similar spatial context. This is very important in any geospatial analysis.\nAlternatively, a pin map cna be prepared by using the code chunk below:\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\ntm_shape(childcare_sf) +\n  tm_dots()\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\n\nNotice that in the interactive mode, tmap is using leaflet for R API. The advantage of this interactive pin map is that it allows user to navigate and zoom around the map freely. We can also query the information of each simple feature (i.e. the point) by clicking of them. Last but not least, we can also change the background of the internet map layer. Currently, three internet map layers are provided. They are: ESRI.WorldGrayCanvas, OpenStreetMap, and ESRI.WorldTopoMap. The default is ESRI.WorldGrayCanvas.\n\nReminder: Always remember to switch back to plot mode after the interactive map. This is because, each interactive mode will consume a connection. Displaying excessive numbers of interactive maps (i.e. not more than 10) in one RMarkdown document when publishing on Netlify should be avoided."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#geospatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#geospatial-data-wrangling",
    "title": "Hands-on_Exercise 2a: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "Although simple feature data frame is gaining popularity again - sp’s Spatial classes, there are, however, many geospatial analysis packages requiring the input of geospatial data in sp’s Spatial classes. In this section, we will learn how to convert simple feature data frame to sp’s Spatial class.\n\n\nThe code chunk below uses as_Spatial() of sf package to convert the three geospatial data from simple feature data frame to sp’s Spatial class.\n\nchildcare &lt;- as_Spatial(childcare_sf)\nmpsz &lt;- as_Spatial(mpsz_sf)\nsg &lt;- as_Spatial(sg_sf)\n\nInformation on the three Spatial classes are shown in the code chunk below:\n\nchildcare\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 2\nnames       :    Name,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Description \nmin values  :   kml_1, &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;018989&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;1, MARINA BOULEVARD, #B1 - 01, ONE MARINA BOULEVARD, SINGAPORE 018989&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;THE LITTLE SKOOL-HOUSE INTERNATIONAL PTE. LTD.&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;08F73931F4A691F4&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt; \nmax values  : kml_999,                  &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;829646&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;200, PONGGOL SEVENTEENTH AVENUE, SINGAPORE 829646&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;Child Care Services&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;RAFFLES KIDZ @ PUNGGOL PTE LTD&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;379D017BF244B0FA&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt; \n\n\n\nmpsz\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 323 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 15\nnames       : OBJECTID, SUBZONE_NO, SUBZONE_N, SUBZONE_C, CA_IND, PLN_AREA_N, PLN_AREA_C,       REGION_N, REGION_C,          INC_CRC, FMEL_UPD_D,     X_ADDR,     Y_ADDR,    SHAPE_Leng,    SHAPE_Area \nmin values  :        1,          1, ADMIRALTY,    AMSZ01,      N, ANG MO KIO,         AM, CENTRAL REGION,       CR, 00F5E30B5C9B7AD8,      16409,  5092.8949,  19579.069, 871.554887798, 39437.9352703 \nmax values  :      323,         17,    YUNNAN,    YSSZ09,      Y,     YISHUN,         YS,    WEST REGION,       WR, FFCCF172717C2EAF,      16409, 50424.7923, 49552.7904, 68083.9364708,  69748298.792 \n\n\n\nsg\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 4\nnames       : GDO_GID, MSLINK, MAPID,              COSTAL_NAM \nmin values  :       1,      1,     0,             ISLAND LINK \nmax values  :      60,     67,     0, SINGAPORE - MAIN ISLAND \n\n\nNotice that the geospatial data have been converted into their respective sp’s Spatial classes.\n\n\n\nspatstat requires the analytical data in ppp object form. There is no direct way to convert a Spatial class into ppp object. First, the Spatial classes needs to be converted into Spatial object first.\nThe codes chunk below converts the Spatial classes into generic sp objects.\n\nchildcare_sp &lt;- as(childcare, \"SpatialPoints\")\nsg_sp &lt;- as(sg, \"SpatialPolygons\")\n\nNext, the sp objects properties are displayed as shown below.\n\nchildcare_sp\n\nclass       : SpatialPoints \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\n\nsg_sp\n\nclass       : SpatialPolygons \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\n\nChallenge: What are the differences between Spatial* classes and generic sp object?\n\n\nNote: Class Hierarchy:Spatial: Specific classes like SpatialPoints, SpatialLines, SpatialPolygons, etc., representing different types of spatial data. sp object: A more generic object from the sp package, can be used for broader purposes without specific geometric constraints\n\n\n\n\nNow, we will use as.ppp() function of spatstat to convert the spatial data into spatstat’s ppp object format.\n\nchildcare_ppp &lt;- as.ppp(childcare_sf)\n\nWarning in as.ppp.sf(childcare_sf): only first attribute column is used for\nmarks\n\nchildcare_ppp\n\nMarked planar point pattern: 1545 points\nmarks are of storage type  'character'\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n\n\nNow, to plot childcare_ppp and examine the difference.\n\nplot(childcare_ppp)\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 1545 symbols are shown in the symbol map\n\n\n\n\n\n\n\n\n\nWe take a quick look at the summary statistics of the newly created ppp object by using the code chunk below.\n\nsummary(childcare_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1545 character character \n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\n\nNotice the warning message about duplicates. In spatial point patterns analysis an issue of significance is the presence of duplicates. The statistical methodology used for spatial point patterns processes is based largely on the assumption that process are simple, that is, that the points cannot be coincident.\n\n\n\nWe can check the duplication in a ppp object by using the code chunk below.\n\nany(duplicated(childcare_ppp))\n\n[1] FALSE\n\n\nTo count the number of co-incidence points, we will use the multiplicity() function as shown in the code chunk below.\n\nmultiplicity(childcare_ppp)\n\n   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [75] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [112] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [149] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [186] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [223] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [260] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [297] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [334] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [371] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [408] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [445] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [482] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [519] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [556] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [593] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [630] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [667] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [704] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [741] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [778] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [815] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [852] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [889] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [926] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [963] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1000] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1037] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1074] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1111] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1148] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1185] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1222] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1259] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1296] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1333] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1370] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1407] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1444] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1481] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1518] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n\n\nTo know how many locations have more than one point event, we can use the code chunk below.\n\nsum(multiplicity(childcare_ppp) &gt; 1)\n\n[1] 0\n\n\nTo view the locations of any duplicate point events, we will plot childcare data by using the code chunk below.\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\ntm_shape(childcare) +\n  tm_dots(alpha = 0.4,\n          size = 0.05)\n\n\n\n\n\n\nChallenge: How to spot the duplicate points from the map shown above?\n\nManual Checking (Visual): If the dataset is small, zoom in on clusters to check for over-plotting. Duplicates will appear as darker points due to overlaid symbols.\nFor duplicates, there are three ways to overcome this problem. The easiest way is to delete the duplicates. But, that will also mean that some useful point events will be lost.\nThe second solution is to use jittering, which will add a small perturbation to the duplicate points so that they do not occupy the exact same space.\nThe third solution is to make each point “unique” and then attach the duplicates of the points to the patterns as marks, as attributes of the points. Then you would need analytical techniques that take into account these marks.\nThe code chunk below implements the jittering approach.\n\nchildcare_ppp_jit &lt;- rjitter(childcare_ppp,\n                             retry = TRUE,\n                             nsim = 1,\n                             drop = TRUE)\n\n\nany(duplicated(childcare_ppp_jit))\n\n[1] FALSE\n\n\nCode chunk result from above shows no duplciated points.\n\n\n\nWhen analysing spatial point patterns, it is a good practice to confine the analysis with a geographical area like Singapore boundary. In spatstat, an object called owin is specially designed to represent this polygonal region.\nThe code chunk below is used to covert sg SpatialPolygon object into owin object of spatstat.\n\nsg_owin &lt;- as.owin(sg_sf)\n\nThe ouput object can be displayed by using the plot() function\n\nplot(sg_owin)\n\n\n\n\n\n\n\n\nand using the summary() function of Base R.\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\n\n\n\nIn this last step of geospatial data wrangling, we will extract childcare events that are located within Singapore by using the code chunk below.\n\nchildcareSG_ppp &lt;- childcare_ppp[sg_owin]\n\nThe output object combined both the point and polygon feature in one ppp object class as shown below.\n\nsummary(childcareSG_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 2.129929e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1545 character character \n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\nPlotting the newly derived childcareSG_ppp\n\nplot(childcareSG_ppp)\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 1545 symbols are shown in the symbol map"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#first-order-spatial-point-patterns-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#first-order-spatial-point-patterns-analysis",
    "title": "Hands-on_Exercise 2a: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "In this section, it will be on learning how to perform first-order Spatial Point Patterns Analysis (SPPA) by using spatstat package. The hands-on exercise will focus on:\n\nderiving kernel density estimation (KDE) layer for visualising and exploring the intensity of point processes,\nperforming Confirmatory Spatial Point Patterns Analysis by using Nearest Neighbour statistics.\n\n\n\nIn this section, it encompasses learnign how to compute the kernel density estimation (KDE) of childcare services in Singapore.\n\n\nThe code chunk below computes a kernel density by using the following configurations of density() of spatstat:\n\nbw.diggle() automatic bandwidth selection method. Other recommended methods are bw.CvL(), bw.scott() or bw.ppl().\n\nThe smoothing kernel used is gaussian, which is the default. Other smoothing methods are: “epanechnikov”, “quartic” or “disc”.\n\nThe intensity estimate is corrected for edge effect bias by using method described by Jones (1993) and Diggle (2010, equation 18.9). The default is FALSE.\n\n\nkde_childcareSG_bw &lt;- density(childcareSG_ppp,\n                              sigma = bw.diggle,\n                              edge = TRUE,\n                            kernel = \"gaussian\")\n\nThe plot() function of Base R is then used to display the kernel density derived.\n\nplot(kde_childcareSG_bw)\n\n\n\n\n\n\n\n\nThe density values of the output ranges from 0 to 0.000035 which is way too small to comprehend. This is because the default unit of measurement of svy21 is in metres. As a result, the density values computed is in “number of points per square meter”.\nBefore moving on to the next section, it is good to know that we can retrieve the bandwidth used to compute the kde layer by using the code chunk below.\n\nbw &lt;- bw.diggle(childcareSG_ppp)\nbw\n\n   sigma \n298.4095 \n\n\n\n\n\nIn the code chunk below, rescale.ppp() is used to covert the unit of measurement from metres to kilometres.\n\nchildcareSG_ppp.km &lt;- rescale.ppp(childcareSG_ppp, 1000, \"km\")\n\nNow, an attempt to re-run density() using the rescaled data set and plot the output kde map.\n\nkde_childcareSG.bw &lt;- density(childcareSG_ppp.km,\n                              sigma = bw.diggle,\n                              edge = TRUE,\n                            kernel = \"gaussian\")\n\n\nplot(kde_childcareSG.bw)\n\n\n\n\n\n\n\n\nNotice that output image looks identical to the earlier version, the only changes are in the data values from the legend.\n\n\n\n\nBesides bw.diggle(), there are three other spatstat functions which can be used to determine the bandwidth, they are: bw.CvL(), bw.scott(), and bw.ppl().\nThis section will attempt to explore the bandwidth return with these automatic bandwidth calculation methods by using the code chunk below.\n\nbw.CvL(childcareSG_ppp.km)\n\n   sigma \n4.543278 \n\n\n\nbw.scott(childcareSG_ppp.km)\n\n sigma.x  sigma.y \n2.224898 1.450966 \n\n\n\nbw.ppl(childcareSG_ppp.km)\n\n    sigma \n0.3897114 \n\n\n\nbw.diggle(childcareSG_ppp.km)\n\n    sigma \n0.2984095 \n\n\nBaddeley et. (2016) suggested the use of the bw.ppl() algorithm because in their experience it tends to produce the more appropriate values when the pattern consists predominantly of tight clusters. But they also insist that if the purpose of one’s study is to detect a single tight cluster in the midst of random noise then the bw.diggle() method seems to work best.\nThe code chunk beow will be used to compare the output of using bw.diggle and bw.ppl methods.\n\nkde_childcareSG.ppl &lt;- density(childcareSG_ppp.km,\n                               sigma = bw.ppl,\n                               edge = TRUE,\n                               kernel = \"gaussian\")\npar(mfrow = c(1,2))\nplot(kde_childcareSG.bw, main = \"bw.diggle\")\nplot(kde_childcareSG.ppl, main = \"bw.ppl\")\n\n\n\n\n\n\n\n\n\n\n\nAs stated earlier the smoothing kernel used is gaussian as a default.\nBy default, the kernel method used in density.ppp() is gaussian. But there are three other options, namely: Epanechnikov, Quartic and Dics.\nThe code chunk below will be used to compute three more kernel density estimations by using these three kernel functions.\n\npar(mfrow = c(2,2))\nplot(density(childcareSG_ppp.km,\n             sigma = bw.ppl,\n             edge = TRUE,\n             kernel = \"gaussian\"),\n     main = \"Gaussian\")\nplot(density(childcareSG_ppp.km,\n             sigma = bw.ppl,\n             edge = TRUE,\n             kernel = \"epanechnikov\"),\n     main = \"Epanechnikov\")\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel\n\nplot(density(childcareSG_ppp.km,\n             sigma = bw.ppl,\n             edge = TRUE,\n             kernel = \"quartic\"),\n     main = \"Quartic\")\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel\n\nplot(density(childcareSG_ppp.km,\n             sigma = bw.ppl,\n             edge = TRUE,\n             kernel = \"disc\"),\n     main = \"Disc\")\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#fixed-and-adaptive-kde",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#fixed-and-adaptive-kde",
    "title": "Hands-on_Exercise 2a: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "Next, will be an attempt to compute a KDE layer by defining a bandwidth of 600 metres. Notice that in the code chunk below, the sigma value used is 0.6. This is because the unit of measurement of childcareSG_ppp.km object is in kilometres, hence the 600m translates to 0.6km.\n\nkde_childcareSG_600 &lt;- density(childcareSG_ppp.km,\n                               sigma = 0.6,\n                               edge = TRUE,\n                              kernel = \"gaussian\")\n\n\nplot(kde_childcareSG_600)\n\n\n\n\n\n\n\n\n\n\n\nFixed bandwidth method is very sensitive to highly skewed distributions of spatial point patterns over geographical units for example urban versus rural. One way to overcome this problem is by using adaptive bandwidth instead.\nIn this section, the objective is learning to derive adaptive kernel density estimation by using density.adaptive() of spatstat.\n\nkde_childcareSG_adaptive &lt;- adaptive.density(childcareSG_ppp.km,\n                                             method = \"kernel\")\n\n\nplot(kde_childcareSG_adaptive)\n\n\n\n\n\n\n\n\nWe can compare the fixed and adaptive kernel density estimation outputs by using the code chunk below.\n\npar(mfrow = c(1,2))\nplot(kde_childcareSG.bw, main = \"Fixed bandwidth\")\nplot(kde_childcareSG_adaptive, main = \"Adaptive bandwidth\")\n\n\n\n\n\n\n\n\n\n\n\nThe results are the same, conversion will be done so that it is suitable for mapping purposes\n\nkde_df &lt;- as.data.frame(kde_childcareSG.bw)\n\ncoordinates(kde_df) &lt;- ~x+y\ngridded(kde_df) &lt;- TRUE\n\nWarning in points2grid(points, tolerance, round): grid has empty column/rows in\ndimension 2\n\nkde_spdf &lt;- as(kde_df, \"SpatialPixelsDataFrame\")\n\nspplot(kde_spdf)\n\n\n\n\n\n\n\n\n\n\nThe gridded kernal density objects will be converted into RasterLayer object by using raster() of raster package.\n\nkde_childcareSG_bw_raster &lt;- raster(kde_childcareSG.bw)\n\nThe properties of kde_childcareSG_bw_raster RasterLayer are shown using the code chunk below:\n\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : layer \nvalues     : -8.476185e-15, 28.51831  (min, max)\n\n\nNotice that the crs property is a NA value.\n\n\n\nThe code chunk below will be used to include the CRS information on kde_childcareSG_bw_raster RasterLayer.\n\nprojection(kde_childcareSG_bw_raster) &lt;- CRS(\"+init=EPSG:3414\")\n\n\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +units=m +no_defs \nsource     : memory\nnames      : layer \nvalues     : -8.476185e-15, 28.51831  (min, max)\n\n\nNotice that the CRS property is completed.\n\n\n\n\nFinally, the code chunk below is used to display the raster in cartographic quality map using tmap package.\n\ntm_shape(kde_childcareSG_bw_raster) + \n  tm_raster(\"layer\", palette = \"viridis\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)\n\nlegend.postion is used for plot mode. Use view.legend.position in tm_view to set the legend position in view mode.\n\n\n\n\n\n\nNotice that the raster values are encoded explicitly onto the raster pixel using the values in “v”” field.\n\n\n\nIn this section, we will learn how to compare KDE of childcares at Punggol, Tampines, Chua Chu Kang and Jurong West planning areas.\n\n\nThe code chunk below will be used to extract the target planning areas.\n\npg &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"PUNGGOL\")\ntm &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"TAMPINES\")\nck &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"CHOA CHU KANG\")\njw &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"JURONG WEST\")\n\nPlotting target planning areas\n\npar(mfrow = c(2,2))\nplot(pg, main = \"Punggol\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\nplot(tm, main = \"Tampines\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\nplot(ck, main = \"Choa Chu Kang\")\n\nWarning: plotting the first 10 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\nplot(jw, main = \"Jurong West\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\n\n\nThese sf objects will be converted into owin objects that is required by spatstat.\n\npg_owin = as.owin(pg)\ntm_owin = as.owin(tm)\nck_owin = as.owin(ck)\njw_owin = as.owin(jw)\n\n\n\n\nBy using the code chunk below, we are able to extract childcare that are within the specific regions to do our analysis later on.\n\nchildcare_pg_ppp = childcare_ppp_jit[pg_owin]\nchildcare_tm_ppp = childcare_ppp_jit[tm_owin]\nchildcare_ck_ppp = childcare_ppp_jit[ck_owin]\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\n\nNext, rescale.ppp() function is used to transform the unit of measurement from metre to kilometre.\n\nchildcare_pg_ppp.km = rescale.ppp(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale.ppp(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale.ppp(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale.ppp(childcare_jw_ppp, 1000, \"km\")\n\nThe code chunk below is then used to plot these four study areas and the locations of the childcare centres.\n\npar(mfrow = c(2,2))\nplot(childcare_pg_ppp.km, main = \"Punggol\")\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 60 symbols are shown in the symbol map\n\nplot(childcare_tm_ppp.km, main = \"Tampines\")\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 89 symbols are shown in the symbol map\n\nplot(childcare_ck_ppp.km, main = \"Choa Chu Kang\")\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 61 symbols are shown in the symbol map\n\nplot(childcare_jw_ppp.km, main = \"Jurong West\")\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 87 symbols are shown in the symbol map\n\n\n\n\n\n\n\n\n\n\n\n\nThe code chunk below will be used to compute the KDE of these four planning areas. bw.diggle method is used to derive the bandwidth of each plot.\n\npar(mfrow = c(2,2))\nplot(density(childcare_pg_ppp.km,\n             sigma = bw.diggle,\n             edge = TRUE,\n             kernel = \"gaussian\"),\n     main = \"Punggol\")\nplot(density(childcare_tm_ppp.km,\n             sigma = bw.diggle,\n             edge = TRUE,\n             kernel = \"gaussian\"),\n     main = \"Tampines\")\nplot(density(childcare_ck_ppp.km,\n             sigma = bw.diggle,\n             edge = TRUE,\n             kernel = \"gaussian\"),\n     main = \"Choa Chu Kang\")\nplot(density(childcare_jw_ppp.km,\n             sigma = bw.diggle,\n             edge = TRUE,\n             kernel = \"gaussian\"),\n     main = \"Jurong West\")\n\n\n\n\n\n\n\n\n\n\n\nFor comparison purposes, 250m bandwidth will be used.\n\npar(mfrow = c(2,2))\nplot(density(childcare_ck_ppp.km,\n             sigma = 0.25,\n             edge = TRUE,\n             kernel = \"gaussian\"),\n     main = \"Choa Chu Kang\")\nplot(density(childcare_jw_ppp.km,\n             sigma = 0.25,\n             edge = TRUE,\n             kernel = \"gaussian\"),\n     main = \"Jurong West\")\nplot(density(childcare_pg_ppp.km,\n             sigma = 0.25,\n             edge = TRUE,\n             kernel = \"gaussian\"),\n     main = \"Punggol\")\nplot(density(childcare_tm_ppp.km,\n             sigma = 0.25,\n             edge = TRUE,\n             kernel = \"gaussian\"),\n     main = \"Tampines\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#nearest-neighbour-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#nearest-neighbour-analysis",
    "title": "Hands-on_Exercise 2a: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "In this section, the Clark-Evans test of aggregation will be performed for a spatial point pattern by using clarkevans.test() of statspat.\nThe test hypotheses are:\nHo = The distribution of childcare services are randomly distributed.\nH1 = The distribution of childcare services are not randomly distributed.\nThe 95% confident interval will be used.\n\n\n\nclarkevans.test(childcareSG_ppp,\n                correction = \"none\",\n                clipregion = \"sg_owin\",\n                alternative = c(\"clustered\"),\n                nsim = 99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcareSG_ppp\nR = 0.55631, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\nConclusions that can be drawn from the test result:\n\nR = 0.55631: This value of R is significantly less than 1, indicating that the distribution of childcare services is clustered rather than random.\np-value &lt; 2.2e-16: The extremely small p-value indicates that the observed clustering is statistically significant. In other words, there is a very strong evidence against the null hypothesis (Ho) of random distribution.\n\n\n\n\n\n\n\nConclusion\n\n\n\nGiven the test result (R = 0.55631) and the very small p-value, we reject the null hypothesis (Ho) at the 95% confidence level. The conclusion is that the distribution of childcare services is not randomly distributed; instead, the services are significantly clustered in certain areas.\nThis suggests that childcare services are more likely to be found near other childcare services, potentially due to factors: like population density, demand for services, or urban planning considerations.\n\n\n\n\n\nIn the code chunk below, clarkevans.test() of spatstat is used to perform the Clark-Evans test of aggregation for childcare centre in Choa Chu Kang planning area.\n\nclarkevans.test(childcare_ck_ppp,\n                correction = \"none\",\n                clipregion = NULL,\n                alternative = c(\"two.sided\"),\n                nsim = 999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_ck_ppp\nR = 0.9587, p-value = 0.5372\nalternative hypothesis: two-sided\n\n\n\n\n\nIn the code chunk below, the similar test is used to analyse the spatial point patterns of childcare centre in Tampines planning area.\n\nclarkevans.test(childcare_tm_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_tm_ppp\nR = 0.7902, p-value = 0.0001529\nalternative hypothesis: two-sided"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html",
    "title": "Hands-on Exercise 1a: Geospatial Data Wrangling with R",
    "section": "",
    "text": "Geospatial Data Science is the process of importing, wrangling, integrating, and processing geographically referenced data sets. In this hands-on exercise, the goal is to learn how to perform geospatial data science tasks in R by using sf package.\nBy the end of this hands-on exercise the following competencies should be acquired:\n\ninstalling and loading sf and tidyverse packages into R environment,\nimporting geospatial data by using appropriate functions of sf package,\nimporting aspatial data by using appropriate function of readr package,\nexploring the contents of simple feature data frame by using appropriate Base R and sf functions,\nassigning or transforming coordinate systems by using using appropriate sf functions,\nconverting an aspatial data into a sf data frame by using appropriate function of sf package,\nperforming geoprocessing tasks by using appropriate functions of sf package,\nperforming data wrangling tasks by using appropriate functions of dplyr package and\nperforming Exploratory Data Analysis (EDA) by using appropriate functions from ggplot2 package.\n\n\nNote: It is encouraged to read the reference guide of each function, especially the input data requirements, syntext and argument option before using them.\n\n\n\n\nData is key to data analytics which also includes geospatial analytics. Hence, before analysis it is required to assemble the necessary data. For this hands-on exercise the data will be extracted from the following sources:\n\nMaster Plan 2014 Subzone Boundary (Web) from data.gov.sg\nPre-Schools Location from data.gov.sg\nCycling Path from LTADataMall\nLatest version of Singapore Airbnb listing data from Inside Airbnb\n\n\nNote: This section does not merely constitute to extracting the necessary data sets. It also aims to introduce the usage of publicly available data sets.\n\n\n\nThe following steps have been carried out for extraction of the data sets:\nIn the Hands-on_Ex01 folder, a sub-folder called data is created. Then, inside the data sub-folder, two other sub-folders are created and are named geospatial and aspatial respectively.\nThe downloaded zipped files Master Plan 2014 Subzone Boundary (Web), Pre-Schools Location and Cycling Path are placed into geospatial sub-folder and unzipped. The unzipped files are then copied from their respective sub-folders and placed inside the geospatial sub-folder.\n\n\n\nThe downloaded listing data file is extracted. And placed in the Downloads folder by cutting and pasting the listing.csv file into the aspatial sub-folder.\n\n\n\n\nTHe following 2 R packages will be used for this hands-on exercise:\n\nsf for importing, managing, and processing geospatial data, and\ntidyverse for performing data science tasks such as importing, wrangling and visualising data.\n\nTidyverse consists of a family of R packages. In this hands-on exercise, the following packages will be used:\n\nreadr for importing csv data,\nreadxl for importing Excel worksheet,\ntidyr for manipulating data,\ndplyr for transforming data, and\nggplot2 for visualising data\n\n\n\n\n\n\n\nNote\n\n\n\nThe code chunk below uses p_load() of pacman package to check if sf and tidyverse packages are installed in the computer. If they are, then they will be launched into R.\n\n\n\npacman::p_load(sf, tidyverse)\n\n\n\n\nIn this section, the geospatial data is imported into R by using st_read() of sf package:\n\nMP14_SUBZONE_WEB_PL, a polygon feature layer in ESRI shapefile format,\nCyclingPath, a line feature layer in ESRI shapefile format, and\nPreSchool, a point feature layer in kml file format.\n\n\n\nThe code chunk below uses st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile into R as a polygon feature data frame. Note that when the input geospatial data is in shapefile format, two arguments will be used, namely: dsn to define the data path and layer to provide the shapefile name.\nAlso note that no extension such as .shp, .dbf, .prj and .shx are needed.\n\nmpsz = st_read(dsn = \"data/geospatial\",\n                  layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nThe message above reveals that the geospatial objects are multipolygon features. There are a total of 323 multipolygon features and 15 fields in mpsz simple feature data frame. mpsz is in svy21 projected coordinates systems. The bounding box provides the x extend and y extend of the data.\n\n\n\nAgain, the code chunk below uses st_read() function of sf package to import CyclingPath shapefile into R but as a line feature data frame.\n\ncyclingpath = st_read(dsn = \"data/geospatial\",\n                         layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 3138 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42644.17 ymax: 48948.15\nProjected CRS: SVY21\n\n\nThe message above reveals that the geospatial objects are linestring features. There are a total of 3138 features and 2 fields in cyclingpath linestring feature data frame and it is in svy21 projected coordinates system as well.\n\n\n\nThe PreSchoolsLocation is in kml format. The code chunk below will be used to import the kml file into R. Notice that in the code chunk below, the complete path and the kml file extension were provided.\n\npreschool = st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nThe message above reveals that preschool is a point feature data frame. There are a total of 2290 features and 2 fields. It is different from the previous two simple feature data frames, preschool is in wgs84 coordinates system.\n\n\n\n\nIn this sub-section, it illustrates different ways to retrieve information related to the content of a simple feature data frame.\n\n\nThe column in the sf data.frame that contains the geometries is a list, of class sfc. The geometry list-column can be retrieved in this case by mpsz$geom or mpsz[[1]], but more a generic way uses st_geometry() as shown in the code chunk below.\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\n\nNote: Note that the print only displays basic information of the feature class such as type of geometry, the geographic extent of the features and the coordinate system of the data.\n\n\n\n\nBesides the basic feature information, more can be learnt about the associated attribute information in the data frame. This where glimpse() of dplyr is handy as shown in the code chunk below.\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\nThe glimpse() report reveals the data type of each fields. For example FMEL-UPD_D field is in date data type and X_ADDR, Y_ADDR, SHAPE_Length and SHAPE_Area fields are all in double-precision values.\n\n\n\nAt times, to reveal the complete information of a feature object, head() of Base R can be used.\n\nhead(mpsz, n=5)\n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n\n\n\nNote: A useful argument of head() is that it allows the user to select the number of records to display (i.e. the n argument).\n\n\n\n\n\nIn geospatial data science, only ooking at the feature information is not enough. We are also interested in visualising the geospatial features. This is when plot() of R Graphic comes in very handy as shown in the code chunk below.\n\nplot(mpsz)\n\n\n\n\n\n\n\n\nThe default plot of an sf object is a multi-plot of all attributes, up to a reasonable maximum as shown above. However, the geometry can only be chosen for plotting by using the code chunk below.\n\nplot(st_geometry(mpsz))\n\n\n\n\n\n\n\n\nAlternatively, the plot of the sf object can also be chosen by using a specific attribute as shown in the code chunk below.\n\n“PLN_AREA_N”“PLN_AREA_C”“REGION_C”\n\n\n\nplot(mpsz[\"PLN_AREA_N\"])\n\n\n\n\n\n\n\n\n\n\n\nplot(mpsz[\"PLN_AREA_C\"])\n\n\n\n\n\n\n\n\n\n\n\nplot(mpsz[\"REGION_C\"])\n\n\n\n\n\n\n\n\n\n\n\n\nNote: plot() is meant for plotting the geospatial object for quick observation. For a high cartographic quality plot, other R package such as tmap should be used.\n\n\n\n\nMap projection is an important property of a geospatial data. In order to perform geoprocessing using two geospatial data, both geospatial data have to be projected using similar coordinate system.\nIn this section, it will illustrate how to project a simple feature data frame from one coordinate system to another coordinate system. The technical term of this process is called projection transformation.\n\n\nA common issue that can happen during importing process of geospatial data into R is that the coordinate system of the source data was either missing (such as due to missing .proj for ESRI shapefile) or wrongly assigned during the importing process.\nThis is an example the coordinate system of mpsz simple feature data frame by using st_crs() of sf package as shown in the code chunk below.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nAlthough the mpsz data frame is projected in svy21 but upon examination at the end of the print, it indicates that the EPSG is 9001. This is a wrong EPSG code because the correct EPSG code for svy21 should be 3414.\nIn order to assign the correct EPSG code to the mpsz data frame, st_set_crs() of sf package is used as shown in the code chunk below.\n\nmpsz3414 &lt;- st_set_crs(mpsz, 3414)\n\nNow, to inspect the CSR again by using the code chunk below.\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nNotice that the EPSG code is 3414 now.\n\n\n\nIn geospatial analytics, it is very common to transform the original data from geographic coordinate system to projected coordinate system. This is because geographic coordinate system is not appropriate if the analysis requires the use of distance or/and area measurements.\nExamining the preschool simple feature data frame as an example. The print below reveals that it is in wgs84 coordinate system.\n\nst_geometry(preschool)\n\nGeometry set for 2290 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\nFirst 5 geometries:\n\n\nHence, this is a scenario that illustrates st_set_crs() is not appropriate and st_transform() of sf package should be used.\nThis is due to the fact that a re-projection is needed for preschool from one coordinate system to another coordinate system mathematically.\nThe projection transformation is performed by using the code chunk below.\n\npreschool3414 &lt;- st_transform(preschool,\n                              crs = 3414)\n\n\nNote: In practice, we will need to find out the appropriate project coordinate system to use before performing the projection transformation.\n\nThe content of preschool3414 sf data frame is displayed again with the code chunk below:\n\nst_geometry(preschool3414)\n\nGeometry set for 2290 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 11810.03 ymin: 25596.33 xmax: 45404.24 ymax: 49300.88\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\nFirst 5 geometries:\n\n\n\n\n\n\n\n\nNote\n\n\n\nNotice that it is in svy21 projected coordinate system now. Furthermore, referencing to Bounding box:, the values are greater than 0-360 range of decimal degree commonly used by most of the geographic coordinate systems.\n\n\n\n\n\n\nIn practice, it is not unusual that we will come across data such as listing of Inside Airbnb. We call this kind of data aspatial data. Mainly because it is not a geospatial data but among the data fields, there are two fields that capture the x- and y-coordinates of the data points.\nIn this section, it will illustrate how to import an aspatial data into R environment and save it as a tibble data frame. Next, it will be converted it into a simple feature data frame.\nFor the purpose of this exercise, the listings.csv data downloaded from AirBnb will be used.\n\n\nSince listings data set is in csv file format, read_csv() of readr package will be used to import listing.csv as shown in the code chunk below. The output R object is called listings and it is a tibble data frame.\n\nlistings &lt;- read_csv(\"data/aspatial/listings.csv\")\n\nAfter importing the data file into R, it is important to examine if the data file has been imported correctly.\nThe code chunk below shows list() of Base R instead of glimpse() to do the job.\n\nlist(listings)\n\n[[1]]\n# A tibble: 3,540 × 18\n       id name      host_id host_name neighbourhood_group neighbourhood latitude\n    &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;               &lt;chr&gt;            &lt;dbl&gt;\n 1  71609 Ensuite …  367042 Belinda   East Region         Tampines          1.35\n 2  71896 B&B  Roo…  367042 Belinda   East Region         Tampines          1.35\n 3  71903 Room 2-n…  367042 Belinda   East Region         Tampines          1.35\n 4 275343 10min wa… 1439258 Kay       Central Region      Bukit Merah       1.29\n 5 275344 15 mins … 1439258 Kay       Central Region      Bukit Merah       1.29\n 6 289234 Booking …  367042 Belinda   East Region         Tampines          1.34\n 7 294281 5 mins w… 1521514 Elizabeth Central Region      Newton            1.31\n 8 324945 Comforta… 1439258 Kay       Central Region      Bukit Merah       1.29\n 9 330095 Relaxing… 1439258 Kay       Central Region      Bukit Merah       1.29\n10 344803 Budget s…  367042 Belinda   East Region         Tampines          1.35\n# ℹ 3,530 more rows\n# ℹ 11 more variables: longitude &lt;dbl&gt;, room_type &lt;chr&gt;, price &lt;dbl&gt;,\n#   minimum_nights &lt;dbl&gt;, number_of_reviews &lt;dbl&gt;, last_review &lt;date&gt;,\n#   reviews_per_month &lt;dbl&gt;, calculated_host_listings_count &lt;dbl&gt;,\n#   availability_365 &lt;dbl&gt;, number_of_reviews_ltm &lt;dbl&gt;, license &lt;chr&gt;\n\n\nThe output reveals that listing tibble data frame consists of 3540 rows and 18 columns. Two useful fields we are going to use in the next phase are latitude and longitude. Note that they are in decimal degree format. As a best guess, the assumption is that the data is in wgs84 Geographic Coordinate System.\n\n\n\nThe code chunk below converts listing data frame into a simple feature data frame by using st_as_sf() of sf packages\n\nlistings_sf &lt;- st_as_sf(listings,\n                        coords = c(\"longitude\", \"latitude\"),\n                        crs = 4326) %&gt;%\n  st_transform(crs = 3414)\n\nThings to learn from the arguments above:\n\ncoords argument requires you to provide the column name of the x-coordinates first then followed by the column name of the y-coordinates.\ncrs argument requires you to provide the coordinates system in epsg format. EPSG: 4326 is wgs84 Geographic Coordinate System and EPSG: 3414 is Singapore SVY21 Projected Coordinate System. You can search for other country’s ESPG code by referring to epsg.io.\n%&gt;% is used to nest st_transform() to transform the newly created simple feature data frame into svy21 projected coordinates system.\n\nNow to examine the content of this newly created listings_sf simple feature data frame.\n\nglimpse(listings_sf)\n\nRows: 3,540\nColumns: 17\n$ id                             &lt;dbl&gt; 71609, 71896, 71903, 275343, 275344, 28…\n$ name                           &lt;chr&gt; \"Ensuite Room (Room 1 & 2) near EXPO\", …\n$ host_id                        &lt;dbl&gt; 367042, 367042, 367042, 1439258, 143925…\n$ host_name                      &lt;chr&gt; \"Belinda\", \"Belinda\", \"Belinda\", \"Kay\",…\n$ neighbourhood_group            &lt;chr&gt; \"East Region\", \"East Region\", \"East Reg…\n$ neighbourhood                  &lt;chr&gt; \"Tampines\", \"Tampines\", \"Tampines\", \"Bu…\n$ room_type                      &lt;chr&gt; \"Private room\", \"Private room\", \"Privat…\n$ price                          &lt;dbl&gt; NA, 80, 80, 50, 50, NA, 85, 65, 45, 54,…\n$ minimum_nights                 &lt;dbl&gt; 92, 92, 92, 180, 180, 92, 92, 180, 180,…\n$ number_of_reviews              &lt;dbl&gt; 19, 24, 46, 20, 16, 12, 131, 17, 5, 60,…\n$ last_review                    &lt;date&gt; 2020-01-17, 2019-10-13, 2020-01-09, 20…\n$ reviews_per_month              &lt;dbl&gt; 0.12, 0.15, 0.29, 0.15, 0.11, 0.08, 0.8…\n$ calculated_host_listings_count &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 7, 49, 49, 6, 7, 7,…\n$ availability_365               &lt;dbl&gt; 89, 148, 90, 62, 0, 88, 365, 0, 0, 365,…\n$ number_of_reviews_ltm          &lt;dbl&gt; 0, 0, 0, 0, 2, 0, 0, 1, 1, 1, 0, 0, 0, …\n$ license                        &lt;chr&gt; NA, NA, NA, \"S0399\", \"S0399\", NA, NA, \"…\n$ geometry                       &lt;POINT [m]&gt; POINT (41972.5 36390.05), POINT (…\n\n\nTable above shows the content of listing_sf. Notice that a new column called geometry has been added into the data frame. On the other hand, the longitude and latitude columns have been dropped from the data frame.\n\n\n\n\nBesides providing functions to handle (i.e. importing, exporting, assigning projection, transforming projection) geospatial data, sf package also offers a wide range of geoprocessing (also known as GIS analysis) functions.\nIn this section, it will provide learning on how to perform two commonly used geoprocessing functions, namely buffering and point in polygon count.\n\n\nThe scenario:\nThe authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on both sides of the current cycling path. You are tasked to determine the extend of the land need to be acquired and their total area.\nThe solution:\nFirstly, st_buffer() of sf package is used to compute the 5-meter buffers around cycling paths\n\nbuffer_cycling &lt;- st_buffer(cyclingpath,\n                            dist = 5, nQuadSegs = 30)\n\nThis is followed by calculating the area of the buffers as shown in the code chunk below:\n\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\nLastly, sum() of Base R will be used to derive the total land involved\n\nsum(buffer_cycling$AREA)\n\n2218855 [m^2]\n\n\nTask Accomplished!\n\n\n\nThe scenario:\nA pre-school service group want to find out the number of pre-schools in each Planning Subzone.\nThe solution:\nThe code chunk below performs two operations at once. Firstly, identifying pre-schools located inside each Planning Subzone by using st_intersects(). Next, length() of Base R is used to calculate numbers of pre-schools that fall inside each planning subzone.\n\nmpsz3414$`PreSch Count` &lt;- lengths(st_intersects(mpsz3414, preschool3414))\n\n\nWarning: This should not confused with st_intersection().\n\nThe summary statistics of the newly derived PreSch Count field can be checked by using summary() as shown in the code chunk below.\n\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\nTo list the planning subzone with the most number of pre-schools, the top_n() of dplyr package is used as shown in the code chunk below.\n\ntop_n(mpsz3414, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\n\nAttempt: Calculate the density of pre-school by planning subzone.\n\nThe solution:\nFirstly, the code chunk below uses st_area() of sf package to derive the area of each planning subzone.\n\nmpsz3414$Area &lt;- mpsz3414 %&gt;%\n  st_area()\n\nNext, mutate() of dplyr package is used to compute the density by using the code chunk below:\n\nmpsz3414 &lt;- mpsz3414 %&gt;%\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)\n\nSimilarly, the planning subzone with the highest density of pre-schools can be listed using the top_n() of dplyr package is used as shown in the code chunk below.\n\ntop_n(mpsz3414, 1, `PreSch Density`)\n\nSimple feature collection with 1 feature and 18 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 29501.64 ymin: 28623.75 xmax: 29976.93 ymax: 29362.03\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO SUBZONE_N SUBZONE_C CA_IND    PLN_AREA_N PLN_AREA_C\n1       27          8     CECIL    DTSZ08      Y DOWNTOWN CORE         DT\n        REGION_N REGION_C          INC_CRC FMEL_UPD_D  X_ADDR   Y_ADDR\n1 CENTRAL REGION       CR 65AA82AF6F4D925D 2014-12-05 29730.2 29011.33\n  SHAPE_Leng SHAPE_Area                       geometry PreSch Count\n1   2116.095   196619.9 MULTIPOLYGON (((29808.18 28...            7\n            Area   PreSch Density\n1 196619.9 [m^2] 35.60169 [1/m^2]\n\n\n\n\n\n\nIn practice, most geospatial analytics start with Exploratory Data Analysis(EDA). In this section, it demonstrates how to use appropriate ggplot2 functions to create functional and yet truthful statistical graphs for EDA purposes.\nFirstly, we will plot a histogram to reveal the distribution of PreSch Density. Conventionally, hist() of R Graphics will be used as shown in the code chunk below.\n\nhist(mpsz3414$`PreSch Density`)\n\n\n\n\n\n\n\n\nAlthough the syntax is very easy to use the output however, is far from meeting publication quality. Furthermore, the function has limited room for further customisation.\nIn the code chunk below, appropriate ggplot2 functions will be used.\n\nggplot(data = mpsz3414,\n       aes(x = as.numeric(`PreSch Density`))) +\n  geom_histogram(bins = 20,\n                 color = \"black\",\n                 fill = \"light blue\") +\n  labs(title = \"Are pre-schools evenly distributed in Singapore ?\",\n       subtitle = \"There are many planning sub-zones with a single pre-school, on the other hand, \\nthere are two planning sub-zones with at least 20 pre-schools\",\n       x = \"Pre-school density (per km sq)\",\n       y = \"Frequency\")\n\n\n\n\n\n\n\n\n\nAttempt: Using ggplot2 method, plot a scatterplot showing the relationship between Pre-school Density and Pre-school Count.\n\n\nggplot(data = mpsz3414,\n       aes(y = `PreSch Count`,\n           x = as.numeric(`PreSch Density`))) +\n  geom_point(color = \"black\",\n             fill = \"light blue\") +\n  xlim(0, 40) +\n  ylim(0, 40) +\n  labs(title = \"\",\n      y = \"Pre-school count\",\n      x = \"Pre-school density (per km sq)\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#learning-outcomes",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#learning-outcomes",
    "title": "Hands-on Exercise 1a: Geospatial Data Wrangling with R",
    "section": "",
    "text": "Geospatial Data Science is the process of importing, wrangling, integrating, and processing geographically referenced data sets. In this hands-on exercise, the goal is to learn how to perform geospatial data science tasks in R by using sf package.\nBy the end of this hands-on exercise the following competencies should be acquired:\n\ninstalling and loading sf and tidyverse packages into R environment,\nimporting geospatial data by using appropriate functions of sf package,\nimporting aspatial data by using appropriate function of readr package,\nexploring the contents of simple feature data frame by using appropriate Base R and sf functions,\nassigning or transforming coordinate systems by using using appropriate sf functions,\nconverting an aspatial data into a sf data frame by using appropriate function of sf package,\nperforming geoprocessing tasks by using appropriate functions of sf package,\nperforming data wrangling tasks by using appropriate functions of dplyr package and\nperforming Exploratory Data Analysis (EDA) by using appropriate functions from ggplot2 package.\n\n\nNote: It is encouraged to read the reference guide of each function, especially the input data requirements, syntext and argument option before using them."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#data-acquisition",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#data-acquisition",
    "title": "Hands-on Exercise 1a: Geospatial Data Wrangling with R",
    "section": "",
    "text": "Data is key to data analytics which also includes geospatial analytics. Hence, before analysis it is required to assemble the necessary data. For this hands-on exercise the data will be extracted from the following sources:\n\nMaster Plan 2014 Subzone Boundary (Web) from data.gov.sg\nPre-Schools Location from data.gov.sg\nCycling Path from LTADataMall\nLatest version of Singapore Airbnb listing data from Inside Airbnb\n\n\nNote: This section does not merely constitute to extracting the necessary data sets. It also aims to introduce the usage of publicly available data sets.\n\n\n\nThe following steps have been carried out for extraction of the data sets:\nIn the Hands-on_Ex01 folder, a sub-folder called data is created. Then, inside the data sub-folder, two other sub-folders are created and are named geospatial and aspatial respectively.\nThe downloaded zipped files Master Plan 2014 Subzone Boundary (Web), Pre-Schools Location and Cycling Path are placed into geospatial sub-folder and unzipped. The unzipped files are then copied from their respective sub-folders and placed inside the geospatial sub-folder.\n\n\n\nThe downloaded listing data file is extracted. And placed in the Downloads folder by cutting and pasting the listing.csv file into the aspatial sub-folder."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#getting-started",
    "title": "Hands-on Exercise 1a: Geospatial Data Wrangling with R",
    "section": "",
    "text": "THe following 2 R packages will be used for this hands-on exercise:\n\nsf for importing, managing, and processing geospatial data, and\ntidyverse for performing data science tasks such as importing, wrangling and visualising data.\n\nTidyverse consists of a family of R packages. In this hands-on exercise, the following packages will be used:\n\nreadr for importing csv data,\nreadxl for importing Excel worksheet,\ntidyr for manipulating data,\ndplyr for transforming data, and\nggplot2 for visualising data\n\n\n\n\n\n\n\nNote\n\n\n\nThe code chunk below uses p_load() of pacman package to check if sf and tidyverse packages are installed in the computer. If they are, then they will be launched into R.\n\n\n\npacman::p_load(sf, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#importing-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#importing-geospatial-data",
    "title": "Hands-on Exercise 1a: Geospatial Data Wrangling with R",
    "section": "",
    "text": "In this section, the geospatial data is imported into R by using st_read() of sf package:\n\nMP14_SUBZONE_WEB_PL, a polygon feature layer in ESRI shapefile format,\nCyclingPath, a line feature layer in ESRI shapefile format, and\nPreSchool, a point feature layer in kml file format.\n\n\n\nThe code chunk below uses st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile into R as a polygon feature data frame. Note that when the input geospatial data is in shapefile format, two arguments will be used, namely: dsn to define the data path and layer to provide the shapefile name.\nAlso note that no extension such as .shp, .dbf, .prj and .shx are needed.\n\nmpsz = st_read(dsn = \"data/geospatial\",\n                  layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nThe message above reveals that the geospatial objects are multipolygon features. There are a total of 323 multipolygon features and 15 fields in mpsz simple feature data frame. mpsz is in svy21 projected coordinates systems. The bounding box provides the x extend and y extend of the data.\n\n\n\nAgain, the code chunk below uses st_read() function of sf package to import CyclingPath shapefile into R but as a line feature data frame.\n\ncyclingpath = st_read(dsn = \"data/geospatial\",\n                         layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 3138 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42644.17 ymax: 48948.15\nProjected CRS: SVY21\n\n\nThe message above reveals that the geospatial objects are linestring features. There are a total of 3138 features and 2 fields in cyclingpath linestring feature data frame and it is in svy21 projected coordinates system as well.\n\n\n\nThe PreSchoolsLocation is in kml format. The code chunk below will be used to import the kml file into R. Notice that in the code chunk below, the complete path and the kml file extension were provided.\n\npreschool = st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nThe message above reveals that preschool is a point feature data frame. There are a total of 2290 features and 2 fields. It is different from the previous two simple feature data frames, preschool is in wgs84 coordinates system."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#checking-the-content-of-a-simple-feature-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#checking-the-content-of-a-simple-feature-data-frame",
    "title": "Hands-on Exercise 1a: Geospatial Data Wrangling with R",
    "section": "",
    "text": "In this sub-section, it illustrates different ways to retrieve information related to the content of a simple feature data frame.\n\n\nThe column in the sf data.frame that contains the geometries is a list, of class sfc. The geometry list-column can be retrieved in this case by mpsz$geom or mpsz[[1]], but more a generic way uses st_geometry() as shown in the code chunk below.\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\n\nNote: Note that the print only displays basic information of the feature class such as type of geometry, the geographic extent of the features and the coordinate system of the data.\n\n\n\n\nBesides the basic feature information, more can be learnt about the associated attribute information in the data frame. This where glimpse() of dplyr is handy as shown in the code chunk below.\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\nThe glimpse() report reveals the data type of each fields. For example FMEL-UPD_D field is in date data type and X_ADDR, Y_ADDR, SHAPE_Length and SHAPE_Area fields are all in double-precision values.\n\n\n\nAt times, to reveal the complete information of a feature object, head() of Base R can be used.\n\nhead(mpsz, n=5)\n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n\n\n\nNote: A useful argument of head() is that it allows the user to select the number of records to display (i.e. the n argument)."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#plotting-the-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#plotting-the-geospatial-data",
    "title": "Hands-on Exercise 1a: Geospatial Data Wrangling with R",
    "section": "",
    "text": "In geospatial data science, only ooking at the feature information is not enough. We are also interested in visualising the geospatial features. This is when plot() of R Graphic comes in very handy as shown in the code chunk below.\n\nplot(mpsz)\n\n\n\n\n\n\n\n\nThe default plot of an sf object is a multi-plot of all attributes, up to a reasonable maximum as shown above. However, the geometry can only be chosen for plotting by using the code chunk below.\n\nplot(st_geometry(mpsz))\n\n\n\n\n\n\n\n\nAlternatively, the plot of the sf object can also be chosen by using a specific attribute as shown in the code chunk below.\n\n“PLN_AREA_N”“PLN_AREA_C”“REGION_C”\n\n\n\nplot(mpsz[\"PLN_AREA_N\"])\n\n\n\n\n\n\n\n\n\n\n\nplot(mpsz[\"PLN_AREA_C\"])\n\n\n\n\n\n\n\n\n\n\n\nplot(mpsz[\"REGION_C\"])\n\n\n\n\n\n\n\n\n\n\n\n\nNote: plot() is meant for plotting the geospatial object for quick observation. For a high cartographic quality plot, other R package such as tmap should be used."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#working-with-projection",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#working-with-projection",
    "title": "Hands-on Exercise 1a: Geospatial Data Wrangling with R",
    "section": "",
    "text": "Map projection is an important property of a geospatial data. In order to perform geoprocessing using two geospatial data, both geospatial data have to be projected using similar coordinate system.\nIn this section, it will illustrate how to project a simple feature data frame from one coordinate system to another coordinate system. The technical term of this process is called projection transformation.\n\n\nA common issue that can happen during importing process of geospatial data into R is that the coordinate system of the source data was either missing (such as due to missing .proj for ESRI shapefile) or wrongly assigned during the importing process.\nThis is an example the coordinate system of mpsz simple feature data frame by using st_crs() of sf package as shown in the code chunk below.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nAlthough the mpsz data frame is projected in svy21 but upon examination at the end of the print, it indicates that the EPSG is 9001. This is a wrong EPSG code because the correct EPSG code for svy21 should be 3414.\nIn order to assign the correct EPSG code to the mpsz data frame, st_set_crs() of sf package is used as shown in the code chunk below.\n\nmpsz3414 &lt;- st_set_crs(mpsz, 3414)\n\nNow, to inspect the CSR again by using the code chunk below.\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nNotice that the EPSG code is 3414 now.\n\n\n\nIn geospatial analytics, it is very common to transform the original data from geographic coordinate system to projected coordinate system. This is because geographic coordinate system is not appropriate if the analysis requires the use of distance or/and area measurements.\nExamining the preschool simple feature data frame as an example. The print below reveals that it is in wgs84 coordinate system.\n\nst_geometry(preschool)\n\nGeometry set for 2290 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\nFirst 5 geometries:\n\n\nHence, this is a scenario that illustrates st_set_crs() is not appropriate and st_transform() of sf package should be used.\nThis is due to the fact that a re-projection is needed for preschool from one coordinate system to another coordinate system mathematically.\nThe projection transformation is performed by using the code chunk below.\n\npreschool3414 &lt;- st_transform(preschool,\n                              crs = 3414)\n\n\nNote: In practice, we will need to find out the appropriate project coordinate system to use before performing the projection transformation.\n\nThe content of preschool3414 sf data frame is displayed again with the code chunk below:\n\nst_geometry(preschool3414)\n\nGeometry set for 2290 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 11810.03 ymin: 25596.33 xmax: 45404.24 ymax: 49300.88\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\nFirst 5 geometries:\n\n\n\n\n\n\n\n\nNote\n\n\n\nNotice that it is in svy21 projected coordinate system now. Furthermore, referencing to Bounding box:, the values are greater than 0-360 range of decimal degree commonly used by most of the geographic coordinate systems."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#importing-and-converting-an-aspatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#importing-and-converting-an-aspatial-data",
    "title": "Hands-on Exercise 1a: Geospatial Data Wrangling with R",
    "section": "",
    "text": "In practice, it is not unusual that we will come across data such as listing of Inside Airbnb. We call this kind of data aspatial data. Mainly because it is not a geospatial data but among the data fields, there are two fields that capture the x- and y-coordinates of the data points.\nIn this section, it will illustrate how to import an aspatial data into R environment and save it as a tibble data frame. Next, it will be converted it into a simple feature data frame.\nFor the purpose of this exercise, the listings.csv data downloaded from AirBnb will be used.\n\n\nSince listings data set is in csv file format, read_csv() of readr package will be used to import listing.csv as shown in the code chunk below. The output R object is called listings and it is a tibble data frame.\n\nlistings &lt;- read_csv(\"data/aspatial/listings.csv\")\n\nAfter importing the data file into R, it is important to examine if the data file has been imported correctly.\nThe code chunk below shows list() of Base R instead of glimpse() to do the job.\n\nlist(listings)\n\n[[1]]\n# A tibble: 3,540 × 18\n       id name      host_id host_name neighbourhood_group neighbourhood latitude\n    &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;               &lt;chr&gt;            &lt;dbl&gt;\n 1  71609 Ensuite …  367042 Belinda   East Region         Tampines          1.35\n 2  71896 B&B  Roo…  367042 Belinda   East Region         Tampines          1.35\n 3  71903 Room 2-n…  367042 Belinda   East Region         Tampines          1.35\n 4 275343 10min wa… 1439258 Kay       Central Region      Bukit Merah       1.29\n 5 275344 15 mins … 1439258 Kay       Central Region      Bukit Merah       1.29\n 6 289234 Booking …  367042 Belinda   East Region         Tampines          1.34\n 7 294281 5 mins w… 1521514 Elizabeth Central Region      Newton            1.31\n 8 324945 Comforta… 1439258 Kay       Central Region      Bukit Merah       1.29\n 9 330095 Relaxing… 1439258 Kay       Central Region      Bukit Merah       1.29\n10 344803 Budget s…  367042 Belinda   East Region         Tampines          1.35\n# ℹ 3,530 more rows\n# ℹ 11 more variables: longitude &lt;dbl&gt;, room_type &lt;chr&gt;, price &lt;dbl&gt;,\n#   minimum_nights &lt;dbl&gt;, number_of_reviews &lt;dbl&gt;, last_review &lt;date&gt;,\n#   reviews_per_month &lt;dbl&gt;, calculated_host_listings_count &lt;dbl&gt;,\n#   availability_365 &lt;dbl&gt;, number_of_reviews_ltm &lt;dbl&gt;, license &lt;chr&gt;\n\n\nThe output reveals that listing tibble data frame consists of 3540 rows and 18 columns. Two useful fields we are going to use in the next phase are latitude and longitude. Note that they are in decimal degree format. As a best guess, the assumption is that the data is in wgs84 Geographic Coordinate System.\n\n\n\nThe code chunk below converts listing data frame into a simple feature data frame by using st_as_sf() of sf packages\n\nlistings_sf &lt;- st_as_sf(listings,\n                        coords = c(\"longitude\", \"latitude\"),\n                        crs = 4326) %&gt;%\n  st_transform(crs = 3414)\n\nThings to learn from the arguments above:\n\ncoords argument requires you to provide the column name of the x-coordinates first then followed by the column name of the y-coordinates.\ncrs argument requires you to provide the coordinates system in epsg format. EPSG: 4326 is wgs84 Geographic Coordinate System and EPSG: 3414 is Singapore SVY21 Projected Coordinate System. You can search for other country’s ESPG code by referring to epsg.io.\n%&gt;% is used to nest st_transform() to transform the newly created simple feature data frame into svy21 projected coordinates system.\n\nNow to examine the content of this newly created listings_sf simple feature data frame.\n\nglimpse(listings_sf)\n\nRows: 3,540\nColumns: 17\n$ id                             &lt;dbl&gt; 71609, 71896, 71903, 275343, 275344, 28…\n$ name                           &lt;chr&gt; \"Ensuite Room (Room 1 & 2) near EXPO\", …\n$ host_id                        &lt;dbl&gt; 367042, 367042, 367042, 1439258, 143925…\n$ host_name                      &lt;chr&gt; \"Belinda\", \"Belinda\", \"Belinda\", \"Kay\",…\n$ neighbourhood_group            &lt;chr&gt; \"East Region\", \"East Region\", \"East Reg…\n$ neighbourhood                  &lt;chr&gt; \"Tampines\", \"Tampines\", \"Tampines\", \"Bu…\n$ room_type                      &lt;chr&gt; \"Private room\", \"Private room\", \"Privat…\n$ price                          &lt;dbl&gt; NA, 80, 80, 50, 50, NA, 85, 65, 45, 54,…\n$ minimum_nights                 &lt;dbl&gt; 92, 92, 92, 180, 180, 92, 92, 180, 180,…\n$ number_of_reviews              &lt;dbl&gt; 19, 24, 46, 20, 16, 12, 131, 17, 5, 60,…\n$ last_review                    &lt;date&gt; 2020-01-17, 2019-10-13, 2020-01-09, 20…\n$ reviews_per_month              &lt;dbl&gt; 0.12, 0.15, 0.29, 0.15, 0.11, 0.08, 0.8…\n$ calculated_host_listings_count &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 7, 49, 49, 6, 7, 7,…\n$ availability_365               &lt;dbl&gt; 89, 148, 90, 62, 0, 88, 365, 0, 0, 365,…\n$ number_of_reviews_ltm          &lt;dbl&gt; 0, 0, 0, 0, 2, 0, 0, 1, 1, 1, 0, 0, 0, …\n$ license                        &lt;chr&gt; NA, NA, NA, \"S0399\", \"S0399\", NA, NA, \"…\n$ geometry                       &lt;POINT [m]&gt; POINT (41972.5 36390.05), POINT (…\n\n\nTable above shows the content of listing_sf. Notice that a new column called geometry has been added into the data frame. On the other hand, the longitude and latitude columns have been dropped from the data frame."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#geoprocessing-with-sf-package",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#geoprocessing-with-sf-package",
    "title": "Hands-on Exercise 1a: Geospatial Data Wrangling with R",
    "section": "",
    "text": "Besides providing functions to handle (i.e. importing, exporting, assigning projection, transforming projection) geospatial data, sf package also offers a wide range of geoprocessing (also known as GIS analysis) functions.\nIn this section, it will provide learning on how to perform two commonly used geoprocessing functions, namely buffering and point in polygon count.\n\n\nThe scenario:\nThe authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on both sides of the current cycling path. You are tasked to determine the extend of the land need to be acquired and their total area.\nThe solution:\nFirstly, st_buffer() of sf package is used to compute the 5-meter buffers around cycling paths\n\nbuffer_cycling &lt;- st_buffer(cyclingpath,\n                            dist = 5, nQuadSegs = 30)\n\nThis is followed by calculating the area of the buffers as shown in the code chunk below:\n\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\nLastly, sum() of Base R will be used to derive the total land involved\n\nsum(buffer_cycling$AREA)\n\n2218855 [m^2]\n\n\nTask Accomplished!\n\n\n\nThe scenario:\nA pre-school service group want to find out the number of pre-schools in each Planning Subzone.\nThe solution:\nThe code chunk below performs two operations at once. Firstly, identifying pre-schools located inside each Planning Subzone by using st_intersects(). Next, length() of Base R is used to calculate numbers of pre-schools that fall inside each planning subzone.\n\nmpsz3414$`PreSch Count` &lt;- lengths(st_intersects(mpsz3414, preschool3414))\n\n\nWarning: This should not confused with st_intersection().\n\nThe summary statistics of the newly derived PreSch Count field can be checked by using summary() as shown in the code chunk below.\n\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\nTo list the planning subzone with the most number of pre-schools, the top_n() of dplyr package is used as shown in the code chunk below.\n\ntop_n(mpsz3414, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\n\nAttempt: Calculate the density of pre-school by planning subzone.\n\nThe solution:\nFirstly, the code chunk below uses st_area() of sf package to derive the area of each planning subzone.\n\nmpsz3414$Area &lt;- mpsz3414 %&gt;%\n  st_area()\n\nNext, mutate() of dplyr package is used to compute the density by using the code chunk below:\n\nmpsz3414 &lt;- mpsz3414 %&gt;%\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)\n\nSimilarly, the planning subzone with the highest density of pre-schools can be listed using the top_n() of dplyr package is used as shown in the code chunk below.\n\ntop_n(mpsz3414, 1, `PreSch Density`)\n\nSimple feature collection with 1 feature and 18 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 29501.64 ymin: 28623.75 xmax: 29976.93 ymax: 29362.03\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO SUBZONE_N SUBZONE_C CA_IND    PLN_AREA_N PLN_AREA_C\n1       27          8     CECIL    DTSZ08      Y DOWNTOWN CORE         DT\n        REGION_N REGION_C          INC_CRC FMEL_UPD_D  X_ADDR   Y_ADDR\n1 CENTRAL REGION       CR 65AA82AF6F4D925D 2014-12-05 29730.2 29011.33\n  SHAPE_Leng SHAPE_Area                       geometry PreSch Count\n1   2116.095   196619.9 MULTIPOLYGON (((29808.18 28...            7\n            Area   PreSch Density\n1 196619.9 [m^2] 35.60169 [1/m^2]"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#exploratory-data-analysis-eda",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#exploratory-data-analysis-eda",
    "title": "Hands-on Exercise 1a: Geospatial Data Wrangling with R",
    "section": "",
    "text": "In practice, most geospatial analytics start with Exploratory Data Analysis(EDA). In this section, it demonstrates how to use appropriate ggplot2 functions to create functional and yet truthful statistical graphs for EDA purposes.\nFirstly, we will plot a histogram to reveal the distribution of PreSch Density. Conventionally, hist() of R Graphics will be used as shown in the code chunk below.\n\nhist(mpsz3414$`PreSch Density`)\n\n\n\n\n\n\n\n\nAlthough the syntax is very easy to use the output however, is far from meeting publication quality. Furthermore, the function has limited room for further customisation.\nIn the code chunk below, appropriate ggplot2 functions will be used.\n\nggplot(data = mpsz3414,\n       aes(x = as.numeric(`PreSch Density`))) +\n  geom_histogram(bins = 20,\n                 color = \"black\",\n                 fill = \"light blue\") +\n  labs(title = \"Are pre-schools evenly distributed in Singapore ?\",\n       subtitle = \"There are many planning sub-zones with a single pre-school, on the other hand, \\nthere are two planning sub-zones with at least 20 pre-schools\",\n       x = \"Pre-school density (per km sq)\",\n       y = \"Frequency\")\n\n\n\n\n\n\n\n\n\nAttempt: Using ggplot2 method, plot a scatterplot showing the relationship between Pre-school Density and Pre-school Count.\n\n\nggplot(data = mpsz3414,\n       aes(y = `PreSch Count`,\n           x = as.numeric(`PreSch Density`))) +\n  geom_point(color = \"black\",\n             fill = \"light blue\") +\n  xlim(0, 40) +\n  ylim(0, 40) +\n  labs(title = \"\",\n      y = \"Pre-school count\",\n      x = \"Pre-school density (per km sq)\")"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hi I’m Zi Jun, a dedicated professional pursuing a Master’s of IT in Business (Analytics Track) at Singapore Management University. With a bachelor’s in Business and a passion for data analytics, I am currently focusing on utilising Python and R programming to uncover insights and solve complex problems. Additionally, I am also picking up technical skills such as SQL to complement areas of data management. This is my personal course webpage for Geospatial Analytics and Application module.\nYou may reach me via email or we can connect with each other via LinkedIn!\n\n\nSingapore Management University Masters of IT in Business (Analytics) | January 2024 - April 2025\nSingapore University of Social Sciences Bachelor of Science (BSc) in Business | July 2023\n\n\n\nEM Engineering (Subsidiary of EM Services) | Executive (Operations) | September 2022 - February 2024\nAlign Technology | Consumer Experience Consultant | May 2021 - July 2022\nThank you for dropping by!"
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About",
    "section": "",
    "text": "Singapore Management University Masters of IT in Business (Analytics) | January 2024 - April 2025\nSingapore University of Social Sciences Bachelor of Science (BSc) in Business | July 2023"
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "About",
    "section": "",
    "text": "EM Engineering (Subsidiary of EM Services) | Executive (Operations) | September 2022 - February 2024\nAlign Technology | Consumer Experience Consultant | May 2021 - July 2022"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html",
    "title": "Hands-on Exercise 1b: Thematic Mapping and GeoVisualisation with R",
    "section": "",
    "text": "In general, thematic mapping involves the use of map symbols to visualize selected properties of geographic features that are not naturally visible, such as population, temperature, crime rate, and property prices, just to mention a few.\nGeovisualisation, on the other hand, works by providing graphical ideation to render a place, a phenomenon or a process visible, enabling humans most powerful information-processing abilities – those of spatial cognition associated with our eye–brain vision system – to be directly brought to bear.\nIn this chapter, the goal is to learn how to plot functional and truthful choropleth maps by using an R package called tmap package.\n\n\n\nIn this hands-on exercise, the key R package used is the tmap package in R. Besides tmap package, four other R packages will be used. They are:\n\nreadr for importing delimited text file,\ntidyr for tidying data,\ndplyr for wrangling data and\nsf for handling geospatial data.\n\nAmong the four packages, readr, tidyr and dplyr are part of tidyverse package.\n\nNote: It is advisable to read the functional description of each function before using them.\n\nThe code chunk below will be used to install and load these packages in RStudio.\n\npacman::p_load(sf, tmap, tidyverse)\n\nNotice that, we only need to install tidyverse instead of readr, tidyr and dplyr individually.\n\n\n\n\n\nTwo data sets will be used to create the choropleth map. They are:\n\nMaster Plan 2014 Subzone Boundary (Web) (i.e. MP14_SUBZONE_WEB_PL) in ESRI shapefile format. It can be downloaded at data.gov.sg This is a geospatial data. It consists of the geographical boundary of Singapore at the planning subzone level. The data is based on the URA Master Plan 2014.\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 in csv format (i.e. respopagesextod2011to2020.csv). This is an aspatial data fie. It can be downloaded at Department of Statistics, Singapore Although it does not contain any coordinates values, but it’s PA and SZ fields can be used as unique identifiers to geocode to the MP14_SUBZONE_WEB_PL shapefile.\n\n\n\n\nThe code chunk below uses the st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile into R as a simple feature data frame called mpsz.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\",\n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nThe contents of mpsz can be examined by using the code chunk below:\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\nNotice that only the first ten records will be displayed. Do you know why?\n\n\n\n\n\n\nReasoning\n\n\n\nDefault Behaviour of sf Objects: When you print an sf object in R, it typically displays only the first 10 rows by default. This behaviour is similar to tibbles, where the intention is to provide a concise and readable output without overwhelming the console with too much data at once.\n\n\n\n\n\nNext, we will import respopagsex2011to2020.csv file into RStudio and save the file into an R dataframe called popdata.\nThe task will be performed by using read_csv() function of readr package as shown in the code chunk below.\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\n\n\n\nBefore a thematic map can be prepared, it is required to prepare a data table with year 2020 values. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.\n\nYOUNG: age group 0 to 4 until age group 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age groups, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\n\nThe following data wrangling and transformation functions will be used: - pivot_wider() of tidyr package, and - mutate(), filter(), group_by() and select() of dplyr package\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from = AG,\n              values_from = POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         + rowSums(.[12])) %&gt;%\n  mutate(`ECONOMY ACTIVE` = rowSums(.[7:11]) +\n  rowSums(.[13:15])) %&gt;%\n  mutate(`AGED` = rowSums(.[16:21])) %&gt;%\n  mutate(`TOTAL` = rowSums(.[3:21])) %&gt;%\n  mutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n  /`ECONOMY ACTIVE`) %&gt;%\n    select(`PA`, `SZ`, `YOUNG`,\n          `ECONOMY ACTIVE`, `AGED`,\n          `TOTAL`, `DEPENDENCY`)\n\n\n\n\nBefore performing the geo-relational join, one extra step is required to convert the values in PA and SZ fields to uppercase. This is because the values of PA and SZ fields are made up of upper- and lowercase. On the other, hand the SUBZONE_N and PLN_AREA_N are in uppercase.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ),\n            .funs = list(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nNext, left_join() of dplyr is used to join the geographical data and attribute table using planning subzone name e.g. SUBZONE_N and SZ as the common identifier.\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\n\n\n\n\n\n\nThing to learn from the code chunk above:\n\n\n\n\nleft_join() of dplyr package is used with mpsz simple feature data frame as the left data table to ensure that the output will be a simple features data frame.\n\n\n\n\n\n\n\n\nChoropleth mapping involves the symbolisation of enumeration units, such as countries, provinces, states, counties or census units, using area patterns or graduated colours. For example, a social scientist may need to use a choropleth map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.\nTwo approaches can be used to prepare thematic map using tmap, they are:\n\nPlotting a thematic map quickly by using qtm().\nPlotting highly customisable thematic map by using tmap elements.\n\n\n\nThe easiest and quickest to draw a choropleth map using tmap is using qtm(). It is concise and provides a good default visualisation in many cases.\nThe code chunk below will draw a cartographic standard choropleth map as shown below:\n\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020,\n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\n\ntmap_mode() with “plot” option is used to produce a static map. For interactive mode, “view” option should be used.\nfill argument is used to map the attribute (i.e. DEPENDENCY)\n\n\n\n\nDespite its usefulness of drawing a choropleth map quickly and easily, the disadvantage of qtm() is that it makes aesthetics of individual layers harder to control. To draw a high quality cartographic choropleth map as shown in the figure below, tmap’s drawing elements should be used.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          title = \"Dependency Ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by Planning Subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45,\n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type = \"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authority (URA)\\n and Population data from Department of Statistics DOS\",\n            position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\nIn the following sub-section, more will be shared on tmap functions that are used to plot these elements.\n\n\nThe basic building block of tmap is tm_shape() followed by one or more layer elements such as tm_fill() and tm_polygons().\nIn the code chunk below, tm_shape() is used to define the input data (i.e mpsz_pop2020) and tm_polygons() is used to draw the planning subzone polygons.\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\n\n\n\n\nTo draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, we just need to assign the target variable such as Dependency to tm_polygons().\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThings to learn from tm_polygons():\n\nThe default interval binning used to draw the choropleth map is called “pretty”. A detailed discussion of the data classification methods supported by tmap will be provided in sub-section 4.3.\nThe default colour scheme used is YlOrRd of ColorBrewer. More will be shown about the color scheme in sub-section 4.4.\nBy default, Missing values will be shaded in grey.\n\n\n\n\ntm_polygons() is a wrapper of tm_fill() and tm_border(). tm_fill() shades the polygons by using the default colour scheme and tm_borders() adds the borders of the shapefile onto the choropleth map.\nThe code chunk below draws a choropleth map by using tm_fill() alone.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nNotice that the planning subzones are shaded according to the respective dependency values\nTo add the boundary of the planning subzones, tm_borders will be used as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1, alpha = 1)\n\n\n\n\n\n\n\n\nNotice that light-grey border lines have been added on the choropleth map.\nThe alpha argument is used to define transparency number between 0 (totally transparent) and 1 (not transparent). By default, the alpha value of the col is used (normally 1).\nBesides alpha argument, there are three other arguments for tm_borders(), they are:\n\ncol = border colour,\nlwd = border line width. The default is 1, and\nlty = border line type. The default is “solid”.\n\n\n\n\n\nMost choropleth maps employ some methods of data classification. The point of classification is to take a large number of observations and group them into data ranges or classes.\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nTo define a data classification method, the style argument of tm_fill() or tm_polygons() will be used.\n\n\nThe code chunk below shows a quantile data classification that used 5 classes.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.8, lwd = 0.1)\n\n\n\n\n\n\n\n\nIn the code chunk below, equal data classification method is used.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.8, lwd = 0.1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nNotice that the distribution of quantile data classification method are more evenly distributed then equal data classification method.\n\n\n\nWarning: Maps Lie!\n\n\nDIY: Using what was learnt, prepare choropleth maps by using different classification methods supported by tmap and compare their differences.\n\n\nDIY: Preparing choropleth maps by using similar classification method but with different numbers of classes (i.e. 2, 6, 10, 20). Compare the output maps, what observation can we draw?\n\n\njenks method (5 classes)jenks method (10 classes)quantile method (10 classes)quantile method (15 classes)\n\n\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"jenks\") +\n  tm_borders(alpha = 0.8, lwd = 0.1)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          n = 10,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.8, lwd = 0.1)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          n = 10,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.8, lwd = 0.1)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          n = 15,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.8, lwd = 0.1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFor all the built-in styles, the category breaks are computed internally. In order to override these defaults, the breakpoints can be set explicitly by means of the breaks argument to the tm_fill(). It is important to note that, in tmap the breaks include a minimum and maximum. As a result, in order to end up with n categories, n+1 elements must be specified in the breaks option (the values must be in increasing order).\nBefore getting started, it is always a good practice to get some descriptive statistics on the variable before setting the break points. Code chunk below will be used to compute and display the descriptive statistics of DEPENDENCY field.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\nWith reference to the results above, break point can be set at 0.60, 0.70, 0.80, and 0.90. In addition, we also need to include a minimum and maximum, which we set at 0 and 100. Our breaks vector is thus c(0, 0.60, 0.70, 0.80, 0.90, 1.00)\nNow, the choropleth map will be plotted by using the code chunk below:\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package.\n\n\nTo change the colour, we assign the preferred colour to palette argument of tm_fill() as shown in the code chunk below:\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nNotice that the choropleth map below is shaded in green.\n\npalette = “Greens”palette = “-Greens”\n\n\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Greens\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\nTo reverse the colour shading, add a “-” prefix.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nNotice that the colour scheme has been reversed.\n\n\n\n\n\n\n\nMap layout refers to the combination of all map elements into a cohesive map. Map elements include among others the objects to be mapped, the title, the scale bar, the compass, margins and aspects ratios. Colour settings and data classification methods covered in the previous section relate to the palette and break-points are used to affect how the map looks.\n\n\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"jenks\",\n          palette = \"Blues\",\n          legend.hist = TRUE,\n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45,\n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\ntmap allows a wide variety of layout settings to be changed. They can be called by using tmap_style().\nThe code chunk below shows the classic style being used.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\n\n\n\n\n\n\n\n\n\nBeside map style, tmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\nIn the code chunk below, tm_compass(), tm_scale_bar() and tm_grid() are used to add compass, scale bar and grid lines onto the choropleth map.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          title = \"No. of Persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby Planning Subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45,\n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type = \"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\",\n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\nTo reset the default style, refer to the code chunk below.\n\ntmap_style(\"white\")\n\n\n\n\n\nSmall multiple maps, also referred to as facet maps, are composed of many maps arranged side-by-side, and sometimes stacked vertically. Small multiple maps enable the visualisation of how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the aesthetic arguments,\nby defining a group-by variable in tm_facets(), and\nby creating multiple stand-alone maps with tmap_arrange().\n\n\n\nIn this example, small multiple choropleth maps are created by defining ncols in tm_fill()\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\",\n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\n\n\n\n\n\n\n\nIn this example, small multiple choropleth maps are created by assigning multiple values to at least one of the aesthetic arguments\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons(c(\"DEPENDENCY\", \"AGED\"),\n          style = c(\"equal\", \"quantile\"),\n          palette = list(\"Blues\", \"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n\nIn this example, multiple small choropleth maps are created by using tm_facets().\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) +\n  tm_facets(by = \"REGION_N\",\n            free.coords = TRUE,\n            drop.shapes = TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"),\n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\nIn this example, multiple small choropleth maps are created by creating multiple stand-alone maps with tmap_arrange().\n\nyoungmap &lt;- tm_shape(mpsz_pop2020) +\n  tm_polygons(\"YOUNG\",\n              style = \"quantile\",\n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020) +\n  tm_polygons(\"AGED\",\n              style = \"quantile\",\n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp = 1, ncol = 2)\n\n\n\n\n\n\n\n\n\neconomyactivemap &lt;- tm_shape(mpsz_pop2020) +\n  tm_polygons(\"ECONOMY ACTIVE\",\n              style = \"quantile\",\n              palette = \"Blues\")\n\ntotalmap &lt;- tm_shape(mpsz_pop2020) +\n  tm_polygons(\"TOTAL\",\n              style = \"quantile\",\n              palette = \"Blues\")\n\ntmap_arrange(economyactivemap, totalmap, asp = 1, ncol = 2)\n\n\n\n\n\n\n\n\n\n\n\n\nInstead of creating small multiple choropleth map, a selection function can be used to map spatial objects meeting the selection criterion.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N == \"CENTRAL REGION\", ]) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          legend.hist = TRUE,\n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45,\n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\nKam, T.S. (2024). Thematic Mapping and GeoVisualisation with R"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#overview",
    "title": "Hands-on Exercise 1b: Thematic Mapping and GeoVisualisation with R",
    "section": "",
    "text": "In general, thematic mapping involves the use of map symbols to visualize selected properties of geographic features that are not naturally visible, such as population, temperature, crime rate, and property prices, just to mention a few.\nGeovisualisation, on the other hand, works by providing graphical ideation to render a place, a phenomenon or a process visible, enabling humans most powerful information-processing abilities – those of spatial cognition associated with our eye–brain vision system – to be directly brought to bear.\nIn this chapter, the goal is to learn how to plot functional and truthful choropleth maps by using an R package called tmap package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#getting-started",
    "title": "Hands-on Exercise 1b: Thematic Mapping and GeoVisualisation with R",
    "section": "",
    "text": "In this hands-on exercise, the key R package used is the tmap package in R. Besides tmap package, four other R packages will be used. They are:\n\nreadr for importing delimited text file,\ntidyr for tidying data,\ndplyr for wrangling data and\nsf for handling geospatial data.\n\nAmong the four packages, readr, tidyr and dplyr are part of tidyverse package.\n\nNote: It is advisable to read the functional description of each function before using them.\n\nThe code chunk below will be used to install and load these packages in RStudio.\n\npacman::p_load(sf, tmap, tidyverse)\n\nNotice that, we only need to install tidyverse instead of readr, tidyr and dplyr individually."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#importing-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#importing-data-into-r",
    "title": "Hands-on Exercise 1b: Thematic Mapping and GeoVisualisation with R",
    "section": "",
    "text": "Two data sets will be used to create the choropleth map. They are:\n\nMaster Plan 2014 Subzone Boundary (Web) (i.e. MP14_SUBZONE_WEB_PL) in ESRI shapefile format. It can be downloaded at data.gov.sg This is a geospatial data. It consists of the geographical boundary of Singapore at the planning subzone level. The data is based on the URA Master Plan 2014.\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 in csv format (i.e. respopagesextod2011to2020.csv). This is an aspatial data fie. It can be downloaded at Department of Statistics, Singapore Although it does not contain any coordinates values, but it’s PA and SZ fields can be used as unique identifiers to geocode to the MP14_SUBZONE_WEB_PL shapefile.\n\n\n\n\nThe code chunk below uses the st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile into R as a simple feature data frame called mpsz.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\",\n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nThe contents of mpsz can be examined by using the code chunk below:\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\nNotice that only the first ten records will be displayed. Do you know why?\n\n\n\n\n\n\nReasoning\n\n\n\nDefault Behaviour of sf Objects: When you print an sf object in R, it typically displays only the first 10 rows by default. This behaviour is similar to tibbles, where the intention is to provide a concise and readable output without overwhelming the console with too much data at once.\n\n\n\n\n\nNext, we will import respopagsex2011to2020.csv file into RStudio and save the file into an R dataframe called popdata.\nThe task will be performed by using read_csv() function of readr package as shown in the code chunk below.\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\n\n\n\nBefore a thematic map can be prepared, it is required to prepare a data table with year 2020 values. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.\n\nYOUNG: age group 0 to 4 until age group 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age groups, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\n\nThe following data wrangling and transformation functions will be used: - pivot_wider() of tidyr package, and - mutate(), filter(), group_by() and select() of dplyr package\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from = AG,\n              values_from = POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         + rowSums(.[12])) %&gt;%\n  mutate(`ECONOMY ACTIVE` = rowSums(.[7:11]) +\n  rowSums(.[13:15])) %&gt;%\n  mutate(`AGED` = rowSums(.[16:21])) %&gt;%\n  mutate(`TOTAL` = rowSums(.[3:21])) %&gt;%\n  mutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n  /`ECONOMY ACTIVE`) %&gt;%\n    select(`PA`, `SZ`, `YOUNG`,\n          `ECONOMY ACTIVE`, `AGED`,\n          `TOTAL`, `DEPENDENCY`)\n\n\n\n\nBefore performing the geo-relational join, one extra step is required to convert the values in PA and SZ fields to uppercase. This is because the values of PA and SZ fields are made up of upper- and lowercase. On the other, hand the SUBZONE_N and PLN_AREA_N are in uppercase.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ),\n            .funs = list(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nNext, left_join() of dplyr is used to join the geographical data and attribute table using planning subzone name e.g. SUBZONE_N and SZ as the common identifier.\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\n\n\n\n\n\n\nThing to learn from the code chunk above:\n\n\n\n\nleft_join() of dplyr package is used with mpsz simple feature data frame as the left data table to ensure that the output will be a simple features data frame."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#choropleth-mapping-geospatial-data-using-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#choropleth-mapping-geospatial-data-using-tmap",
    "title": "Hands-on Exercise 1b: Thematic Mapping and GeoVisualisation with R",
    "section": "",
    "text": "Choropleth mapping involves the symbolisation of enumeration units, such as countries, provinces, states, counties or census units, using area patterns or graduated colours. For example, a social scientist may need to use a choropleth map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.\nTwo approaches can be used to prepare thematic map using tmap, they are:\n\nPlotting a thematic map quickly by using qtm().\nPlotting highly customisable thematic map by using tmap elements.\n\n\n\nThe easiest and quickest to draw a choropleth map using tmap is using qtm(). It is concise and provides a good default visualisation in many cases.\nThe code chunk below will draw a cartographic standard choropleth map as shown below:\n\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020,\n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\n\ntmap_mode() with “plot” option is used to produce a static map. For interactive mode, “view” option should be used.\nfill argument is used to map the attribute (i.e. DEPENDENCY)\n\n\n\n\nDespite its usefulness of drawing a choropleth map quickly and easily, the disadvantage of qtm() is that it makes aesthetics of individual layers harder to control. To draw a high quality cartographic choropleth map as shown in the figure below, tmap’s drawing elements should be used.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          title = \"Dependency Ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by Planning Subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45,\n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type = \"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authority (URA)\\n and Population data from Department of Statistics DOS\",\n            position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\nIn the following sub-section, more will be shared on tmap functions that are used to plot these elements.\n\n\nThe basic building block of tmap is tm_shape() followed by one or more layer elements such as tm_fill() and tm_polygons().\nIn the code chunk below, tm_shape() is used to define the input data (i.e mpsz_pop2020) and tm_polygons() is used to draw the planning subzone polygons.\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\n\n\n\n\nTo draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, we just need to assign the target variable such as Dependency to tm_polygons().\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThings to learn from tm_polygons():\n\nThe default interval binning used to draw the choropleth map is called “pretty”. A detailed discussion of the data classification methods supported by tmap will be provided in sub-section 4.3.\nThe default colour scheme used is YlOrRd of ColorBrewer. More will be shown about the color scheme in sub-section 4.4.\nBy default, Missing values will be shaded in grey.\n\n\n\n\ntm_polygons() is a wrapper of tm_fill() and tm_border(). tm_fill() shades the polygons by using the default colour scheme and tm_borders() adds the borders of the shapefile onto the choropleth map.\nThe code chunk below draws a choropleth map by using tm_fill() alone.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nNotice that the planning subzones are shaded according to the respective dependency values\nTo add the boundary of the planning subzones, tm_borders will be used as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1, alpha = 1)\n\n\n\n\n\n\n\n\nNotice that light-grey border lines have been added on the choropleth map.\nThe alpha argument is used to define transparency number between 0 (totally transparent) and 1 (not transparent). By default, the alpha value of the col is used (normally 1).\nBesides alpha argument, there are three other arguments for tm_borders(), they are:\n\ncol = border colour,\nlwd = border line width. The default is 1, and\nlty = border line type. The default is “solid”.\n\n\n\n\n\nMost choropleth maps employ some methods of data classification. The point of classification is to take a large number of observations and group them into data ranges or classes.\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nTo define a data classification method, the style argument of tm_fill() or tm_polygons() will be used.\n\n\nThe code chunk below shows a quantile data classification that used 5 classes.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.8, lwd = 0.1)\n\n\n\n\n\n\n\n\nIn the code chunk below, equal data classification method is used.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.8, lwd = 0.1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nNotice that the distribution of quantile data classification method are more evenly distributed then equal data classification method.\n\n\n\nWarning: Maps Lie!\n\n\nDIY: Using what was learnt, prepare choropleth maps by using different classification methods supported by tmap and compare their differences.\n\n\nDIY: Preparing choropleth maps by using similar classification method but with different numbers of classes (i.e. 2, 6, 10, 20). Compare the output maps, what observation can we draw?\n\n\njenks method (5 classes)jenks method (10 classes)quantile method (10 classes)quantile method (15 classes)\n\n\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"jenks\") +\n  tm_borders(alpha = 0.8, lwd = 0.1)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          n = 10,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.8, lwd = 0.1)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          n = 10,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.8, lwd = 0.1)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          n = 15,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.8, lwd = 0.1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFor all the built-in styles, the category breaks are computed internally. In order to override these defaults, the breakpoints can be set explicitly by means of the breaks argument to the tm_fill(). It is important to note that, in tmap the breaks include a minimum and maximum. As a result, in order to end up with n categories, n+1 elements must be specified in the breaks option (the values must be in increasing order).\nBefore getting started, it is always a good practice to get some descriptive statistics on the variable before setting the break points. Code chunk below will be used to compute and display the descriptive statistics of DEPENDENCY field.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\nWith reference to the results above, break point can be set at 0.60, 0.70, 0.80, and 0.90. In addition, we also need to include a minimum and maximum, which we set at 0 and 100. Our breaks vector is thus c(0, 0.60, 0.70, 0.80, 0.90, 1.00)\nNow, the choropleth map will be plotted by using the code chunk below:\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package.\n\n\nTo change the colour, we assign the preferred colour to palette argument of tm_fill() as shown in the code chunk below:\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nNotice that the choropleth map below is shaded in green.\n\npalette = “Greens”palette = “-Greens”\n\n\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Greens\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\nTo reverse the colour shading, add a “-” prefix.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nNotice that the colour scheme has been reversed.\n\n\n\n\n\n\n\nMap layout refers to the combination of all map elements into a cohesive map. Map elements include among others the objects to be mapped, the title, the scale bar, the compass, margins and aspects ratios. Colour settings and data classification methods covered in the previous section relate to the palette and break-points are used to affect how the map looks.\n\n\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"jenks\",\n          palette = \"Blues\",\n          legend.hist = TRUE,\n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45,\n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\ntmap allows a wide variety of layout settings to be changed. They can be called by using tmap_style().\nThe code chunk below shows the classic style being used.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\n\n\n\n\n\n\n\n\n\nBeside map style, tmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\nIn the code chunk below, tm_compass(), tm_scale_bar() and tm_grid() are used to add compass, scale bar and grid lines onto the choropleth map.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          title = \"No. of Persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby Planning Subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45,\n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type = \"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\",\n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\nTo reset the default style, refer to the code chunk below.\n\ntmap_style(\"white\")\n\n\n\n\n\nSmall multiple maps, also referred to as facet maps, are composed of many maps arranged side-by-side, and sometimes stacked vertically. Small multiple maps enable the visualisation of how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the aesthetic arguments,\nby defining a group-by variable in tm_facets(), and\nby creating multiple stand-alone maps with tmap_arrange().\n\n\n\nIn this example, small multiple choropleth maps are created by defining ncols in tm_fill()\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\",\n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\n\n\n\n\n\n\n\nIn this example, small multiple choropleth maps are created by assigning multiple values to at least one of the aesthetic arguments\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons(c(\"DEPENDENCY\", \"AGED\"),\n          style = c(\"equal\", \"quantile\"),\n          palette = list(\"Blues\", \"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n\nIn this example, multiple small choropleth maps are created by using tm_facets().\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) +\n  tm_facets(by = \"REGION_N\",\n            free.coords = TRUE,\n            drop.shapes = TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"),\n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\nIn this example, multiple small choropleth maps are created by creating multiple stand-alone maps with tmap_arrange().\n\nyoungmap &lt;- tm_shape(mpsz_pop2020) +\n  tm_polygons(\"YOUNG\",\n              style = \"quantile\",\n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020) +\n  tm_polygons(\"AGED\",\n              style = \"quantile\",\n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp = 1, ncol = 2)\n\n\n\n\n\n\n\n\n\neconomyactivemap &lt;- tm_shape(mpsz_pop2020) +\n  tm_polygons(\"ECONOMY ACTIVE\",\n              style = \"quantile\",\n              palette = \"Blues\")\n\ntotalmap &lt;- tm_shape(mpsz_pop2020) +\n  tm_polygons(\"TOTAL\",\n              style = \"quantile\",\n              palette = \"Blues\")\n\ntmap_arrange(economyactivemap, totalmap, asp = 1, ncol = 2)\n\n\n\n\n\n\n\n\n\n\n\n\nInstead of creating small multiple choropleth map, a selection function can be used to map spatial objects meeting the selection criterion.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N == \"CENTRAL REGION\", ]) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          legend.hist = TRUE,\n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45,\n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#references",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#references",
    "title": "Hands-on Exercise 1b: Thematic Mapping and GeoVisualisation with R",
    "section": "",
    "text": "Kam, T.S. (2024). Thematic Mapping and GeoVisualisation with R"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html",
    "title": "Hands-on Exercise 2b: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "Spatial Point Pattern Analysis is the evaluation of the pattern or distribution, of a set of points on a surface. The point can be locations of:\n\nevents such as crime, traffic accidents and disease onset, or\nbusiness services (coffee and fast food outlets) or facilities such as childcare and elder care centres.\n\nBy using appropriate functions of spatstat, this hands-on exercise aims to discover the spatial point processes of childcare centres in Singapore.\nThe specific questions we would like to answer are as follows:\n\nare the childcare centres in Singapore randomly distributed throughout the country?\n\nif the answer is no, then the next logical question is where are the locations with higher concentration of childcare centres?\n\n\n\n\nThree data sets will be used to provide answers to the questions above, they are:\n\nCHILDCARE, a point feature data providing both location and attribute information of childcare centres. It was downloaded from Data.gov.sg and is in geojson format.\nMP14_SUBZONE_WEB_PL, a polygon feature data providing information of URA 2014 Master Plan Planning Subzone boundary data. It is in ESRI shapefile format. This data set was also downloaded from Data.gov.sg.\nCostalOutline, a polygon feature data showing the national boundary of Singapore. It is provided by SLA and is in ESRI shapefile format.\n\n\n\n\nIn this hands-on exercise, five R packages will be used, they are:\n\nsf, a relatively new R package specially designed to import, manage and process vector-based geospatial data in R.\nspatstat, which has a wide range of useful functions for point pattern analysis. In this hands-on exercise, it will be used to perform 1st- and 2nd-order spatial point patterns analysis and derive kernel density estimation (KDE) layer.\nraster which reads, writes, manipulates, analyses and model of gridded spatial data (i.e. raster). In this hands-on exercise, it will be used to convert image output generate by spatstat into raster format.\nmaptools which provides a set of tools for manipulating geographic data. In this hands-on exercise, we mainly use it to convert Spatial objects into ppp format of spatstat.\ntmap which provides functions for plotting cartographic quality static point patterns maps or interactive maps by using leaflet API.\n\nThe code chunk below is used to install and launch the five R packages.\n\npacman::p_load(sf, raster, spatstat, tmap, tidyverse)\n\n\n\n\n\n\nIn this section, st_read() of sf package will be used to import these three geospatial data sets into R.\n\nchildcare_sf &lt;- st_read(\"data/child-care-services-geojson.geojson\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `child-care-services-geojson' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nsg_sf &lt;- st_read(dsn = \"data\", layer = \"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data' using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\n\nmpsz_sf &lt;- st_read(dsn = \"data\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nBefore using these data for analysis, it is important to ensure that they are projected in same projection system.\nCode chunk below will retrieve the referencing system information of these geospatial data.\n\nst_crs(childcare_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\nst_crs(sg_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\nst_crs(mpsz_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nNotice that except childcare_sf, both sg_sf and mpsz_sf do not have proper crs information.\nThe code chunk below will assign the correct crs to sg_sf and mpsz_sf simple feature data frames in relation to the referencing system of Singapore’s national projected coordinate system.\n\nsg_sf &lt;- st_set_crs(sg_sf, 3414)\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\n\nChecking the CSR of sg_sf using code chunk below.\n\nst_crs(sg_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\nmpsz_sf &lt;- st_set_crs(mpsz_sf, 3414)\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\n\nChecking the CSR again by using the code chunk below.\n\nst_crs(mpsz_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\n\nAfter checking the referencing system of each geospatial data data frame, it is also useful to plot a map to show their spatial patterns.\n\ntm_shape(sg_sf) +\n  tm_polygons() +\ntm_shape(mpsz_sf) +\n  tm_polygons() +\ntm_shape(childcare_sf) +\n  tm_dots()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nAll the geospatial layers are within the same map extend. This shows that their referencing system and coordinate values are referred to a similar spatial context. This is very important in any geospatial analysis.\n\n\nAlternatively, a pin map can be preapred by using the code chunk below.\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\ntm_shape(childcare_sf) +\n  tm_dots()\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\n\n\n\n\n\n\n\nPoints to note\n\n\n\nNotice that at the interactive mode, tmap is using leaflet for R API. The advantage of this interactive pin map is it allows users to navigate and zoom around the map freely. Users can also query the information of each simple feature (i.e. the point) by clicking of them. Last but not least, users can also change the background of the internet map layer. Currently, three internet map layers are provided. They are: ESRI.WorldGrayCanvas, OpenStreetMap, and ESRI.WorldTopoMap. The default is ESRI.WorldGrayCanvas.\n\n\n\n\n\n\n\n\nReminder\n\n\n\nAlways remember to switch back to plot mode after the interactive map. This is because, each interactive mode will consume a connection. Users should also avoid displaying excessive numbers of interactive maps (i.e. not more than 10) in one RMarkdown document when publishing on Netlify.\n\n\n\n\n\n\nAlthough simple feature data frame is gaining popularity against sp’s Spatial classes, there are, however, many geospatial analysis packages which require the input geospatial data be in sp’s Spatial classes. In this section, we will learn how to convert simple feature data frame to sp’s Spatial class.\n\n\nThe as.ppp() function of spatstat is used to convert the spatial data into spatstat’s ppp object format.\n\nchildcare_ppp &lt;- as.ppp(childcare_sf)\n\nWarning in as.ppp.sf(childcare_sf): only first attribute column is used for\nmarks\n\nchildcare_ppp\n\nMarked planar point pattern: 1545 points\nmarks are of storage type  'character'\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n\n\nPlotting childcare_ppp and examining the differences.\n\nplot(childcare_ppp)\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 1545 symbols are shown in the symbol map\n\n\n\n\n\n\n\n\n\nsummary statistics of the newly created ppp object by using the code chunk below\n\nsummary(childcare_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1545 character character \n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\n\n\n\n\n\n\n\nWarning\n\n\n\nNotice the warning message about duplicates. In spatial point patterns analysis an issue of significance is the presence of duplicates. The statistical methodology used for spatial point patterns processes is based largely on the assumption that process are simple, that is, that the points cannot be coincident.\n\n\n\n\n\nChecking of duplication in a ppp object by using the code chunk below.\n\nany(duplicated(childcare_ppp))\n\n[1] FALSE\n\n\nTo count the number of co-indicence point, multiplicity() function is used as shown in the code chunk below.\n\nmultiplicity(childcare_ppp)\n\n   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [75] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [112] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [149] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [186] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [223] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [260] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [297] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [334] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [371] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [408] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [445] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [482] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [519] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [556] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [593] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [630] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [667] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [704] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [741] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [778] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [815] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [852] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [889] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [926] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [963] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1000] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1037] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1074] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1111] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1148] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1185] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1222] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1259] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1296] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1333] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1370] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1407] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1444] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1481] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1518] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n\n\nTo know how many locations have more than one point event, we can use the code chunk below.\n\nsum(multiplicity(childcare_ppp) &gt; 1)\n\n[1] 0\n\n\nThe output shows that there are 0 duplicated point events.\nTo view the locations of these duplicate point events, the childcare data can be plotted by using the code chunk below.\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\ntm_shape(childcare_sf) +\n  tm_dots(alpha = 0.4,\n          size = 0.05)\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\n\nThere are three ways to overcome the problem of duplication.The easiest way is to delete the duplicates. But, that will also mean that some useful point events will be lost.\nThe second solution is to use jittering, which will add a small perturbation to the duplicate points so that they do not occupy the exact same space.\nThe third solution is to make each point “unique” and then attach the duplicates of the points to the patterns as marks, as attributes of the points. Then analytical techniques can be carried out that take into account these marks.\nThe code chunk below implements the jittering approach.\n\nchildcare_ppp_jit &lt;- rjitter(childcare_ppp,\n                             retry = TRUE,\n                             nsim = 1,\n                             drop = TRUE)\n\nThe code chunk below is used to check if there are any duplicated points in the geospatial data.\n\nany(duplicated(childcare_ppp_jit))\n\n[1] FALSE\n\n\n\n\n\nWhen analysing spatial point patterns, it is a good practice to confine the analysis with a geographical area like Singapore boundary. In spatstat, an object called owin is specially designed to represent this polygonal region.\nThe code chunk below is used to covert sg SpatialPolygon object into owin object of spatstat.\n\nsg_owin &lt;- as.owin(sg_sf)\n\nThe output object can be displayed by using plot() function\n\nplot(sg_owin)\n\n\n\n\n\n\n\n\nThe summary() function of Base R is also utilised\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\n\n\n\nIn this final stage of geospatial data wrangling, extraction of childcare events that are located within Singapore is carried out by using the code chunk below.\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\n\nThe output object combines both the point and polygon feature in one ppp object class as shown below.\n\nsummary(childcareSG_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 2.129929e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1545 character character \n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\nThe newly derived childcareSG_ppp as shown below is plotted using code chunk below.\n\nplot(childcareSG_ppp)\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 1545 symbols are shown in the symbol map\n\n\n\n\n\n\n\n\n\n\n\nCode chunk below will be used to extract the target planning areas.\n\npg &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"PUNGGOL\")\ntm &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"TAMPINES\")\nck &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"CHOA CHU KANG\")\njw &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"JURONG WEST\")\n\nPlot of target planning areas\n\npar(mfrow = c(2,2))\nplot(pg, main = \"Punggol\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\nplot(tm, main = \"Tampines\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\nplot(ck, main = \"Choa Chu Kang\")\n\nWarning: plotting the first 10 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\nplot(jw, main = \"Jurong West\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\n\n\nIn this section, the sf objects will be converted into owin objects that are required by spatstat.\n\npg_owin = as.owin(pg)\ntm_owin = as.owin(tm)\nck_owin = as.owin(ck)\njw_owin = as.owin(jw)\n\n\n\n\nCode chunk below is used to extract childcare that is within the specific region to do analysis later on.\n\nchildcare_pg_ppp = childcare_ppp_jit[pg_owin]\nchildcare_tm_ppp = childcare_ppp_jit[tm_owin]\nchildcare_ck_ppp = childcare_ppp_jit[ck_owin]\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\n\nrescale() function is used to trasnform the unit of measurement from metre to kilometres.\n\nchildcare_pg_ppp.km = rescale(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale(childcare_jw_ppp, 1000, \"km\")\n\nCode chunk below is used to plot these four study areas and the respective locations of the childcare centres.\n\npar(mfrow = c(2,2))\nplot(childcare_pg_ppp.km, main = \"Punggol\")\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 61 symbols are shown in the symbol map\n\nplot(childcare_tm_ppp.km, main = \"Tampines\")\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 89 symbols are shown in the symbol map\n\nplot(childcare_ck_ppp.km, main = \"Choa Chu Kang\")\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 61 symbols are shown in the symbol map\n\nplot(childcare_jw_ppp.km, main = \"Jurong West\")\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 88 symbols are shown in the symbol map\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe G function measures the distribution of the distances from an arbitrary event to its nearest event. In this section, we will learn how to compute G-function estimation by using Gest() of spatstat package. We will also learn how to perform a monte carlo simulation test using envelope() of spatstat package.\n\n\n\n\nThe code chunk below is used to compute G-function using Gest() of spatat package.\n\nG_CK = Gest(childcare_ck_ppp, correction = \"border\")\nplot(G_CK, xlim = c(0,500))\n\n\n\n\n\n\n\n\n\n\n\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with G-function\n\nG_CK.csr &lt;- envelope(childcare_ck_ppp, Gest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(G_CK.csr)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nG_TM = Gest(childcare_tm_ppp, correction = \"best\")\nplot(G_TM)\n\n\n\n\n\n\n\n\n\n\n\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected is p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nG_TM.csr &lt;- envelope(childcare_tm_ppp, Gest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(G_TM.csr)\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe F function estimates the empty space function F(r) or its hazard rate h(r) from a point pattern in a window of arbitrary shape. In this section, we will learn how to compute F-function estimation by using Fest() of spatstat package. We will also learn how to perform monta carlo simulation test using envelope() of spatstat package.\n\n\n\n\nThe code chunk below is used to compute F-function using Fest() of spatstat package.\n\nF_CK = Fest(childcare_ck_ppp)\nplot(F_CK)\n\n\n\n\n\n\n\n\n\n\n\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with F-function\n\nF_CK.csr &lt;- envelope(childcare_ck_ppp, Fest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(F_CK.csr)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMonte Carlo test with F-function\n\nF_TM = Fest(childcare_tm_ppp, correction = \"best\")\nplot(F_TM)\n\n\n\n\n\n\n\n\n\n\n\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected is p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nF_TM.csr &lt;- envelope(childcare_tm_ppp, Fest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(F_TM.csr)\n\n\n\n\n\n\n\n\n\n\n\n\n\nK-function measures the number of events found up to a given distance of any particular event. In this section, an attempt to compute K-function estimates by using Kest() of spatstat package. We will also learn how to perform monte carlo simulation test using envelope() of spatstat package.\n\n\n\n\n\nK_CK = Kest(childcare_ck_ppp, correction = \"Ripley\")\nplot(K_CK, . -r ~ r, ylab= \"K(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n\n\n\n\n\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nK_CK.csr &lt;- envelope(childcare_ck_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(K_CK.csr, . - r ~ r, xlab=\"d\", ylab=\"K(d)-r\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nK_TM = Kest(childcare_tm_ppp, correction = \"Ripley\")\nplot(K_TM, . -r ~ r, \n     ylab= \"K(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n\n\n\n\n\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nK_TM.csr &lt;- envelope(childcare_tm_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(K_TM.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"K(d)-r\", xlim=c(0,500))\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn this section, we will learn how to compute L-function estimation by using Lest() of spatstat package. Similarly, we will also learn how to perform monte carlo simulation test using envelope() of spatstat package.\n\n\n\n\n\nL_CK = Lest(childcare_ck_ppp, correction = \"Ripley\")\nplot(L_CK, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n\n\n\n\n\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value if smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nL_CK.csr &lt;- envelope(childcare_ck_ppp, Lest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(L_CK.csr, . - r ~ r, xlab=\"d\", ylab=\"L(d)-r\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nL_TM = Lest(childcare_tm_ppp, correction = \"Ripley\")\nplot(L_TM, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n\n\n\n\n\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nThe code chunk below will be used to perform the hypothesis testing.\n\nL_TM.csr &lt;- envelope(childcare_tm_ppp, Lest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\nFinally, to plot the model output by using the code chunk below.\n\nplot(L_TM.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"L(d)-r\", xlim=c(0,500))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#overview",
    "title": "Hands-on Exercise 2b: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "Spatial Point Pattern Analysis is the evaluation of the pattern or distribution, of a set of points on a surface. The point can be locations of:\n\nevents such as crime, traffic accidents and disease onset, or\nbusiness services (coffee and fast food outlets) or facilities such as childcare and elder care centres.\n\nBy using appropriate functions of spatstat, this hands-on exercise aims to discover the spatial point processes of childcare centres in Singapore.\nThe specific questions we would like to answer are as follows:\n\nare the childcare centres in Singapore randomly distributed throughout the country?\n\nif the answer is no, then the next logical question is where are the locations with higher concentration of childcare centres?"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#the-data",
    "title": "Hands-on Exercise 2b: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "Three data sets will be used to provide answers to the questions above, they are:\n\nCHILDCARE, a point feature data providing both location and attribute information of childcare centres. It was downloaded from Data.gov.sg and is in geojson format.\nMP14_SUBZONE_WEB_PL, a polygon feature data providing information of URA 2014 Master Plan Planning Subzone boundary data. It is in ESRI shapefile format. This data set was also downloaded from Data.gov.sg.\nCostalOutline, a polygon feature data showing the national boundary of Singapore. It is provided by SLA and is in ESRI shapefile format."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#installing-and-loading-the-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#installing-and-loading-the-r-packages",
    "title": "Hands-on Exercise 2b: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "In this hands-on exercise, five R packages will be used, they are:\n\nsf, a relatively new R package specially designed to import, manage and process vector-based geospatial data in R.\nspatstat, which has a wide range of useful functions for point pattern analysis. In this hands-on exercise, it will be used to perform 1st- and 2nd-order spatial point patterns analysis and derive kernel density estimation (KDE) layer.\nraster which reads, writes, manipulates, analyses and model of gridded spatial data (i.e. raster). In this hands-on exercise, it will be used to convert image output generate by spatstat into raster format.\nmaptools which provides a set of tools for manipulating geographic data. In this hands-on exercise, we mainly use it to convert Spatial objects into ppp format of spatstat.\ntmap which provides functions for plotting cartographic quality static point patterns maps or interactive maps by using leaflet API.\n\nThe code chunk below is used to install and launch the five R packages.\n\npacman::p_load(sf, raster, spatstat, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#spatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#spatial-data-wrangling",
    "title": "Hands-on Exercise 2b: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "In this section, st_read() of sf package will be used to import these three geospatial data sets into R.\n\nchildcare_sf &lt;- st_read(\"data/child-care-services-geojson.geojson\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `child-care-services-geojson' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nsg_sf &lt;- st_read(dsn = \"data\", layer = \"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data' using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\n\nmpsz_sf &lt;- st_read(dsn = \"data\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nBefore using these data for analysis, it is important to ensure that they are projected in same projection system.\nCode chunk below will retrieve the referencing system information of these geospatial data.\n\nst_crs(childcare_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\nst_crs(sg_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\nst_crs(mpsz_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nNotice that except childcare_sf, both sg_sf and mpsz_sf do not have proper crs information.\nThe code chunk below will assign the correct crs to sg_sf and mpsz_sf simple feature data frames in relation to the referencing system of Singapore’s national projected coordinate system.\n\nsg_sf &lt;- st_set_crs(sg_sf, 3414)\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\n\nChecking the CSR of sg_sf using code chunk below.\n\nst_crs(sg_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\nmpsz_sf &lt;- st_set_crs(mpsz_sf, 3414)\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\n\nChecking the CSR again by using the code chunk below.\n\nst_crs(mpsz_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\n\nAfter checking the referencing system of each geospatial data data frame, it is also useful to plot a map to show their spatial patterns.\n\ntm_shape(sg_sf) +\n  tm_polygons() +\ntm_shape(mpsz_sf) +\n  tm_polygons() +\ntm_shape(childcare_sf) +\n  tm_dots()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nAll the geospatial layers are within the same map extend. This shows that their referencing system and coordinate values are referred to a similar spatial context. This is very important in any geospatial analysis.\n\n\nAlternatively, a pin map can be preapred by using the code chunk below.\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\ntm_shape(childcare_sf) +\n  tm_dots()\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\n\n\n\n\n\n\n\nPoints to note\n\n\n\nNotice that at the interactive mode, tmap is using leaflet for R API. The advantage of this interactive pin map is it allows users to navigate and zoom around the map freely. Users can also query the information of each simple feature (i.e. the point) by clicking of them. Last but not least, users can also change the background of the internet map layer. Currently, three internet map layers are provided. They are: ESRI.WorldGrayCanvas, OpenStreetMap, and ESRI.WorldTopoMap. The default is ESRI.WorldGrayCanvas.\n\n\n\n\n\n\n\n\nReminder\n\n\n\nAlways remember to switch back to plot mode after the interactive map. This is because, each interactive mode will consume a connection. Users should also avoid displaying excessive numbers of interactive maps (i.e. not more than 10) in one RMarkdown document when publishing on Netlify."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#geospatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#geospatial-data-wrangling",
    "title": "Hands-on Exercise 2b: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "Although simple feature data frame is gaining popularity against sp’s Spatial classes, there are, however, many geospatial analysis packages which require the input geospatial data be in sp’s Spatial classes. In this section, we will learn how to convert simple feature data frame to sp’s Spatial class.\n\n\nThe as.ppp() function of spatstat is used to convert the spatial data into spatstat’s ppp object format.\n\nchildcare_ppp &lt;- as.ppp(childcare_sf)\n\nWarning in as.ppp.sf(childcare_sf): only first attribute column is used for\nmarks\n\nchildcare_ppp\n\nMarked planar point pattern: 1545 points\nmarks are of storage type  'character'\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n\n\nPlotting childcare_ppp and examining the differences.\n\nplot(childcare_ppp)\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 1545 symbols are shown in the symbol map\n\n\n\n\n\n\n\n\n\nsummary statistics of the newly created ppp object by using the code chunk below\n\nsummary(childcare_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1545 character character \n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\n\n\n\n\n\n\n\nWarning\n\n\n\nNotice the warning message about duplicates. In spatial point patterns analysis an issue of significance is the presence of duplicates. The statistical methodology used for spatial point patterns processes is based largely on the assumption that process are simple, that is, that the points cannot be coincident.\n\n\n\n\n\nChecking of duplication in a ppp object by using the code chunk below.\n\nany(duplicated(childcare_ppp))\n\n[1] FALSE\n\n\nTo count the number of co-indicence point, multiplicity() function is used as shown in the code chunk below.\n\nmultiplicity(childcare_ppp)\n\n   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [75] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [112] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [149] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [186] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [223] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [260] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [297] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [334] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [371] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [408] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [445] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [482] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [519] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [556] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [593] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [630] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [667] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [704] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [741] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [778] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [815] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [852] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [889] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [926] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [963] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1000] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1037] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1074] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1111] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1148] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1185] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1222] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1259] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1296] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1333] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1370] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1407] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1444] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1481] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1518] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n\n\nTo know how many locations have more than one point event, we can use the code chunk below.\n\nsum(multiplicity(childcare_ppp) &gt; 1)\n\n[1] 0\n\n\nThe output shows that there are 0 duplicated point events.\nTo view the locations of these duplicate point events, the childcare data can be plotted by using the code chunk below.\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\ntm_shape(childcare_sf) +\n  tm_dots(alpha = 0.4,\n          size = 0.05)\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\n\nThere are three ways to overcome the problem of duplication.The easiest way is to delete the duplicates. But, that will also mean that some useful point events will be lost.\nThe second solution is to use jittering, which will add a small perturbation to the duplicate points so that they do not occupy the exact same space.\nThe third solution is to make each point “unique” and then attach the duplicates of the points to the patterns as marks, as attributes of the points. Then analytical techniques can be carried out that take into account these marks.\nThe code chunk below implements the jittering approach.\n\nchildcare_ppp_jit &lt;- rjitter(childcare_ppp,\n                             retry = TRUE,\n                             nsim = 1,\n                             drop = TRUE)\n\nThe code chunk below is used to check if there are any duplicated points in the geospatial data.\n\nany(duplicated(childcare_ppp_jit))\n\n[1] FALSE\n\n\n\n\n\nWhen analysing spatial point patterns, it is a good practice to confine the analysis with a geographical area like Singapore boundary. In spatstat, an object called owin is specially designed to represent this polygonal region.\nThe code chunk below is used to covert sg SpatialPolygon object into owin object of spatstat.\n\nsg_owin &lt;- as.owin(sg_sf)\n\nThe output object can be displayed by using plot() function\n\nplot(sg_owin)\n\n\n\n\n\n\n\n\nThe summary() function of Base R is also utilised\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\n\n\n\nIn this final stage of geospatial data wrangling, extraction of childcare events that are located within Singapore is carried out by using the code chunk below.\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\n\nThe output object combines both the point and polygon feature in one ppp object class as shown below.\n\nsummary(childcareSG_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 2.129929e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1545 character character \n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\nThe newly derived childcareSG_ppp as shown below is plotted using code chunk below.\n\nplot(childcareSG_ppp)\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 1545 symbols are shown in the symbol map\n\n\n\n\n\n\n\n\n\n\n\nCode chunk below will be used to extract the target planning areas.\n\npg &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"PUNGGOL\")\ntm &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"TAMPINES\")\nck &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"CHOA CHU KANG\")\njw &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"JURONG WEST\")\n\nPlot of target planning areas\n\npar(mfrow = c(2,2))\nplot(pg, main = \"Punggol\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\nplot(tm, main = \"Tampines\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\nplot(ck, main = \"Choa Chu Kang\")\n\nWarning: plotting the first 10 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\nplot(jw, main = \"Jurong West\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\n\n\nIn this section, the sf objects will be converted into owin objects that are required by spatstat.\n\npg_owin = as.owin(pg)\ntm_owin = as.owin(tm)\nck_owin = as.owin(ck)\njw_owin = as.owin(jw)\n\n\n\n\nCode chunk below is used to extract childcare that is within the specific region to do analysis later on.\n\nchildcare_pg_ppp = childcare_ppp_jit[pg_owin]\nchildcare_tm_ppp = childcare_ppp_jit[tm_owin]\nchildcare_ck_ppp = childcare_ppp_jit[ck_owin]\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\n\nrescale() function is used to trasnform the unit of measurement from metre to kilometres.\n\nchildcare_pg_ppp.km = rescale(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale(childcare_jw_ppp, 1000, \"km\")\n\nCode chunk below is used to plot these four study areas and the respective locations of the childcare centres.\n\npar(mfrow = c(2,2))\nplot(childcare_pg_ppp.km, main = \"Punggol\")\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 61 symbols are shown in the symbol map\n\nplot(childcare_tm_ppp.km, main = \"Tampines\")\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 89 symbols are shown in the symbol map\n\nplot(childcare_ck_ppp.km, main = \"Choa Chu Kang\")\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 61 symbols are shown in the symbol map\n\nplot(childcare_jw_ppp.km, main = \"Jurong West\")\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 88 symbols are shown in the symbol map"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#analysing-spatial-point-process-using-g-function",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#analysing-spatial-point-process-using-g-function",
    "title": "Hands-on Exercise 2b: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "The G function measures the distribution of the distances from an arbitrary event to its nearest event. In this section, we will learn how to compute G-function estimation by using Gest() of spatstat package. We will also learn how to perform a monte carlo simulation test using envelope() of spatstat package.\n\n\n\n\nThe code chunk below is used to compute G-function using Gest() of spatat package.\n\nG_CK = Gest(childcare_ck_ppp, correction = \"border\")\nplot(G_CK, xlim = c(0,500))\n\n\n\n\n\n\n\n\n\n\n\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with G-function\n\nG_CK.csr &lt;- envelope(childcare_ck_ppp, Gest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(G_CK.csr)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nG_TM = Gest(childcare_tm_ppp, correction = \"best\")\nplot(G_TM)\n\n\n\n\n\n\n\n\n\n\n\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected is p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nG_TM.csr &lt;- envelope(childcare_tm_ppp, Gest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(G_TM.csr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#analysing-spatial-point-process-using-f-function",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#analysing-spatial-point-process-using-f-function",
    "title": "Hands-on Exercise 2b: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "The F function estimates the empty space function F(r) or its hazard rate h(r) from a point pattern in a window of arbitrary shape. In this section, we will learn how to compute F-function estimation by using Fest() of spatstat package. We will also learn how to perform monta carlo simulation test using envelope() of spatstat package.\n\n\n\n\nThe code chunk below is used to compute F-function using Fest() of spatstat package.\n\nF_CK = Fest(childcare_ck_ppp)\nplot(F_CK)\n\n\n\n\n\n\n\n\n\n\n\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with F-function\n\nF_CK.csr &lt;- envelope(childcare_ck_ppp, Fest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(F_CK.csr)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMonte Carlo test with F-function\n\nF_TM = Fest(childcare_tm_ppp, correction = \"best\")\nplot(F_TM)\n\n\n\n\n\n\n\n\n\n\n\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected is p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nF_TM.csr &lt;- envelope(childcare_tm_ppp, Fest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(F_TM.csr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#analysing-spatial-point-process-using-k-function",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#analysing-spatial-point-process-using-k-function",
    "title": "Hands-on Exercise 2b: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "K-function measures the number of events found up to a given distance of any particular event. In this section, an attempt to compute K-function estimates by using Kest() of spatstat package. We will also learn how to perform monte carlo simulation test using envelope() of spatstat package.\n\n\n\n\n\nK_CK = Kest(childcare_ck_ppp, correction = \"Ripley\")\nplot(K_CK, . -r ~ r, ylab= \"K(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n\n\n\n\n\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nK_CK.csr &lt;- envelope(childcare_ck_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(K_CK.csr, . - r ~ r, xlab=\"d\", ylab=\"K(d)-r\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nK_TM = Kest(childcare_tm_ppp, correction = \"Ripley\")\nplot(K_TM, . -r ~ r, \n     ylab= \"K(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n\n\n\n\n\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nK_TM.csr &lt;- envelope(childcare_tm_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(K_TM.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"K(d)-r\", xlim=c(0,500))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#analysing-spatial-point-process-using-l-function",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#analysing-spatial-point-process-using-l-function",
    "title": "Hands-on Exercise 2b: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "In this section, we will learn how to compute L-function estimation by using Lest() of spatstat package. Similarly, we will also learn how to perform monte carlo simulation test using envelope() of spatstat package.\n\n\n\n\n\nL_CK = Lest(childcare_ck_ppp, correction = \"Ripley\")\nplot(L_CK, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n\n\n\n\n\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value if smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nL_CK.csr &lt;- envelope(childcare_ck_ppp, Lest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(L_CK.csr, . - r ~ r, xlab=\"d\", ylab=\"L(d)-r\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nL_TM = Lest(childcare_tm_ppp, correction = \"Ripley\")\nplot(L_TM, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n\n\n\n\n\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nThe code chunk below will be used to perform the hypothesis testing.\n\nL_TM.csr &lt;- envelope(childcare_tm_ppp, Lest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\nFinally, to plot the model output by using the code chunk below.\n\nplot(L_TM.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"L(d)-r\", xlim=c(0,500))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/data/MPSZ-2019.html",
    "href": "In-class_Ex/In-class_Ex01/data/MPSZ-2019.html",
    "title": "ISSS626-GAA",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "title": "In-class Exercise 2",
    "section": "",
    "text": "maptools is already retired and binary is removed from CRAN. However, we can download it from Posit Public Package Manager snapshots by using the code chunk below.\n\ninstall.packages(\"maptools\",\n                 repos = \"https://packagemanager.posit.co/cran/2023-10-13\")\n\nHowever, after installation is completed it is important to note the usage of code chunk below to avoid maptools from being re-downloaded and being installed repetitively every time the Quarto document has been rendered.\n\n\n\n\n\npacman::p_load(sf, raster, spatstat, tmap, tidyverse)\n\n\n\n\nIn sf package, there are two functions that allow us to combine multiple simple features into one simple features. They are st_combine() and st_union().\n\nst_combine() returns a single, combined geometry, with no resolved boundaries; returned geometries may well be invalid.\nIf y is missing, st_union(x) returns a single geometry with resolved boundaries, else the geometries for all union-ed pairs of x[i] and y[j].\n\n\nchildcare_sf &lt;- st_read(\"data/child-care-services-geojson.geojson\") %&gt;%\n  st_transform(crs = 3414)\n\n\nmpsz_sf &lt;- st_read(dsn = \"data\", layer=\"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\zjho008\\ISSS626-GAA\\In-class_Ex\\In-class_Ex02\\data' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\n\nIn code chunk below, st_union() is used to derive the coastal outline sf tibble data.frame\n\nsg_sf &lt;- mpsz_sf %&gt;%\n  st_union()\n\nsg_sf will look similar to the figure shown below using the following code chunk:\n\nplot(sg_sf)\n\n\n\n\n\n\n\n\n\n\n\nspatstat R package is a comprehensive open-source toolbox for analysing Spatial Point Patterns. It focuses on two-dimensional point patterns, including multi-type or marked points, in any spatial region.\n\n\n\n\n\n\nThe spatstat package now contains only documentation and introductory material. It provides beginner’s introductions, vignettes, interactive demonstration scripts, and a few help files summarising the package.\nThe spatstat.data package now contains all the datasets for spatstat.\nThe spatstat.utils package contains basic utility functions for spatstat.\nThe spatstat.univar package contains functions for estimating and manipulating probability distributions of one-dimensional random variables.\nThe spatstat.sparse package contains functions for manipulating sparse arrays and performing linear algebra.\nThe spatstat.geom package contains definitions of spatial objects (such as point patterns, windows and pixel images) and code which performs geometrical operations.\nThe spatstat.random package contains functions for random generation of spatial patterns and random simulation of models.\nThe spatstat.explore package contains the code for exploratory data analysis and nonparametric analysis of spatial data.\nThe spatstat.model package contains the code for model-fitting, model diagnostics, and formal inference.\nThe spatstat.linnet package defines spatial data on a linear network, and performs geometrical operations and statistical analysis on such data.\n\n\n\n\n\nWorking with sf data.frame\nIn the code chunk below, as.ppp() of spatstat.geom package is used to derive a ppp object layer directly from a sf tibble data.frame.\n\nchildcare_ppp &lt;- as.ppp(childcare_sf)\n\nWarning in as.ppp.sf(childcare_sf): only first attribute column is used for\nmarks\n\nplot(childcare_ppp)\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 1545 symbols are shown in the symbol map\n\n\n\n\n\n\n\n\n\nsummary() function is used to reveal properties of the ppp object created\n\nsummary(childcare_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1545 character character \n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\n\n\n\n\nThe code chunk as.owin() of spatstat.geom is used to create an owin object class from polygon sf tibble data.frame.\n\nsg_owin &lt;- as.owin(sg_sf)\nplot(sg_owin)\n\n\n\n\n\n\n\n\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n80 separate polygons (35 holes)\n                  vertices         area relative.area\npolygon 1            14650  6.97996e+08      8.93e-01\npolygon 2 (hole)         3 -2.21090e+00     -2.83e-09\npolygon 3              285  1.61128e+06      2.06e-03\npolygon 4 (hole)         3 -2.05920e-03     -2.63e-12\npolygon 5 (hole)         3 -8.83647e-03     -1.13e-11\npolygon 6              668  5.40368e+07      6.91e-02\npolygon 7               44  2.26577e+03      2.90e-06\npolygon 8               27  1.50315e+04      1.92e-05\npolygon 9              711  1.28815e+07      1.65e-02\npolygon 10 (hole)       36 -4.01660e+04     -5.14e-05\npolygon 11 (hole)      317 -5.11280e+04     -6.54e-05\npolygon 12 (hole)        3 -3.41405e-01     -4.37e-10\npolygon 13 (hole)        3 -2.89050e-05     -3.70e-14\npolygon 14              77  3.29939e+05      4.22e-04\npolygon 15              30  2.80002e+04      3.58e-05\npolygon 16 (hole)        3 -2.83151e-01     -3.62e-10\npolygon 17              71  8.18750e+03      1.05e-05\npolygon 18 (hole)        3 -1.68316e-04     -2.15e-13\npolygon 19 (hole)       36 -7.79904e+03     -9.97e-06\npolygon 20 (hole)        4 -2.05611e-02     -2.63e-11\npolygon 21 (hole)        3 -2.18000e-06     -2.79e-15\npolygon 22 (hole)        3 -3.65501e-03     -4.67e-12\npolygon 23 (hole)        3 -4.95057e-02     -6.33e-11\npolygon 24 (hole)        3 -3.99521e-02     -5.11e-11\npolygon 25 (hole)        3 -6.62377e-01     -8.47e-10\npolygon 26 (hole)        3 -2.09065e-03     -2.67e-12\npolygon 27              91  1.49663e+04      1.91e-05\npolygon 28 (hole)       26 -1.25665e+03     -1.61e-06\npolygon 29 (hole)      349 -1.21433e+03     -1.55e-06\npolygon 30 (hole)       20 -4.39069e+00     -5.62e-09\npolygon 31 (hole)       48 -1.38338e+02     -1.77e-07\npolygon 32 (hole)       28 -1.99862e+01     -2.56e-08\npolygon 33              40  1.38607e+04      1.77e-05\npolygon 34 (hole)       40 -6.00381e+03     -7.68e-06\npolygon 35 (hole)        7 -1.40545e-01     -1.80e-10\npolygon 36 (hole)       12 -8.36709e+01     -1.07e-07\npolygon 37              45  2.51218e+03      3.21e-06\npolygon 38             142  3.22293e+03      4.12e-06\npolygon 39             148  3.10395e+03      3.97e-06\npolygon 40              75  1.73526e+04      2.22e-05\npolygon 41              83  5.28920e+03      6.76e-06\npolygon 42             211  4.70521e+05      6.02e-04\npolygon 43             106  3.04104e+03      3.89e-06\npolygon 44             266  1.50631e+06      1.93e-03\npolygon 45              71  5.63061e+03      7.20e-06\npolygon 46              10  1.99717e+02      2.55e-07\npolygon 47             478  2.06120e+06      2.64e-03\npolygon 48             155  2.67502e+05      3.42e-04\npolygon 49            1027  1.27782e+06      1.63e-03\npolygon 50 (hole)        3 -1.16959e-03     -1.50e-12\npolygon 51              65  8.42861e+04      1.08e-04\npolygon 52              47  3.82087e+04      4.89e-05\npolygon 53               6  4.50259e+02      5.76e-07\npolygon 54             132  9.53357e+04      1.22e-04\npolygon 55 (hole)        3 -3.23310e-04     -4.13e-13\npolygon 56               4  2.69313e+02      3.44e-07\npolygon 57 (hole)        3 -1.46474e-03     -1.87e-12\npolygon 58            1045  4.44510e+06      5.68e-03\npolygon 59              22  6.74651e+03      8.63e-06\npolygon 60              64  3.43149e+04      4.39e-05\npolygon 61 (hole)        3 -1.98390e-03     -2.54e-12\npolygon 62 (hole)        4 -1.13774e-02     -1.46e-11\npolygon 63              14  5.86546e+03      7.50e-06\npolygon 64              95  5.96187e+04      7.62e-05\npolygon 65 (hole)        4 -1.86410e-02     -2.38e-11\npolygon 66 (hole)        3 -5.12482e-03     -6.55e-12\npolygon 67 (hole)        3 -1.96410e-03     -2.51e-12\npolygon 68 (hole)        3 -5.55856e-03     -7.11e-12\npolygon 69             234  2.08755e+06      2.67e-03\npolygon 70              10  4.90942e+02      6.28e-07\npolygon 71             234  4.72886e+05      6.05e-04\npolygon 72 (hole)       13 -3.91907e+02     -5.01e-07\npolygon 73              15  4.03300e+04      5.16e-05\npolygon 74             227  1.10308e+06      1.41e-03\npolygon 75              10  6.60195e+03      8.44e-06\npolygon 76              19  3.09221e+04      3.95e-05\npolygon 77             145  9.61782e+05      1.23e-03\npolygon 78              30  4.28933e+03      5.49e-06\npolygon 79              37  1.29481e+04      1.66e-05\npolygon 80               4  9.47108e+01      1.21e-07\nenclosing rectangle: [2667.54, 56396.44] x [15748.72, 50256.33] units\n                     (53730 x 34510 units)\nWindow area = 781945000 square units\nFraction of frame area: 0.422\n\n\n\n\n\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\n\nFollowing which the output combines both the point and polygon feature in one ppp object class as shown in the code chunk below.\n\nplot(childcareSG_ppp)\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 1545 symbols are shown in the symbol map\n\n\n\n\n\n\n\n\n\n\n\n\nCode chunk below is used to re-scale the unit of measurement from metres to kilometres before KDE is performed.\n\nchildcareSG_ppp.km &lt;- rescale.ppp(childcareSG_ppp, 1000, \"km\")\n\n\nkde_childcareSG_adaptive &lt;- adaptive.density(childcareSG_ppp.km,\n                                             method = \"kernel\")\n\nplot(kde_childcareSG_adaptive)\n\n\n\n\n\n\n\n\n\n\n\nThe code chunk shows two different ways to convert KDE output into grid objects\n\nmaptools methodspatstat.geom method\n\n\nmaptool must be installed for this method\n\npar(bg = '#E4D5C9')\n\n\ngridded_kde_childcareSG_ad &lt;- maptools::as.SpatialGridDataFrame.im(\n  kde_childcareSG_adaptive)\n\nPlease note that 'maptools' will be retired during October 2023,\nplan transition at your earliest convenience (see\nhttps://r-spatial.org/r/2023/05/15/evolution4.html and earlier blogs\nfor guidance);some functionality will be moved to 'sp'.\n Checking rgeos availability: FALSE\n\nspplot(gridded_kde_childcareSG_ad)\n\n\n\n\n\n\n\n\n\n\n\ngridded_kde_childcareSG_ad &lt;- as(kde_childcareSG_adaptive,\n                                 \"SpatialGridDataFrame\")\n\nspplot(gridded_kde_childcareSG_ad)\n\n\n\n\n\n\n\n\nBoth methods have simialr or otherwise the same results however usage if spatstat.geom is preferred as maptools has been retired\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nIn order to ensure reproducibility, it is important to include the code chunk below before using spatial spatstat functions involving Monte Carlo simulation\nWithout doing so f values for instance might change each time the code chunk is ran.\n\nset.seed(1234)\n\n\n\n\n\n\n\n\n\nRoad traffic injuries, WHO.\nRoad traffic deaths and injuries in Thailand\n\nThe study area comprises of the Bangkok Metropolitan Region.\n\n\n\n\n\n\nNote\n\n\n\nProjected coordinate system of Thailand is WGS 84 / UTM zone 47N and the EPSG code is 32647.\n\n\n\n\n\n\nFor this case study, three basic data sets are needed, they are:\n\nThailand Road Accident [2019-2022] on Kaggle\nThailand Roads (OpenStreetMap Export) on HDX.\nThailand - Subnational Administrative Boundaries on HDX.\n\n\n\n\nImporting the downloaded accident data into R environment and saving the output as an sf tibble data.frame.\n\nrdacc_sf &lt;- read_csv(\"data/Thailand/archive/thai_road_accident_2019_2022.csv\") %&gt;%\n  filter(!is.na(longitude) & longitude != \"\",\n         !is.na(latitude) & latitude != \"\") %&gt;%\n  st_as_sf(coords = c(\n    \"longitude\", \"latitude\"),\n    crs = 4326) %&gt;%\n  st_transform(crs = 32647)\n\nRows: 81735 Columns: 18\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (10): province_th, province_en, agency, route, vehicle_type, presumed_c...\ndbl   (6): acc_code, number_of_vehicles_involved, number_of_fatalities, numb...\ndttm  (2): incident_datetime, report_datetime\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nImporting the ACLED data into R environment as an sf tibble data.frame."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#issue-1-installing-maptools",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#issue-1-installing-maptools",
    "title": "In-class Exercise 2",
    "section": "",
    "text": "maptools is already retired and binary is removed from CRAN. However, we can download it from Posit Public Package Manager snapshots by using the code chunk below.\n\ninstall.packages(\"maptools\",\n                 repos = \"https://packagemanager.posit.co/cran/2023-10-13\")\n\nHowever, after installation is completed it is important to note the usage of code chunk below to avoid maptools from being re-downloaded and being installed repetitively every time the Quarto document has been rendered."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#loading-r-packages",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#loading-r-packages",
    "title": "In-class Exercise 2",
    "section": "",
    "text": "pacman::p_load(sf, raster, spatstat, tmap, tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#issue-2-creating-coastal-outline",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#issue-2-creating-coastal-outline",
    "title": "In-class Exercise 2",
    "section": "",
    "text": "In sf package, there are two functions that allow us to combine multiple simple features into one simple features. They are st_combine() and st_union().\n\nst_combine() returns a single, combined geometry, with no resolved boundaries; returned geometries may well be invalid.\nIf y is missing, st_union(x) returns a single geometry with resolved boundaries, else the geometries for all union-ed pairs of x[i] and y[j].\n\n\nchildcare_sf &lt;- st_read(\"data/child-care-services-geojson.geojson\") %&gt;%\n  st_transform(crs = 3414)\n\n\nmpsz_sf &lt;- st_read(dsn = \"data\", layer=\"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\zjho008\\ISSS626-GAA\\In-class_Ex\\In-class_Ex02\\data' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#working-with-st_union",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#working-with-st_union",
    "title": "In-class Exercise 2",
    "section": "",
    "text": "In code chunk below, st_union() is used to derive the coastal outline sf tibble data.frame\n\nsg_sf &lt;- mpsz_sf %&gt;%\n  st_union()\n\nsg_sf will look similar to the figure shown below using the following code chunk:\n\nplot(sg_sf)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#spatstat-package",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#spatstat-package",
    "title": "In-class Exercise 2",
    "section": "",
    "text": "spatstat R package is a comprehensive open-source toolbox for analysing Spatial Point Patterns. It focuses on two-dimensional point patterns, including multi-type or marked points, in any spatial region."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#spatstat",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#spatstat",
    "title": "In-class Exercise 2",
    "section": "",
    "text": "The spatstat package now contains only documentation and introductory material. It provides beginner’s introductions, vignettes, interactive demonstration scripts, and a few help files summarising the package.\nThe spatstat.data package now contains all the datasets for spatstat.\nThe spatstat.utils package contains basic utility functions for spatstat.\nThe spatstat.univar package contains functions for estimating and manipulating probability distributions of one-dimensional random variables.\nThe spatstat.sparse package contains functions for manipulating sparse arrays and performing linear algebra.\nThe spatstat.geom package contains definitions of spatial objects (such as point patterns, windows and pixel images) and code which performs geometrical operations.\nThe spatstat.random package contains functions for random generation of spatial patterns and random simulation of models.\nThe spatstat.explore package contains the code for exploratory data analysis and nonparametric analysis of spatial data.\nThe spatstat.model package contains the code for model-fitting, model diagnostics, and formal inference.\nThe spatstat.linnet package defines spatial data on a linear network, and performs geometrical operations and statistical analysis on such data."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#creating-ppp-objects-from-sf-data.frame",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#creating-ppp-objects-from-sf-data.frame",
    "title": "In-class Exercise 2",
    "section": "",
    "text": "Working with sf data.frame\nIn the code chunk below, as.ppp() of spatstat.geom package is used to derive a ppp object layer directly from a sf tibble data.frame.\n\nchildcare_ppp &lt;- as.ppp(childcare_sf)\n\nWarning in as.ppp.sf(childcare_sf): only first attribute column is used for\nmarks\n\nplot(childcare_ppp)\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 1545 symbols are shown in the symbol map\n\n\n\n\n\n\n\n\n\nsummary() function is used to reveal properties of the ppp object created\n\nsummary(childcare_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1545 character character \n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#creating-owin-object-from-sf-data.frame",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#creating-owin-object-from-sf-data.frame",
    "title": "In-class Exercise 2",
    "section": "",
    "text": "The code chunk as.owin() of spatstat.geom is used to create an owin object class from polygon sf tibble data.frame.\n\nsg_owin &lt;- as.owin(sg_sf)\nplot(sg_owin)\n\n\n\n\n\n\n\n\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n80 separate polygons (35 holes)\n                  vertices         area relative.area\npolygon 1            14650  6.97996e+08      8.93e-01\npolygon 2 (hole)         3 -2.21090e+00     -2.83e-09\npolygon 3              285  1.61128e+06      2.06e-03\npolygon 4 (hole)         3 -2.05920e-03     -2.63e-12\npolygon 5 (hole)         3 -8.83647e-03     -1.13e-11\npolygon 6              668  5.40368e+07      6.91e-02\npolygon 7               44  2.26577e+03      2.90e-06\npolygon 8               27  1.50315e+04      1.92e-05\npolygon 9              711  1.28815e+07      1.65e-02\npolygon 10 (hole)       36 -4.01660e+04     -5.14e-05\npolygon 11 (hole)      317 -5.11280e+04     -6.54e-05\npolygon 12 (hole)        3 -3.41405e-01     -4.37e-10\npolygon 13 (hole)        3 -2.89050e-05     -3.70e-14\npolygon 14              77  3.29939e+05      4.22e-04\npolygon 15              30  2.80002e+04      3.58e-05\npolygon 16 (hole)        3 -2.83151e-01     -3.62e-10\npolygon 17              71  8.18750e+03      1.05e-05\npolygon 18 (hole)        3 -1.68316e-04     -2.15e-13\npolygon 19 (hole)       36 -7.79904e+03     -9.97e-06\npolygon 20 (hole)        4 -2.05611e-02     -2.63e-11\npolygon 21 (hole)        3 -2.18000e-06     -2.79e-15\npolygon 22 (hole)        3 -3.65501e-03     -4.67e-12\npolygon 23 (hole)        3 -4.95057e-02     -6.33e-11\npolygon 24 (hole)        3 -3.99521e-02     -5.11e-11\npolygon 25 (hole)        3 -6.62377e-01     -8.47e-10\npolygon 26 (hole)        3 -2.09065e-03     -2.67e-12\npolygon 27              91  1.49663e+04      1.91e-05\npolygon 28 (hole)       26 -1.25665e+03     -1.61e-06\npolygon 29 (hole)      349 -1.21433e+03     -1.55e-06\npolygon 30 (hole)       20 -4.39069e+00     -5.62e-09\npolygon 31 (hole)       48 -1.38338e+02     -1.77e-07\npolygon 32 (hole)       28 -1.99862e+01     -2.56e-08\npolygon 33              40  1.38607e+04      1.77e-05\npolygon 34 (hole)       40 -6.00381e+03     -7.68e-06\npolygon 35 (hole)        7 -1.40545e-01     -1.80e-10\npolygon 36 (hole)       12 -8.36709e+01     -1.07e-07\npolygon 37              45  2.51218e+03      3.21e-06\npolygon 38             142  3.22293e+03      4.12e-06\npolygon 39             148  3.10395e+03      3.97e-06\npolygon 40              75  1.73526e+04      2.22e-05\npolygon 41              83  5.28920e+03      6.76e-06\npolygon 42             211  4.70521e+05      6.02e-04\npolygon 43             106  3.04104e+03      3.89e-06\npolygon 44             266  1.50631e+06      1.93e-03\npolygon 45              71  5.63061e+03      7.20e-06\npolygon 46              10  1.99717e+02      2.55e-07\npolygon 47             478  2.06120e+06      2.64e-03\npolygon 48             155  2.67502e+05      3.42e-04\npolygon 49            1027  1.27782e+06      1.63e-03\npolygon 50 (hole)        3 -1.16959e-03     -1.50e-12\npolygon 51              65  8.42861e+04      1.08e-04\npolygon 52              47  3.82087e+04      4.89e-05\npolygon 53               6  4.50259e+02      5.76e-07\npolygon 54             132  9.53357e+04      1.22e-04\npolygon 55 (hole)        3 -3.23310e-04     -4.13e-13\npolygon 56               4  2.69313e+02      3.44e-07\npolygon 57 (hole)        3 -1.46474e-03     -1.87e-12\npolygon 58            1045  4.44510e+06      5.68e-03\npolygon 59              22  6.74651e+03      8.63e-06\npolygon 60              64  3.43149e+04      4.39e-05\npolygon 61 (hole)        3 -1.98390e-03     -2.54e-12\npolygon 62 (hole)        4 -1.13774e-02     -1.46e-11\npolygon 63              14  5.86546e+03      7.50e-06\npolygon 64              95  5.96187e+04      7.62e-05\npolygon 65 (hole)        4 -1.86410e-02     -2.38e-11\npolygon 66 (hole)        3 -5.12482e-03     -6.55e-12\npolygon 67 (hole)        3 -1.96410e-03     -2.51e-12\npolygon 68 (hole)        3 -5.55856e-03     -7.11e-12\npolygon 69             234  2.08755e+06      2.67e-03\npolygon 70              10  4.90942e+02      6.28e-07\npolygon 71             234  4.72886e+05      6.05e-04\npolygon 72 (hole)       13 -3.91907e+02     -5.01e-07\npolygon 73              15  4.03300e+04      5.16e-05\npolygon 74             227  1.10308e+06      1.41e-03\npolygon 75              10  6.60195e+03      8.44e-06\npolygon 76              19  3.09221e+04      3.95e-05\npolygon 77             145  9.61782e+05      1.23e-03\npolygon 78              30  4.28933e+03      5.49e-06\npolygon 79              37  1.29481e+04      1.66e-05\npolygon 80               4  9.47108e+01      1.21e-07\nenclosing rectangle: [2667.54, 56396.44] x [15748.72, 50256.33] units\n                     (53730 x 34510 units)\nWindow area = 781945000 square units\nFraction of frame area: 0.422"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#combining-the-point-events-object-and-owin-object",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#combining-the-point-events-object-and-owin-object",
    "title": "In-class Exercise 2",
    "section": "",
    "text": "childcareSG_ppp = childcare_ppp[sg_owin]\n\nFollowing which the output combines both the point and polygon feature in one ppp object class as shown in the code chunk below.\n\nplot(childcareSG_ppp)\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 1545 symbols are shown in the symbol map"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#kernel-density-estimation-of-spatial-point-events",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#kernel-density-estimation-of-spatial-point-events",
    "title": "In-class Exercise 2",
    "section": "",
    "text": "Code chunk below is used to re-scale the unit of measurement from metres to kilometres before KDE is performed.\n\nchildcareSG_ppp.km &lt;- rescale.ppp(childcareSG_ppp, 1000, \"km\")\n\n\nkde_childcareSG_adaptive &lt;- adaptive.density(childcareSG_ppp.km,\n                                             method = \"kernel\")\n\nplot(kde_childcareSG_adaptive)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#kernel-density-estimation",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#kernel-density-estimation",
    "title": "In-class Exercise 2",
    "section": "",
    "text": "The code chunk shows two different ways to convert KDE output into grid objects\n\nmaptools methodspatstat.geom method\n\n\nmaptool must be installed for this method\n\npar(bg = '#E4D5C9')\n\n\ngridded_kde_childcareSG_ad &lt;- maptools::as.SpatialGridDataFrame.im(\n  kde_childcareSG_adaptive)\n\nPlease note that 'maptools' will be retired during October 2023,\nplan transition at your earliest convenience (see\nhttps://r-spatial.org/r/2023/05/15/evolution4.html and earlier blogs\nfor guidance);some functionality will be moved to 'sp'.\n Checking rgeos availability: FALSE\n\nspplot(gridded_kde_childcareSG_ad)\n\n\n\n\n\n\n\n\n\n\n\ngridded_kde_childcareSG_ad &lt;- as(kde_childcareSG_adaptive,\n                                 \"SpatialGridDataFrame\")\n\nspplot(gridded_kde_childcareSG_ad)\n\n\n\n\n\n\n\n\nBoth methods have simialr or otherwise the same results however usage if spatstat.geom is preferred as maptools has been retired"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#monte-carlo-simulation",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#monte-carlo-simulation",
    "title": "In-class Exercise 2",
    "section": "",
    "text": "Tip\n\n\n\nIn order to ensure reproducibility, it is important to include the code chunk below before using spatial spatstat functions involving Monte Carlo simulation\nWithout doing so f values for instance might change each time the code chunk is ran.\n\nset.seed(1234)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#geospatial-analytics-for-social-good-thailand-road-accident-case-study",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#geospatial-analytics-for-social-good-thailand-road-accident-case-study",
    "title": "In-class Exercise 2",
    "section": "",
    "text": "Road traffic injuries, WHO.\nRoad traffic deaths and injuries in Thailand\n\nThe study area comprises of the Bangkok Metropolitan Region.\n\n\n\n\n\n\nNote\n\n\n\nProjected coordinate system of Thailand is WGS 84 / UTM zone 47N and the EPSG code is 32647."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#the-datasets",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#the-datasets",
    "title": "In-class Exercise 2",
    "section": "",
    "text": "For this case study, three basic data sets are needed, they are:\n\nThailand Road Accident [2019-2022] on Kaggle\nThailand Roads (OpenStreetMap Export) on HDX.\nThailand - Subnational Administrative Boundaries on HDX."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#importing-the-traffic-accident-data",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#importing-the-traffic-accident-data",
    "title": "In-class Exercise 2",
    "section": "",
    "text": "Importing the downloaded accident data into R environment and saving the output as an sf tibble data.frame.\n\nrdacc_sf &lt;- read_csv(\"data/Thailand/archive/thai_road_accident_2019_2022.csv\") %&gt;%\n  filter(!is.na(longitude) & longitude != \"\",\n         !is.na(latitude) & latitude != \"\") %&gt;%\n  st_as_sf(coords = c(\n    \"longitude\", \"latitude\"),\n    crs = 4326) %&gt;%\n  st_transform(crs = 32647)\n\nRows: 81735 Columns: 18\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (10): province_th, province_en, agency, route, vehicle_type, presumed_c...\ndbl   (6): acc_code, number_of_vehicles_involved, number_of_fatalities, numb...\ndttm  (2): incident_datetime, report_datetime\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#visualising-the-accident-data",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#visualising-the-accident-data",
    "title": "In-class Exercise 2",
    "section": "",
    "text": "Importing the ACLED data into R environment as an sf tibble data.frame."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "",
    "text": "According to the World Health Organization (WHO), road traffic accidents claim the lives of around 1.19 million people annually and leave 20 to 50 million others with non-fatal injuries. Vulnerable road users, such as pedestrians, cyclists, and motorcyclists, account for more than half of these fatalities.\nRoad traffic injuries are the leading cause of death for individuals aged 5 to 29. Additionally, two-thirds of road traffic fatalities occur among people of working age (18–59 years). Despite having only about 60% of the world’s vehicles, low- and middle-income countries account for 92% of road traffic fatalities.\nBeyond the human toll, road accidents impose a significant economic burden on victims and their families due to medical costs and the loss of productivity from those who are killed or disabled. On a national level, these injuries cost countries around 3% of their gross domestic product (GDP).\nThailand has the most dangerous roads in Southeast Asia and ranks among the worst globally, with approximately 20,000 deaths from road accidents each year, averaging 56 deaths per day (WHO) and a million injuries each year, incurring an economic loss of 500,000 million baht.\nBetween 2014 and 2021, Thailand saw a rise in accident frequency, with 19% occurring on the national highways, which serve as the main public roads connecting regions, provinces, and key locations. Nationally, there is a 66% chance of encountering accident-prone areas, also known as ‘black spots.’ These are distributed as follows: 66% on straight road sections, 13% on curves, 6% at median points of cross intersections, 5% at T- or Y-intersections, 3% at cross intersections, and 2% on both bridges and steep slopes.\n\n\nThe primary causes of road traffic accidents can be attributed to behavioural factors, such as: driver behaviour, performance, and environmental factors, like weather conditions and road design. While past studies using Spatial Point Patterns Analysis (SPPA) have explored these factors, they often overlook the impact of temporal factors, such as season or time of day.\nThe task is to identify factors influencing road traffic accidents in the Bangkok Metropolitan Region (BMR) using both spatial and spatio-temporal point patterns analysis. The objectives include visualizing spatio-temporal accident dynamics and conducting detailed spatial and temporal analyses using Network Spatial Point Patterns Analysis methods.\n\n\n\nThree basic data sets must be used for this exercise, they are:\n\nThailand Road Accident [2019-2022] on Kaggle\n\nThis dataset provides comprehensive statistics on recorded road accidents in Thailand, spanning from approximately 2019 to 2022. The data was sourced from raw information provided by the Office of the Permanent Secretary, Ministry of Transport. The dataset encompasses various aspects of road accidents and aims to shed light on the trends and patterns within this critical area of concern, analysis of this data could be crucial in guiding road safety policies and measures\n\nThailand Roads (OpenStreetMap Export) on HDX.\nThailand - Subnational Administrative Boundaries on HDX.\n\n\n\n\n\n\nIn this exercise, seven R packages will be used, they are:\n\nR Packages\n\n\n\n\n\n\nPackages\nDescription\n\n\n\n\nsf\nA relatively new R package specially designed to import, manage and process vector-based geospatial data in R\n\n\nspatstat\nWhich has a wide range of useful functions for point pattern analysis. In this hands-on exercise, it will be used to perform 1st- and 2nd-order spatial point patterns analysis and derive kernel density estimation (KDE) layer.\n\n\nraster\nWhich reads, writes, manipulates, analyses and model of gridded spatial data (i.e. raster). In this exercise, it will be used to convert image output generate by spatstat into raster format\n\n\ntmap\nwhich provides functions for plotting cartographic quality static point patterns maps or interactive maps by using leaflet API.\n\n\ntidyverse\na family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs\n\n\nspNetwork\nWhich provides functions to perform Spatial Point Patterns Analysis such as kernel density estimation (KDE) and K-function on network. It also can be used to build spatial matrices (‘listw’ objects like in ‘spdep’ package) to conduct any kind of traditional spatial analysis with spatial weights based on reticular distances\n\n\nspdep\nto compute spatial contiguity weights\n\n\nlubridate\npackage implements some graph layout algorithms that are not available in igraph or other packages\n\n\n\nThe code chunk below is used to setup the R environment\n\npacman::p_load(sf, spatstat, raster, tmap,tidyverse,\n               spNetwork, spdep, lubridate)\n\nset.seed(1234) # To ensure that random processes in the code produce the same results every time the code is run. \n\n\n\n\n\n\n\nThis project will focus on the Bangkok Metropolitan Region (BMR) which comprises of five provinces surrounding Bangkok, namely, Samut Prakan, Pathum Thani, Nakhon Pathom, Samut Sakhon, and Nonthaburi. These areas are referred to as the Five Provinces and the Vicinity. Together with the Bangkok Metropolitan Area (BMA), they have become the Bangkok Metropolitan Region (BMR) Source%2C%20or%20Greater%20Bangkok.).\nThe code chunk below will be used to facilitate the extraction of the BMR for the datasets to avoid unnecessary provinces to be read and putting a strain on computing resources.\n\nbmr_provinces &lt;- c(\"Bangkok\", \"Samut Prakan\", \"Pathum Thani\", \"Nakhon Pathom\", \"Samut Sakhon\", \"Nonthaburi\")\n\n\n\n\nThe thai_road_accident_2019_2022 data set is csv file format, read_csv() of the readr package will be used to import thai_road_accident_2019_2022.csv as shown from the code chunk below. The output R Object is called rdacc as is a tibble data frame.\n\nrdacc &lt;- read_csv(\"data/rawdata/thai_road_accident_2019_2022.csv\")\n\nUpon some initial observation of the data set, it is observed that there are missing / NA values in the latitude & longitude columns which will have to be removed as it will not be suitable to do any spatial analysis on this observations. Following which there is also an incident_datetime column spanning from years 2019 to 2022 which will be utilised to identify the date and time occurrences of accidents. As such that column will be transformed for the date and time to be used for analysis.\nAdditionally to further set the scene (timings typically from 7 – 9 AM and 4 – 7 PM on weekdays while considering weekends to be peak throughout) will also be as pre-determined for Bangkok’s rush hours otherwise known as peak hours traffic.\nThe code chunk below also converts rdacc data frame into a simple feature data frame by using st_as_sf() of sf packages.\n\nrdacc_sf &lt;- rdacc %&gt;%\n  filter(!is.na(longitude) & longitude != \"\", \n         !is.na(latitude) & latitude != \"\") %&gt;%\n  mutate(Day_num = day(incident_datetime)) %&gt;%\n  mutate(Dayofweek = wday(incident_datetime, label = TRUE, week_start = 1)) %&gt;%\n  mutate(Month_num = month(incident_datetime)) %&gt;%\n  mutate(Month_fac = month(incident_datetime,\n                       label = TRUE,\n                       abbr = TRUE)) %&gt;%\n  mutate(Year = year(incident_datetime)) %&gt;%\n  mutate(Hour_of_day = hour(incident_datetime)) %&gt;%\n  st_as_sf(coords = c(\"longitude\", \"latitude\"),\n           crs = 4326) %&gt;%\n  st_transform(crs = 32647)\n\n\n\n\nrdacc_sf_bmr &lt;- rdacc_sf %&gt;%\n    filter(province_en %in% bmr_provinces)\n\nThe simple feature data frame is saved into a physical file for usage. By doing so the need to repeat the steps above is not needed when running the quarto document.\n\nwrite_rds(rdacc_sf_bmr, \"data/rds/rdacc_sf_bmr.rds\")\n\nTo retrieve file\n\nrdacc_sf_bmr &lt;- read_rds(\"data/rds/rdacc_sf_bmr.rds\")\n\n\n\n\n\nst_geometry(rdacc_sf_bmr)\n\nGeometry set for 12986 features \nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 591277.5 ymin: 1486846 xmax: 710166.1 ymax: 1576520\nProjected CRS: WGS 84 / UTM zone 47N\nFirst 5 geometries:\n\n\n\n\n\n\n\nThailand Roads (OpenStreetMap Export)Assigning EPSG code and projection transformationViewing the road_sf data frameFinal CheckSelecting the relevant highway classifications\n\n\nThis dataset is in shp format and the code chunk below is used to read the file into the R environment.\n\nroad_sf &lt;- st_read(dsn = \"data/rawdata\", \n                   layer = \"hotosm_tha_roads_lines_shp\")\n\nReading layer `hotosm_tha_roads_lines_shp' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Take-home_Ex\\Take-home_Ex01\\data\\rawdata' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2792590 features and 14 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 97.34457 ymin: 5.643645 xmax: 105.6528 ymax: 20.47168\nCRS:           NA\n\n\n\n\nUpon importing the OSM Export, it is observed from the results that the CRS field shows NA. Hence, we will set the CRS to WGS84 with the default EPSG code of 4326 using st_set_crs() of sf package.\n\nroad_sf &lt;- st_set_crs(road_sf, 4326)\n\nNow, to check the CSR again by using the code chunk below.\n\nst_crs(road_sf)\n\nCoordinate Reference System:\n  User input: EPSG:4326 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n        MEMBER[\"World Geodetic System 1984 (Transit)\"],\n        MEMBER[\"World Geodetic System 1984 (G730)\"],\n        MEMBER[\"World Geodetic System 1984 (G873)\"],\n        MEMBER[\"World Geodetic System 1984 (G1150)\"],\n        MEMBER[\"World Geodetic System 1984 (G1674)\"],\n        MEMBER[\"World Geodetic System 1984 (G1762)\"],\n        MEMBER[\"World Geodetic System 1984 (G2139)\"],\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]],\n        ENSEMBLEACCURACY[2.0]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    USAGE[\n        SCOPE[\"Horizontal component of 3D system.\"],\n        AREA[\"World.\"],\n        BBOX[-90,-180,90,180]],\n    ID[\"EPSG\",4326]]\n\n\nFollowing which, we can utilise st_transform() of sf package to re-project road_sf from one coordinate system to another coordinate system mathematically.\n\nroad_sf &lt;- st_transform(road_sf,\n                        crs = 32647)\n\n\n\nNext, let us display the content of road_sf sf data frame as shown in the code chunk below using st_geometry() and glimpse() functions.\n\nst_geometry(road_sf)\n\nGeometry set for 2792590 features \nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 325313.7 ymin: 624248.4 xmax: 1215576 ymax: 2263968\nProjected CRS: WGS 84 / UTM zone 47N\nFirst 5 geometries:\n\n\n\nglimpse(road_sf)\n\nRows: 2,792,590\nColumns: 15\n$ name       &lt;chr&gt; \"ถนนฉลองกรุง\", \"ซอยฉลองกรุง 1/1\", NA, NA, \"ถนนฉลองกรุง\", NA, \"…\n$ name_en    &lt;chr&gt; \"Chalong Krung Road\", \"Soi Chalong Krung 1/1\", NA, NA, \"Cha…\n$ highway    &lt;chr&gt; \"secondary\", \"residential\", \"secondary_link\", \"service\", \"s…\n$ surface    &lt;chr&gt; \"paved\", NA, NA, NA, \"concrete\", NA, NA, \"unpaved\", NA, NA,…\n$ smoothness &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ width      &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ lanes      &lt;chr&gt; NA, NA, NA, NA, \"2\", NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ oneway     &lt;chr&gt; \"yes\", NA, \"yes\", NA, \"yes\", NA, NA, NA, NA, NA, NA, NA, NA…\n$ bridge     &lt;chr&gt; NA, NA, NA, NA, \"yes\", NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ layer      &lt;chr&gt; NA, NA, NA, NA, \"1\", NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ source     &lt;chr&gt; NA, NA, NA, NA, \"Bing\", NA, NA, \"GPS\", NA, NA, NA, NA, NA, …\n$ name_th    &lt;chr&gt; \"ถนนฉลองกรุง\", \"ซอยฉลองกรุง 1/1\", NA, NA, \"ถนนฉลองกรุง\", NA, \"…\n$ osm_id     &lt;dbl&gt; 1125681229, 594401607, 472283206, 594401608, 116847248, 317…\n$ osm_type   &lt;chr&gt; \"ways_line\", \"ways_line\", \"ways_line\", \"ways_line\", \"ways_l…\n$ geometry   &lt;MULTILINESTRING [m]&gt; MULTILINESTRING ((693686.1 ..., MULTILINEST…\n\n\n\n\nTo check the CSR again by using the code chunk below.\n\nst_crs(road_sf)\n\nCoordinate Reference System:\n  User input: EPSG:32647 \n  wkt:\nPROJCRS[\"WGS 84 / UTM zone 47N\",\n    BASEGEOGCRS[\"WGS 84\",\n        ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n            MEMBER[\"World Geodetic System 1984 (Transit)\"],\n            MEMBER[\"World Geodetic System 1984 (G730)\"],\n            MEMBER[\"World Geodetic System 1984 (G873)\"],\n            MEMBER[\"World Geodetic System 1984 (G1150)\"],\n            MEMBER[\"World Geodetic System 1984 (G1674)\"],\n            MEMBER[\"World Geodetic System 1984 (G1762)\"],\n            MEMBER[\"World Geodetic System 1984 (G2139)\"],\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ENSEMBLEACCURACY[2.0]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4326]],\n    CONVERSION[\"UTM zone 47N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",99,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Navigation and medium accuracy spatial referencing.\"],\n        AREA[\"Between 96°E and 102°E, northern hemisphere between equator and 84°N, onshore and offshore. China. Indonesia. Laos. Malaysia - West Malaysia. Mongolia. Myanmar (Burma). Russian Federation. Thailand.\"],\n        BBOX[0,96,84,102]],\n    ID[\"EPSG\",32647]]\n\n\n\n\nAs the road data set provided by OSM is very comprehensive it will increase the computation times a lot and some of the classes might not be useful for analysis. Hence, we will explore what are the classes included and selecting those relevant ones based on the Highway Classification.\n\nunique(road_sf$highway)\n\n [1] \"secondary\"      \"residential\"    \"secondary_link\" \"service\"       \n [5] \"tertiary\"       \"path\"           \"footway\"        \"track\"         \n [9] \"unclassified\"   \"trunk\"          \"trunk_link\"     \"primary\"       \n[13] \"primary_link\"   \"steps\"          \"motorway_link\"  \"cycleway\"      \n[17] \"pedestrian\"     \"tertiary_link\"  \"motorway\"       \"construction\"  \n[21] \"road\"           \"raceway\"        \"corridor\"       \"living_street\" \n[25] \"escape\"         \"proposed\"       \"busway\"         \"bridleway\"     \n[29] \"abandoned\"      \"parth\"          \"barrier\"        \"paved\"         \n\n\nThe code chunk below is used to filter only the relevant highways based on the classification and selecting other relevant columns that will be used.\n\nroad_sf &lt;- road_sf %&gt;%\n    filter(highway %in% c(\"motorway\", \"trunk\", \"primary\", \"secondary\", \"tertiary\", \"unclassified\",\n                          \"residential\", \"service\")) %&gt;%\n    select(highway, osm_id, osm_type, geometry)\n\n\n\n\nwrite_rds(road_sf, \"data/rds/road_sf.rds\")\n\nTo retrieve file\n\nroad_sf &lt;- read_rds(\"data/rds/road_sf.rds\")\n\n\n\n\n\n\n\n\n\n\nProjectionWorking with st_geometry()Working with projectionWorking with glimpse()Plotting the Geospatial Data\n\n\nReading the administrative boundaries for Thailand\nIt is also relevant to note from the HDX website the levels stated in the dataset represent different administrative levels.\n\n\n\nThailand - Subnational Administrative Boundaries\n\n\n\nthadm &lt;- st_read(dsn = \"data/rawdata\", \n                 layer = \"tha_admbnda_adm1_rtsd_20220121\")\n\nReading layer `tha_admbnda_adm1_rtsd_20220121' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Take-home_Ex\\Take-home_Ex01\\data\\rawdata' \n  using driver `ESRI Shapefile'\nSimple feature collection with 77 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nGeodetic CRS:  WGS 84\n\n\nThe message above reveals that the geospatial objects are multipolygon features. There are a total of 77 multipolygon feature representing the different provinces in Thailand and 16 fields in thadm (Thailand Administrative) simple feature data frame. thadm is in WGS84 Geodetic coordinates system. The bounding box provides the x extend and y extend of the data.\n\nthadm2 &lt;- st_read(dsn = \"data/rawdata\", \n                 layer = \"tha_admbnda_adm2_rtsd_20220121\")\n\nReading layer `tha_admbnda_adm2_rtsd_20220121' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Take-home_Ex\\Take-home_Ex01\\data\\rawdata' \n  using driver `ESRI Shapefile'\nSimple feature collection with 928 features and 19 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nGeodetic CRS:  WGS 84\n\n\n\n\nThe column in the sf data.frame that contains the geometries is a list, of class sfc. We can retrieve the geometry list-column in this case by thadm$geometry, but the more generic way uses st_geometry() as shown in the code chunk below.\n\nst_geometry(thadm)\n\nGeometry set for 77 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nGeodetic CRS:  WGS 84\nFirst 5 geometries:\n\n\nNotice that the print only displays basic information of the feature class such as type of geometry, the geographic extent of the features and the coordinate system of the data.\n\nst_geometry(thadm2)\n\nGeometry set for 928 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nGeodetic CRS:  WGS 84\nFirst 5 geometries:\n\n\n\n\nOne of the common issue that can happen during importing geospatial data into R is that the coordinate system of the source data was either missing (such as due to missing .proj for ESRI shapefile) or wrongly assigned during the importing process.\nThis is an example the coordinate system of mpsz simple feature data frame by using st_crs() of sf package as shown in the code chunk below.\n\nst_crs(thadm)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\nAlthough thadm data frame is projected in WGS84 but when we read until the end of the print, it indicates that the EPSG is 4326. This is a wrong EPSG code because the correct EPSG code for Thailand should be 32647.\n\nst_crs(thadm2)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\n\nthadm &lt;- st_transform(thadm, crs = 32647)\n\n\nthadm2 &lt;- st_transform(thadm2, crs = 32647)\n\nDoing checks to ensure the following steps have been carried out correctly.\n\nst_crs(thadm)\n\nCoordinate Reference System:\n  User input: EPSG:32647 \n  wkt:\nPROJCRS[\"WGS 84 / UTM zone 47N\",\n    BASEGEOGCRS[\"WGS 84\",\n        ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n            MEMBER[\"World Geodetic System 1984 (Transit)\"],\n            MEMBER[\"World Geodetic System 1984 (G730)\"],\n            MEMBER[\"World Geodetic System 1984 (G873)\"],\n            MEMBER[\"World Geodetic System 1984 (G1150)\"],\n            MEMBER[\"World Geodetic System 1984 (G1674)\"],\n            MEMBER[\"World Geodetic System 1984 (G1762)\"],\n            MEMBER[\"World Geodetic System 1984 (G2139)\"],\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ENSEMBLEACCURACY[2.0]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4326]],\n    CONVERSION[\"UTM zone 47N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",99,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Navigation and medium accuracy spatial referencing.\"],\n        AREA[\"Between 96°E and 102°E, northern hemisphere between equator and 84°N, onshore and offshore. China. Indonesia. Laos. Malaysia - West Malaysia. Mongolia. Myanmar (Burma). Russian Federation. Thailand.\"],\n        BBOX[0,96,84,102]],\n    ID[\"EPSG\",32647]]\n\n\n\nst_crs(thadm2)\n\nCoordinate Reference System:\n  User input: EPSG:32647 \n  wkt:\nPROJCRS[\"WGS 84 / UTM zone 47N\",\n    BASEGEOGCRS[\"WGS 84\",\n        ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n            MEMBER[\"World Geodetic System 1984 (Transit)\"],\n            MEMBER[\"World Geodetic System 1984 (G730)\"],\n            MEMBER[\"World Geodetic System 1984 (G873)\"],\n            MEMBER[\"World Geodetic System 1984 (G1150)\"],\n            MEMBER[\"World Geodetic System 1984 (G1674)\"],\n            MEMBER[\"World Geodetic System 1984 (G1762)\"],\n            MEMBER[\"World Geodetic System 1984 (G2139)\"],\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ENSEMBLEACCURACY[2.0]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4326]],\n    CONVERSION[\"UTM zone 47N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",99,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Navigation and medium accuracy spatial referencing.\"],\n        AREA[\"Between 96°E and 102°E, northern hemisphere between equator and 84°N, onshore and offshore. China. Indonesia. Laos. Malaysia - West Malaysia. Mongolia. Myanmar (Burma). Russian Federation. Thailand.\"],\n        BBOX[0,96,84,102]],\n    ID[\"EPSG\",32647]]\n\n\n\n\nBesides the basic feature information, we also would like to learn more about the associated attribute information in the data frame. This is the time glimpse() of dplyr comes in handy as shown in the code chunk below.\n\nglimpse(thadm)\n\nRows: 77\nColumns: 17\n$ Shape_Leng &lt;dbl&gt; 2.417227, 1.695100, 1.251111, 1.884945, 3.041716, 1.739908,…\n$ Shape_Area &lt;dbl&gt; 0.13133873, 0.07926199, 0.05323766, 0.12698345, 0.21393797,…\n$ ADM1_EN    &lt;chr&gt; \"Bangkok\", \"Samut Prakan\", \"Nonthaburi\", \"Pathum Thani\", \"P…\n$ ADM1_TH    &lt;chr&gt; \"กรุงเทพมหานคร\", \"สมุทรปราการ\", \"นนทบุรี\", \"ปทุมธานี\", \"พระนครศรีอ…\n$ ADM1_PCODE &lt;chr&gt; \"TH10\", \"TH11\", \"TH12\", \"TH13\", \"TH14\", \"TH15\", \"TH16\", \"TH…\n$ ADM1_REF   &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ ADM1ALT1EN &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ ADM1ALT2EN &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ ADM1ALT1TH &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ ADM1ALT2TH &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ ADM0_EN    &lt;chr&gt; \"Thailand\", \"Thailand\", \"Thailand\", \"Thailand\", \"Thailand\",…\n$ ADM0_TH    &lt;chr&gt; \"ประเทศไทย\", \"ประเทศไทย\", \"ประเทศไทย\", \"ประเทศไทย\", \"ประเทศ…\n$ ADM0_PCODE &lt;chr&gt; \"TH\", \"TH\", \"TH\", \"TH\", \"TH\", \"TH\", \"TH\", \"TH\", \"TH\", \"TH\",…\n$ date       &lt;date&gt; 2019-02-18, 2019-02-18, 2019-02-18, 2019-02-18, 2019-02-18…\n$ validOn    &lt;date&gt; 2022-01-22, 2022-01-22, 2022-01-22, 2022-01-22, 2022-01-22…\n$ validTo    &lt;date&gt; -001-11-30, -001-11-30, -001-11-30, -001-11-30, -001-11-30…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((674339.8 15..., MULTIPOLYGON (…\n\n\nglimpse() report reveals the data type of each fields. For example date field is in date data type, Shape_Leng and Shape_Area fields are all in double-precision values.\n\nglimpse(thadm2)\n\nRows: 928\nColumns: 20\n$ Shape_Leng &lt;dbl&gt; 0.08541733, 0.13413177, 0.67634217, 0.08588647, 0.30172202,…\n$ Shape_Area &lt;dbl&gt; 0.0004504685, 0.0009501914, 0.0198588627, 0.0003369561, 0.0…\n$ ADM2_EN    &lt;chr&gt; \"Phra Nakhon\", \"Dusit\", \"Nong Chok\", \"Bang Rak\", \"Bang Khen…\n$ ADM2_TH    &lt;chr&gt; \"พระนคร\", \"ดุสิต\", \"หนองจอก\", \"บางรัก\", \"บางเขน\", \"บางกะปิ\", \"ป…\n$ ADM2_PCODE &lt;chr&gt; \"TH1001\", \"TH1002\", \"TH1003\", \"TH1004\", \"TH1005\", \"TH1006\",…\n$ ADM2_REF   &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ ADM2ALT1EN &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ ADM2ALT2EN &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ ADM2ALT1TH &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ ADM2ALT2TH &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ ADM1_EN    &lt;chr&gt; \"Bangkok\", \"Bangkok\", \"Bangkok\", \"Bangkok\", \"Bangkok\", \"Ban…\n$ ADM1_TH    &lt;chr&gt; \"กรุงเทพมหานคร\", \"กรุงเทพมหานคร\", \"กรุงเทพมหานคร\", \"กรุงเทพมหาน…\n$ ADM1_PCODE &lt;chr&gt; \"TH10\", \"TH10\", \"TH10\", \"TH10\", \"TH10\", \"TH10\", \"TH10\", \"TH…\n$ ADM0_EN    &lt;chr&gt; \"Thailand\", \"Thailand\", \"Thailand\", \"Thailand\", \"Thailand\",…\n$ ADM0_TH    &lt;chr&gt; \"ประเทศไทย\", \"ประเทศไทย\", \"ประเทศไทย\", \"ประเทศไทย\", \"ประเทศ…\n$ ADM0_PCODE &lt;chr&gt; \"TH\", \"TH\", \"TH\", \"TH\", \"TH\", \"TH\", \"TH\", \"TH\", \"TH\", \"TH\",…\n$ date       &lt;date&gt; 2019-02-18, 2019-02-18, 2019-02-18, 2019-02-18, 2019-02-18…\n$ validOn    &lt;date&gt; 2022-01-22, 2022-01-22, 2022-01-22, 2022-01-22, 2022-01-22…\n$ validTo    &lt;date&gt; -001-11-30, -001-11-30, -001-11-30, -001-11-30, -001-11-30…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((662263.2 15..., MULTIPOLYGON (…\n\n\n\n\nIn geospatial data science, by looking at the feature information is not enough. We are also interested to visualise the geospatial features. This is the time plot() of R Graphic comes in very handy as shown in the code chunk below.\n\nplot(st_geometry(thadm))\n\n\n\n\n\n\n\n\nAlternatively, we can also choose the plot the sf object by using a specific attribute as shown in the code chunk below.\n\nplot(thadm[\"ADM1_EN\"])\n\n\n\n\n\n\n\n\nplot() function is utilised again to visualise the features but consisting the districts\n\n\n\n\n\n\n\ntm_shape(thadm)+\n  tm_fill(\"ADM1_EN\", \n          title = \"Thailand Boundary\") +\n  tm_layout(main.title = \"Map of Thailand\",\n            main.title.position = \"center\",\n            main.title.size = 1.5,\n            legend.height = 0.6, \n            legend.width = 0.4,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type = \"4star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha = 0.2) +\n  tmap_options(max.categories = 77)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nbmr_provinces will be used in confining the geospatial data to the study area,we will utilise the code chunk below.\n\nthadm_bmr &lt;- thadm %&gt;%\n  filter(ADM1_EN %in% bmr_provinces)\n\nsummary(thadm_bmr)\n\n   Shape_Leng      Shape_Area        ADM1_EN            ADM1_TH         \n Min.   :1.251   Min.   :0.05324   Length:6           Length:6          \n 1st Qu.:1.599   1st Qu.:0.07349   Class :character   Class :character  \n Median :1.790   Median :0.10312   Mode  :character   Mode  :character  \n Mean   :1.880   Mean   :0.10688                                        \n 3rd Qu.:2.284   3rd Qu.:0.13025                                        \n Max.   :2.463   Max.   :0.17891                                        \n  ADM1_PCODE          ADM1_REF          ADM1ALT1EN         ADM1ALT2EN       \n Length:6           Length:6           Length:6           Length:6          \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n  ADM1ALT1TH         ADM1ALT2TH          ADM0_EN            ADM0_TH         \n Length:6           Length:6           Length:6           Length:6          \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n  ADM0_PCODE             date               validOn          \n Length:6           Min.   :2019-02-18   Min.   :2022-01-22  \n Class :character   1st Qu.:2019-02-18   1st Qu.:2022-01-22  \n Mode  :character   Median :2019-02-18   Median :2022-01-22  \n                    Mean   :2019-02-18   Mean   :2022-01-22  \n                    3rd Qu.:2019-02-18   3rd Qu.:2022-01-22  \n                    Max.   :2019-02-18   Max.   :2022-01-22  \n    validTo                    geometry\n Min.   :-001-11-30   MULTIPOLYGON :6  \n 1st Qu.:-001-11-30   epsg:32647   :0  \n Median :-001-11-30   +proj=utm ...:0  \n Mean   :-001-11-30                    \n 3rd Qu.:-001-11-30                    \n Max.   :-001-11-30                    \n\n\n\nthadm2_bmr &lt;- thadm2 %&gt;%\n  filter(ADM1_EN %in% bmr_provinces)\n\nsummary(thadm2_bmr)\n\n   Shape_Leng        Shape_Area          ADM2_EN            ADM2_TH         \n Min.   :0.05123   Min.   :0.0001177   Length:79          Length:79         \n 1st Qu.:0.16740   1st Qu.:0.0010931   Class :character   Class :character  \n Median :0.28074   Median :0.0030914   Mode  :character   Mode  :character  \n Mean   :0.41054   Mean   :0.0081177                                        \n 3rd Qu.:0.61018   3rd Qu.:0.0107533                                        \n Max.   :1.26897   Max.   :0.0454895                                        \n  ADM2_PCODE          ADM2_REF          ADM2ALT1EN         ADM2ALT2EN       \n Length:79          Length:79          Length:79          Length:79         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n  ADM2ALT1TH         ADM2ALT2TH          ADM1_EN            ADM1_TH         \n Length:79          Length:79          Length:79          Length:79         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n  ADM1_PCODE          ADM0_EN            ADM0_TH           ADM0_PCODE       \n Length:79          Length:79          Length:79          Length:79         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n      date               validOn              validTo          \n Min.   :2019-02-18   Min.   :2022-01-22   Min.   :-001-11-30  \n 1st Qu.:2019-02-18   1st Qu.:2022-01-22   1st Qu.:-001-11-30  \n Median :2019-02-18   Median :2022-01-22   Median :-001-11-30  \n Mean   :2019-02-18   Mean   :2022-01-22   Mean   :-001-11-30  \n 3rd Qu.:2019-02-18   3rd Qu.:2022-01-22   3rd Qu.:-001-11-30  \n Max.   :2019-02-18   Max.   :2022-01-22   Max.   :-001-11-30  \n          geometry \n MULTIPOLYGON :79  \n epsg:32647   : 0  \n +proj=utm ...: 0  \n                   \n                   \n                   \n\n\n\ntm_shape(thadm_bmr)+\n  tm_fill(\"ADM1_EN\", \n          title = \"Thailand BMR\") +\n  tm_layout(main.title = \"Maping of Bangkok Metropolitan Region\",\n            main.title.position = \"center\",\n            main.title.size = 1.5,\n            legend.height = 0.6, \n            legend.width = 0.4,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type = \"4star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha = 0.2)\n\n\n\n\n\n\n\n\n\ntm_shape(thadm2_bmr)+\n  tm_fill(\"ADM1_EN\", \n          title = \"Thailand BMR\") +\n  tm_layout(main.title = \"Maping of Bangkok Metropolitan Region\",\n            main.title.position = \"center\",\n            main.title.size = 1.5,\n            legend.height = 0.6, \n            legend.width = 0.4,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type = \"4star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha = 0.2)\n\n\n\n\n\n\n\n\nThe simple feature data frame is saved into a physical file for usage. By doing so the need to repeat the steps above is not needed.\n\n\n\nwrite_rds(thadm_bmr, \"data/rds/thadm_bmr.rds\")\n\nTo retrieve file\n\nthadm_bmr &lt;- read_rds(\"data/rds/thadm_bmr.rds\")\n\n\n\n\n\nwrite_rds(thadm2_bmr, \"data/rds/thadm2_bmr.rds\")\n\nTo retrieve file\n\nthadm2_bmr &lt;- read_rds(\"data/rds/thadm2_bmr.rds\")\n\n\n\n\n\n\nIn this step, the code chunk uses st_intersection() at the province level and saved as an RDS file.\n\nth_bmr_province &lt;- st_intersection(thadm_bmr, road_sf)\n\nFollowing the earlier steps, this will be saved as an RDS file in order to improve computational efficiency.\n\nwrite_rds(th_bmr_province, \"data/rds/th_bmr_province.rds\") \n\nTo retrieve file\n\nth_bmr_province &lt;- read_rds(\"data/rds/th_bmr_province.rds\")\n\nIn this following step, st_intersection() function is applied at the district level and saved as an RDS file.\n\nth_bmr_network &lt;- st_intersection(thadm2_bmr, th_bmr_province)\n\n\nwrite_rds(th_bmr_network,\"data/rds/th_bmr_network.rds\")\n\nTo retrieve file\n\nth_bmr_network &lt;- read_rds(\"data/rds/th_bmr_network.rds\")\n\n\n\n\n\n\nWe will proceed to do some initial visualisation of the data to get a better sense of the accident data.\nThe barplot while not classified under as a spatial EDA kick-starts the EDA process.\n\nggplot(rdacc_sf_bmr, aes(x = province_en)) +\n  geom_bar(fill = \"salmon\", color = \"black\", bins = 20) +\n  geom_text(stat = \"count\", aes(label = after_stat(count)), vjust = -0.5) +\n  labs(title = \"Count of Accidents by Province within BMR\",\n       x = \"Province\",\n       y = \"Count of Accidents\")\n\n\n\n\n\n\n\n\nFrom the barplot it can be observed that out of the 6 provinces in the BMR, Bangkok has the highest count of accidents followed by Samut Prakan and Pathum Thani.\n\n\n\nThe elements of tmap are utilised in the code chunk below to plat a cartographic map to supplement the initial observations in the bar plot.\nMaking use of the view mode it presents details for each accident point in the BMR, stating the presumed_cause, accident_type, weather and road conditions as well as shown in a snippet below.\nSnapshot of an accident point\n\ntmap_mode(\"plot\")\n\ntm_shape(thadm2_bmr) +\n  tm_borders(alpha = 1, col = \"black\") +\n  tm_fill(\"ADM1_EN\") +\n  \ntm_shape(rdacc_sf_bmr) +\n  tm_dots(col = \"darkred\", alpha = 0.5, size = 0.05) +\n  tm_layout(frame = FALSE) +\n  tm_compass(type = \"4star\", size = 2)\n\n\n\n\n\n\n\n\nBased on the plot above, some observations can be inferred from the map visual where accidents tend to be more concentrated in the provinces of Bangkok, Samut Prakan and Pathum Thani.\n\n\n\nA series of time factors ranging from years to hours are also shown in relation to accident occurences.\n\nYearsMonthsDaysHours\n\n\n\nggplot(rdacc_sf_bmr, aes(x = Year)) +\n  geom_bar(fill = \"blue\", color = \"black\") +\n labs(x = \"Month\", y = \"Count\", title = \"Barplot of Accidents in BMR across Years\")\n\n\n\n\n\n\n\n\nBased on the year observations the accidents seem relatively even with the exception of year 2022 surpassing a 3500 accident count.\n\n\n\nggplot(rdacc_sf_bmr, aes(x = Month_fac)) +\n  geom_bar(fill = \"blue\", color = \"black\") +\n labs(x = \"Month\", y = \"Count\", title = \"Barplot of Accidents in BMR across Months\")\n\n\n\n\n\n\n\n\nFor a month period, we can observe that the Months of January, April, October and December stand out amongst the rest of the months. A simple explanation could be:\n\nJanuary (New Year celebrations, Chinese New Year)\nApril (Songkran)\nOctober (Festivals - King Chulalongkorn Day etc. or Increasing tourist visits in Q4)\nDecember (Chrismas and End of Year celebrations)\n\nNote that this are some assumptions based on occurring events/festivals that occur in Thailand.\n\n\n\nggplot(rdacc_sf_bmr, aes(x = Dayofweek)) +\n  geom_bar(fill = \"blue\", color = \"black\") +\n labs(x = \"Month\", y = \"Count\", title = \"Barplot of Accidents in BMR across Days\")\n\n\n\n\n\n\n\n\n\n\n\nggplot(rdacc_sf_bmr, aes(x = Hour_of_day)) +\n  geom_bar(fill = \"blue\", color = \"black\") +\n labs(x = \"Hour of Day\", y = \"Count\", title = \"Barplot of Accidents in BMR across 24 hours\")\n\n\n\n\n\n\n\n\nHigher occurence of accidents occuring during the following hours:\n\n7am - 11am\n1pm - 4pm\n7pm\n\n\n\n\n\n\n\n\n\n\nMoving to geospatial analysis, the packages require the input geospatial data in sp’s Spatial* classes. In this section, simple feature data frame will be converted to sp’s Spatial* class.\n\n\nThe code chunk below uses as_Spatial() of sf package to convert the geospatial data from simple feature data frame to sp’s Spatial class.\n\nbmr_accidents &lt;- as_Spatial(rdacc_sf_bmr)\nbmr &lt;- as_Spatial(thadm_bmr)\n\nDisplaying the information of the Spatial* classes as shown in the code chunk below.\n\nbmr_accidents\n\nclass       : SpatialPointsDataFrame \nfeatures    : 12986 \nextent      : 591277.5, 710166.1, 1486846, 1576520  (xmin, xmax, ymin, ymax)\ncrs         : +proj=utm +zone=47 +datum=WGS84 +units=m +no_defs \nvariables   : 22\nnames       : acc_code, incident_datetime, report_datetime,   province_th,  province_en,                           agency,                                       route,         vehicle_type,        presumed_cause,                    accident_type, number_of_vehicles_involved, number_of_fatalities, number_of_injuries, weather_condition,           road_description, ... \nmin values  :   571882,        1546309500,      1546311900,  กรุงเทพมหานคร,      Bangkok,           department of highways,        เชื่อมทางหลวงท้องถิ่นบางเสาธง - บ้านช้างตาย, 4-wheel pickup truck,    abrupt lane change, collision at intersection corner,                           0,                    0,                  0,             clear, connecting to private area, ... \nmax values  :  7570954,        1672528260,      1674726540,      สมุทรสาคร, Samut Sakhon, expressway authority of thailand,                          อุดมสุข - สมุทรปราการ,                  van, worn-out/tire blowout,     turning/retreating collision,                          12,                   13,                 51,             rainy,             y-intersection, ... \n\n\n\nbmr\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 6 \nextent      : 587893.5, 712440.5, 1484414, 1579076  (xmin, xmax, ymin, ymax)\ncrs         : +proj=utm +zone=47 +datum=WGS84 +units=m +no_defs \nvariables   : 16\nnames       :    Shape_Leng,      Shape_Area,      ADM1_EN,       ADM1_TH, ADM1_PCODE, ADM1_REF, ADM1ALT1EN, ADM1ALT2EN, ADM1ALT1TH, ADM1ALT2TH,  ADM0_EN,   ADM0_TH, ADM0_PCODE,  date, validOn, ... \nmin values  : 1.25111117749, 0.0532376597241,      Bangkok,  กรุงเทพมหานคร,       TH10,       NA,         NA,         NA,         NA,         NA, Thailand, ประเทศไทย,         TH, 17945,   19014, ... \nmax values  : 2.46303035967,  0.178914199749, Samut Sakhon,      สมุทรสาคร,       TH74,       NA,         NA,         NA,         NA,         NA, Thailand, ประเทศไทย,         TH, 17945,   19014, ... \n\n\n\n\n\n\nbmr_accidents_sp &lt;- as(bmr_accidents, \"SpatialPoints\")\n\nbmr_sp &lt;- as(bmr, \"SpatialPolygons\")\n\nDisplaying the sp objects properties as shown below.\n\nbmr_accidents_sp\n\nclass       : SpatialPoints \nfeatures    : 12986 \nextent      : 591277.5, 710166.1, 1486846, 1576520  (xmin, xmax, ymin, ymax)\ncrs         : +proj=utm +zone=47 +datum=WGS84 +units=m +no_defs \n\n\n\nbmr_sp\n\nclass       : SpatialPolygons \nfeatures    : 6 \nextent      : 587893.5, 712440.5, 1484414, 1579076  (xmin, xmax, ymin, ymax)\ncrs         : +proj=utm +zone=47 +datum=WGS84 +units=m +no_defs \n\n\n\n\n\nNext, as.ppp() function of spatstat will be used to convert the spatial data into spatstat’s ppp object format.\n\nbmr_accidents_ppp &lt;- as.ppp(rdacc_sf_bmr)\n\nbmr_accidents_ppp\n\nMarked planar point pattern: 12986 points\nmarks are numeric, of storage type  'double'\nwindow: rectangle = [591277.5, 710166.1] x [1486845.7, 1576520.5] units\n\n\n\nplot(bmr_accidents_ppp)\n\n\n\n\n\n\n\n\nUsing the summary() function allows a preview of the summary statistics of the newly created ppp object.\n\nsummary(bmr_accidents_ppp)\n\nMarked planar point pattern:  12986 points\nAverage intensity 1.218049e-06 points per square unit\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 571882 3788970 3834532 4314457 6092694 7570954 \n\nWindow: rectangle = [591277.5, 710166.1] x [1486845.7, 1576520.5] units\n                    (118900 x 89670 units)\nWindow area = 10661300000 square units\n\n\n\n\nBefore any further evaluation, the ppp object will be checked for duplicates using the code chunk below.\n\nany(duplicated(bmr_accidents_ppp))\n\n[1] FALSE\n\n\nUpon running the code chunk it gives a result of FALSE indicating no duplicated observations.\nTo count the number of co-incidence points, the multiplicity() function will be used as shown in the code chunk below.\n\nmultiplicity(bmr_accidents_ppp)\n\n    [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n   [37] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n   [73] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [109] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [145] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [181] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [217] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [253] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [289] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [325] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [361] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [397] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [433] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [469] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [505] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [541] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [577] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [613] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [649] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [685] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [721] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [757] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [793] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [829] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [865] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [901] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [937] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [973] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [1009] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [1045] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [1081] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [1117] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [1153] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [1189] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [1225] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [1261] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [1297] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [1333] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [1369] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [1405] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [1441] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [1477] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [1513] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [1549] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [1585] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [1621] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [1657] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [1693] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [1729] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [1765] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [1801] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [1837] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [1873] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [1909] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [1945] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [1981] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [2017] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [2053] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [2089] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [2125] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [2161] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [2197] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [2233] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [2269] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [2305] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [2341] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [2377] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [2413] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [2449] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [2485] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [2521] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [2557] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [2593] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [2629] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [2665] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [2701] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [2737] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [2773] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [2809] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [2845] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [2881] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [2917] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [2953] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [2989] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [3025] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [3061] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [3097] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [3133] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [3169] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [3205] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [3241] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [3277] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [3313] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [3349] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [3385] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [3421] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [3457] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [3493] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [3529] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [3565] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [3601] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [3637] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [3673] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [3709] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [3745] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [3781] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [3817] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [3853] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [3889] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [3925] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [3961] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [3997] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [4033] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [4069] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [4105] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [4141] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [4177] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [4213] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [4249] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [4285] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [4321] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [4357] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [4393] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [4429] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [4465] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [4501] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [4537] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [4573] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [4609] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [4645] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [4681] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [4717] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [4753] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [4789] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [4825] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [4861] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [4897] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [4933] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [4969] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [5005] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [5041] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [5077] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [5113] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [5149] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [5185] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [5221] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [5257] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [5293] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [5329] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [5365] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [5401] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [5437] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [5473] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [5509] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [5545] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [5581] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [5617] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [5653] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [5689] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [5725] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [5761] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [5797] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [5833] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [5869] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [5905] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [5941] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [5977] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [6013] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [6049] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [6085] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [6121] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [6157] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [6193] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [6229] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [6265] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [6301] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [6337] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [6373] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [6409] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [6445] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [6481] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [6517] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [6553] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [6589] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [6625] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [6661] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [6697] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [6733] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [6769] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [6805] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [6841] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [6877] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [6913] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [6949] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [6985] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [7021] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [7057] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [7093] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [7129] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [7165] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [7201] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [7237] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [7273] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [7309] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [7345] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [7381] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [7417] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [7453] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [7489] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [7525] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [7561] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [7597] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [7633] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [7669] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [7705] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [7741] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [7777] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [7813] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [7849] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [7885] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [7921] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [7957] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [7993] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [8029] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [8065] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [8101] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [8137] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [8173] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [8209] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [8245] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [8281] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [8317] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [8353] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [8389] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [8425] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [8461] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [8497] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [8533] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [8569] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [8605] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [8641] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [8677] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [8713] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [8749] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [8785] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [8821] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [8857] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [8893] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [8929] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [8965] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [9001] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [9037] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [9073] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [9109] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [9145] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [9181] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [9217] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [9253] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [9289] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [9325] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [9361] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [9397] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [9433] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [9469] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [9505] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [9541] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [9577] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [9613] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [9649] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [9685] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [9721] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [9757] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [9793] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [9829] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [9865] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [9901] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [9937] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [9973] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[10009] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[10045] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[10081] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[10117] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[10153] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[10189] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[10225] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[10261] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[10297] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[10333] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[10369] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[10405] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[10441] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[10477] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[10513] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[10549] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[10585] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[10621] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[10657] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[10693] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[10729] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[10765] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[10801] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[10837] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[10873] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[10909] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[10945] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[10981] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[11017] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[11053] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[11089] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[11125] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[11161] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[11197] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[11233] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[11269] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[11305] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[11341] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[11377] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[11413] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[11449] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[11485] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[11521] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[11557] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[11593] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[11629] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[11665] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[11701] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[11737] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[11773] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[11809] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[11845] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[11881] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[11917] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[11953] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[11989] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[12025] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[12061] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[12097] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[12133] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[12169] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[12205] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[12241] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[12277] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[12313] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[12349] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[12385] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[12421] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[12457] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[12493] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[12529] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[12565] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[12601] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[12637] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[12673] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[12709] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[12745] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[12781] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[12817] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[12853] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[12889] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[12925] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[12961] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n\n\nFollowing which to know how many locations have more than one point event, the code chunk below can be used.\n\nsum(multiplicity(bmr_accidents_ppp) &gt; 1)\n\n[1] 0\n\n\nThe output shows that there 0 duplicated point events.\nThe code chunk below is used to view the point events and plot the rdacc_sf_bmr data with the code chunk below.\n\ntmap_mode(\"plot\")\ntm_shape(rdacc_sf_bmr) +\n  tm_dots(alpha = 0.5,\n          size = 0.05)\n\n\n\n\n\n\n\n\nAdditionally, the code chunk below is used to plot a map to show spatial patterns of the accidents.\n\ntm_shape(thadm_bmr) +\n  tm_polygons() +\ntm_shape(thadm2_bmr) +\n  tm_polygons() +\ntm_shape(rdacc_sf_bmr)+\n  tm_dots()\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn the next step of spatial point patterns analysis, is to confine the analysis with a geographical area (etc. like Singapore boundary) and in the case for this exercise the BMR. In spatstat, an object called owin is specially designed to help represent this polygonal region.\nThe code chunk below is used to covert bmr_sp SpatialPolygon object into owin object of spatstat and subsequently the plot with a summary() function of Base R.\n\nbmr_owin &lt;- as.owin(thadm2_bmr)\n\n\nplot(bmr_owin)\n\n\n\n\n\n\n\n\n\nsummary(bmr_owin)\n\nWindow: polygonal boundary\nsingle connected closed polygon with 13779 vertices\nenclosing rectangle: [587893.5, 712440.5] x [1484413.7, 1579076.3] units\n                     (124500 x 94660 units)\nWindow area = 7668990000 square units\nFraction of frame area: 0.65\n\n\n\n\n\nIn the final stage of geospatial data wrangling, we will extract the accident events that are located within the BMR by using the code chunk below.\nThe output object combines both the point and polygon features in one ppp object class as shown below.\n\nbmr_accidents_ppp = bmr_accidents_ppp[bmr_owin]\n\n\nsummary(bmr_accidents_ppp)\n\nMarked planar point pattern:  12986 points\nAverage intensity 1.693312e-06 points per square unit\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 571882 3788970 3834532 4314457 6092694 7570954 \n\nWindow: polygonal boundary\nsingle connected closed polygon with 13779 vertices\nenclosing rectangle: [587893.5, 712440.5] x [1484413.7, 1579076.3] units\n                     (124500 x 94660 units)\nWindow area = 7668990000 square units\nFraction of frame area: 0.65\n\n\nThe newly derived bmr_accidents_ppp is plotted below.\n\nplot(bmr_accidents_ppp)\n\n\n\n\n\n\n\n\n\n\n\nIn this section,first-order SPPA will be performed by using spatstat package. The kernel density estimation (KDE) layer for visualising and exploring the intensity of point processes of accident data will be derived before performing Confirmatory Spatial Point Patterns Analysis by using Nearest Neighbour statistics.\n\n\n\nThe computation of kernel density estimation (KDE) of accident spots in BMR. The code chunk below computeskernel density by using the following configurations of density() of spatstat:\n\n\n\n\n\n\nNote\n\n\n\n\nbw.diggle() automatic bandwidth selection method. Primarily because the primary focus is identifying detailed accident hotspots, where fine-scale resolution is important, bw.diggle() is a solid choice since it provides more granular bandwidth selection, allowing for the identification of localized patterns in the data.\nThe smoothing kernel used is gaussian, which is the default. Other smoothing methods are: “epanechnikov”, “quartic” or “disc”.\n\n\n\n\nkde_bmr_accidents_bw &lt;- density(bmr_accidents_ppp,\n                                sigma = bw.diggle,\n                                edge = TRUE,\n                                kernel = \"gaussian\")\nplot(kde_bmr_accidents_bw)\n\n\n\n\n\n\n\n\nFrom the plot, we can observe that the output range from 0 to 0.00015 which are too small to comprehend. This due to the unit of measurement in metres, implying that the density values computed is in the unit of “number of points per square meter”.\nCode chunk below retrieves the bandwidth used to compute the kde layer.\n\nbw &lt;- bw.diggle(bmr_accidents_ppp)\nbw\n\n   sigma \n13.41546 \n\n\n\n\nThe rescale.ppp() function of the spatstat package is then used to convert the unit of measurement from metres to kilometres.\n\nbmr_accidents_ppp.km &lt;- rescale.ppp(bmr_accidents_ppp, 1000, \"km\")\n\nUpon rescaling, the density() can be re-run with the rescaled data and plotting the output again.\n\nkde_bmr_accidents.bw &lt;- density(bmr_accidents_ppp.km,\n                                sigma = bw.diggle,\n                                edge = TRUE,\n                                kernel = \"gaussian\")\nplot(kde_bmr_accidents.bw)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNotice that the output plot is identical to the earlier version, the only changes are the data values in the legend.\n\n\n\n\n\n\n\n\nIn this section, the KDE layer will be computed with a bandwidth of 1000 metres.\n\nIn the code chunk below, the sigma value used is 1 as the unit of measurement for bmr_accidents_ppp.km is in kilometres. (e.g. 1000m = 1km)\n\n\nkde_bmr_accidents_1 &lt;- density(bmr_accidents_ppp.km,\n                               sigma=1,\n                               edge=TRUE,\n                               kernel=\"gaussian\")\nplot(kde_bmr_accidents_1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n\nThe plot seems to highlight several concentrated accident hotspots along major roads and highways. This fine-level resolution will further aid in identifying detailed spatial trends in accident occurrences, which is important for urban traffic management.\nThe next steps involve validating these findings with confirmatory spatial analysis (such as nearest neighbour statistics) or possibly further refining bandwidth selection to ensure that hotspots are accurately represented across various road types or urban zones.\n\n\n\n\n\n\nWith how the plot seems to show concentrated accident hotspots, due to how a fixed bandwidth method is very sensitive to highly skewed distribution of spatial point patterns over geographical units for example urban versus rural.\nOne way to overcome this problem is by using adaptive bandwidth instead. In this section, adaptive kernel density estimation will be derived by using density.adaptive()of spatstat.\n\nkde_bmr_accidents_adaptive &lt;- adaptive.density(bmr_accidents_ppp.km,\n                                               method=\"kernel\")\n\n\nplot(kde_bmr_accidents_adaptive)\n\n\n\n\n\n\n\n\nComparing the fixed and adaptive kernel density estimation outputs by using the code chunk below:\n\npar(mfrow=c(1,2))\nplot(kde_bmr_accidents.bw, main = \"Fixed bandwidth\")\nplot(kde_bmr_accidents_adaptive, main = \"Adaptive bandwidth\")\n\n\n\n\n\n\n\n\n\n\nNext, the gridded kernel density objects will be converted into RasterLayer object by using raster() of raster package.\n\nkde_bmr_accidents_bw_raster &lt;- raster(kde_bmr_accidents.bw)\n\nkde_bmr_accidents_bw_raster # Checking the properties of the RasterLayer\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.973023, 0.7395512  (x, y)\nextent     : 587.8935, 712.4405, 1484.414, 1579.076  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : layer \nvalues     : -4.760739e-14, 233.4629  (min, max)\n\n\nFrom the results, the CRS property is stated as NA.\n\n\n\nCode chunk below will be used to include the CRS information on kde_bmr_accidents_bw_raster RasterLayer.\n\nprojection(kde_bmr_accidents_bw_raster) &lt;- CRS(\"+init=EPSG:32647\")\nkde_bmr_accidents_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.973023, 0.7395512  (x, y)\nextent     : 587.8935, 712.4405, 1484.414, 1579.076  (xmin, xmax, ymin, ymax)\ncrs        : +proj=utm +zone=47 +datum=WGS84 +units=m +no_defs \nsource     : memory\nnames      : layer \nvalues     : -4.760739e-14, 233.4629  (min, max)\n\n\n\ntm_shape(kde_bmr_accidents_bw_raster) + \n  tm_raster(\"layer\", palette = \"viridis\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)\n\n\n\n\n\n\n\n\n\nbk &lt;- thadm2_bmr %&gt;%\n  filter(ADM1_EN == \"Bangkok\")\nsp &lt;- thadm2_bmr %&gt;%\n  filter(ADM1_EN == \"Samut Prakan\")\npt &lt;- thadm2_bmr %&gt;%\n  filter(ADM1_EN == \"Pathum Thani\")\nnp &lt;- thadm2_bmr %&gt;%\n  filter(ADM1_EN == \"Nakhon Pathom\")\nss &lt;- thadm2_bmr %&gt;%\n  filter(ADM1_EN == \"Samut Sakhon\")\nnt &lt;- thadm2_bmr %&gt;%\n  filter(ADM1_EN == \"Nonthaburi\")\n\n\npar(mfrow=c(2,2))\nplot(bk, main = \"Bangkok\")\n\n\n\n\n\n\n\n\n\npar(mfrow=c(2,2))\nplot(sp, main = \"Samut Prakan\")\n\n\n\n\n\n\n\n\n\npar(mfrow=c(2,2))\nplot(pt, main = \"Pathum Thani\")\n\n\n\n\n\n\n\n\n\npar(mfrow=c(2,2))\nplot(np, main = \"Nakhon Pathom\")\n\n\n\n\n\n\n\n\n\npar(mfrow=c(3,3))\nplot(ss, main = \"Samut Sakhon\")\n\n\n\n\n\n\n\n\n\npar(mfrow=c(2,2))\nplot(nt, main = \"Nonthaburi\")\n\n\n\n\n\n\n\n\n\n\n\nSimilarly, now we will convert these sf objects into owin objects that is required by spatstat.\n\nbk_owin = as.owin(bk)\nsp_owin = as.owin(sp)\npt_owin = as.owin(pt)\nnp_owin = as.owin(np)\nss_owin = as.owin(ss)\nnt_owin = as.owin(nt)\n\n\n\n\n\nbmr_accidents_bk_ppp = bmr_accidents_ppp[bk_owin]\nbmr_accidents_sp_ppp = bmr_accidents_ppp[sp_owin]\nbmr_accidents_pt_ppp = bmr_accidents_ppp[pt_owin]\nbmr_accidents_np_ppp = bmr_accidents_ppp[np_owin]\nbmr_accidents_ss_ppp = bmr_accidents_ppp[ss_owin]\nbmr_accidents_nt_ppp = bmr_accidents_ppp[nt_owin]\n\nFollowing which, rescale.ppp() function is used to transform the unit of measurement from metres to kilometres similar to what was done in the section above.\n\nbmr_accidents_bk_ppp.km = rescale.ppp(bmr_accidents_bk_ppp, 1000, \"km\")\nbmr_accidents_sp_ppp.km = rescale.ppp(bmr_accidents_sp_ppp, 1000, \"km\")\nbmr_accidents_pt_ppp.km = rescale.ppp(bmr_accidents_pt_ppp, 1000, \"km\")\nbmr_accidents_np_ppp.km = rescale.ppp(bmr_accidents_np_ppp, 1000, \"km\")\nbmr_accidents_ss_ppp.km = rescale.ppp(bmr_accidents_ss_ppp, 1000, \"km\")\nbmr_accidents_nt_ppp.km = rescale.ppp(bmr_accidents_nt_ppp, 1000, \"km\")\n\nThe code chunk below is used to plot these six study areas (provinces) within the BMR and the location of incidents of the road accidents.\n\npar(mfrow=c(2,3))\nplot(bmr_accidents_bk_ppp.km, main=\"Bangkok\")\nplot(bmr_accidents_sp_ppp.km, main=\"Samut Prakan\")\nplot(bmr_accidents_pt_ppp.km, main=\"Pathum Thani\")\nplot(bmr_accidents_np_ppp.km, main=\"Nakhon Pathom\")\nplot(bmr_accidents_ss_ppp.km, main=\"Samut Sakhon\")\nplot(bmr_accidents_nt_ppp.km, main=\"Nonthaburi\")\n\n\n\n\n\n\n\n\n\n\n\n\npar(mfrow=c(2,3))\nplot(density(bmr_accidents_bk_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n             main=\"Bangkok\")\nplot(density(bmr_accidents_sp_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n             main=\"Samut Prakan\")\nplot(density(bmr_accidents_pt_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n             main=\"Pathum Thani\")\nplot(density(bmr_accidents_np_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n             main=\"Nakhon Pathom\")\nplot(density(bmr_accidents_ss_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n             main=\"Samut Sakhon\")\nplot(density(bmr_accidents_nt_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n             main=\"Nonthaburi\")\n\n\n\n\n\n\n\n\n\n\n\nIn this section, the Clark-Evans test of aggregation for a spatial point patternv will be performed by using clarkevans.test() of statspat.\nThe test hypothesis are:\nHo = The distribution of accident spots in BMR are randomly distributed.\nH1= The distribution of accident spots in BMR are not randomly distributed.\nA 95% confidence interval will be used.\n\nclarkevans.test(bmr_accidents_ppp,\n                correction=\"none\",\n                clipregion=\"bmr_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  bmr_accidents_ppp\nR = 0.19109, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\n\n\n\n\n\n\nConclusions from the test result\n\n\n\nGiven the test result (R = 0.19109) and the very small p-value, we reject the null hypothesis (Ho) at the 95% confidence level. The conclusion is that the distribution of accident spots in BMR is not randomly distributed; instead, the accidents are significantly clustered in certain areas.\nThis suggests that accident spots in BMR are more likely to be found around other accident spots, potentially due to factors: like roads having high curves, intersections and driver behaviour of speeding and unsafe lane changing.\n\n\n\n\n\n\nBangkokSamut PrakanPathum ThaniNakhon PathomSamut SakhonNonthaburi\n\n\n\nclarkevans.test(bmr_accidents_bk_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  bmr_accidents_bk_ppp\nR = 0.12115, p-value &lt; 2.2e-16\nalternative hypothesis: two-sided\n\n\n\n\n\nclarkevans.test(bmr_accidents_sp_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  bmr_accidents_sp_ppp\nR = 0.14367, p-value &lt; 2.2e-16\nalternative hypothesis: two-sided\n\n\n\n\n\nclarkevans.test(bmr_accidents_pt_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  bmr_accidents_pt_ppp\nR = 0.24798, p-value &lt; 2.2e-16\nalternative hypothesis: two-sided\n\n\n\n\n\nclarkevans.test(bmr_accidents_np_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  bmr_accidents_np_ppp\nR = 0.28949, p-value &lt; 2.2e-16\nalternative hypothesis: two-sided\n\n\n\n\n\nclarkevans.test(bmr_accidents_ss_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  bmr_accidents_ss_ppp\nR = 0.23989, p-value &lt; 2.2e-16\nalternative hypothesis: two-sided\n\n\n\n\n\nclarkevans.test(bmr_accidents_nt_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  bmr_accidents_nt_ppp\nR = 0.38919, p-value &lt; 2.2e-16\nalternative hypothesis: two-sided\n\n\n\n\n\nFrom the test results from each province their R Values are also of very small p-value, this further helps in the analysis that we reject the null hypothesis (Ho) at the 95% confidence level. The hypothesis that the distribution of accident spots in the provinces are also not randomly distributed; instead, the accidents are significantly clustered in certain areas."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#datasets",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#datasets",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "",
    "text": "Three basic data sets must be used for this exercise, they are:\n\nThailand Road Accident [2019-2022] on Kaggle\n\nThis dataset provides comprehensive statistics on recorded road accidents in Thailand, spanning from approximately 2019 to 2022. The data was sourced from raw information provided by the Office of the Permanent Secretary, Ministry of Transport. The dataset encompasses various aspects of road accidents and aims to shed light on the trends and patterns within this critical area of concern, analysis of this data could be crucial in guiding road safety policies and measures\n\nThailand Roads (OpenStreetMap Export) on HDX.\nThailand - Subnational Administrative Boundaries on HDX."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#setting-up",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#setting-up",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "",
    "text": "In this exercise, seven R packages will be used, they are:\n\nR Packages\n\n\n\n\n\n\nPackages\nDescription\n\n\n\n\nsf\nA relatively new R package specially designed to import, manage and process vector-based geospatial data in R\n\n\nspatstat\nWhich has a wide range of useful functions for point pattern analysis. In this hands-on exercise, it will be used to perform 1st- and 2nd-order spatial point patterns analysis and derive kernel density estimation (KDE) layer.\n\n\nraster\nWhich reads, writes, manipulates, analyses and model of gridded spatial data (i.e. raster). In this exercise, it will be used to convert image output generate by spatstat into raster format\n\n\ntmap\nwhich provides functions for plotting cartographic quality static point patterns maps or interactive maps by using leaflet API.\n\n\ntidyverse\na family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs\n\n\nspNetwork\nWhich provides functions to perform Spatial Point Patterns Analysis such as kernel density estimation (KDE) and K-function on network. It also can be used to build spatial matrices (‘listw’ objects like in ‘spdep’ package) to conduct any kind of traditional spatial analysis with spatial weights based on reticular distances\n\n\nspdep\nto compute spatial contiguity weights\n\n\nlubridate\npackage implements some graph layout algorithms that are not available in igraph or other packages\n\n\n\nThe code chunk below is used to setup the R environment\n\npacman::p_load(sf, spatstat, raster, tmap,tidyverse,\n               spNetwork, spdep, lubridate)\n\nset.seed(1234) # To ensure that random processes in the code produce the same results every time the code is run."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#objectives",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#objectives",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "",
    "text": "The primary causes of road traffic accidents can be attributed to behavioural factors, such as: driver behaviour, performance, and environmental factors, like weather conditions and road design. While past studies using Spatial Point Patterns Analysis (SPPA) have explored these factors, they often overlook the impact of temporal factors, such as season or time of day.\nThe task is to identify factors influencing road traffic accidents in the Bangkok Metropolitan Region (BMR) using both spatial and spatio-temporal point patterns analysis. The objectives include visualizing spatio-temporal accident dynamics and conducting detailed spatial and temporal analyses using Network Spatial Point Patterns Analysis methods."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "title": "In-class Exercise 3",
    "section": "",
    "text": "pacman::p_load(sf, spNetwork, tmap, tidyverse)\n\n\n\n\nThe code chunk below uses st_read() of sf package to import Punggol_St and Punggol_CC geospatial data sets into RStudio as sf data frames.\n#Punggol_St is in ESRI Shapefile format\n\nnetwork &lt;- st_read(dsn = \"data/geospatial\",\n                   layer = \"Punggol_St\")\n\nReading layer `Punggol_St' from data source \n  `C:\\zjho008\\ISSS626-GAA\\In-class_Ex\\In-class_Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2642 features and 2 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 34038.56 ymin: 40941.11 xmax: 38882.85 ymax: 44801.27\nProjected CRS: SVY21 / Singapore TM\n\n\nData has to be in linestring and not multiple linestring. Use st to convert it from multi line to single line.\n\nchildcare &lt;- st_read(dsn = \"data/geospatial\",\n                     layer = \"Punggol_CC\") %&gt;%\n  st_zm(drop = TRUE,\n        what = \"ZM\") # to remove z value\n\nReading layer `Punggol_CC' from data source \n  `C:\\zjho008\\ISSS626-GAA\\In-class_Ex\\In-class_Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 61 features and 1 field\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 34423.98 ymin: 41503.6 xmax: 37619.47 ymax: 44685.77\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\n\n\nWe can examine the structure of the output simple data features data tables in R studio.\nchildcare File is in kml format hence the dimension shown is XYZ (additional dimension). It is important to note the dimension. Upon further inspection under geometry the childcare data has point Z.\n\nNote: for take home exercise under entire data file, 1 folder as rawdata, with another separate folder as data for analysis.\n\n\n\n\nBefore we jump into the analysis, it is a good practice to visualise the geospatial data. There are at least two ways to visualise the geospatial data. One way is by using plot() of Base R as shown in the code chunk below.\n\nplot(st_geometry(network)) # plotting the road network first, especially when in sf layer\nplot(childcare, add = T, col = 'red', pch = 19) # followed by the childcare # since mapped with colours when plotted multiple colours do not appear\n\n\n\n\n\n\n\n# add = T -&gt; T = TRUE the point is plotted twice.\n\nCode chunk result when removing the st_geometry:\n\nplot(network)\nplot(childcare, add = T, col = 'red', pch = 19)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nnetwork has 3 columns: Link ID St_name Geometry\nRemoving st_geometry will result in individual columns which are pulled out and plotted individually.\n\n\nTo visualise the data with high cartographic quality and in an interactive manner. The mapping function of tmap package can be used as shown in the code chunk below.\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\ntm_shape(childcare) + # specifying the layer that is being used\n  tm_dots(col = \"red\") +\n  tm_shape(network) + # to use the extent of the map layer\n  tm_lines()\n\n\n\n\n\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\n\nways to add markers;\nhttps://r-tmap.github.io/tmap/reference/index.html\nSpecify the shape object: tm_symbols() tm_squares() tm_bubbles() tm_dots() - to keep the size constant when performing zoom functions tm_markers()\nMaking the plot an interactive layer\n\ntmap_mode('view') #just by switching to 'view' to achieve the interactivity\n\ntmap mode set to interactive viewing\n\ntm_shape(childcare) + # specifying the layer that is being used\n  tm_dots(col = \"red\") +\n  tm_shape(network) + # to use the extent of the map layer\n  tm_lines()\n\n\n\n\ntmap_mode('plot') # to ensure after the session is ended it will end in the plot mode to reduce resource consumption\n\ntmap mode set to plotting\n\n\n\n\n\n\n\n\nNote\n\n\n\nChildcare & network can be switched on and off accordingly.\n3 different data consumptions: 2 layers of ESRI map data (WorldGray Canvas & OpenStreetMap) Topographic layer\n\n\nmpabox ~ leaflet\nWhile using tmap methods requires a longer code chunk the benefit it brings are the flexibility and customisation that can be done.\n\n\nBefore computing NKDE, the Spatial Lines object needs to be cut into lixels with a specified minimal distance. This task can be performed by using lixelize_lines() of spNetwork as shown in the code chunk below.\n\nlixels &lt;- lixelize_lines(network,\n                         700,  \n                         mindist = 350)\n\ngiven that it is a road network and in the context of the childcare - so using the reasonable walking distance based on weather and perceived hindrance is about 700 metres based on a study for perceivable walking distance.\nmindist is set as half for the minimum walking distance.\n2642 segments in the line network. to split into line segment each should be 700 and in the centre the minimum distance should be 350m.\nAfter running the code chunk the segments, the remaining is slightly greater than 350.\nif increase to 500 the segment is 2645\nif reduce to 150m the segment is still the same 2645.\nFor take home ex 3, the BMR has to be plotted - a rough gauge of the general distance so we should not use a distance smaller than the point. Calculating the nearest neighbour to find out the nearest neighbour -\nbased on distances starting on the lowest 25 percentile of accidents along the road segment. Want to acheive a segment that can pick up some accident occurences.\n\n\n\nNext, lines_center() of spNetwork will be used to generate a SpatialPointsDataFrame (i.e. samples) with line centre points as shown in the code chunk below.\n\nsamples &lt;- lines_center(lixels) # sf format\n\n\n\n\n\n\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\ntm_shape(lixels) +\n  tm_lines() +\n  tm_shape(samples) +\n  tm_dots(size = 0.01)\n\n\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\n\n\n\nWe are ready to compute the NKDE by using the code chunk below:\n\ndensities &lt;- nkde(network,\n                  events = childcare,\n                  w = rep(1, nrow(childcare)),\n                  samples = samples,\n                  kernel_name = \"quartic\",\n                  bw = 300,\n                  div = \"bw\",\n                  method = \"simple\",\n                  digits = 1,\n                  tol = 1,\n                  grid_shape = c(1,1),\n                  max_depth = 8,\n                  agg = 5,\n                  sparse = TRUE,\n                  verbose = FALSE)\n\n# avoid gaussian if intensity changes to negative # 3 methods: simple, continous, discontinous\nthe computed density values (i.e. densities) into samples and lixels objects as density field.\n\nsamples$density &lt;- densities\nlixels$density &lt;- densities\n\nTo append the intensity values into the simple tibular frame or lixel data frame simialr to a left join.\nAvoid sorting to avoid changing the sequence.\nvalues attached to the line and point.\nSince the svy21 projection system is in metres, the computed density values are very small i.e. 0.0000005. The code chunk below is used to rescale the density values from number of events per metre to number of events per kilometre.\n\n# rescaling\n\nsamples$density &lt;- samples$density*1000\nlixels$density &lt;- lixels$density*1000\n\nThe code below uses appropriate functions of tmap package to prepare interactive and high cartographic quality map visualisation.\n\ntmap_mode(mode = c(\"view\"))\n\ntmap mode set to interactive viewing\n\ntm_shape(lixels) +\n  tm_lines(col = \"density\") +\n  tm_shape(childcare) +\n  tm_dots()\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\n\n\nkfun_childcare &lt;- kfunctions(network,\n                             childcare,\n                             start = 0,\n                             end = 1000,\n                             step = 50,\n                             width = 50,\n                             nsim = 99, # simulations are starting from zero\n                             resolution = 50,\n                             verbose = FALSE,\n                             conf_int = 0.05)\n\nThe output of kfunctions() is a list with the following values:\n\nplotkA, a ggplot2 object representing the values of the k-function\nplotgA, a ggplot2 object representing the values of the g-function\nvaluesA, a DataFrame with the values used to build the plots\n\nVisualising the ggplot2 object of k-function by using the code chunk below.\n\nK-FunctionG-Function\n\n\n\nkfun_childcare$plotk # whether to plot G / K function\n\n\n\n\n\n\n\n\n2 possible patterns observed\nregular pattern below the envelope - showing signs of regularity - childcare centres near to each other e.g. at 200m apart which is showing the signs of regularity\nand complete spatial randomness at the upper portion.\n\n\n\nkfun_childcare$plotg # whether to plot G / K function\n\n\n\n\n\n\n\n\nboth functions are returned"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#loading-r-packages",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#loading-r-packages",
    "title": "In-class Exercise 3",
    "section": "",
    "text": "pacman::p_load(sf, spNetwork, tmap, tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#data-import-and-preparation",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#data-import-and-preparation",
    "title": "In-class Exercise 3",
    "section": "",
    "text": "The code chunk below uses st_read() of sf package to import Punggol_St and Punggol_CC geospatial data sets into RStudio as sf data frames.\n#Punggol_St is in ESRI Shapefile format\n\nnetwork &lt;- st_read(dsn = \"data/geospatial\",\n                   layer = \"Punggol_St\")\n\nReading layer `Punggol_St' from data source \n  `C:\\zjho008\\ISSS626-GAA\\In-class_Ex\\In-class_Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2642 features and 2 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 34038.56 ymin: 40941.11 xmax: 38882.85 ymax: 44801.27\nProjected CRS: SVY21 / Singapore TM\n\n\nData has to be in linestring and not multiple linestring. Use st to convert it from multi line to single line.\n\nchildcare &lt;- st_read(dsn = \"data/geospatial\",\n                     layer = \"Punggol_CC\") %&gt;%\n  st_zm(drop = TRUE,\n        what = \"ZM\") # to remove z value\n\nReading layer `Punggol_CC' from data source \n  `C:\\zjho008\\ISSS626-GAA\\In-class_Ex\\In-class_Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 61 features and 1 field\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 34423.98 ymin: 41503.6 xmax: 37619.47 ymax: 44685.77\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\n\n\nWe can examine the structure of the output simple data features data tables in R studio.\nchildcare File is in kml format hence the dimension shown is XYZ (additional dimension). It is important to note the dimension. Upon further inspection under geometry the childcare data has point Z.\n\nNote: for take home exercise under entire data file, 1 folder as rawdata, with another separate folder as data for analysis."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#visualising-the-geospatial-data",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#visualising-the-geospatial-data",
    "title": "In-class Exercise 3",
    "section": "",
    "text": "Before we jump into the analysis, it is a good practice to visualise the geospatial data. There are at least two ways to visualise the geospatial data. One way is by using plot() of Base R as shown in the code chunk below.\n\nplot(st_geometry(network)) # plotting the road network first, especially when in sf layer\nplot(childcare, add = T, col = 'red', pch = 19) # followed by the childcare # since mapped with colours when plotted multiple colours do not appear\n\n\n\n\n\n\n\n# add = T -&gt; T = TRUE the point is plotted twice.\n\nCode chunk result when removing the st_geometry:\n\nplot(network)\nplot(childcare, add = T, col = 'red', pch = 19)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nnetwork has 3 columns: Link ID St_name Geometry\nRemoving st_geometry will result in individual columns which are pulled out and plotted individually.\n\n\nTo visualise the data with high cartographic quality and in an interactive manner. The mapping function of tmap package can be used as shown in the code chunk below.\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\ntm_shape(childcare) + # specifying the layer that is being used\n  tm_dots(col = \"red\") +\n  tm_shape(network) + # to use the extent of the map layer\n  tm_lines()\n\n\n\n\n\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\n\nways to add markers;\nhttps://r-tmap.github.io/tmap/reference/index.html\nSpecify the shape object: tm_symbols() tm_squares() tm_bubbles() tm_dots() - to keep the size constant when performing zoom functions tm_markers()\nMaking the plot an interactive layer\n\ntmap_mode('view') #just by switching to 'view' to achieve the interactivity\n\ntmap mode set to interactive viewing\n\ntm_shape(childcare) + # specifying the layer that is being used\n  tm_dots(col = \"red\") +\n  tm_shape(network) + # to use the extent of the map layer\n  tm_lines()\n\n\n\n\ntmap_mode('plot') # to ensure after the session is ended it will end in the plot mode to reduce resource consumption\n\ntmap mode set to plotting\n\n\n\n\n\n\n\n\nNote\n\n\n\nChildcare & network can be switched on and off accordingly.\n3 different data consumptions: 2 layers of ESRI map data (WorldGray Canvas & OpenStreetMap) Topographic layer\n\n\nmpabox ~ leaflet\nWhile using tmap methods requires a longer code chunk the benefit it brings are the flexibility and customisation that can be done.\n\n\nBefore computing NKDE, the Spatial Lines object needs to be cut into lixels with a specified minimal distance. This task can be performed by using lixelize_lines() of spNetwork as shown in the code chunk below.\n\nlixels &lt;- lixelize_lines(network,\n                         700,  \n                         mindist = 350)\n\ngiven that it is a road network and in the context of the childcare - so using the reasonable walking distance based on weather and perceived hindrance is about 700 metres based on a study for perceivable walking distance.\nmindist is set as half for the minimum walking distance.\n2642 segments in the line network. to split into line segment each should be 700 and in the centre the minimum distance should be 350m.\nAfter running the code chunk the segments, the remaining is slightly greater than 350.\nif increase to 500 the segment is 2645\nif reduce to 150m the segment is still the same 2645.\nFor take home ex 3, the BMR has to be plotted - a rough gauge of the general distance so we should not use a distance smaller than the point. Calculating the nearest neighbour to find out the nearest neighbour -\nbased on distances starting on the lowest 25 percentile of accidents along the road segment. Want to acheive a segment that can pick up some accident occurences.\n\n\n\nNext, lines_center() of spNetwork will be used to generate a SpatialPointsDataFrame (i.e. samples) with line centre points as shown in the code chunk below.\n\nsamples &lt;- lines_center(lixels) # sf format"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#visualising-the-lixel-segment",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#visualising-the-lixel-segment",
    "title": "In-class Exercise 3",
    "section": "",
    "text": "tmap_mode('view')\n\ntmap mode set to interactive viewing\n\ntm_shape(lixels) +\n  tm_lines() +\n  tm_shape(samples) +\n  tm_dots(size = 0.01)\n\n\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\n\n\n\nWe are ready to compute the NKDE by using the code chunk below:\n\ndensities &lt;- nkde(network,\n                  events = childcare,\n                  w = rep(1, nrow(childcare)),\n                  samples = samples,\n                  kernel_name = \"quartic\",\n                  bw = 300,\n                  div = \"bw\",\n                  method = \"simple\",\n                  digits = 1,\n                  tol = 1,\n                  grid_shape = c(1,1),\n                  max_depth = 8,\n                  agg = 5,\n                  sparse = TRUE,\n                  verbose = FALSE)\n\n# avoid gaussian if intensity changes to negative # 3 methods: simple, continous, discontinous\nthe computed density values (i.e. densities) into samples and lixels objects as density field.\n\nsamples$density &lt;- densities\nlixels$density &lt;- densities\n\nTo append the intensity values into the simple tibular frame or lixel data frame simialr to a left join.\nAvoid sorting to avoid changing the sequence.\nvalues attached to the line and point.\nSince the svy21 projection system is in metres, the computed density values are very small i.e. 0.0000005. The code chunk below is used to rescale the density values from number of events per metre to number of events per kilometre.\n\n# rescaling\n\nsamples$density &lt;- samples$density*1000\nlixels$density &lt;- lixels$density*1000\n\nThe code below uses appropriate functions of tmap package to prepare interactive and high cartographic quality map visualisation.\n\ntmap_mode(mode = c(\"view\"))\n\ntmap mode set to interactive viewing\n\ntm_shape(lixels) +\n  tm_lines(col = \"density\") +\n  tm_shape(childcare) +\n  tm_dots()\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\n\n\nkfun_childcare &lt;- kfunctions(network,\n                             childcare,\n                             start = 0,\n                             end = 1000,\n                             step = 50,\n                             width = 50,\n                             nsim = 99, # simulations are starting from zero\n                             resolution = 50,\n                             verbose = FALSE,\n                             conf_int = 0.05)\n\nThe output of kfunctions() is a list with the following values:\n\nplotkA, a ggplot2 object representing the values of the k-function\nplotgA, a ggplot2 object representing the values of the g-function\nvaluesA, a DataFrame with the values used to build the plots\n\nVisualising the ggplot2 object of k-function by using the code chunk below.\n\nK-FunctionG-Function\n\n\n\nkfun_childcare$plotk # whether to plot G / K function\n\n\n\n\n\n\n\n\n2 possible patterns observed\nregular pattern below the envelope - showing signs of regularity - childcare centres near to each other e.g. at 200m apart which is showing the signs of regularity\nand complete spatial randomness at the upper portion.\n\n\n\nkfun_childcare$plotg # whether to plot G / K function\n\n\n\n\n\n\n\n\nboth functions are returned"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#g-function",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#g-function",
    "title": "In-class Exercise 3",
    "section": "",
    "text": "kfun_childcare$plotg # whether to plot G / K function\n\n\n\n\n\n\n\n\nboth functions are returned"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "title": "In-class Exercise 4",
    "section": "",
    "text": "pacman::p_load(sf, tmap, tidyverse, knitr, GWmodel, ggstatsplot)\n\n\n\n\nGWmodel\nPackage GWmodel\nFocus is on the Geographically weighted summary statistics (GWSS)\nWhich helps to determine the optimal cut-off metrics\nbw.gwr - e.g. look into data and recommend appropriate bandwidth for cut off adaptive - optimum number of neighbours for statistical significance.\n\n\n\nFor this in-class exericse, Hunan shp file will be used to\n\nhunan_sf &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\zjho008\\ISSS626-GAA\\In-class_Ex\\In-class_Ex04\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\nNote CRS is not defined when importing the data and the CRS is WGS84.\n\n\n\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nNote: read_csv() is from the tidyverse package\n\n\n\nhunan_sf &lt;- left_join(hunan_sf ,hunan2012) %&gt;%\n  select(1:3, 7, 15, 16, 31, 32)\n\nJoining with `by = join_by(County)`\n\n\nNAME_2, ID_3, NAME_3 (name of county), COUNTY, GDP, 26 - GIO, 31- Agri, 32- Service\nA selection is done in the code chunk above to select variables that will be used for analysis\nfor relational joins there has to be a common identifier - values have to be identical\n\nGood practice: to check through the name and the values/fields to ensure they are the same before performing the join. In this case from observation County has the same variable name. For this exercise the COUNTY variable was added into the hunan_2012 dataset. Otherwise, NAME_3 will have to be used and argument JOIN_BY() has to be used.\n\nE.g. the website from URA code to convert from mix of upper case and lower case (data from singstat) to all upper case before joining with the URA data\n\n\n\n\nTo use GWmodel the file has to be converted from SF to SP\n\nhunan_sp &lt;- hunan_sf %&gt;%\n  as_Spatial()\n\nA list is given instead of a data table.\n\nclass(hunan_sp) [1] “SpatialPolygonsDataFrame” attr(,“package”) [1] “sp”\n\n\n\n\n\n\n\nCross Validation - “taking one out and putting one back”\n\n\n\nbw_CV &lt;- bw.gwr(GDPPC ~ 1, # arbitrary number 1 as independent variable\n             data = hunan_sp, # hunan data\n             approach = \"CV\", # cross validation is used\n             adaptive = TRUE,\n             kernel = \"bisquare\",\n             longlat = T) # value taken in is in KM\n\nAdaptive bandwidth: 62 CV score: 15515442343 \nAdaptive bandwidth: 46 CV score: 14937956887 \nAdaptive bandwidth: 36 CV score: 14408561608 \nAdaptive bandwidth: 29 CV score: 14198527496 \nAdaptive bandwidth: 26 CV score: 13898800611 \nAdaptive bandwidth: 22 CV score: 13662299974 \nAdaptive bandwidth: 22 CV score: 13662299974 \n\n\nThe score will eventually stop and the optimal number of neighbour is 22. This is also the same result if AIC is used. However, note that this will not always be the case for both approaches. ## AIC\n\nbw_CV &lt;- bw.gwr(GDPPC ~ 1, \n             data = hunan_sp, \n             approach = \"AIC\", \n             adaptive = TRUE,\n             kernel = \"bisquare\",\n             longlat = T)\n\nAdaptive bandwidth (number of nearest neighbours): 62 AICc value: 1923.156 \nAdaptive bandwidth (number of nearest neighbours): 46 AICc value: 1920.469 \nAdaptive bandwidth (number of nearest neighbours): 36 AICc value: 1917.324 \nAdaptive bandwidth (number of nearest neighbours): 29 AICc value: 1916.661 \nAdaptive bandwidth (number of nearest neighbours): 26 AICc value: 1914.897 \nAdaptive bandwidth (number of nearest neighbours): 22 AICc value: 1914.045 \nAdaptive bandwidth (number of nearest neighbours): 22 AICc value: 1914.045 \n\n\nchange rate will stop and that is where the optimal value is determined Statistical method\n\n\n\n\n\n\n\n\n\n\nCross Validation\n\n\n\nbw_CV &lt;- bw.gwr(GDPPC ~ 1,\n             data = hunan_sp,\n             approach = \"CV\",\n             adaptive = FALSE,\n             kernel = \"bisquare\",\n             longlat = T)\n\nFixed bandwidth: 357.4897 CV score: 16265191728 \nFixed bandwidth: 220.985 CV score: 14954930931 \nFixed bandwidth: 136.6204 CV score: 14134185837 \nFixed bandwidth: 84.48025 CV score: 13693362460 \nFixed bandwidth: 52.25585 CV score: Inf \nFixed bandwidth: 104.396 CV score: 13891052305 \nFixed bandwidth: 72.17162 CV score: 13577893677 \nFixed bandwidth: 64.56447 CV score: 14681160609 \nFixed bandwidth: 76.8731 CV score: 13444716890 \nFixed bandwidth: 79.77877 CV score: 13503296834 \nFixed bandwidth: 75.07729 CV score: 13452450771 \nFixed bandwidth: 77.98296 CV score: 13457916138 \nFixed bandwidth: 76.18716 CV score: 13442911302 \nFixed bandwidth: 75.76323 CV score: 13444600639 \nFixed bandwidth: 76.44916 CV score: 13442994078 \nFixed bandwidth: 76.02523 CV score: 13443285248 \nFixed bandwidth: 76.28724 CV score: 13442844774 \nFixed bandwidth: 76.34909 CV score: 13442864995 \nFixed bandwidth: 76.24901 CV score: 13442855596 \nFixed bandwidth: 76.31086 CV score: 13442847019 \nFixed bandwidth: 76.27264 CV score: 13442846793 \nFixed bandwidth: 76.29626 CV score: 13442844829 \nFixed bandwidth: 76.28166 CV score: 13442845238 \nFixed bandwidth: 76.29068 CV score: 13442844678 \nFixed bandwidth: 76.29281 CV score: 13442844691 \nFixed bandwidth: 76.28937 CV score: 13442844698 \nFixed bandwidth: 76.2915 CV score: 13442844676 \nFixed bandwidth: 76.292 CV score: 13442844679 \nFixed bandwidth: 76.29119 CV score: 13442844676 \nFixed bandwidth: 76.29099 CV score: 13442844676 \nFixed bandwidth: 76.29131 CV score: 13442844676 \nFixed bandwidth: 76.29138 CV score: 13442844676 \nFixed bandwidth: 76.29126 CV score: 13442844676 \nFixed bandwidth: 76.29123 CV score: 13442844676 \n\n\nValue is in KM - 76 KM ## AIC\n\nbw_CV &lt;- bw.gwr(GDPPC ~ 1, \n             data = hunan_sp, \n             approach = \"AIC\", \n             adaptive = FALSE,\n             kernel = \"bisquare\",\n             longlat = T)\n\nFixed bandwidth: 357.4897 AICc value: 1927.631 \nFixed bandwidth: 220.985 AICc value: 1921.547 \nFixed bandwidth: 136.6204 AICc value: 1919.993 \nFixed bandwidth: 84.48025 AICc value: 1940.603 \nFixed bandwidth: 168.8448 AICc value: 1919.457 \nFixed bandwidth: 188.7606 AICc value: 1920.007 \nFixed bandwidth: 156.5362 AICc value: 1919.41 \nFixed bandwidth: 148.929 AICc value: 1919.527 \nFixed bandwidth: 161.2377 AICc value: 1919.392 \nFixed bandwidth: 164.1433 AICc value: 1919.403 \nFixed bandwidth: 159.4419 AICc value: 1919.393 \nFixed bandwidth: 162.3475 AICc value: 1919.394 \nFixed bandwidth: 160.5517 AICc value: 1919.391 \n\n\n\n\n\nWhen using different methods some would give the same answwer while some would give a different answer. So it is a good practice to test out the different methods\nIn this case the adaptive method is better as the Cross Validation and AIC gives the same output.\n\n\n\n\n\n\n\nbw_AIC &lt;- bw.gwr(GDPPC ~ 1, \n             data = hunan_sp, \n             approach = \"AIC\", \n             adaptive = TRUE,\n             kernel = \"bisquare\",\n             longlat = T)\n\nAdaptive bandwidth (number of nearest neighbours): 62 AICc value: 1923.156 \nAdaptive bandwidth (number of nearest neighbours): 46 AICc value: 1920.469 \nAdaptive bandwidth (number of nearest neighbours): 36 AICc value: 1917.324 \nAdaptive bandwidth (number of nearest neighbours): 29 AICc value: 1916.661 \nAdaptive bandwidth (number of nearest neighbours): 26 AICc value: 1914.897 \nAdaptive bandwidth (number of nearest neighbours): 22 AICc value: 1914.045 \nAdaptive bandwidth (number of nearest neighbours): 22 AICc value: 1914.045 \n\nbw_AIC\n\n[1] 22\n\n\n\ngwstat &lt;- gwss(data = hunan_sp,\n               vars = \"GDPPC\",\n               bw = bw_AIC,\n               kernel = \"bisquare\",\n               adaptive = TRUE,\n               longlat = T)\n\n\nNote: that the Kernel, Adaptive and Longlat have to remain the same when doing the calulation\n\n\n\n\nCode chunk below is used to extract SDF data table from gwss object output from gwss(). It will be converted into data.frame by using as.data.frame()\n\ngwstat_df &lt;- as.data.frame(gwstat$SDF)\n\nNext, cbin*d() is used to append the newly derived data.frame onto hunan_sf sf data.frame\n\nhunan_gstat &lt;- cbind(hunan_sf, gwstat_df)\n\n\nThe Geographhically Weighted Mean\n\n\n\n\n\n\n\n\n\n\n\nShowing growth at the main cities first whereas the rural areas see slower growth - which is commonly observed in developing countries. ## The code\n\ntm_shape(hunan_gstat) +\n  tm_fill(\"GDPPC_LM\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) + # or tm_polygons\n  tm_layout(main.title = \"distribution of geogrpahically weighted mean\",\n            main.title.position = \"centre\",\n            main.title.size = 2.0,\n            legend.title.size = 1.2,\n            legend.height = 1.50,\n            legend.width = 1.50,\n            frame = TRUE)\n\n\n\n\n\n\n\n\n\nBusiness Question: Is there any relationship between GDP per capita and Gross Industry Output?\n\n\n\n\nFrom the p-value there is a relatively strong correlation and statistical significance.\nCertain areas not as highly correlated with neighbours while others are more correlated - Geographic view vs statistical solution view.\ngwCorr - 0.750 to 0.761\nThe 1st band not as correlated with its neighbours\nLocal correlation can also be shown\n\n\ncolumn 12 and 13 selected where we see the correlation coefficient."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#loading-r-packages",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#loading-r-packages",
    "title": "In-class Exercise 4",
    "section": "",
    "text": "pacman::p_load(sf, tmap, tidyverse, knitr, GWmodel, ggstatsplot)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#additional-package",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#additional-package",
    "title": "In-class Exercise 4",
    "section": "",
    "text": "GWmodel\nPackage GWmodel\nFocus is on the Geographically weighted summary statistics (GWSS)\nWhich helps to determine the optimal cut-off metrics\nbw.gwr - e.g. look into data and recommend appropriate bandwidth for cut off adaptive - optimum number of neighbours for statistical significance."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#data-import-and-preparation",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#data-import-and-preparation",
    "title": "In-class Exercise 4",
    "section": "",
    "text": "For this in-class exericse, Hunan shp file will be used to\n\nhunan_sf &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\zjho008\\ISSS626-GAA\\In-class_Ex\\In-class_Ex04\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\nNote CRS is not defined when importing the data and the CRS is WGS84."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#importign-the-hunan_2012-table",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#importign-the-hunan_2012-table",
    "title": "In-class Exercise 4",
    "section": "",
    "text": "hunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nNote: read_csv() is from the tidyverse package\n\n\n\nhunan_sf &lt;- left_join(hunan_sf ,hunan2012) %&gt;%\n  select(1:3, 7, 15, 16, 31, 32)\n\nJoining with `by = join_by(County)`\n\n\nNAME_2, ID_3, NAME_3 (name of county), COUNTY, GDP, 26 - GIO, 31- Agri, 32- Service\nA selection is done in the code chunk above to select variables that will be used for analysis\nfor relational joins there has to be a common identifier - values have to be identical\n\nGood practice: to check through the name and the values/fields to ensure they are the same before performing the join. In this case from observation County has the same variable name. For this exercise the COUNTY variable was added into the hunan_2012 dataset. Otherwise, NAME_3 will have to be used and argument JOIN_BY() has to be used.\n\nE.g. the website from URA code to convert from mix of upper case and lower case (data from singstat) to all upper case before joining with the URA data"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#converting-to-spatialpolygon-data.frame",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#converting-to-spatialpolygon-data.frame",
    "title": "In-class Exercise 4",
    "section": "",
    "text": "To use GWmodel the file has to be converted from SF to SP\n\nhunan_sp &lt;- hunan_sf %&gt;%\n  as_Spatial()\n\nA list is given instead of a data table.\n\nclass(hunan_sp) [1] “SpatialPolygonsDataFrame” attr(,“package”) [1] “sp”"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#geographically-weighted-summary-statistics-with-adaptative-bandwidth",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#geographically-weighted-summary-statistics-with-adaptative-bandwidth",
    "title": "In-class Exercise 4",
    "section": "",
    "text": "Cross Validation - “taking one out and putting one back”\n\n\n\nbw_CV &lt;- bw.gwr(GDPPC ~ 1, # arbitrary number 1 as independent variable\n             data = hunan_sp, # hunan data\n             approach = \"CV\", # cross validation is used\n             adaptive = TRUE,\n             kernel = \"bisquare\",\n             longlat = T) # value taken in is in KM\n\nAdaptive bandwidth: 62 CV score: 15515442343 \nAdaptive bandwidth: 46 CV score: 14937956887 \nAdaptive bandwidth: 36 CV score: 14408561608 \nAdaptive bandwidth: 29 CV score: 14198527496 \nAdaptive bandwidth: 26 CV score: 13898800611 \nAdaptive bandwidth: 22 CV score: 13662299974 \nAdaptive bandwidth: 22 CV score: 13662299974 \n\n\nThe score will eventually stop and the optimal number of neighbour is 22. This is also the same result if AIC is used. However, note that this will not always be the case for both approaches. ## AIC\n\nbw_CV &lt;- bw.gwr(GDPPC ~ 1, \n             data = hunan_sp, \n             approach = \"AIC\", \n             adaptive = TRUE,\n             kernel = \"bisquare\",\n             longlat = T)\n\nAdaptive bandwidth (number of nearest neighbours): 62 AICc value: 1923.156 \nAdaptive bandwidth (number of nearest neighbours): 46 AICc value: 1920.469 \nAdaptive bandwidth (number of nearest neighbours): 36 AICc value: 1917.324 \nAdaptive bandwidth (number of nearest neighbours): 29 AICc value: 1916.661 \nAdaptive bandwidth (number of nearest neighbours): 26 AICc value: 1914.897 \nAdaptive bandwidth (number of nearest neighbours): 22 AICc value: 1914.045 \nAdaptive bandwidth (number of nearest neighbours): 22 AICc value: 1914.045 \n\n\nchange rate will stop and that is where the optimal value is determined Statistical method"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#geographically-weighted-summary-statistics-with-fixed-bandwidth",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#geographically-weighted-summary-statistics-with-fixed-bandwidth",
    "title": "In-class Exercise 4",
    "section": "",
    "text": "Cross Validation\n\n\n\nbw_CV &lt;- bw.gwr(GDPPC ~ 1,\n             data = hunan_sp,\n             approach = \"CV\",\n             adaptive = FALSE,\n             kernel = \"bisquare\",\n             longlat = T)\n\nFixed bandwidth: 357.4897 CV score: 16265191728 \nFixed bandwidth: 220.985 CV score: 14954930931 \nFixed bandwidth: 136.6204 CV score: 14134185837 \nFixed bandwidth: 84.48025 CV score: 13693362460 \nFixed bandwidth: 52.25585 CV score: Inf \nFixed bandwidth: 104.396 CV score: 13891052305 \nFixed bandwidth: 72.17162 CV score: 13577893677 \nFixed bandwidth: 64.56447 CV score: 14681160609 \nFixed bandwidth: 76.8731 CV score: 13444716890 \nFixed bandwidth: 79.77877 CV score: 13503296834 \nFixed bandwidth: 75.07729 CV score: 13452450771 \nFixed bandwidth: 77.98296 CV score: 13457916138 \nFixed bandwidth: 76.18716 CV score: 13442911302 \nFixed bandwidth: 75.76323 CV score: 13444600639 \nFixed bandwidth: 76.44916 CV score: 13442994078 \nFixed bandwidth: 76.02523 CV score: 13443285248 \nFixed bandwidth: 76.28724 CV score: 13442844774 \nFixed bandwidth: 76.34909 CV score: 13442864995 \nFixed bandwidth: 76.24901 CV score: 13442855596 \nFixed bandwidth: 76.31086 CV score: 13442847019 \nFixed bandwidth: 76.27264 CV score: 13442846793 \nFixed bandwidth: 76.29626 CV score: 13442844829 \nFixed bandwidth: 76.28166 CV score: 13442845238 \nFixed bandwidth: 76.29068 CV score: 13442844678 \nFixed bandwidth: 76.29281 CV score: 13442844691 \nFixed bandwidth: 76.28937 CV score: 13442844698 \nFixed bandwidth: 76.2915 CV score: 13442844676 \nFixed bandwidth: 76.292 CV score: 13442844679 \nFixed bandwidth: 76.29119 CV score: 13442844676 \nFixed bandwidth: 76.29099 CV score: 13442844676 \nFixed bandwidth: 76.29131 CV score: 13442844676 \nFixed bandwidth: 76.29138 CV score: 13442844676 \nFixed bandwidth: 76.29126 CV score: 13442844676 \nFixed bandwidth: 76.29123 CV score: 13442844676 \n\n\nValue is in KM - 76 KM ## AIC\n\nbw_CV &lt;- bw.gwr(GDPPC ~ 1, \n             data = hunan_sp, \n             approach = \"AIC\", \n             adaptive = FALSE,\n             kernel = \"bisquare\",\n             longlat = T)\n\nFixed bandwidth: 357.4897 AICc value: 1927.631 \nFixed bandwidth: 220.985 AICc value: 1921.547 \nFixed bandwidth: 136.6204 AICc value: 1919.993 \nFixed bandwidth: 84.48025 AICc value: 1940.603 \nFixed bandwidth: 168.8448 AICc value: 1919.457 \nFixed bandwidth: 188.7606 AICc value: 1920.007 \nFixed bandwidth: 156.5362 AICc value: 1919.41 \nFixed bandwidth: 148.929 AICc value: 1919.527 \nFixed bandwidth: 161.2377 AICc value: 1919.392 \nFixed bandwidth: 164.1433 AICc value: 1919.403 \nFixed bandwidth: 159.4419 AICc value: 1919.393 \nFixed bandwidth: 162.3475 AICc value: 1919.394 \nFixed bandwidth: 160.5517 AICc value: 1919.391 \n\n\n\n\n\nWhen using different methods some would give the same answwer while some would give a different answer. So it is a good practice to test out the different methods\nIn this case the adaptive method is better as the Cross Validation and AIC gives the same output."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#geographically-weighted-summary-statistics-with-adaptative-bandwidth-1",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#geographically-weighted-summary-statistics-with-adaptative-bandwidth-1",
    "title": "In-class Exercise 4",
    "section": "",
    "text": "bw_AIC &lt;- bw.gwr(GDPPC ~ 1, \n             data = hunan_sp, \n             approach = \"AIC\", \n             adaptive = TRUE,\n             kernel = \"bisquare\",\n             longlat = T)\n\nAdaptive bandwidth (number of nearest neighbours): 62 AICc value: 1923.156 \nAdaptive bandwidth (number of nearest neighbours): 46 AICc value: 1920.469 \nAdaptive bandwidth (number of nearest neighbours): 36 AICc value: 1917.324 \nAdaptive bandwidth (number of nearest neighbours): 29 AICc value: 1916.661 \nAdaptive bandwidth (number of nearest neighbours): 26 AICc value: 1914.897 \nAdaptive bandwidth (number of nearest neighbours): 22 AICc value: 1914.045 \nAdaptive bandwidth (number of nearest neighbours): 22 AICc value: 1914.045 \n\nbw_AIC\n\n[1] 22\n\n\n\ngwstat &lt;- gwss(data = hunan_sp,\n               vars = \"GDPPC\",\n               bw = bw_AIC,\n               kernel = \"bisquare\",\n               adaptive = TRUE,\n               longlat = T)\n\n\nNote: that the Kernel, Adaptive and Longlat have to remain the same when doing the calulation\n\n\n\n\nCode chunk below is used to extract SDF data table from gwss object output from gwss(). It will be converted into data.frame by using as.data.frame()\n\ngwstat_df &lt;- as.data.frame(gwstat$SDF)\n\nNext, cbin*d() is used to append the newly derived data.frame onto hunan_sf sf data.frame\n\nhunan_gstat &lt;- cbind(hunan_sf, gwstat_df)\n\n\nThe Geographhically Weighted Mean\n\n\n\n\n\n\n\n\n\n\n\nShowing growth at the main cities first whereas the rural areas see slower growth - which is commonly observed in developing countries. ## The code\n\ntm_shape(hunan_gstat) +\n  tm_fill(\"GDPPC_LM\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) + # or tm_polygons\n  tm_layout(main.title = \"distribution of geogrpahically weighted mean\",\n            main.title.position = \"centre\",\n            main.title.size = 2.0,\n            legend.title.size = 1.2,\n            legend.height = 1.50,\n            legend.width = 1.50,\n            frame = TRUE)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#geogrpahically-weighted-correlation-with-adaptive-bandwidth",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#geogrpahically-weighted-correlation-with-adaptive-bandwidth",
    "title": "In-class Exercise 4",
    "section": "",
    "text": "Business Question: Is there any relationship between GDP per capita and Gross Industry Output?"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#conventional-statistical-solution",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#conventional-statistical-solution",
    "title": "In-class Exercise 4",
    "section": "",
    "text": "From the p-value there is a relatively strong correlation and statistical significance.\nCertain areas not as highly correlated with neighbours while others are more correlated - Geographic view vs statistical solution view.\ngwCorr - 0.750 to 0.761\nThe 1st band not as correlated with its neighbours\nLocal correlation can also be shown\n\n\ncolumn 12 and 13 selected where we see the correlation coefficient."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "title": "Hands-on Exercise 4: Spatial Weights and Applications",
    "section": "",
    "text": "In this hands-on exercise, it will run through the process of computing spatial weights using R. By the end to this hands-on exercise, one should be able to:\n\nimport geospatial data using appropriate function(s) of sf package,\nimport csv file using appropriate function of readr package,\nperform relational join using appropriate join function of dplyr package,\ncompute spatial weights using appropriate functions of spdep package, and\ncalculate spatially lagged variables using appropriate functions of spdep package.\n\n\n\n\nTwo data sets will be used in this hands-on exercise, they are:\n\nHunan county boundary layer. This is a geospatial data set in ESRI shapefile format.\nHunan_2012.csv; This csv file contains selected Hunan’s local development indicators in 2012.\n\n\n\nBefore getting started, ensure that spdep, sf, tmap, tidyverse and knitrpackages of R are currently installed in R.\n\npacman::p_load(spdep, sf, tmap, tidyverse, knitr)\n\n\n\n\n\nIn this section, the geospatial data and its associated attribute table will be brought in R environment. The geospatial data is in ESRI shapefile format and the attribute table is in csv format.\n\n\nThe code chunk below uses st_read() of sf package to import Hunan shapefile into R. The imported shapefile will be a simple feature Object of sf.\n\nhunan &lt;- st_read(dsn = \"data/geospatial\",\n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex04\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n\nNext, Hunan_2012.csv will be imported into R by using read_csv() of readr package. The output is a R dataframe class.\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nThe code chunk below will be used to update the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 dataframe. This is performed by using left_join() of dplyr package.\nThe select() function is used to select variables that are objectively used for the spatial analysis.\n\nhunan &lt;- left_join(hunan, hunan2012) %&gt;%\n  select(1:4, 7, 15)\n\nJoining with `by = join_by(County)`\n\n\n\n\n\n\nNow, a basemap and a choropleth map will be prepared showing the distribution of GDPPC 2012 by using qtm() of tmap package.\n\nbasemap &lt;- tm_shape(hunan) +\n  tm_polygons() +\n  tm_text(\"NAME_3\", size = 0.5)\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\ntmap_arrange(basemap, gdppc, asp = 1, ncol = 2)\n\n\n\n\n\n\n\n\n\nNote: Gross Domestic Product per Capita (GDPPC)\n\n\n\n\nIn this section, we will learn how to use poly2nb() of spdep package to compute contiguity weight matrices for the study area.\nThis function builds a neighbours list based on regions with contiguous boundaries. From the documentation, we learn that we can pass a “queen” argument that takes TRUE or FALSE as options. If this argument is not specified the argument’s default is set to TRUE, that is, if we don’t specify queen = FALSE this function will return a list of first order neighbours using the Queen criteria.\n\n\nThe code chunk below is used to compute Queen contiguity weight matrix.\n\nwm_q &lt;- poly2nb(hunan, queen = TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report above shows that there are 88 area units (regions) in Hunan. The most connected area unit has 11 neighbours. There are two area units with only one neighbour.\nFor each polygon in the polygon object, wm_q lists all neighbouring polygons. For example, to see the neighbours for the first polygon in the object, type:\n\nwm_q[[1]]\n\n[1]  2  3  4 57 85\n\n\nPolygon 1 has 5 neighbours. The numbers represent the polygon IDs as stored in hunan SpatialPolygonsDataFrame class.\nWe can retrieve the county name of Polygon ID=1 by using the code chunk below:\n\nhunan$County[1]\n\n[1] \"Anxiang\"\n\n\nThe output reveals that Polygon ID=1 is Anxiang county.\nTo reveal the county names of the five neighbouring polygons, the code chunk will be used:\n\nhunan$NAME_3[c(2,3,4,57,85)]\n\n[1] \"Hanshou\" \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\"\n\n\nWe can retrieve the GDPPC of these five counties by using the code chunk below.\n\nnb1 &lt;- wm_q[[1]]\nnb1 &lt;- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\nThe printed output above shows that the GDPPC of the five nearest neighbours based on Queen’s method are 20981, 34592, 24473, 21311 and 22879 respectively.\nWe can display the complete weight matrix by using str().\n\nstr(wm_q)\n\nList of 88\n $ : int [1:5] 2 3 4 57 85\n $ : int [1:5] 1 57 58 78 85\n $ : int [1:4] 1 4 5 85\n $ : int [1:4] 1 3 5 6\n $ : int [1:4] 3 4 6 85\n $ : int [1:5] 4 5 69 75 85\n $ : int [1:4] 67 71 74 84\n $ : int [1:7] 9 46 47 56 78 80 86\n $ : int [1:6] 8 66 68 78 84 86\n $ : int [1:8] 16 17 19 20 22 70 72 73\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:3] 11 15 17\n $ : int [1:4] 13 14 17 83\n $ : int [1:5] 10 17 22 72 83\n $ : int [1:7] 10 11 14 15 16 72 83\n $ : int [1:5] 20 22 23 77 83\n $ : int [1:6] 10 20 21 73 74 86\n $ : int [1:7] 10 18 19 21 22 23 82\n $ : int [1:5] 19 20 35 82 86\n $ : int [1:5] 10 16 18 20 83\n $ : int [1:7] 18 20 38 41 77 79 82\n $ : int [1:5] 25 28 31 32 54\n $ : int [1:5] 24 28 31 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:3] 26 29 42\n $ : int [1:5] 24 25 33 49 54\n $ : int [1:3] 27 37 42\n $ : int 33\n $ : int [1:8] 24 25 32 36 39 40 56 81\n $ : int [1:8] 24 31 50 54 55 56 75 85\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 47 80 82 86\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:4] 29 42 43 44\n $ : int [1:4] 23 44 77 79\n $ : int [1:5] 31 40 42 43 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:7] 26 27 29 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:4] 37 38 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:3] 8 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:5] 32 48 52 54 55\n $ : int [1:3] 48 49 52\n $ : int [1:5] 48 49 50 51 54\n $ : int [1:3] 48 55 75\n $ : int [1:6] 24 28 32 49 50 52\n $ : int [1:5] 32 48 50 53 75\n $ : int [1:7] 8 31 32 36 78 80 85\n $ : int [1:6] 1 2 58 64 76 85\n $ : int [1:5] 2 57 68 76 78\n $ : int [1:4] 60 61 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:7] 12 59 60 62 63 77 87\n $ : int [1:3] 61 77 87\n $ : int [1:4] 12 61 77 83\n $ : int [1:2] 57 76\n $ : int 76\n $ : int [1:5] 9 67 68 76 84\n $ : int [1:4] 7 66 76 84\n $ : int [1:5] 9 58 66 76 78\n $ : int [1:3] 6 75 85\n $ : int [1:3] 10 72 73\n $ : int [1:3] 7 73 74\n $ : int [1:5] 10 11 16 17 70\n $ : int [1:5] 10 19 70 71 74\n $ : int [1:6] 7 19 71 73 84 86\n $ : int [1:6] 6 32 53 55 69 85\n $ : int [1:7] 57 58 64 65 66 67 68\n $ : int [1:7] 18 23 38 61 62 63 83\n $ : int [1:7] 2 8 9 56 58 68 85\n $ : int [1:7] 23 38 40 41 43 44 45\n $ : int [1:8] 8 34 35 36 41 45 47 56\n $ : int [1:6] 25 26 31 33 39 42\n $ : int [1:5] 20 21 23 35 41\n $ : int [1:9] 12 13 15 16 17 18 22 63 77\n $ : int [1:6] 7 9 66 67 74 86\n $ : int [1:11] 1 2 3 5 6 32 56 57 69 75 ...\n $ : int [1:9] 8 9 19 21 35 46 47 74 84\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language poly2nb(pl = hunan, queen = TRUE)\n - attr(*, \"type\")= chr \"queen\"\n - attr(*, \"sym\")= logi TRUE\n\n\n\n\n\n\n\n\nWarning\n\n\n\nBe warned: The output might cut across several pages. Do consider saving the trees if you are going to print out the report.\n\n\n\n\n\nleast connectedmost connected\n\n\n\nwm_q[[30]]\n\n[1] 33\n\nwm_q[[65]]\n\n[1] 76\n\n\n\n\n\nwm_q[[85]]\n\n [1]  1  2  3  5  6 32 56 57 69 75 78\n\n\n\nhunan$County[85]\n\n[1] \"Taoyuan\"\n\n\nTo reveal the county names of the eleven neighbouring polygons, the code chunk will be used:\n\nhunan$NAME_3[c(1,2,3,5,6,32,56,57,69,75,78)]\n\n [1] \"Anxiang\"  \"Hanshou\"  \"Jinshi\"   \"Linli\"    \"Shimen\"   \"Yuanling\"\n [7] \"Anhua\"    \"Nan\"      \"Cili\"     \"Sangzhi\"  \"Taojiang\"\n\n\nRevealing the GDPPC of there eleven counties by using the code chunk below.\n\nnb1 &lt;- wm_q[[85]]\nnb1 &lt;- hunan$GDPPC[nb1]\nnb1\n\n [1] 23667 20981 34592 25554 27137 24194 14567 21311 18714 14624 19509\n\n\n\n\n\n\n\n\n\nThe code chunk below is used to compute Rook contiguity weight matrix.\n\nwm_r &lt;- poly2nb(hunan, queen = FALSE)\nsummary(wm_r)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connected area unit has 10 neighbours. There are two area units with only one neighbours.\n\n\n\nA connectivity graph takes a point and displays a line to each neighbouring point. We are working with polygons at the moment, so we will need to get points in order to make our connectivity graphs. The most typically used method for this will be polygon centroids. We will calculate these in the sf package before moving onto the graphs. Getting Latitude and Longitude of Polygon Centroids\nWe will need points to associate with each polygon before we can make our connectivity graph. It will be a little more complicated than just running st_centroid on the sf object: us.bound. We need the coordinates in a separate data frame for this to work. To do this we will use a mapping function. The mapping function applies a given function to each element of a vector and returns a vector of the same length. Our input vector will be the geometry column of us.bound. Our function will be st_centroid. We will be using map_dbl variation of map from the purrr package. For more documentation, check out map documentation\nTo get our longitude values we map the st_centroid function over the geometry column of us.bound and access the longitude value through double bracket notation [[]] and 1. This allows us to get only the longitude, which is the first value in each centroid.\n\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\nWe can do the same for latitude with one key difference. We access the second value per each centroid with [[2]].\n\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\nNow that longitude and latitude is obtained, we use cbind to put longitude and latitude into the same object.\n\ncoords &lt;- cbind(longitude, latitude)\n\nUpon running the code chunk, we can check the first few observations to see if things are formatted correctly.\n\nhead(coords)\n\n     longitude latitude\n[1,]  112.1531 29.44362\n[2,]  112.0372 28.86489\n[3,]  111.8917 29.47107\n[4,]  111.7031 29.74499\n[5,]  111.6138 29.49258\n[6,]  111.0341 29.79863\n\n\n\n\n\nplot(hunan$geometry, border = \"lightgrey\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\n\n\n\n\n\n\n\n\n\n\n\n\nplot(hunan$geometry, border = \"lightgrey\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\n\n\n\n\n\n\n\n\n\n\n\n\npar(mfrow = c(1,2))\nplot(hunan$geometry, border = \"lightgrey\", main = \"Queen Contiguity\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\nplot(hunan$geometry, border = \"lightgrey\", main = \"Rook Contiguity\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn this section, we will learn how to derive distance-based weight matrices by using dnearneigh() of spdep package.\nThe function identifies neighbours of region points by Euclidean distance with a distance band with lower d1= and upper d2= bounds controlled by the bounds = argument. If un-projected coordinates are used and either specified in the coordinates object x or with x as a two column matrix and = TRUE, great circle distances in km will be calculated assuming the WGS84 reference ellipsoid.\n\n\nFirstly, we need to determine the upper limit for distance band by using the steps below:\n\nReturn a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using knearneigh() of spdep.\nConvert the knn object returned by knearneigh() into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using knn2nb().\nReturn the length of neighbour relationship edges by using nbdists() of spdep. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise.\nRemove the list structure of the returned object by using unlist().\n\n\n#coords &lt;- coordinates(hunan)\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nThe summary report shows that the largest first nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour.\n\n\n\nNow, we will compute the distance weight matrix by using dnearneigh() as shown in the code chunk below.\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\n\nQuiz: What is the meaning of “Average number of links: 3.681818” shown above?\nInterpretation: An average of 3.681818 means that, on average, each point has about 3.68 neighbours within the specified distance band (0 to 62 km in this case). This gives a sense of the overall connectivity in the spatial network. A higher average number of links suggests that points are more densely connected, while a lower number suggests sparser connections.\n\nNext, we will use str() to display the content of wm_d62 weight matrix.\n\nstr(wm_d62)\n\nList of 88\n $ : int [1:5] 3 4 5 57 64\n $ : int [1:4] 57 58 78 85\n $ : int [1:4] 1 4 5 57\n $ : int [1:3] 1 3 5\n $ : int [1:4] 1 3 4 85\n $ : int 69\n $ : int [1:2] 67 84\n $ : int [1:4] 9 46 47 78\n $ : int [1:4] 8 46 68 84\n $ : int [1:4] 16 22 70 72\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:2] 11 17\n $ : int 13\n $ : int [1:4] 10 17 22 83\n $ : int [1:3] 11 14 16\n $ : int [1:3] 20 22 63\n $ : int [1:5] 20 21 73 74 82\n $ : int [1:5] 18 19 21 22 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:4] 10 16 18 20\n $ : int [1:3] 41 77 82\n $ : int [1:4] 25 28 31 54\n $ : int [1:4] 24 28 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:2] 26 29\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:2] 27 37\n $ : int 33\n $ : int [1:2] 24 36\n $ : int 50\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:5] 31 34 45 56 80\n $ : int [1:2] 29 42\n $ : int [1:3] 44 77 79\n $ : int [1:4] 40 42 43 81\n $ : int [1:3] 39 45 79\n $ : int [1:5] 23 35 45 79 82\n $ : int [1:5] 26 37 39 43 81\n $ : int [1:3] 39 42 44\n $ : int [1:2] 38 43\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:5] 8 9 35 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:4] 48 49 50 52\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:2] 48 55\n $ : int [1:5] 24 28 49 50 52\n $ : int [1:4] 48 50 53 75\n $ : int 36\n $ : int [1:5] 1 2 3 58 64\n $ : int [1:5] 2 57 64 66 68\n $ : int [1:3] 60 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:5] 12 60 62 63 87\n $ : int [1:4] 61 63 77 87\n $ : int [1:5] 12 18 61 62 83\n $ : int [1:4] 1 57 58 76\n $ : int 76\n $ : int [1:5] 58 67 68 76 84\n $ : int [1:2] 7 66\n $ : int [1:4] 9 58 66 84\n $ : int [1:2] 6 75\n $ : int [1:3] 10 72 73\n $ : int [1:2] 73 74\n $ : int [1:3] 10 11 70\n $ : int [1:4] 19 70 71 74\n $ : int [1:5] 19 21 71 73 86\n $ : int [1:2] 55 69\n $ : int [1:3] 64 65 66\n $ : int [1:3] 23 38 62\n $ : int [1:2] 2 8\n $ : int [1:4] 38 40 41 45\n $ : int [1:5] 34 35 36 45 47\n $ : int [1:5] 25 26 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:4] 12 13 16 63\n $ : int [1:4] 7 9 66 68\n $ : int [1:2] 2 5\n $ : int [1:4] 21 46 47 74\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language dnearneigh(x = coords, d1 = 0, d2 = 62, longlat = TRUE)\n - attr(*, \"dnn\")= num [1:2] 0 62\n - attr(*, \"bounds\")= chr [1:2] \"GE\" \"LE\"\n - attr(*, \"nbtype\")= chr \"distance\"\n - attr(*, \"sym\")= logi TRUE\n\n\nAnother way to display the structure of the weight matrix is to combine table() and card() of spdep.\n\ntable(hunan$County, card(wm_d62))\n\n               \n                1 2 3 4 5 6\n  Anhua         1 0 0 0 0 0\n  Anren         0 0 0 1 0 0\n  Anxiang       0 0 0 0 1 0\n  Baojing       0 0 0 0 1 0\n  Chaling       0 0 1 0 0 0\n  Changning     0 0 1 0 0 0\n  Changsha      0 0 0 1 0 0\n  Chengbu       0 1 0 0 0 0\n  Chenxi        0 0 0 1 0 0\n  Cili          0 1 0 0 0 0\n  Dao           0 0 0 1 0 0\n  Dongan        0 0 1 0 0 0\n  Dongkou       0 0 0 1 0 0\n  Fenghuang     0 0 0 1 0 0\n  Guidong       0 0 1 0 0 0\n  Guiyang       0 0 0 1 0 0\n  Guzhang       0 0 0 0 0 1\n  Hanshou       0 0 0 1 0 0\n  Hengdong      0 0 0 0 1 0\n  Hengnan       0 0 0 0 1 0\n  Hengshan      0 0 0 0 0 1\n  Hengyang      0 0 0 0 0 1\n  Hongjiang     0 0 0 0 1 0\n  Huarong       0 0 0 1 0 0\n  Huayuan       0 0 0 1 0 0\n  Huitong       0 0 0 1 0 0\n  Jiahe         0 0 0 0 1 0\n  Jianghua      0 0 1 0 0 0\n  Jiangyong     0 1 0 0 0 0\n  Jingzhou      0 1 0 0 0 0\n  Jinshi        0 0 0 1 0 0\n  Jishou        0 0 0 0 0 1\n  Lanshan       0 0 0 1 0 0\n  Leiyang       0 0 0 1 0 0\n  Lengshuijiang 0 0 1 0 0 0\n  Li            0 0 1 0 0 0\n  Lianyuan      0 0 0 0 1 0\n  Liling        0 1 0 0 0 0\n  Linli         0 0 0 1 0 0\n  Linwu         0 0 0 1 0 0\n  Linxiang      1 0 0 0 0 0\n  Liuyang       0 1 0 0 0 0\n  Longhui       0 0 1 0 0 0\n  Longshan      0 1 0 0 0 0\n  Luxi          0 0 0 0 1 0\n  Mayang        0 0 0 0 0 1\n  Miluo         0 0 0 0 1 0\n  Nan           0 0 0 0 1 0\n  Ningxiang     0 0 0 1 0 0\n  Ningyuan      0 0 0 0 1 0\n  Pingjiang     0 1 0 0 0 0\n  Qidong        0 0 1 0 0 0\n  Qiyang        0 0 1 0 0 0\n  Rucheng       0 1 0 0 0 0\n  Sangzhi       0 1 0 0 0 0\n  Shaodong      0 0 0 0 1 0\n  Shaoshan      0 0 0 0 1 0\n  Shaoyang      0 0 0 1 0 0\n  Shimen        1 0 0 0 0 0\n  Shuangfeng    0 0 0 0 0 1\n  Shuangpai     0 0 0 1 0 0\n  Suining       0 0 0 0 1 0\n  Taojiang      0 1 0 0 0 0\n  Taoyuan       0 1 0 0 0 0\n  Tongdao       0 1 0 0 0 0\n  Wangcheng     0 0 0 1 0 0\n  Wugang        0 0 1 0 0 0\n  Xiangtan      0 0 0 1 0 0\n  Xiangxiang    0 0 0 0 1 0\n  Xiangyin      0 0 0 1 0 0\n  Xinhua        0 0 0 0 1 0\n  Xinhuang      1 0 0 0 0 0\n  Xinning       0 1 0 0 0 0\n  Xinshao       0 0 0 0 0 1\n  Xintian       0 0 0 0 1 0\n  Xupu          0 1 0 0 0 0\n  Yanling       0 0 1 0 0 0\n  Yizhang       1 0 0 0 0 0\n  Yongshun      0 0 0 1 0 0\n  Yongxing      0 0 0 1 0 0\n  You           0 0 0 1 0 0\n  Yuanjiang     0 0 0 0 1 0\n  Yuanling      1 0 0 0 0 0\n  Yueyang       0 0 1 0 0 0\n  Zhijiang      0 0 0 0 1 0\n  Zhongfang     0 0 0 1 0 0\n  Zhuzhou       0 0 0 0 1 0\n  Zixing        0 0 1 0 0 0\n\n\n\nn_comp &lt;- n.comp.nb(wm_d62)\nn_comp$nc\n\n[1] 1\n\n\n\ntable(n_comp$comp.id)\n\n\n 1 \n88 \n\n\n\n\nNext, we will plot the distance weight matrix by using the code chunk below.\n\nplot(hunan$geometry, border = \"lightgrey\")\nplot(wm_d62, coords, add = TRUE)\nplot(k1, coords, add = TRUE, col = \"red\", length = 0.08)\n\n\n\n\n\n\n\n\nThe red lines show the links of 1st nearest neighbours and the black lines show the links of neighbours within the cut-off distance of 62km.\nAlternatively, we can plot both of them next to each other by using the code chunk below.\n\npar(mfrow = c(1,2))\nplot(hunan$geometry, border = \"lightgrey\", main = \"1st nearest neighbours\")\nplot(k1, coords, add = TRUE, col = \"red\", length = 0.88)\nplot(hunan$geometry, border = \"lightgrey\", main = \"Distance link\")\nplot(wm_d62, coords, add = TRUE, pch = 19, cex = 0.6)\n\n\n\n\n\n\n\n\n\n\n\n\nOne of the characteristics of fixed distance weight matrix is that the more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours soothes the neighbour relationship across more neighbours.\nIt is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below.\n\nknn6 &lt;- knn2nb(knearneigh(coords, k=6))\nknn6\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 528 \nPercentage nonzero weights: 6.818182 \nAverage number of links: 6 \nNon-symmetric neighbours list\n\n\nSimilarly, the content of the matrix can be displayed by using str().\n\nstr(knn6)\n\nList of 88\n $ : int [1:6] 2 3 4 5 57 64\n $ : int [1:6] 1 3 57 58 78 85\n $ : int [1:6] 1 2 4 5 57 85\n $ : int [1:6] 1 3 5 6 69 85\n $ : int [1:6] 1 3 4 6 69 85\n $ : int [1:6] 3 4 5 69 75 85\n $ : int [1:6] 9 66 67 71 74 84\n $ : int [1:6] 9 46 47 78 80 86\n $ : int [1:6] 8 46 66 68 84 86\n $ : int [1:6] 16 19 22 70 72 73\n $ : int [1:6] 10 14 16 17 70 72\n $ : int [1:6] 13 15 60 61 63 83\n $ : int [1:6] 12 15 60 61 63 83\n $ : int [1:6] 11 15 16 17 72 83\n $ : int [1:6] 12 13 14 17 60 83\n $ : int [1:6] 10 11 17 22 72 83\n $ : int [1:6] 10 11 14 16 72 83\n $ : int [1:6] 20 22 23 63 77 83\n $ : int [1:6] 10 20 21 73 74 82\n $ : int [1:6] 18 19 21 22 23 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:6] 10 16 18 19 20 83\n $ : int [1:6] 18 20 41 77 79 82\n $ : int [1:6] 25 28 31 52 54 81\n $ : int [1:6] 24 28 31 33 54 81\n $ : int [1:6] 25 27 29 33 42 81\n $ : int [1:6] 26 29 30 37 42 81\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:6] 26 27 37 42 43 81\n $ : int [1:6] 26 27 28 33 49 81\n $ : int [1:6] 24 25 36 39 40 54\n $ : int [1:6] 24 31 50 54 55 56\n $ : int [1:6] 25 26 28 30 49 81\n $ : int [1:6] 36 40 41 45 56 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:6] 26 27 29 42 43 44\n $ : int [1:6] 23 43 44 62 77 79\n $ : int [1:6] 25 40 42 43 44 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:6] 26 27 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:6] 37 38 39 42 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:6] 8 9 35 47 78 86\n $ : int [1:6] 8 21 35 46 80 86\n $ : int [1:6] 49 50 51 52 53 55\n $ : int [1:6] 28 33 48 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:6] 28 48 49 50 52 54\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:6] 48 50 51 52 55 75\n $ : int [1:6] 24 28 49 50 51 52\n $ : int [1:6] 32 48 50 52 53 75\n $ : int [1:6] 32 34 36 78 80 85\n $ : int [1:6] 1 2 3 58 64 68\n $ : int [1:6] 2 57 64 66 68 78\n $ : int [1:6] 12 13 60 61 87 88\n $ : int [1:6] 12 13 59 61 63 87\n $ : int [1:6] 12 13 60 62 63 87\n $ : int [1:6] 12 38 61 63 77 87\n $ : int [1:6] 12 18 60 61 62 83\n $ : int [1:6] 1 3 57 58 68 76\n $ : int [1:6] 58 64 66 67 68 76\n $ : int [1:6] 9 58 67 68 76 84\n $ : int [1:6] 7 65 66 68 76 84\n $ : int [1:6] 9 57 58 66 78 84\n $ : int [1:6] 4 5 6 32 75 85\n $ : int [1:6] 10 16 19 22 72 73\n $ : int [1:6] 7 19 73 74 84 86\n $ : int [1:6] 10 11 14 16 17 70\n $ : int [1:6] 10 19 21 70 71 74\n $ : int [1:6] 19 21 71 73 84 86\n $ : int [1:6] 6 32 50 53 55 69\n $ : int [1:6] 58 64 65 66 67 68\n $ : int [1:6] 18 23 38 61 62 63\n $ : int [1:6] 2 8 9 46 58 68\n $ : int [1:6] 38 40 41 43 44 45\n $ : int [1:6] 34 35 36 41 45 47\n $ : int [1:6] 25 26 28 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:6] 12 13 15 16 22 63\n $ : int [1:6] 7 9 66 68 71 74\n $ : int [1:6] 2 3 4 5 56 69\n $ : int [1:6] 8 9 21 46 47 74\n $ : int [1:6] 59 60 61 62 63 88\n $ : int [1:6] 59 60 61 62 63 87\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language knearneigh(x = coords, k = 6)\n - attr(*, \"sym\")= logi FALSE\n - attr(*, \"type\")= chr \"knn\"\n - attr(*, \"knn-k\")= num 6\n - attr(*, \"class\")= chr \"nb\"\n\n\n\n\n\n\n\n\nNote\n\n\n\nNotice that each county has six neighbours, no less no more!\n\n\n\n\nWe can plot the weight matrix using the code chunk below.\n\nplot(hunan$geometry, border = \"lightgrey\")\nplot(knn6, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis section will show how to derive a spatial weight matrix based on Inverse Distance method. Firstly, to compute the distances between areas by using nbdists() of spdep\n\ndist &lt;- nbdists(wm_q, coords, longlat = TRUE)\nids &lt;- lapply(dist, function(x) 1/(x))\nids\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n[[2]]\n[1] 0.01535405 0.01764308 0.01925924 0.02323898 0.01719350\n\n[[3]]\n[1] 0.03916350 0.02822040 0.03695795 0.01395765\n\n[[4]]\n[1] 0.01820896 0.02822040 0.03414741 0.01539065\n\n[[5]]\n[1] 0.03695795 0.03414741 0.01524598 0.01618354\n\n[[6]]\n[1] 0.015390649 0.015245977 0.021748129 0.011883901 0.009810297\n\n[[7]]\n[1] 0.01708612 0.01473997 0.01150924 0.01872915\n\n[[8]]\n[1] 0.02022144 0.03453056 0.02529256 0.01036340 0.02284457 0.01500600 0.01515314\n\n[[9]]\n[1] 0.02022144 0.01574888 0.02109502 0.01508028 0.02902705 0.01502980\n\n[[10]]\n[1] 0.02281552 0.01387777 0.01538326 0.01346650 0.02100510 0.02631658 0.01874863\n[8] 0.01500046\n\n[[11]]\n[1] 0.01882869 0.02243492 0.02247473\n\n[[12]]\n[1] 0.02779227 0.02419652 0.02333385 0.02986130 0.02335429\n\n[[13]]\n[1] 0.02779227 0.02650020 0.02670323 0.01714243\n\n[[14]]\n[1] 0.01882869 0.01233868 0.02098555\n\n[[15]]\n[1] 0.02650020 0.01233868 0.01096284 0.01562226\n\n[[16]]\n[1] 0.02281552 0.02466962 0.02765018 0.01476814 0.01671430\n\n[[17]]\n[1] 0.01387777 0.02243492 0.02098555 0.01096284 0.02466962 0.01593341 0.01437996\n\n[[18]]\n[1] 0.02039779 0.02032767 0.01481665 0.01473691 0.01459380\n\n[[19]]\n[1] 0.01538326 0.01926323 0.02668415 0.02140253 0.01613589 0.01412874\n\n[[20]]\n[1] 0.01346650 0.02039779 0.01926323 0.01723025 0.02153130 0.01469240 0.02327034\n\n[[21]]\n[1] 0.02668415 0.01723025 0.01766299 0.02644986 0.02163800\n\n[[22]]\n[1] 0.02100510 0.02765018 0.02032767 0.02153130 0.01489296\n\n[[23]]\n[1] 0.01481665 0.01469240 0.01401432 0.02246233 0.01880425 0.01530458 0.01849605\n\n[[24]]\n[1] 0.02354598 0.01837201 0.02607264 0.01220154 0.02514180\n\n[[25]]\n[1] 0.02354598 0.02188032 0.01577283 0.01949232 0.02947957\n\n[[26]]\n[1] 0.02155798 0.01745522 0.02212108 0.02220532\n\n[[27]]\n[1] 0.02155798 0.02490625 0.01562326\n\n[[28]]\n[1] 0.01837201 0.02188032 0.02229549 0.03076171 0.02039506\n\n[[29]]\n[1] 0.02490625 0.01686587 0.01395022\n\n[[30]]\n[1] 0.02090587\n\n[[31]]\n[1] 0.02607264 0.01577283 0.01219005 0.01724850 0.01229012 0.01609781 0.01139438\n[8] 0.01150130\n\n[[32]]\n[1] 0.01220154 0.01219005 0.01712515 0.01340413 0.01280928 0.01198216 0.01053374\n[8] 0.01065655\n\n[[33]]\n[1] 0.01949232 0.01745522 0.02229549 0.02090587 0.01979045\n\n[[34]]\n[1] 0.03113041 0.03589551 0.02882915\n\n[[35]]\n[1] 0.01766299 0.02185795 0.02616766 0.02111721 0.02108253 0.01509020\n\n[[36]]\n[1] 0.01724850 0.03113041 0.01571707 0.01860991 0.02073549 0.01680129\n\n[[37]]\n[1] 0.01686587 0.02234793 0.01510990 0.01550676\n\n[[38]]\n[1] 0.01401432 0.02407426 0.02276151 0.01719415\n\n[[39]]\n[1] 0.01229012 0.02172543 0.01711924 0.02629732 0.01896385\n\n[[40]]\n[1] 0.01609781 0.01571707 0.02172543 0.01506473 0.01987922 0.01894207\n\n[[41]]\n[1] 0.02246233 0.02185795 0.02205991 0.01912542 0.01601083 0.01742892\n\n[[42]]\n[1] 0.02212108 0.01562326 0.01395022 0.02234793 0.01711924 0.01836831 0.01683518\n\n[[43]]\n[1] 0.01510990 0.02629732 0.01506473 0.01836831 0.03112027 0.01530782\n\n[[44]]\n[1] 0.01550676 0.02407426 0.03112027 0.01486508\n\n[[45]]\n[1] 0.03589551 0.01860991 0.01987922 0.02205991 0.02107101 0.01982700\n\n[[46]]\n[1] 0.03453056 0.04033752 0.02689769\n\n[[47]]\n[1] 0.02529256 0.02616766 0.04033752 0.01949145 0.02181458\n\n[[48]]\n[1] 0.02313819 0.03370576 0.02289485 0.01630057 0.01818085\n\n[[49]]\n[1] 0.03076171 0.02138091 0.02394529 0.01990000\n\n[[50]]\n[1] 0.01712515 0.02313819 0.02551427 0.02051530 0.02187179\n\n[[51]]\n[1] 0.03370576 0.02138091 0.02873854\n\n[[52]]\n[1] 0.02289485 0.02394529 0.02551427 0.02873854 0.03516672\n\n[[53]]\n[1] 0.01630057 0.01979945 0.01253977\n\n[[54]]\n[1] 0.02514180 0.02039506 0.01340413 0.01990000 0.02051530 0.03516672\n\n[[55]]\n[1] 0.01280928 0.01818085 0.02187179 0.01979945 0.01882298\n\n[[56]]\n[1] 0.01036340 0.01139438 0.01198216 0.02073549 0.01214479 0.01362855 0.01341697\n\n[[57]]\n[1] 0.028079221 0.017643082 0.031423501 0.029114131 0.013520292 0.009903702\n\n[[58]]\n[1] 0.01925924 0.03142350 0.02722997 0.01434859 0.01567192\n\n[[59]]\n[1] 0.01696711 0.01265572 0.01667105 0.01785036\n\n[[60]]\n[1] 0.02419652 0.02670323 0.01696711 0.02343040\n\n[[61]]\n[1] 0.02333385 0.01265572 0.02343040 0.02514093 0.02790764 0.01219751 0.02362452\n\n[[62]]\n[1] 0.02514093 0.02002219 0.02110260\n\n[[63]]\n[1] 0.02986130 0.02790764 0.01407043 0.01805987\n\n[[64]]\n[1] 0.02911413 0.01689892\n\n[[65]]\n[1] 0.02471705\n\n[[66]]\n[1] 0.01574888 0.01726461 0.03068853 0.01954805 0.01810569\n\n[[67]]\n[1] 0.01708612 0.01726461 0.01349843 0.01361172\n\n[[68]]\n[1] 0.02109502 0.02722997 0.03068853 0.01406357 0.01546511\n\n[[69]]\n[1] 0.02174813 0.01645838 0.01419926\n\n[[70]]\n[1] 0.02631658 0.01963168 0.02278487\n\n[[71]]\n[1] 0.01473997 0.01838483 0.03197403\n\n[[72]]\n[1] 0.01874863 0.02247473 0.01476814 0.01593341 0.01963168\n\n[[73]]\n[1] 0.01500046 0.02140253 0.02278487 0.01838483 0.01652709\n\n[[74]]\n[1] 0.01150924 0.01613589 0.03197403 0.01652709 0.01342099 0.02864567\n\n[[75]]\n[1] 0.011883901 0.010533736 0.012539774 0.018822977 0.016458383 0.008217581\n\n[[76]]\n[1] 0.01352029 0.01434859 0.01689892 0.02471705 0.01954805 0.01349843 0.01406357\n\n[[77]]\n[1] 0.014736909 0.018804247 0.022761507 0.012197506 0.020022195 0.014070428\n[7] 0.008440896\n\n[[78]]\n[1] 0.02323898 0.02284457 0.01508028 0.01214479 0.01567192 0.01546511 0.01140779\n\n[[79]]\n[1] 0.01530458 0.01719415 0.01894207 0.01912542 0.01530782 0.01486508 0.02107101\n\n[[80]]\n[1] 0.01500600 0.02882915 0.02111721 0.01680129 0.01601083 0.01982700 0.01949145\n[8] 0.01362855\n\n[[81]]\n[1] 0.02947957 0.02220532 0.01150130 0.01979045 0.01896385 0.01683518\n\n[[82]]\n[1] 0.02327034 0.02644986 0.01849605 0.02108253 0.01742892\n\n[[83]]\n[1] 0.023354289 0.017142433 0.015622258 0.016714303 0.014379961 0.014593799\n[7] 0.014892965 0.018059871 0.008440896\n\n[[84]]\n[1] 0.01872915 0.02902705 0.01810569 0.01361172 0.01342099 0.01297994\n\n[[85]]\n [1] 0.011451133 0.017193502 0.013957649 0.016183544 0.009810297 0.010656545\n [7] 0.013416965 0.009903702 0.014199260 0.008217581 0.011407794\n\n[[86]]\n[1] 0.01515314 0.01502980 0.01412874 0.02163800 0.01509020 0.02689769 0.02181458\n[8] 0.02864567 0.01297994\n\n[[87]]\n[1] 0.01667105 0.02362452 0.02110260 0.02058034\n\n[[88]]\n[1] 0.01785036 0.02058034\n\n\n\n\n\nNext, we need to assign weights to each neighbouring polygon. In our case, each neighbouring polygon will be assigned equal weight (style=“W”). This is accomplished by assigning the fraction 1/(#ofneighbours) to each neighbouring county then summing the weighted income values.\nWhile this is the most intuitive way to summaries the neighbours’ values it has one drawback in that polygons along the edges of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data. For this example, we’ll stick with the style=“W” option for simplicity’s sake but note that other more robust options are available, notably style=“B”.\n\nrswm_q &lt;- nb2listw(wm_q, style = \"W\", zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\nThe zero.policy = TRUE option allows for lists of non-neighbours. This should be used with caution since the user may not be aware of missing neighbours in their dataset however, a zero.policy of FALSE would return an error.\nTo see the weight of the first polygon’s eight neighbours type:\n\nrswm_q$weights[10]\n\n[[1]]\n[1] 0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125\n\n\nEach neighbour is assigned a value 0.125 of the total weight. This means that when R computes the average neighbouring income values, each neighbour’s income will be multiplied by 0.125 before being tallied.\nUsing the same method, we can also derive a row standardised distance weight matrix by using the code chunk below.\n\nrswm_ids &lt;- nb2listw(wm_q, glist = ids, style = \"B\", zero.policy = TRUE)\nrswm_ids\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn       S0        S1     S2\nB 88 7744 8.786867 0.3776535 3.8137\n\n\n\nrswm_ids$weights[1]\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n\nResults of previous code chunk shown above.\n\nsummary(unlist(rswm_ids$weights))\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n0.008218 0.015088 0.018739 0.019614 0.022823 0.040338 \n\n\n\n\n\nIn this section, it shows how to create four different spatial lagged variables, they are:\n\nspatial lag with row-standardized weights,\nspatial lag as a sum of neighbouring values,\nspatial window average, and\nspatial window sum.\n\n\n\nFinally, we’ll compute the average neighbour GDPPC value for each polygon. These values are often referred to as spatially lagged values.\n\nGDPPC.lag &lt;- lag.listw(rswm_q, hunan$GDPPC)\nGDPPC.lag\n\n [1] 24847.20 22724.80 24143.25 27737.50 27270.25 21248.80 43747.00 33582.71\n [9] 45651.17 32027.62 32671.00 20810.00 25711.50 30672.33 33457.75 31689.20\n[17] 20269.00 23901.60 25126.17 21903.43 22718.60 25918.80 20307.00 20023.80\n[25] 16576.80 18667.00 14394.67 19848.80 15516.33 20518.00 17572.00 15200.12\n[33] 18413.80 14419.33 24094.50 22019.83 12923.50 14756.00 13869.80 12296.67\n[41] 15775.17 14382.86 11566.33 13199.50 23412.00 39541.00 36186.60 16559.60\n[49] 20772.50 19471.20 19827.33 15466.80 12925.67 18577.17 14943.00 24913.00\n[57] 25093.00 24428.80 17003.00 21143.75 20435.00 17131.33 24569.75 23835.50\n[65] 26360.00 47383.40 55157.75 37058.00 21546.67 23348.67 42323.67 28938.60\n[73] 25880.80 47345.67 18711.33 29087.29 20748.29 35933.71 15439.71 29787.50\n[81] 18145.00 21617.00 29203.89 41363.67 22259.09 44939.56 16902.00 16930.00\n\n\nRecall in the previous section, we retrieved the GDPPC of these five countries by using the code chunk below:\n\nnb1 &lt;- wm_q[[1]]\nnb1 &lt;- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\nWe can append the spatially lag GDPPC values onto hunan sf data frame by using the code chunk below.\n\nlag.list &lt;- list(hunan$NAME_3, lag.listw(rswm_q, hunan$GDPPC))\nlag.res &lt;- as.data.frame(lag.list)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag GDPPC\")\nhunan &lt;- left_join(hunan,lag.res)\n\nJoining with `by = join_by(NAME_3)`\n\n\nThe following table shows the average neighboring income values (stored in the Inc.lag object) for each county.\n\nhead(hunan)\n\nSimple feature collection with 6 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 110.4922 ymin: 28.61762 xmax: 112.3013 ymax: 30.12812\nGeodetic CRS:  WGS 84\n   NAME_2  ID_3  NAME_3   ENGTYPE_3  County GDPPC lag GDPPC\n1 Changde 21098 Anxiang      County Anxiang 23667  24847.20\n2 Changde 21100 Hanshou      County Hanshou 20981  22724.80\n3 Changde 21101  Jinshi County City  Jinshi 34592  24143.25\n4 Changde 21102      Li      County      Li 24473  27737.50\n5 Changde 21103   Linli      County   Linli 25554  27270.25\n6 Changde 21104  Shimen      County  Shimen 27137  21248.80\n                        geometry\n1 POLYGON ((112.0625 29.75523...\n2 POLYGON ((112.2288 29.11684...\n3 POLYGON ((111.8927 29.6013,...\n4 POLYGON ((111.3731 29.94649...\n5 POLYGON ((111.6324 29.76288...\n6 POLYGON ((110.8825 30.11675...\n\n\nNext, to plot both the GDPPC and spatial lag GDPPC for comparison using the code chunk below.\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\nlag_gdppc &lt;- qtm(hunan, \"lag GDPPC\")\ntmap_arrange(gdppc, lag_gdppc, asp = 1, ncol = 2)\n\n\n\n\n\n\n\n\n\n\n\nWe can calculate spatial lag as a sum of neighbouring values by assigning binary weights. This requires us to go back to our neighbours list, then apply a function that will assign binary weights, then we use glist = in the nb2listw function to explicitly assign these weights.\nWe start by applying a function that will assign a value of 1 per each neighbour. This is done with lapply(), which we have been using to manipulate the neighbours structure throughout the past notebooks. Basically it applies a function across each value in the neighbours structure.\n\nb_weights &lt;- lapply(wm_q, function(x) 0*x + 1)\nb_weights2 &lt;- nb2listw(wm_q, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1    S2\nB 88 7744 448 896 10224\n\n\nWith the proper weights assigned, we can use lag.listw() to compute a lag variable from our weight and GDPPC.\n\nlag_sum &lt;- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nlag.res &lt;- as.data.frame(lag_sum)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag_sum GDPPC\")\n\nFirst, to examine the result by using the code chunk below.\n\nlag_sum\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 124236 113624  96573 110950 109081 106244 174988 235079 273907 256221\n[11]  98013 104050 102846  92017 133831 158446 141883 119508 150757 153324\n[21] 113593 129594 142149 100119  82884  74668  43184  99244  46549  20518\n[31] 140576 121601  92069  43258 144567 132119  51694  59024  69349  73780\n[41]  94651 100680  69398  52798 140472 118623 180933  82798  83090  97356\n[51]  59482  77334  38777 111463  74715 174391 150558 122144  68012  84575\n[61] 143045  51394  98279  47671  26360 236917 220631 185290  64640  70046\n[71] 126971 144693 129404 284074 112268 203611 145238 251536 108078 238300\n[81] 108870 108085 262835 248182 244850 404456  67608  33860\n\n\nNext, to append the lag_sum GDPPC field into hunan sf data frame by using the code chunk below.\n\nhunan &lt;- left_join(hunan, lag.res)\n\nJoining with `by = join_by(NAME_3)`\n\n\nFollowing which, to plot both the GDPPC and Spatial Lag Sum GDPPC for comparison using the code chunk below.\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\nlag_sum_gdppc &lt;- qtm(hunan, \"lag_sum GDPPC\")\ntmap_arrange(gdppc, lag_sum_gdppc, asp = 1, ncol = 2)\n\n\n\n\n\n\n\n\n\n\n\nThe spatial window average uses row-standardized weights and includes the diagonal element. To do this in R, we need to go back to the neighbors structure and add the diagonal element before assigning weights.\nTo add the diagonal element to the neighbour list, we just need to use include.self() from spdep.\n\nwm_qs &lt;- include.self(wm_q)\n\nNotice that the Number of non-zero links, Percentage non-zero weights and Average number of links are 536, 6.921488 and 6.090909 respectively as compared to wm_q of 448, 5.785124 and 5.090909\nLet us take a good look at the neighbour list of area [1] by using the code chunk below.\n\nwm_qs[[1]]\n\n[1]  1  2  3  4 57 85\n\n\nNotice that now [1] has six neighbours instead of five.\nNow we obtain weights with nb2listw()\n\nwm_qs &lt;- nb2listw(wm_qs)\nwm_qs\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 30.90265 357.5308\n\n\nAgain, utilising nb2listw() and glist() to explicitly assign weight values.\nLastly, we just need to create the lag variable from our weight structure and GDPPC variable.\n\nlag_w_avg_gpdpc &lt;- lag.listw(wm_qs, \n                             hunan$GDPPC)\nlag_w_avg_gpdpc\n\n [1] 24650.50 22434.17 26233.00 27084.60 26927.00 22230.17 47621.20 37160.12\n [9] 49224.71 29886.89 26627.50 22690.17 25366.40 25825.75 30329.00 32682.83\n[17] 25948.62 23987.67 25463.14 21904.38 23127.50 25949.83 20018.75 19524.17\n[25] 18955.00 17800.40 15883.00 18831.33 14832.50 17965.00 17159.89 16199.44\n[33] 18764.50 26878.75 23188.86 20788.14 12365.20 15985.00 13764.83 11907.43\n[41] 17128.14 14593.62 11644.29 12706.00 21712.29 43548.25 35049.00 16226.83\n[49] 19294.40 18156.00 19954.75 18145.17 12132.75 18419.29 14050.83 23619.75\n[57] 24552.71 24733.67 16762.60 20932.60 19467.75 18334.00 22541.00 26028.00\n[65] 29128.50 46569.00 47576.60 36545.50 20838.50 22531.00 42115.50 27619.00\n[73] 27611.33 44523.29 18127.43 28746.38 20734.50 33880.62 14716.38 28516.22\n[81] 18086.14 21244.50 29568.80 48119.71 22310.75 43151.60 17133.40 17009.33\n\n\nNext, to convert the lag variable listw object into a data.frame by using as.data.frame().\n\nlag.list.wm_qs &lt;- list(hunan$NAME_3, lag.listw(wm_qs, hunan$GDPPC))\nlag_wm_qs.res &lt;- as.data.frame(lag.list.wm_qs)\ncolnames(lag_wm_qs.res) &lt;- c(\"NAME_3\", \"lag_window_avg GDPPC\")\n\n\n\n\n\n\n\nNote\n\n\n\nThe third command line on the code chunk above renames the field names of lag_wm_q1.res object into NAME_3 and lag_window_avg GDPPC respectively.\n\n\nNext, the code chunk below will be used to append lag_window_avg GDPPC values onto hunan sf data.frame by using left_join() of dplyr package.\n\nhunan &lt;- left_join(hunan, lag_wm_qs.res)\n\nJoining with `by = join_by(NAME_3)`\n\n\nTo compare the values of lag GDPPC and Spatial window average, kable() of Knitr package is used to prepare a table using the code chunk below.\n\nhunan %&gt;%\n  select(\"County\", \n         \"lag GDPPC\", \n         \"lag_window_avg GDPPC\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag GDPPC\nlag_window_avg GDPPC\ngeometry\n\n\n\n\nAnxiang\n24847.20\n24650.50\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n22724.80\n22434.17\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n24143.25\n26233.00\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n27737.50\n27084.60\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n27270.25\n26927.00\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n21248.80\n22230.17\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n43747.00\n47621.20\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n33582.71\n37160.12\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n45651.17\n49224.71\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n32027.62\n29886.89\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n32671.00\n26627.50\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n20810.00\n22690.17\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n25711.50\n25366.40\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n30672.33\n25825.75\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n33457.75\n30329.00\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n31689.20\n32682.83\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n20269.00\n25948.62\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n23901.60\n23987.67\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n25126.17\n25463.14\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n21903.43\n21904.38\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n22718.60\n23127.50\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n25918.80\n25949.83\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n20307.00\n20018.75\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n20023.80\n19524.17\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n16576.80\n18955.00\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n18667.00\n17800.40\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n14394.67\n15883.00\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n19848.80\n18831.33\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n15516.33\n14832.50\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518.00\n17965.00\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n17572.00\n17159.89\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n15200.12\n16199.44\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n18413.80\n18764.50\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n14419.33\n26878.75\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n24094.50\n23188.86\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n22019.83\n20788.14\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n12923.50\n12365.20\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n14756.00\n15985.00\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n13869.80\n13764.83\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n12296.67\n11907.43\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n15775.17\n17128.14\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n14382.86\n14593.62\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n11566.33\n11644.29\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n13199.50\n12706.00\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n23412.00\n21712.29\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n39541.00\n43548.25\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n36186.60\n35049.00\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n16559.60\n16226.83\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n20772.50\n19294.40\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n19471.20\n18156.00\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n19827.33\n19954.75\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n15466.80\n18145.17\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n12925.67\n12132.75\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n18577.17\n18419.29\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n14943.00\n14050.83\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n24913.00\n23619.75\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n25093.00\n24552.71\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n24428.80\n24733.67\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n17003.00\n16762.60\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n21143.75\n20932.60\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n20435.00\n19467.75\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n17131.33\n18334.00\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n24569.75\n22541.00\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n23835.50\n26028.00\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360.00\n29128.50\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n47383.40\n46569.00\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n55157.75\n47576.60\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n37058.00\n36545.50\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n21546.67\n20838.50\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n23348.67\n22531.00\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n42323.67\n42115.50\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n28938.60\n27619.00\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n25880.80\n27611.33\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n47345.67\n44523.29\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n18711.33\n18127.43\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n29087.29\n28746.38\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n20748.29\n20734.50\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n35933.71\n33880.62\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n15439.71\n14716.38\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n29787.50\n28516.22\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n18145.00\n18086.14\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n21617.00\n21244.50\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n29203.89\n29568.80\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n41363.67\n48119.71\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n22259.09\n22310.75\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n44939.56\n43151.60\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n16902.00\n17133.40\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n16930.00\n17009.33\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\nLastly, qtm() of tmap package is used to plot the lag_gdppc and w_ave_gdppc maps next to each other for quick comparison.\n\nw_avg_gdppc &lt;- qtm(hunan, \"lag_window_avg GDPPC\")\ntmap_arrange(lag_gdppc, w_avg_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nFor more effective comparison, it is advisable to use the core tmap mapping functions.\n\n\n\n\n\nThe spatial window sum is the counter part of the window average, but without using row-standardized weights.\nTo add the diagonal element to the neighbour list, we just need to use include.self() from spdep.\n\nwm_qs &lt;- include.self(wm_q)\nwm_qs\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\nAssigning binary weights to the neighbour structure that includes the diagonal element.\n\nb_weights &lt;- lapply(wm_qs, function(x) 0*x + 1)\nb_weights[1]\n\n[[1]]\n[1] 1 1 1 1 1 1\n\n\n\nNotice that now [1] has six neighbours instead of five.\n\nAgain, we use nb2listw() and glist() to explicitly assign weight values.\n\nb_weights2 &lt;- nb2listw(wm_qs, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 536 1072 14160\n\n\nWith our new weight structure, we can compute the lag variable with lag.listw().\n\nw_sum_gdppc &lt;- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nw_sum_gdppc\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 147903 134605 131165 135423 134635 133381 238106 297281 344573 268982\n[11] 106510 136141 126832 103303 151645 196097 207589 143926 178242 175235\n[21] 138765 155699 160150 117145 113730  89002  63532 112988  59330  35930\n[31] 154439 145795 112587 107515 162322 145517  61826  79925  82589  83352\n[41] 119897 116749  81510  63530 151986 174193 210294  97361  96472 108936\n[51]  79819 108871  48531 128935  84305 188958 171869 148402  83813 104663\n[61] 155742  73336 112705  78084  58257 279414 237883 219273  83354  90124\n[71] 168462 165714 165668 311663 126892 229971 165876 271045 117731 256646\n[81] 126603 127467 295688 336838 267729 431516  85667  51028\n\n\nNext, we will convert the lag variable listw object into a data.frame by using as.data.frame().\n\nw_sum_gdppc.res &lt;- as.data.frame(w_sum_gdppc)\ncolnames(w_sum_gdppc.res) &lt;- c(\"NAME_3\", \"w_sum GDPPC\")\n\nNote: The second command line on the code chunk above renames the field names of w_sum_gdppc.res object into NAME_3 and w_sum GDPPC respectively.\nNext, the code chunk below will be used to append w_sum GDPPC values onto hunan sf data.frame by using left_join() of dplyr package.\n\nhunan &lt;- left_join(hunan, w_sum_gdppc.res)\n\nJoining with `by = join_by(NAME_3)`\n\n\nOnce again, qtm() of tmap package is used to plot the lag_sum GDPPC and w_sum_gdppc maps next to each other for quick comparison.\n\nw_sum_gdppc &lt;- qtm(hunan, \"w_sum GDPPC\")\ntmap_arrange(lag_sum_gdppc, w_sum_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIt is advisable to use the core tmap mapping functions for a more effective comparison.\n\n\n\n\n\n\n\nCreating Neighbours using sf objects"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#overview",
    "title": "Hands-on Exercise 4: Spatial Weights and Applications",
    "section": "",
    "text": "In this hands-on exercise, it will run through the process of computing spatial weights using R. By the end to this hands-on exercise, one should be able to:\n\nimport geospatial data using appropriate function(s) of sf package,\nimport csv file using appropriate function of readr package,\nperform relational join using appropriate join function of dplyr package,\ncompute spatial weights using appropriate functions of spdep package, and\ncalculate spatially lagged variables using appropriate functions of spdep package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#the-study-area-and-data",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#the-study-area-and-data",
    "title": "Hands-on Exercise 4: Spatial Weights and Applications",
    "section": "",
    "text": "Two data sets will be used in this hands-on exercise, they are:\n\nHunan county boundary layer. This is a geospatial data set in ESRI shapefile format.\nHunan_2012.csv; This csv file contains selected Hunan’s local development indicators in 2012.\n\n\n\nBefore getting started, ensure that spdep, sf, tmap, tidyverse and knitrpackages of R are currently installed in R.\n\npacman::p_load(spdep, sf, tmap, tidyverse, knitr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#getting-the-data-into-the-r-environment",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#getting-the-data-into-the-r-environment",
    "title": "Hands-on Exercise 4: Spatial Weights and Applications",
    "section": "",
    "text": "In this section, the geospatial data and its associated attribute table will be brought in R environment. The geospatial data is in ESRI shapefile format and the attribute table is in csv format.\n\n\nThe code chunk below uses st_read() of sf package to import Hunan shapefile into R. The imported shapefile will be a simple feature Object of sf.\n\nhunan &lt;- st_read(dsn = \"data/geospatial\",\n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex04\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n\nNext, Hunan_2012.csv will be imported into R by using read_csv() of readr package. The output is a R dataframe class.\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nThe code chunk below will be used to update the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 dataframe. This is performed by using left_join() of dplyr package.\nThe select() function is used to select variables that are objectively used for the spatial analysis.\n\nhunan &lt;- left_join(hunan, hunan2012) %&gt;%\n  select(1:4, 7, 15)\n\nJoining with `by = join_by(County)`"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-regional-development-indicator",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-regional-development-indicator",
    "title": "Hands-on Exercise 4: Spatial Weights and Applications",
    "section": "",
    "text": "Now, a basemap and a choropleth map will be prepared showing the distribution of GDPPC 2012 by using qtm() of tmap package.\n\nbasemap &lt;- tm_shape(hunan) +\n  tm_polygons() +\n  tm_text(\"NAME_3\", size = 0.5)\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\ntmap_arrange(basemap, gdppc, asp = 1, ncol = 2)\n\n\n\n\n\n\n\n\n\nNote: Gross Domestic Product per Capita (GDPPC)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-contiguity-spatial-weights",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-contiguity-spatial-weights",
    "title": "Hands-on Exercise 4: Spatial Weights and Applications",
    "section": "",
    "text": "In this section, we will learn how to use poly2nb() of spdep package to compute contiguity weight matrices for the study area.\nThis function builds a neighbours list based on regions with contiguous boundaries. From the documentation, we learn that we can pass a “queen” argument that takes TRUE or FALSE as options. If this argument is not specified the argument’s default is set to TRUE, that is, if we don’t specify queen = FALSE this function will return a list of first order neighbours using the Queen criteria.\n\n\nThe code chunk below is used to compute Queen contiguity weight matrix.\n\nwm_q &lt;- poly2nb(hunan, queen = TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report above shows that there are 88 area units (regions) in Hunan. The most connected area unit has 11 neighbours. There are two area units with only one neighbour.\nFor each polygon in the polygon object, wm_q lists all neighbouring polygons. For example, to see the neighbours for the first polygon in the object, type:\n\nwm_q[[1]]\n\n[1]  2  3  4 57 85\n\n\nPolygon 1 has 5 neighbours. The numbers represent the polygon IDs as stored in hunan SpatialPolygonsDataFrame class.\nWe can retrieve the county name of Polygon ID=1 by using the code chunk below:\n\nhunan$County[1]\n\n[1] \"Anxiang\"\n\n\nThe output reveals that Polygon ID=1 is Anxiang county.\nTo reveal the county names of the five neighbouring polygons, the code chunk will be used:\n\nhunan$NAME_3[c(2,3,4,57,85)]\n\n[1] \"Hanshou\" \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\"\n\n\nWe can retrieve the GDPPC of these five counties by using the code chunk below.\n\nnb1 &lt;- wm_q[[1]]\nnb1 &lt;- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\nThe printed output above shows that the GDPPC of the five nearest neighbours based on Queen’s method are 20981, 34592, 24473, 21311 and 22879 respectively.\nWe can display the complete weight matrix by using str().\n\nstr(wm_q)\n\nList of 88\n $ : int [1:5] 2 3 4 57 85\n $ : int [1:5] 1 57 58 78 85\n $ : int [1:4] 1 4 5 85\n $ : int [1:4] 1 3 5 6\n $ : int [1:4] 3 4 6 85\n $ : int [1:5] 4 5 69 75 85\n $ : int [1:4] 67 71 74 84\n $ : int [1:7] 9 46 47 56 78 80 86\n $ : int [1:6] 8 66 68 78 84 86\n $ : int [1:8] 16 17 19 20 22 70 72 73\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:3] 11 15 17\n $ : int [1:4] 13 14 17 83\n $ : int [1:5] 10 17 22 72 83\n $ : int [1:7] 10 11 14 15 16 72 83\n $ : int [1:5] 20 22 23 77 83\n $ : int [1:6] 10 20 21 73 74 86\n $ : int [1:7] 10 18 19 21 22 23 82\n $ : int [1:5] 19 20 35 82 86\n $ : int [1:5] 10 16 18 20 83\n $ : int [1:7] 18 20 38 41 77 79 82\n $ : int [1:5] 25 28 31 32 54\n $ : int [1:5] 24 28 31 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:3] 26 29 42\n $ : int [1:5] 24 25 33 49 54\n $ : int [1:3] 27 37 42\n $ : int 33\n $ : int [1:8] 24 25 32 36 39 40 56 81\n $ : int [1:8] 24 31 50 54 55 56 75 85\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 47 80 82 86\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:4] 29 42 43 44\n $ : int [1:4] 23 44 77 79\n $ : int [1:5] 31 40 42 43 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:7] 26 27 29 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:4] 37 38 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:3] 8 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:5] 32 48 52 54 55\n $ : int [1:3] 48 49 52\n $ : int [1:5] 48 49 50 51 54\n $ : int [1:3] 48 55 75\n $ : int [1:6] 24 28 32 49 50 52\n $ : int [1:5] 32 48 50 53 75\n $ : int [1:7] 8 31 32 36 78 80 85\n $ : int [1:6] 1 2 58 64 76 85\n $ : int [1:5] 2 57 68 76 78\n $ : int [1:4] 60 61 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:7] 12 59 60 62 63 77 87\n $ : int [1:3] 61 77 87\n $ : int [1:4] 12 61 77 83\n $ : int [1:2] 57 76\n $ : int 76\n $ : int [1:5] 9 67 68 76 84\n $ : int [1:4] 7 66 76 84\n $ : int [1:5] 9 58 66 76 78\n $ : int [1:3] 6 75 85\n $ : int [1:3] 10 72 73\n $ : int [1:3] 7 73 74\n $ : int [1:5] 10 11 16 17 70\n $ : int [1:5] 10 19 70 71 74\n $ : int [1:6] 7 19 71 73 84 86\n $ : int [1:6] 6 32 53 55 69 85\n $ : int [1:7] 57 58 64 65 66 67 68\n $ : int [1:7] 18 23 38 61 62 63 83\n $ : int [1:7] 2 8 9 56 58 68 85\n $ : int [1:7] 23 38 40 41 43 44 45\n $ : int [1:8] 8 34 35 36 41 45 47 56\n $ : int [1:6] 25 26 31 33 39 42\n $ : int [1:5] 20 21 23 35 41\n $ : int [1:9] 12 13 15 16 17 18 22 63 77\n $ : int [1:6] 7 9 66 67 74 86\n $ : int [1:11] 1 2 3 5 6 32 56 57 69 75 ...\n $ : int [1:9] 8 9 19 21 35 46 47 74 84\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language poly2nb(pl = hunan, queen = TRUE)\n - attr(*, \"type\")= chr \"queen\"\n - attr(*, \"sym\")= logi TRUE\n\n\n\n\n\n\n\n\nWarning\n\n\n\nBe warned: The output might cut across several pages. Do consider saving the trees if you are going to print out the report.\n\n\n\n\n\nleast connectedmost connected\n\n\n\nwm_q[[30]]\n\n[1] 33\n\nwm_q[[65]]\n\n[1] 76\n\n\n\n\n\nwm_q[[85]]\n\n [1]  1  2  3  5  6 32 56 57 69 75 78\n\n\n\nhunan$County[85]\n\n[1] \"Taoyuan\"\n\n\nTo reveal the county names of the eleven neighbouring polygons, the code chunk will be used:\n\nhunan$NAME_3[c(1,2,3,5,6,32,56,57,69,75,78)]\n\n [1] \"Anxiang\"  \"Hanshou\"  \"Jinshi\"   \"Linli\"    \"Shimen\"   \"Yuanling\"\n [7] \"Anhua\"    \"Nan\"      \"Cili\"     \"Sangzhi\"  \"Taojiang\"\n\n\nRevealing the GDPPC of there eleven counties by using the code chunk below.\n\nnb1 &lt;- wm_q[[85]]\nnb1 &lt;- hunan$GDPPC[nb1]\nnb1\n\n [1] 23667 20981 34592 25554 27137 24194 14567 21311 18714 14624 19509\n\n\n\n\n\n\n\n\n\nThe code chunk below is used to compute Rook contiguity weight matrix.\n\nwm_r &lt;- poly2nb(hunan, queen = FALSE)\nsummary(wm_r)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connected area unit has 10 neighbours. There are two area units with only one neighbours.\n\n\n\nA connectivity graph takes a point and displays a line to each neighbouring point. We are working with polygons at the moment, so we will need to get points in order to make our connectivity graphs. The most typically used method for this will be polygon centroids. We will calculate these in the sf package before moving onto the graphs. Getting Latitude and Longitude of Polygon Centroids\nWe will need points to associate with each polygon before we can make our connectivity graph. It will be a little more complicated than just running st_centroid on the sf object: us.bound. We need the coordinates in a separate data frame for this to work. To do this we will use a mapping function. The mapping function applies a given function to each element of a vector and returns a vector of the same length. Our input vector will be the geometry column of us.bound. Our function will be st_centroid. We will be using map_dbl variation of map from the purrr package. For more documentation, check out map documentation\nTo get our longitude values we map the st_centroid function over the geometry column of us.bound and access the longitude value through double bracket notation [[]] and 1. This allows us to get only the longitude, which is the first value in each centroid.\n\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\nWe can do the same for latitude with one key difference. We access the second value per each centroid with [[2]].\n\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\nNow that longitude and latitude is obtained, we use cbind to put longitude and latitude into the same object.\n\ncoords &lt;- cbind(longitude, latitude)\n\nUpon running the code chunk, we can check the first few observations to see if things are formatted correctly.\n\nhead(coords)\n\n     longitude latitude\n[1,]  112.1531 29.44362\n[2,]  112.0372 28.86489\n[3,]  111.8917 29.47107\n[4,]  111.7031 29.74499\n[5,]  111.6138 29.49258\n[6,]  111.0341 29.79863\n\n\n\n\n\nplot(hunan$geometry, border = \"lightgrey\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\n\n\n\n\n\n\n\n\n\n\n\n\nplot(hunan$geometry, border = \"lightgrey\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\n\n\n\n\n\n\n\n\n\n\n\n\npar(mfrow = c(1,2))\nplot(hunan$geometry, border = \"lightgrey\", main = \"Queen Contiguity\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\nplot(hunan$geometry, border = \"lightgrey\", main = \"Rook Contiguity\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-distance-based-neighbours",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-distance-based-neighbours",
    "title": "Hands-on Exercise 4: Spatial Weights and Applications",
    "section": "",
    "text": "In this section, we will learn how to derive distance-based weight matrices by using dnearneigh() of spdep package.\nThe function identifies neighbours of region points by Euclidean distance with a distance band with lower d1= and upper d2= bounds controlled by the bounds = argument. If un-projected coordinates are used and either specified in the coordinates object x or with x as a two column matrix and = TRUE, great circle distances in km will be calculated assuming the WGS84 reference ellipsoid.\n\n\nFirstly, we need to determine the upper limit for distance band by using the steps below:\n\nReturn a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using knearneigh() of spdep.\nConvert the knn object returned by knearneigh() into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using knn2nb().\nReturn the length of neighbour relationship edges by using nbdists() of spdep. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise.\nRemove the list structure of the returned object by using unlist().\n\n\n#coords &lt;- coordinates(hunan)\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nThe summary report shows that the largest first nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour.\n\n\n\nNow, we will compute the distance weight matrix by using dnearneigh() as shown in the code chunk below.\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\n\nQuiz: What is the meaning of “Average number of links: 3.681818” shown above?\nInterpretation: An average of 3.681818 means that, on average, each point has about 3.68 neighbours within the specified distance band (0 to 62 km in this case). This gives a sense of the overall connectivity in the spatial network. A higher average number of links suggests that points are more densely connected, while a lower number suggests sparser connections.\n\nNext, we will use str() to display the content of wm_d62 weight matrix.\n\nstr(wm_d62)\n\nList of 88\n $ : int [1:5] 3 4 5 57 64\n $ : int [1:4] 57 58 78 85\n $ : int [1:4] 1 4 5 57\n $ : int [1:3] 1 3 5\n $ : int [1:4] 1 3 4 85\n $ : int 69\n $ : int [1:2] 67 84\n $ : int [1:4] 9 46 47 78\n $ : int [1:4] 8 46 68 84\n $ : int [1:4] 16 22 70 72\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:2] 11 17\n $ : int 13\n $ : int [1:4] 10 17 22 83\n $ : int [1:3] 11 14 16\n $ : int [1:3] 20 22 63\n $ : int [1:5] 20 21 73 74 82\n $ : int [1:5] 18 19 21 22 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:4] 10 16 18 20\n $ : int [1:3] 41 77 82\n $ : int [1:4] 25 28 31 54\n $ : int [1:4] 24 28 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:2] 26 29\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:2] 27 37\n $ : int 33\n $ : int [1:2] 24 36\n $ : int 50\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:5] 31 34 45 56 80\n $ : int [1:2] 29 42\n $ : int [1:3] 44 77 79\n $ : int [1:4] 40 42 43 81\n $ : int [1:3] 39 45 79\n $ : int [1:5] 23 35 45 79 82\n $ : int [1:5] 26 37 39 43 81\n $ : int [1:3] 39 42 44\n $ : int [1:2] 38 43\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:5] 8 9 35 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:4] 48 49 50 52\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:2] 48 55\n $ : int [1:5] 24 28 49 50 52\n $ : int [1:4] 48 50 53 75\n $ : int 36\n $ : int [1:5] 1 2 3 58 64\n $ : int [1:5] 2 57 64 66 68\n $ : int [1:3] 60 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:5] 12 60 62 63 87\n $ : int [1:4] 61 63 77 87\n $ : int [1:5] 12 18 61 62 83\n $ : int [1:4] 1 57 58 76\n $ : int 76\n $ : int [1:5] 58 67 68 76 84\n $ : int [1:2] 7 66\n $ : int [1:4] 9 58 66 84\n $ : int [1:2] 6 75\n $ : int [1:3] 10 72 73\n $ : int [1:2] 73 74\n $ : int [1:3] 10 11 70\n $ : int [1:4] 19 70 71 74\n $ : int [1:5] 19 21 71 73 86\n $ : int [1:2] 55 69\n $ : int [1:3] 64 65 66\n $ : int [1:3] 23 38 62\n $ : int [1:2] 2 8\n $ : int [1:4] 38 40 41 45\n $ : int [1:5] 34 35 36 45 47\n $ : int [1:5] 25 26 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:4] 12 13 16 63\n $ : int [1:4] 7 9 66 68\n $ : int [1:2] 2 5\n $ : int [1:4] 21 46 47 74\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language dnearneigh(x = coords, d1 = 0, d2 = 62, longlat = TRUE)\n - attr(*, \"dnn\")= num [1:2] 0 62\n - attr(*, \"bounds\")= chr [1:2] \"GE\" \"LE\"\n - attr(*, \"nbtype\")= chr \"distance\"\n - attr(*, \"sym\")= logi TRUE\n\n\nAnother way to display the structure of the weight matrix is to combine table() and card() of spdep.\n\ntable(hunan$County, card(wm_d62))\n\n               \n                1 2 3 4 5 6\n  Anhua         1 0 0 0 0 0\n  Anren         0 0 0 1 0 0\n  Anxiang       0 0 0 0 1 0\n  Baojing       0 0 0 0 1 0\n  Chaling       0 0 1 0 0 0\n  Changning     0 0 1 0 0 0\n  Changsha      0 0 0 1 0 0\n  Chengbu       0 1 0 0 0 0\n  Chenxi        0 0 0 1 0 0\n  Cili          0 1 0 0 0 0\n  Dao           0 0 0 1 0 0\n  Dongan        0 0 1 0 0 0\n  Dongkou       0 0 0 1 0 0\n  Fenghuang     0 0 0 1 0 0\n  Guidong       0 0 1 0 0 0\n  Guiyang       0 0 0 1 0 0\n  Guzhang       0 0 0 0 0 1\n  Hanshou       0 0 0 1 0 0\n  Hengdong      0 0 0 0 1 0\n  Hengnan       0 0 0 0 1 0\n  Hengshan      0 0 0 0 0 1\n  Hengyang      0 0 0 0 0 1\n  Hongjiang     0 0 0 0 1 0\n  Huarong       0 0 0 1 0 0\n  Huayuan       0 0 0 1 0 0\n  Huitong       0 0 0 1 0 0\n  Jiahe         0 0 0 0 1 0\n  Jianghua      0 0 1 0 0 0\n  Jiangyong     0 1 0 0 0 0\n  Jingzhou      0 1 0 0 0 0\n  Jinshi        0 0 0 1 0 0\n  Jishou        0 0 0 0 0 1\n  Lanshan       0 0 0 1 0 0\n  Leiyang       0 0 0 1 0 0\n  Lengshuijiang 0 0 1 0 0 0\n  Li            0 0 1 0 0 0\n  Lianyuan      0 0 0 0 1 0\n  Liling        0 1 0 0 0 0\n  Linli         0 0 0 1 0 0\n  Linwu         0 0 0 1 0 0\n  Linxiang      1 0 0 0 0 0\n  Liuyang       0 1 0 0 0 0\n  Longhui       0 0 1 0 0 0\n  Longshan      0 1 0 0 0 0\n  Luxi          0 0 0 0 1 0\n  Mayang        0 0 0 0 0 1\n  Miluo         0 0 0 0 1 0\n  Nan           0 0 0 0 1 0\n  Ningxiang     0 0 0 1 0 0\n  Ningyuan      0 0 0 0 1 0\n  Pingjiang     0 1 0 0 0 0\n  Qidong        0 0 1 0 0 0\n  Qiyang        0 0 1 0 0 0\n  Rucheng       0 1 0 0 0 0\n  Sangzhi       0 1 0 0 0 0\n  Shaodong      0 0 0 0 1 0\n  Shaoshan      0 0 0 0 1 0\n  Shaoyang      0 0 0 1 0 0\n  Shimen        1 0 0 0 0 0\n  Shuangfeng    0 0 0 0 0 1\n  Shuangpai     0 0 0 1 0 0\n  Suining       0 0 0 0 1 0\n  Taojiang      0 1 0 0 0 0\n  Taoyuan       0 1 0 0 0 0\n  Tongdao       0 1 0 0 0 0\n  Wangcheng     0 0 0 1 0 0\n  Wugang        0 0 1 0 0 0\n  Xiangtan      0 0 0 1 0 0\n  Xiangxiang    0 0 0 0 1 0\n  Xiangyin      0 0 0 1 0 0\n  Xinhua        0 0 0 0 1 0\n  Xinhuang      1 0 0 0 0 0\n  Xinning       0 1 0 0 0 0\n  Xinshao       0 0 0 0 0 1\n  Xintian       0 0 0 0 1 0\n  Xupu          0 1 0 0 0 0\n  Yanling       0 0 1 0 0 0\n  Yizhang       1 0 0 0 0 0\n  Yongshun      0 0 0 1 0 0\n  Yongxing      0 0 0 1 0 0\n  You           0 0 0 1 0 0\n  Yuanjiang     0 0 0 0 1 0\n  Yuanling      1 0 0 0 0 0\n  Yueyang       0 0 1 0 0 0\n  Zhijiang      0 0 0 0 1 0\n  Zhongfang     0 0 0 1 0 0\n  Zhuzhou       0 0 0 0 1 0\n  Zixing        0 0 1 0 0 0\n\n\n\nn_comp &lt;- n.comp.nb(wm_d62)\nn_comp$nc\n\n[1] 1\n\n\n\ntable(n_comp$comp.id)\n\n\n 1 \n88 \n\n\n\n\nNext, we will plot the distance weight matrix by using the code chunk below.\n\nplot(hunan$geometry, border = \"lightgrey\")\nplot(wm_d62, coords, add = TRUE)\nplot(k1, coords, add = TRUE, col = \"red\", length = 0.08)\n\n\n\n\n\n\n\n\nThe red lines show the links of 1st nearest neighbours and the black lines show the links of neighbours within the cut-off distance of 62km.\nAlternatively, we can plot both of them next to each other by using the code chunk below.\n\npar(mfrow = c(1,2))\nplot(hunan$geometry, border = \"lightgrey\", main = \"1st nearest neighbours\")\nplot(k1, coords, add = TRUE, col = \"red\", length = 0.88)\nplot(hunan$geometry, border = \"lightgrey\", main = \"Distance link\")\nplot(wm_d62, coords, add = TRUE, pch = 19, cex = 0.6)\n\n\n\n\n\n\n\n\n\n\n\n\nOne of the characteristics of fixed distance weight matrix is that the more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours soothes the neighbour relationship across more neighbours.\nIt is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below.\n\nknn6 &lt;- knn2nb(knearneigh(coords, k=6))\nknn6\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 528 \nPercentage nonzero weights: 6.818182 \nAverage number of links: 6 \nNon-symmetric neighbours list\n\n\nSimilarly, the content of the matrix can be displayed by using str().\n\nstr(knn6)\n\nList of 88\n $ : int [1:6] 2 3 4 5 57 64\n $ : int [1:6] 1 3 57 58 78 85\n $ : int [1:6] 1 2 4 5 57 85\n $ : int [1:6] 1 3 5 6 69 85\n $ : int [1:6] 1 3 4 6 69 85\n $ : int [1:6] 3 4 5 69 75 85\n $ : int [1:6] 9 66 67 71 74 84\n $ : int [1:6] 9 46 47 78 80 86\n $ : int [1:6] 8 46 66 68 84 86\n $ : int [1:6] 16 19 22 70 72 73\n $ : int [1:6] 10 14 16 17 70 72\n $ : int [1:6] 13 15 60 61 63 83\n $ : int [1:6] 12 15 60 61 63 83\n $ : int [1:6] 11 15 16 17 72 83\n $ : int [1:6] 12 13 14 17 60 83\n $ : int [1:6] 10 11 17 22 72 83\n $ : int [1:6] 10 11 14 16 72 83\n $ : int [1:6] 20 22 23 63 77 83\n $ : int [1:6] 10 20 21 73 74 82\n $ : int [1:6] 18 19 21 22 23 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:6] 10 16 18 19 20 83\n $ : int [1:6] 18 20 41 77 79 82\n $ : int [1:6] 25 28 31 52 54 81\n $ : int [1:6] 24 28 31 33 54 81\n $ : int [1:6] 25 27 29 33 42 81\n $ : int [1:6] 26 29 30 37 42 81\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:6] 26 27 37 42 43 81\n $ : int [1:6] 26 27 28 33 49 81\n $ : int [1:6] 24 25 36 39 40 54\n $ : int [1:6] 24 31 50 54 55 56\n $ : int [1:6] 25 26 28 30 49 81\n $ : int [1:6] 36 40 41 45 56 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:6] 26 27 29 42 43 44\n $ : int [1:6] 23 43 44 62 77 79\n $ : int [1:6] 25 40 42 43 44 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:6] 26 27 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:6] 37 38 39 42 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:6] 8 9 35 47 78 86\n $ : int [1:6] 8 21 35 46 80 86\n $ : int [1:6] 49 50 51 52 53 55\n $ : int [1:6] 28 33 48 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:6] 28 48 49 50 52 54\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:6] 48 50 51 52 55 75\n $ : int [1:6] 24 28 49 50 51 52\n $ : int [1:6] 32 48 50 52 53 75\n $ : int [1:6] 32 34 36 78 80 85\n $ : int [1:6] 1 2 3 58 64 68\n $ : int [1:6] 2 57 64 66 68 78\n $ : int [1:6] 12 13 60 61 87 88\n $ : int [1:6] 12 13 59 61 63 87\n $ : int [1:6] 12 13 60 62 63 87\n $ : int [1:6] 12 38 61 63 77 87\n $ : int [1:6] 12 18 60 61 62 83\n $ : int [1:6] 1 3 57 58 68 76\n $ : int [1:6] 58 64 66 67 68 76\n $ : int [1:6] 9 58 67 68 76 84\n $ : int [1:6] 7 65 66 68 76 84\n $ : int [1:6] 9 57 58 66 78 84\n $ : int [1:6] 4 5 6 32 75 85\n $ : int [1:6] 10 16 19 22 72 73\n $ : int [1:6] 7 19 73 74 84 86\n $ : int [1:6] 10 11 14 16 17 70\n $ : int [1:6] 10 19 21 70 71 74\n $ : int [1:6] 19 21 71 73 84 86\n $ : int [1:6] 6 32 50 53 55 69\n $ : int [1:6] 58 64 65 66 67 68\n $ : int [1:6] 18 23 38 61 62 63\n $ : int [1:6] 2 8 9 46 58 68\n $ : int [1:6] 38 40 41 43 44 45\n $ : int [1:6] 34 35 36 41 45 47\n $ : int [1:6] 25 26 28 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:6] 12 13 15 16 22 63\n $ : int [1:6] 7 9 66 68 71 74\n $ : int [1:6] 2 3 4 5 56 69\n $ : int [1:6] 8 9 21 46 47 74\n $ : int [1:6] 59 60 61 62 63 88\n $ : int [1:6] 59 60 61 62 63 87\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language knearneigh(x = coords, k = 6)\n - attr(*, \"sym\")= logi FALSE\n - attr(*, \"type\")= chr \"knn\"\n - attr(*, \"knn-k\")= num 6\n - attr(*, \"class\")= chr \"nb\"\n\n\n\n\n\n\n\n\nNote\n\n\n\nNotice that each county has six neighbours, no less no more!\n\n\n\n\nWe can plot the weight matrix using the code chunk below.\n\nplot(hunan$geometry, border = \"lightgrey\")\nplot(knn6, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#thailand---subnational-administrative-boundaries",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#thailand---subnational-administrative-boundaries",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "",
    "text": "ProjectionWorking with st_geometry()Working with projectionWorking with glimpse()Plotting the Geospatial Data\n\n\nReading the administrative boundaries for Thailand\nIt is also relevant to note from the HDX website the levels stated in the dataset represent different administrative levels.\n\n\n\nThailand - Subnational Administrative Boundaries\n\n\n\nthadm &lt;- st_read(dsn = \"data/rawdata\", \n                 layer = \"tha_admbnda_adm1_rtsd_20220121\")\n\nReading layer `tha_admbnda_adm1_rtsd_20220121' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Take-home_Ex\\Take-home_Ex01\\data\\rawdata' \n  using driver `ESRI Shapefile'\nSimple feature collection with 77 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nGeodetic CRS:  WGS 84\n\n\nThe message above reveals that the geospatial objects are multipolygon features. There are a total of 77 multipolygon feature representing the different provinces in Thailand and 16 fields in thadm (Thailand Administrative) simple feature data frame. thadm is in WGS84 Geodetic coordinates system. The bounding box provides the x extend and y extend of the data.\n\nthadm2 &lt;- st_read(dsn = \"data/rawdata\", \n                 layer = \"tha_admbnda_adm2_rtsd_20220121\")\n\nReading layer `tha_admbnda_adm2_rtsd_20220121' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Take-home_Ex\\Take-home_Ex01\\data\\rawdata' \n  using driver `ESRI Shapefile'\nSimple feature collection with 928 features and 19 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nGeodetic CRS:  WGS 84\n\n\n\n\nThe column in the sf data.frame that contains the geometries is a list, of class sfc. We can retrieve the geometry list-column in this case by thadm$geometry, but the more generic way uses st_geometry() as shown in the code chunk below.\n\nst_geometry(thadm)\n\nGeometry set for 77 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nGeodetic CRS:  WGS 84\nFirst 5 geometries:\n\n\nNotice that the print only displays basic information of the feature class such as type of geometry, the geographic extent of the features and the coordinate system of the data.\n\nst_geometry(thadm2)\n\nGeometry set for 928 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nGeodetic CRS:  WGS 84\nFirst 5 geometries:\n\n\n\n\nOne of the common issue that can happen during importing geospatial data into R is that the coordinate system of the source data was either missing (such as due to missing .proj for ESRI shapefile) or wrongly assigned during the importing process.\nThis is an example the coordinate system of mpsz simple feature data frame by using st_crs() of sf package as shown in the code chunk below.\n\nst_crs(thadm)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\nAlthough thadm data frame is projected in WGS84 but when we read until the end of the print, it indicates that the EPSG is 4326. This is a wrong EPSG code because the correct EPSG code for Thailand should be 32647.\n\nst_crs(thadm2)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\n\nthadm &lt;- st_transform(thadm, crs = 32647)\n\n\nthadm2 &lt;- st_transform(thadm2, crs = 32647)\n\nDoing checks to ensure the following steps have been carried out correctly.\n\nst_crs(thadm)\n\nCoordinate Reference System:\n  User input: EPSG:32647 \n  wkt:\nPROJCRS[\"WGS 84 / UTM zone 47N\",\n    BASEGEOGCRS[\"WGS 84\",\n        ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n            MEMBER[\"World Geodetic System 1984 (Transit)\"],\n            MEMBER[\"World Geodetic System 1984 (G730)\"],\n            MEMBER[\"World Geodetic System 1984 (G873)\"],\n            MEMBER[\"World Geodetic System 1984 (G1150)\"],\n            MEMBER[\"World Geodetic System 1984 (G1674)\"],\n            MEMBER[\"World Geodetic System 1984 (G1762)\"],\n            MEMBER[\"World Geodetic System 1984 (G2139)\"],\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ENSEMBLEACCURACY[2.0]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4326]],\n    CONVERSION[\"UTM zone 47N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",99,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Navigation and medium accuracy spatial referencing.\"],\n        AREA[\"Between 96°E and 102°E, northern hemisphere between equator and 84°N, onshore and offshore. China. Indonesia. Laos. Malaysia - West Malaysia. Mongolia. Myanmar (Burma). Russian Federation. Thailand.\"],\n        BBOX[0,96,84,102]],\n    ID[\"EPSG\",32647]]\n\n\n\nst_crs(thadm2)\n\nCoordinate Reference System:\n  User input: EPSG:32647 \n  wkt:\nPROJCRS[\"WGS 84 / UTM zone 47N\",\n    BASEGEOGCRS[\"WGS 84\",\n        ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n            MEMBER[\"World Geodetic System 1984 (Transit)\"],\n            MEMBER[\"World Geodetic System 1984 (G730)\"],\n            MEMBER[\"World Geodetic System 1984 (G873)\"],\n            MEMBER[\"World Geodetic System 1984 (G1150)\"],\n            MEMBER[\"World Geodetic System 1984 (G1674)\"],\n            MEMBER[\"World Geodetic System 1984 (G1762)\"],\n            MEMBER[\"World Geodetic System 1984 (G2139)\"],\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ENSEMBLEACCURACY[2.0]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4326]],\n    CONVERSION[\"UTM zone 47N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",99,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Navigation and medium accuracy spatial referencing.\"],\n        AREA[\"Between 96°E and 102°E, northern hemisphere between equator and 84°N, onshore and offshore. China. Indonesia. Laos. Malaysia - West Malaysia. Mongolia. Myanmar (Burma). Russian Federation. Thailand.\"],\n        BBOX[0,96,84,102]],\n    ID[\"EPSG\",32647]]\n\n\n\n\nBesides the basic feature information, we also would like to learn more about the associated attribute information in the data frame. This is the time glimpse() of dplyr comes in handy as shown in the code chunk below.\n\nglimpse(thadm)\n\nRows: 77\nColumns: 17\n$ Shape_Leng &lt;dbl&gt; 2.417227, 1.695100, 1.251111, 1.884945, 3.041716, 1.739908,…\n$ Shape_Area &lt;dbl&gt; 0.13133873, 0.07926199, 0.05323766, 0.12698345, 0.21393797,…\n$ ADM1_EN    &lt;chr&gt; \"Bangkok\", \"Samut Prakan\", \"Nonthaburi\", \"Pathum Thani\", \"P…\n$ ADM1_TH    &lt;chr&gt; \"กรุงเทพมหานคร\", \"สมุทรปราการ\", \"นนทบุรี\", \"ปทุมธานี\", \"พระนครศรีอ…\n$ ADM1_PCODE &lt;chr&gt; \"TH10\", \"TH11\", \"TH12\", \"TH13\", \"TH14\", \"TH15\", \"TH16\", \"TH…\n$ ADM1_REF   &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ ADM1ALT1EN &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ ADM1ALT2EN &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ ADM1ALT1TH &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ ADM1ALT2TH &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ ADM0_EN    &lt;chr&gt; \"Thailand\", \"Thailand\", \"Thailand\", \"Thailand\", \"Thailand\",…\n$ ADM0_TH    &lt;chr&gt; \"ประเทศไทย\", \"ประเทศไทย\", \"ประเทศไทย\", \"ประเทศไทย\", \"ประเทศ…\n$ ADM0_PCODE &lt;chr&gt; \"TH\", \"TH\", \"TH\", \"TH\", \"TH\", \"TH\", \"TH\", \"TH\", \"TH\", \"TH\",…\n$ date       &lt;date&gt; 2019-02-18, 2019-02-18, 2019-02-18, 2019-02-18, 2019-02-18…\n$ validOn    &lt;date&gt; 2022-01-22, 2022-01-22, 2022-01-22, 2022-01-22, 2022-01-22…\n$ validTo    &lt;date&gt; -001-11-30, -001-11-30, -001-11-30, -001-11-30, -001-11-30…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((674339.8 15..., MULTIPOLYGON (…\n\n\nglimpse() report reveals the data type of each fields. For example date field is in date data type, Shape_Leng and Shape_Area fields are all in double-precision values.\n\nglimpse(thadm2)\n\nRows: 928\nColumns: 20\n$ Shape_Leng &lt;dbl&gt; 0.08541733, 0.13413177, 0.67634217, 0.08588647, 0.30172202,…\n$ Shape_Area &lt;dbl&gt; 0.0004504685, 0.0009501914, 0.0198588627, 0.0003369561, 0.0…\n$ ADM2_EN    &lt;chr&gt; \"Phra Nakhon\", \"Dusit\", \"Nong Chok\", \"Bang Rak\", \"Bang Khen…\n$ ADM2_TH    &lt;chr&gt; \"พระนคร\", \"ดุสิต\", \"หนองจอก\", \"บางรัก\", \"บางเขน\", \"บางกะปิ\", \"ป…\n$ ADM2_PCODE &lt;chr&gt; \"TH1001\", \"TH1002\", \"TH1003\", \"TH1004\", \"TH1005\", \"TH1006\",…\n$ ADM2_REF   &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ ADM2ALT1EN &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ ADM2ALT2EN &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ ADM2ALT1TH &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ ADM2ALT2TH &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ ADM1_EN    &lt;chr&gt; \"Bangkok\", \"Bangkok\", \"Bangkok\", \"Bangkok\", \"Bangkok\", \"Ban…\n$ ADM1_TH    &lt;chr&gt; \"กรุงเทพมหานคร\", \"กรุงเทพมหานคร\", \"กรุงเทพมหานคร\", \"กรุงเทพมหาน…\n$ ADM1_PCODE &lt;chr&gt; \"TH10\", \"TH10\", \"TH10\", \"TH10\", \"TH10\", \"TH10\", \"TH10\", \"TH…\n$ ADM0_EN    &lt;chr&gt; \"Thailand\", \"Thailand\", \"Thailand\", \"Thailand\", \"Thailand\",…\n$ ADM0_TH    &lt;chr&gt; \"ประเทศไทย\", \"ประเทศไทย\", \"ประเทศไทย\", \"ประเทศไทย\", \"ประเทศ…\n$ ADM0_PCODE &lt;chr&gt; \"TH\", \"TH\", \"TH\", \"TH\", \"TH\", \"TH\", \"TH\", \"TH\", \"TH\", \"TH\",…\n$ date       &lt;date&gt; 2019-02-18, 2019-02-18, 2019-02-18, 2019-02-18, 2019-02-18…\n$ validOn    &lt;date&gt; 2022-01-22, 2022-01-22, 2022-01-22, 2022-01-22, 2022-01-22…\n$ validTo    &lt;date&gt; -001-11-30, -001-11-30, -001-11-30, -001-11-30, -001-11-30…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((662263.2 15..., MULTIPOLYGON (…\n\n\n\n\nIn geospatial data science, by looking at the feature information is not enough. We are also interested to visualise the geospatial features. This is the time plot() of R Graphic comes in very handy as shown in the code chunk below.\n\nplot(st_geometry(thadm))\n\n\n\n\n\n\n\n\nAlternatively, we can also choose the plot the sf object by using a specific attribute as shown in the code chunk below.\n\nplot(thadm[\"ADM1_EN\"])\n\n\n\n\n\n\n\n\nplot() function is utilised again to visualise the features but consisting the districts\n\n\n\n\n\n\n\ntm_shape(thadm)+\n  tm_fill(\"ADM1_EN\", \n          title = \"Thailand Boundary\") +\n  tm_layout(main.title = \"Map of Thailand\",\n            main.title.position = \"center\",\n            main.title.size = 1.5,\n            legend.height = 0.6, \n            legend.width = 0.4,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type = \"4star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha = 0.2) +\n  tmap_options(max.categories = 77)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-wrangling",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-wrangling",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "",
    "text": "bmr_provinces will be used in confining the geospatial data to the study area,we will utilise the code chunk below.\n\nthadm_bmr &lt;- thadm %&gt;%\n  filter(ADM1_EN %in% bmr_provinces)\n\nsummary(thadm_bmr)\n\n   Shape_Leng      Shape_Area        ADM1_EN            ADM1_TH         \n Min.   :1.251   Min.   :0.05324   Length:6           Length:6          \n 1st Qu.:1.599   1st Qu.:0.07349   Class :character   Class :character  \n Median :1.790   Median :0.10312   Mode  :character   Mode  :character  \n Mean   :1.880   Mean   :0.10688                                        \n 3rd Qu.:2.284   3rd Qu.:0.13025                                        \n Max.   :2.463   Max.   :0.17891                                        \n  ADM1_PCODE          ADM1_REF          ADM1ALT1EN         ADM1ALT2EN       \n Length:6           Length:6           Length:6           Length:6          \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n  ADM1ALT1TH         ADM1ALT2TH          ADM0_EN            ADM0_TH         \n Length:6           Length:6           Length:6           Length:6          \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n  ADM0_PCODE             date               validOn          \n Length:6           Min.   :2019-02-18   Min.   :2022-01-22  \n Class :character   1st Qu.:2019-02-18   1st Qu.:2022-01-22  \n Mode  :character   Median :2019-02-18   Median :2022-01-22  \n                    Mean   :2019-02-18   Mean   :2022-01-22  \n                    3rd Qu.:2019-02-18   3rd Qu.:2022-01-22  \n                    Max.   :2019-02-18   Max.   :2022-01-22  \n    validTo                    geometry\n Min.   :-001-11-30   MULTIPOLYGON :6  \n 1st Qu.:-001-11-30   epsg:32647   :0  \n Median :-001-11-30   +proj=utm ...:0  \n Mean   :-001-11-30                    \n 3rd Qu.:-001-11-30                    \n Max.   :-001-11-30                    \n\n\n\nthadm2_bmr &lt;- thadm2 %&gt;%\n  filter(ADM1_EN %in% bmr_provinces)\n\nsummary(thadm2_bmr)\n\n   Shape_Leng        Shape_Area          ADM2_EN            ADM2_TH         \n Min.   :0.05123   Min.   :0.0001177   Length:79          Length:79         \n 1st Qu.:0.16740   1st Qu.:0.0010931   Class :character   Class :character  \n Median :0.28074   Median :0.0030914   Mode  :character   Mode  :character  \n Mean   :0.41054   Mean   :0.0081177                                        \n 3rd Qu.:0.61018   3rd Qu.:0.0107533                                        \n Max.   :1.26897   Max.   :0.0454895                                        \n  ADM2_PCODE          ADM2_REF          ADM2ALT1EN         ADM2ALT2EN       \n Length:79          Length:79          Length:79          Length:79         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n  ADM2ALT1TH         ADM2ALT2TH          ADM1_EN            ADM1_TH         \n Length:79          Length:79          Length:79          Length:79         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n  ADM1_PCODE          ADM0_EN            ADM0_TH           ADM0_PCODE       \n Length:79          Length:79          Length:79          Length:79         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n      date               validOn              validTo          \n Min.   :2019-02-18   Min.   :2022-01-22   Min.   :-001-11-30  \n 1st Qu.:2019-02-18   1st Qu.:2022-01-22   1st Qu.:-001-11-30  \n Median :2019-02-18   Median :2022-01-22   Median :-001-11-30  \n Mean   :2019-02-18   Mean   :2022-01-22   Mean   :-001-11-30  \n 3rd Qu.:2019-02-18   3rd Qu.:2022-01-22   3rd Qu.:-001-11-30  \n Max.   :2019-02-18   Max.   :2022-01-22   Max.   :-001-11-30  \n          geometry \n MULTIPOLYGON :79  \n epsg:32647   : 0  \n +proj=utm ...: 0  \n                   \n                   \n                   \n\n\n\ntm_shape(thadm_bmr)+\n  tm_fill(\"ADM1_EN\", \n          title = \"Thailand BMR\") +\n  tm_layout(main.title = \"Maping of Bangkok Metropolitan Region\",\n            main.title.position = \"center\",\n            main.title.size = 1.5,\n            legend.height = 0.6, \n            legend.width = 0.4,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type = \"4star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha = 0.2)\n\n\n\n\n\n\n\n\n\ntm_shape(thadm2_bmr)+\n  tm_fill(\"ADM1_EN\", \n          title = \"Thailand BMR\") +\n  tm_layout(main.title = \"Maping of Bangkok Metropolitan Region\",\n            main.title.position = \"center\",\n            main.title.size = 1.5,\n            legend.height = 0.6, \n            legend.width = 0.4,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type = \"4star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha = 0.2)\n\n\n\n\n\n\n\n\nThe simple feature data frame is saved into a physical file for usage. By doing so the need to repeat the steps above is not needed.\n\n\n\nwrite_rds(thadm_bmr, \"data/rds/thadm_bmr.rds\")\n\nTo retrieve file\n\nthadm_bmr &lt;- read_rds(\"data/rds/thadm_bmr.rds\")\n\n\n\n\n\nwrite_rds(thadm2_bmr, \"data/rds/thadm2_bmr.rds\")\n\nTo retrieve file\n\nthadm2_bmr &lt;- read_rds(\"data/rds/thadm2_bmr.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#spatial-exploratory-data-analysis-eda",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#spatial-exploratory-data-analysis-eda",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "",
    "text": "We will proceed to do some initial visualisation of the data to get a better sense of how accidents may be distributed in the BMR.\nThe barplot while not classified under as a spatial EDA kick-starts the EDA process.\n\nggplot(rdacc_sf_bmr, aes(x = province_en)) +\n  geom_bar(fill = \"salmon\", color = \"black\", bins = 20) +\n  geom_text(stat = \"count\", aes(label = ..count..), vjust = -0.5) +\n  labs(title = \"Count of Accidents by Province within BMR\",\n       x = \"Province\",\n       y = \"Count of Accidents\")\n\n\n\n\n\n\n\n\n\nggplot(rdacc_sf_bmr, aes(x = Month_fac)) +\n  geom_bar(fill = \"blue\", color = \"black\") +\n labs(x = \"Month\", y = \"Count\", title = \"Barplot of Accidents in BMR across Months\")\n\n\n\n\n\n\n\n\n\nggplot(rdacc_sf_bmr, aes(x = hour_of_day)) +\n  geom_bar(fill = \"blue\", color = \"black\") +\n labs(x = \"Hour of Day\", y = \"Count\", title = \"Barplot of Accidents in BMR across 24 hours\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "Introducing sfdep.\n\nsfdep creates a sf and tidyverse friendly interface to the package as well as introducing new functionalities that are not present in spdep.\nsfdep utilizes list columns extensively to make this interface possible\n\n\n\n\nThe code chunk below is used to perform the following tasks:\n\ncreating a package list containing the necessary R packages,\nchecking if the R packages in the package list have been installed in R,\n\nif they have yet to be installed, RStudio will installed the missing packages,\n\nlaunching the packages into R environment.\n\n\npacman::p_load(sf, sfdep, spdep, tmap, tidyverse)\n\n\n\n\n\nFor the purpose of this in-class exercise, the Hunan data sets will be used. There are two data sets in this use case, they are:\n\nHunan, a geospatial data set in ESRI shapefile format, and\nHunan_2012, an attribute data set in csv format.\n\n\n\nThe code chunk below uses st_read() of sf package to import Hunan shapefile into R. The imported shapefile will be simple features Object of sf.\n\nhunan &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\zjho008\\ISSS626-GAA\\In-class_Ex\\In-class_Ex05\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n\nNext, we will import Hunan_2012.csv into R by using read_csv() of readr package. The output is R data frame class.\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nThe code chunk below will be used to update the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 dataframe. This is performed by using left_join() of dplyr package.\n\nhunan_GDPPC &lt;- left_join(hunan,hunan2012) %&gt;%\n  select(1:4, 7, 15)\n\nJoining with `by = join_by(County)`\n\n\n\n\n\n\n\n\nNote\n\n\n\nFor this exercise, we only retain columns 1 to 4, column 7 and column 15. It is advisable to examine the output sf data.frame to learn know what are these fields.\nIn order to retain the geospatial properties, the left data frame must the sf data.frame (i.e. hunan)\n\n\n\n\n\nNow, we are going to prepare a choropleth map showing the distribution of GDPPC 2012 by using qtm() of tmap package.\n\nThe plotThe code\n\n\n\n\ntmap mode set to plotting\n\n\n\n\n\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\ntm_shape(hunan_GDPPC) +\n  tm_fill(\"GDPPC\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"GDPPC\") +\n  tm_layout(main.title = \"Distribution of GDP per capita by county, Hunan Province\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2)\n\n\n\n\n\n\n\n\n\n\n\nwm_q &lt;- hunan_GDPPC %&gt;%\n  mutate(nb = st_contiguity(geometry),\n         wt = st_weights(nb,\n                         style = \"W\"),\n         .before = 1)\n\n\n\n\n\nwm_q\n\nSimple feature collection with 88 features and 8 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\nFirst 10 features:\n                               nb\n1                 2, 3, 4, 57, 85\n2               1, 57, 58, 78, 85\n3                     1, 4, 5, 85\n4                      1, 3, 5, 6\n5                     3, 4, 6, 85\n6                4, 5, 69, 75, 85\n7                  67, 71, 74, 84\n8       9, 46, 47, 56, 78, 80, 86\n9           8, 66, 68, 78, 84, 86\n10 16, 17, 19, 20, 22, 70, 72, 73\n                                                                            wt\n1                                                      0.2, 0.2, 0.2, 0.2, 0.2\n2                                                      0.2, 0.2, 0.2, 0.2, 0.2\n3                                                       0.25, 0.25, 0.25, 0.25\n4                                                       0.25, 0.25, 0.25, 0.25\n5                                                       0.25, 0.25, 0.25, 0.25\n6                                                      0.2, 0.2, 0.2, 0.2, 0.2\n7                                                       0.25, 0.25, 0.25, 0.25\n8  0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571\n9             0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667\n10                      0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125\n     NAME_2  ID_3    NAME_3   ENGTYPE_3    County GDPPC\n1   Changde 21098   Anxiang      County   Anxiang 23667\n2   Changde 21100   Hanshou      County   Hanshou 20981\n3   Changde 21101    Jinshi County City    Jinshi 34592\n4   Changde 21102        Li      County        Li 24473\n5   Changde 21103     Linli      County     Linli 25554\n6   Changde 21104    Shimen      County    Shimen 27137\n7  Changsha 21109   Liuyang County City   Liuyang 63118\n8  Changsha 21110 Ningxiang      County Ningxiang 62202\n9  Changsha 21111 Wangcheng      County Wangcheng 70666\n10 Chenzhou 21112     Anren      County     Anren 12761\n                         geometry\n1  POLYGON ((112.0625 29.75523...\n2  POLYGON ((112.2288 29.11684...\n3  POLYGON ((111.8927 29.6013,...\n4  POLYGON ((111.3731 29.94649...\n5  POLYGON ((111.6324 29.76288...\n6  POLYGON ((110.8825 30.11675...\n7  POLYGON ((113.9905 28.5682,...\n8  POLYGON ((112.7181 28.38299...\n9  POLYGON ((112.7914 28.52688...\n10 POLYGON ((113.1757 26.82734...\n\n\n\n\n\nIn the code chunk below, global_moran() function is used to compute the Moran’s I value. Different from the spdep package, the output is a tibble data.frame.\n\nmoranI &lt;- global_moran(wm_q$GDPPC,\n                       wm_q$nb,\n                       wm_q$wt)\nglimpse(moranI)\n\nList of 2\n $ I: num 0.301\n $ K: num 7.64\n\n\n\n\n\nMoran’s I test will be performed instead of just computing the Moran’s I statistics. With sfdep package, Moran’s I test can be performed by using global_moran_test() as shown in the code chunk below.\n\nglobal_moran_test(wm_q$GDPPC,\n                       wm_q$nb,\n                       wm_q$wt)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\n\n\n\n\n\n\nTip\n\n\n\n\nThe default for alternative argument is “two.sided”. Other supported arguments are “greater” or “less”. randomization, and\nBy default the randomization argument is TRUE. Otherwise if FALSE, under the assumption of normality.\n\n\n\n\n\n\nIn practice, Monte carlo simulation should be used to perform the statistical test. For sfdep, it is supported by globel_moran_perm()\n\nStep 1Step 2Report\n\n\nIt is a good practice to use set.seed() before performing simulation. This is to ensure that the computation is reproducible.\n\nset.seed(1234)\n\n\n\nNext, global_moran_perm() is used to perform Monte Carlo simulation.\n\nglobal_moran_perm(wm_q$GDPPC,\n                       wm_q$nb,\n                       wm_q$wt,\n                  nsim = 99)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.30075, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\n\nThe statistical report on previous tab shows that the p-value (2.2e-16 is the scientific notation of 0.00000000000000022) is smaller than alpha value of 0.05. Hence, we have enough statistical evidence to reject the null hypothesis that the spatial distribution of GPD per capita resembles a random distribution (i.e. independent from spatial). Because the Moran’s I statistics is greater than 0. We can infer that the spatial distribution shows sign of clustering.\n\n\n\n\n\n\n\nLISA map is a categorical map showing outliers and clusters. There are two types of outliers namely: High-Low and Low-High outliers. Likewise, there are two types of clusters namely: High-High and Low-Low clusters. In fact, LISA map is an interpreted map by combining local Moran’s I of geographical areas and their respective p-values.\n\n\n\n\nThe codeThe output\n\n\nThe code chunk below demonstrates how to compute Local Moran’s I of GDPPC at county level by using local_moran() of sfdep package\n\nlisa &lt;- wm_q %&gt;%\n  mutate(local_moran = local_moran(\n    GDPPC, nb, wt, nsim = 99), # 100 simulations\n          .before = 1) %&gt;%\n  unnest(local_moran)\n\n\n\nThe output of local_moran() is a sf data.frame containing the columns ii, eii, var_ii, z_ii, p_ii, p_ii_sim, and p_folded_sim.\n\nii: local moran statistic\neii: expectation of local moran statistic; for localmoran_permthe permutation sample means\nvar_ii: variance of local moran statistic; for localmoran_permthe permutation sample standard deviations\nz_ii: standard deviate of local moran statistic; for localmoran_perm based on permutation sample means and standard deviations p_ii: p-value of local moran statistic using pnorm(); for localmoran_perm using standard deviatse based on permutation sample means and standard deviations p_ii_sim: For localmoran_perm(), rank() and punif() of observed statistic rank for [0, 1] p-values using alternative= -p_folded_sim: the simulation folded [0, 0.5] range ranked p-value (based on https://github.com/pysal/esda/blob/4a63e0b5df1e754b17b5f1205b cadcbecc5e061/esda/crand.py#L211-L213)\nskewness: For localmoran_perm, the output of e1071::skewness() for the permutation samples underlying the standard deviates\nkurtosis: For localmoran_perm, the output of e1071::kurtosis() for the permutation samples underlying the standard deviates.\n\n\n\n\n\n\n\nIn this code chunk below, tmap functions are used prepare a choropleth map by using value in the ii field.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(lisa) +\n  tm_fill(\"p_ii_sim\") + \n  tm_borders(alpha = 0.5) +\n   tm_layout(main.title = \"p-value of local Moran's I\",\n            main.title.size = 2)\n\n\n\n\n\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\n  tm_shape(lisa) +\n    tm_fill(\"ii\") +\n    tm_borders(alpha = 0.5) +\n    tm_view(set.zoom.limits = c(6,8)) +\n    tm_layout(\n      main.title = \"local Moran's I of GDPPC\",\n      main.title.size = 2)\n\nVariable(s) \"ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n\n\n\ntmap mode set to plotting\n\n\nVariable(s) \"ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlisa_sig &lt;- lisa %&gt;%\n  filter(p_ii_sim &lt; 0.05)\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(lisa) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig) +\n  tm_fill(\"mean\") +\n  tm_borders(alpha = 0.4)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\n\n\n\n\n\n\n\nLISA map is a categorical map showing outliers and clusters. there are two types of outliers namely: High-Low and Low-High outliers. Likewise, there are two types of clusters namely: High-High and Low-Low clusters. In fact, LISA map is an interpreted map by combining local Moran’s I of geographical areas and their respective p-values. For instance isolating those below p-value of 0.05.\n\n\n\n\nHCSA uses spatial weights to identify locations of statistically significant hot spots and cold spots in an spatially weighted attribute that are in proximity to one another based on a calculated distance. The analysis groups features when similar high (hot) or low (cold) values are found in a cluster. The polygon features usually represent administration boundaries or a custom grid structure.\n\n\n\n\nwe will need to derive a spatial weight matrix before we can compute local Gi* statistics. The code chunk below will be used to derive a spatial weight matrix by using sfdep functions and tidyverse approach.\n\nwm_idw &lt;- hunan_GDPPC %&gt;%\n  mutate(nb = include_self(\n    st_contiguity(geometry)),\n    wts = st_inverse_distance(nb,\n                              geometry,\n                              scale = 1,\n                              alpha = 1),\n          .before = 1)\n\n! Polygon provided. Using point on surface.\n\n\nWarning: There was 1 warning in `stopifnot()`.\nℹ In argument: `wts = st_inverse_distance(nb, geometry, scale = 1, alpha = 1)`.\nCaused by warning in `st_point_on_surface.sfc()`:\n! st_point_on_surface may not give correct results for longitude/latitude data\n\n\n\n\n\nHCSA &lt;- wm_idw %&gt;%\n  mutate(local_Gi = local_gstar_perm(\n    GDPPC, nb, wts, nsim = 99),\n          .before = 1) %&gt;%\n  unnest(local_Gi)\nHCSA\n\nSimple feature collection with 88 features and 18 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n# A tibble: 88 × 19\n    gi_star cluster     e_gi  var_gi std_dev p_value p_sim p_folded_sim skewness\n      &lt;dbl&gt; &lt;fct&gt;      &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n 1  0.261   Low     0.00126  1.07e-7  0.283  7.78e-1  0.66         0.33    0.783\n 2 -0.276   Low     0.000969 4.76e-8 -0.123  9.02e-1  0.98         0.49    0.713\n 3  0.00573 High    0.00156  2.53e-7 -0.0571 9.54e-1  0.78         0.39    0.972\n 4  0.528   High    0.00155  2.97e-7  0.321  7.48e-1  0.56         0.28    0.942\n 5  0.466   High    0.00137  2.76e-7  0.386  7.00e-1  0.52         0.26    1.32 \n 6 -0.445   High    0.000992 7.08e-8 -0.588  5.57e-1  0.68         0.34    0.692\n 7  2.99    High    0.000700 4.05e-8  3.13   1.74e-3  0.04         0.02    0.975\n 8  2.04    High    0.00152  1.58e-7  1.77   7.59e-2  0.16         0.08    1.26 \n 9  4.42    High    0.00130  1.18e-7  4.22   2.39e-5  0.02         0.01    1.20 \n10  1.21    Low     0.00175  1.25e-7  1.49   1.36e-1  0.18         0.09    0.408\n# ℹ 78 more rows\n# ℹ 10 more variables: kurtosis &lt;dbl&gt;, nb &lt;nb&gt;, wts &lt;list&gt;, NAME_2 &lt;chr&gt;,\n#   ID_3 &lt;int&gt;, NAME_3 &lt;chr&gt;, ENGTYPE_3 &lt;chr&gt;, County &lt;chr&gt;, GDPPC &lt;dbl&gt;,\n#   geometry &lt;POLYGON [°]&gt;\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(HCSA) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8))\n\nVariable(s) \"gi_star\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(HCSA) +\n  tm_fill(\"p_sim\") + \n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\nFor effective comparison, both maps can be plotted next to each other as shown below.\n\n\ntmap mode set to plotting\n\n\nVariable(s) \"gi_star\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlotting the significant (i.e. p-values less than 0.05) hot spot and cold spot areas by using appropriate tmap functions as shown below.\n\n\n\n\n\n\ntmap mode set to plotting\n\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\n\n\n\n\n\n\n\n\n\n\n\nHCSA_sig &lt;- HCSA  %&gt;%\n  filter(p_sim &lt; 0.05)\ntmap_mode(\"plot\")\ntm_shape(HCSA) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(HCSA_sig) +\n  tm_fill(\"cluster\") + \n  tm_borders(alpha = 0.4)\n\n\n\n\nThe plot reveals that there is one hot spot area and two cold spot areas. Interestingly, the hot spot areas coincide with the High-high cluster identifies by using local Moran’s I method in the earlier sub-section."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#getting-startted",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#getting-startted",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "Introducing sfdep.\n\nsfdep creates a sf and tidyverse friendly interface to the package as well as introducing new functionalities that are not present in spdep.\nsfdep utilizes list columns extensively to make this interface possible\n\n\n\n\nThe code chunk below is used to perform the following tasks:\n\ncreating a package list containing the necessary R packages,\nchecking if the R packages in the package list have been installed in R,\n\nif they have yet to be installed, RStudio will installed the missing packages,\n\nlaunching the packages into R environment.\n\n\npacman::p_load(sf, sfdep, spdep, tmap, tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#getting-the-data-into-r-environment",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#getting-the-data-into-r-environment",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "For the purpose of this in-class exercise, the Hunan data sets will be used. There are two data sets in this use case, they are:\n\nHunan, a geospatial data set in ESRI shapefile format, and\nHunan_2012, an attribute data set in csv format.\n\n\n\nThe code chunk below uses st_read() of sf package to import Hunan shapefile into R. The imported shapefile will be simple features Object of sf.\n\nhunan &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\zjho008\\ISSS626-GAA\\In-class_Ex\\In-class_Ex05\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n\nNext, we will import Hunan_2012.csv into R by using read_csv() of readr package. The output is R data frame class.\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nThe code chunk below will be used to update the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 dataframe. This is performed by using left_join() of dplyr package.\n\nhunan_GDPPC &lt;- left_join(hunan,hunan2012) %&gt;%\n  select(1:4, 7, 15)\n\nJoining with `by = join_by(County)`\n\n\n\n\n\n\n\n\nNote\n\n\n\nFor this exercise, we only retain columns 1 to 4, column 7 and column 15. It is advisable to examine the output sf data.frame to learn know what are these fields.\nIn order to retain the geospatial properties, the left data frame must the sf data.frame (i.e. hunan)\n\n\n\n\n\nNow, we are going to prepare a choropleth map showing the distribution of GDPPC 2012 by using qtm() of tmap package.\n\nThe plotThe code\n\n\n\n\ntmap mode set to plotting\n\n\n\n\n\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\ntm_shape(hunan_GDPPC) +\n  tm_fill(\"GDPPC\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"GDPPC\") +\n  tm_layout(main.title = \"Distribution of GDP per capita by county, Hunan Province\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#global-measures-of-spatial-autocorrelation",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#global-measures-of-spatial-autocorrelation",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "wm_q &lt;- hunan_GDPPC %&gt;%\n  mutate(nb = st_contiguity(geometry),\n         wt = st_weights(nb,\n                         style = \"W\"),\n         .before = 1)\n\n\n\n\n\nwm_q\n\nSimple feature collection with 88 features and 8 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\nFirst 10 features:\n                               nb\n1                 2, 3, 4, 57, 85\n2               1, 57, 58, 78, 85\n3                     1, 4, 5, 85\n4                      1, 3, 5, 6\n5                     3, 4, 6, 85\n6                4, 5, 69, 75, 85\n7                  67, 71, 74, 84\n8       9, 46, 47, 56, 78, 80, 86\n9           8, 66, 68, 78, 84, 86\n10 16, 17, 19, 20, 22, 70, 72, 73\n                                                                            wt\n1                                                      0.2, 0.2, 0.2, 0.2, 0.2\n2                                                      0.2, 0.2, 0.2, 0.2, 0.2\n3                                                       0.25, 0.25, 0.25, 0.25\n4                                                       0.25, 0.25, 0.25, 0.25\n5                                                       0.25, 0.25, 0.25, 0.25\n6                                                      0.2, 0.2, 0.2, 0.2, 0.2\n7                                                       0.25, 0.25, 0.25, 0.25\n8  0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571\n9             0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667\n10                      0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125\n     NAME_2  ID_3    NAME_3   ENGTYPE_3    County GDPPC\n1   Changde 21098   Anxiang      County   Anxiang 23667\n2   Changde 21100   Hanshou      County   Hanshou 20981\n3   Changde 21101    Jinshi County City    Jinshi 34592\n4   Changde 21102        Li      County        Li 24473\n5   Changde 21103     Linli      County     Linli 25554\n6   Changde 21104    Shimen      County    Shimen 27137\n7  Changsha 21109   Liuyang County City   Liuyang 63118\n8  Changsha 21110 Ningxiang      County Ningxiang 62202\n9  Changsha 21111 Wangcheng      County Wangcheng 70666\n10 Chenzhou 21112     Anren      County     Anren 12761\n                         geometry\n1  POLYGON ((112.0625 29.75523...\n2  POLYGON ((112.2288 29.11684...\n3  POLYGON ((111.8927 29.6013,...\n4  POLYGON ((111.3731 29.94649...\n5  POLYGON ((111.6324 29.76288...\n6  POLYGON ((110.8825 30.11675...\n7  POLYGON ((113.9905 28.5682,...\n8  POLYGON ((112.7181 28.38299...\n9  POLYGON ((112.7914 28.52688...\n10 POLYGON ((113.1757 26.82734...\n\n\n\n\n\nIn the code chunk below, global_moran() function is used to compute the Moran’s I value. Different from the spdep package, the output is a tibble data.frame.\n\nmoranI &lt;- global_moran(wm_q$GDPPC,\n                       wm_q$nb,\n                       wm_q$wt)\nglimpse(moranI)\n\nList of 2\n $ I: num 0.301\n $ K: num 7.64\n\n\n\n\n\nMoran’s I test will be performed instead of just computing the Moran’s I statistics. With sfdep package, Moran’s I test can be performed by using global_moran_test() as shown in the code chunk below.\n\nglobal_moran_test(wm_q$GDPPC,\n                       wm_q$nb,\n                       wm_q$wt)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\n\n\n\n\n\n\nTip\n\n\n\n\nThe default for alternative argument is “two.sided”. Other supported arguments are “greater” or “less”. randomization, and\nBy default the randomization argument is TRUE. Otherwise if FALSE, under the assumption of normality.\n\n\n\n\n\n\nIn practice, Monte carlo simulation should be used to perform the statistical test. For sfdep, it is supported by globel_moran_perm()\n\nStep 1Step 2Report\n\n\nIt is a good practice to use set.seed() before performing simulation. This is to ensure that the computation is reproducible.\n\nset.seed(1234)\n\n\n\nNext, global_moran_perm() is used to perform Monte Carlo simulation.\n\nglobal_moran_perm(wm_q$GDPPC,\n                       wm_q$nb,\n                       wm_q$wt,\n                  nsim = 99)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.30075, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\n\nThe statistical report on previous tab shows that the p-value (2.2e-16 is the scientific notation of 0.00000000000000022) is smaller than alpha value of 0.05. Hence, we have enough statistical evidence to reject the null hypothesis that the spatial distribution of GPD per capita resembles a random distribution (i.e. independent from spatial). Because the Moran’s I statistics is greater than 0. We can infer that the spatial distribution shows sign of clustering."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#lisa-map",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#lisa-map",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "LISA map is a categorical map showing outliers and clusters. There are two types of outliers namely: High-Low and Low-High outliers. Likewise, there are two types of clusters namely: High-High and Low-Low clusters. In fact, LISA map is an interpreted map by combining local Moran’s I of geographical areas and their respective p-values."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#computing-local-morans-i-1",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#computing-local-morans-i-1",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "The codeThe output\n\n\nThe code chunk below demonstrates how to compute Local Moran’s I of GDPPC at county level by using local_moran() of sfdep package\n\nlisa &lt;- wm_q %&gt;%\n  mutate(local_moran = local_moran(\n    GDPPC, nb, wt, nsim = 99), # 100 simulations\n          .before = 1) %&gt;%\n  unnest(local_moran)\n\n\n\nThe output of local_moran() is a sf data.frame containing the columns ii, eii, var_ii, z_ii, p_ii, p_ii_sim, and p_folded_sim.\n\nii: local moran statistic\neii: expectation of local moran statistic; for localmoran_permthe permutation sample means\nvar_ii: variance of local moran statistic; for localmoran_permthe permutation sample standard deviations\nz_ii: standard deviate of local moran statistic; for localmoran_perm based on permutation sample means and standard deviations p_ii: p-value of local moran statistic using pnorm(); for localmoran_perm using standard deviatse based on permutation sample means and standard deviations p_ii_sim: For localmoran_perm(), rank() and punif() of observed statistic rank for [0, 1] p-values using alternative= -p_folded_sim: the simulation folded [0, 0.5] range ranked p-value (based on https://github.com/pysal/esda/blob/4a63e0b5df1e754b17b5f1205b cadcbecc5e061/esda/crand.py#L211-L213)\nskewness: For localmoran_perm, the output of e1071::skewness() for the permutation samples underlying the standard deviates\nkurtosis: For localmoran_perm, the output of e1071::kurtosis() for the permutation samples underlying the standard deviates."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualising-p-value-of-local-morans-i",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualising-p-value-of-local-morans-i",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "In this code chunk below, tmap functions are used prepare a choropleth map by using value in the ii field.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(lisa) +\n  tm_fill(\"p_ii_sim\") + \n  tm_borders(alpha = 0.5) +\n   tm_layout(main.title = \"p-value of local Moran's I\",\n            main.title.size = 2)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualising-local-morans-i",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualising-local-morans-i",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "tmap_mode(\"plot\")\n\ntmap mode set to plotting\n\n  tm_shape(lisa) +\n    tm_fill(\"ii\") +\n    tm_borders(alpha = 0.5) +\n    tm_view(set.zoom.limits = c(6,8)) +\n    tm_layout(\n      main.title = \"local Moran's I of GDPPC\",\n      main.title.size = 2)\n\nVariable(s) \"ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n\n\n\ntmap mode set to plotting\n\n\nVariable(s) \"ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#plotting-lisa-map",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#plotting-lisa-map",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "lisa_sig &lt;- lisa %&gt;%\n  filter(p_ii_sim &lt; 0.05)\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(lisa) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig) +\n  tm_fill(\"mean\") +\n  tm_borders(alpha = 0.4)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\n\n\n\n\n\n\n\nLISA map is a categorical map showing outliers and clusters. there are two types of outliers namely: High-Low and Low-High outliers. Likewise, there are two types of clusters namely: High-High and Low-Low clusters. In fact, LISA map is an interpreted map by combining local Moran’s I of geographical areas and their respective p-values. For instance isolating those below p-value of 0.05."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#hot-spot-and-cold-spot-area-analysis-hcsa",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#hot-spot-and-cold-spot-area-analysis-hcsa",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "HCSA uses spatial weights to identify locations of statistically significant hot spots and cold spots in an spatially weighted attribute that are in proximity to one another based on a calculated distance. The analysis groups features when similar high (hot) or low (cold) values are found in a cluster. The polygon features usually represent administration boundaries or a custom grid structure."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#computing-local-gi-statistics",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#computing-local-gi-statistics",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "we will need to derive a spatial weight matrix before we can compute local Gi* statistics. The code chunk below will be used to derive a spatial weight matrix by using sfdep functions and tidyverse approach.\n\nwm_idw &lt;- hunan_GDPPC %&gt;%\n  mutate(nb = include_self(\n    st_contiguity(geometry)),\n    wts = st_inverse_distance(nb,\n                              geometry,\n                              scale = 1,\n                              alpha = 1),\n          .before = 1)\n\n! Polygon provided. Using point on surface.\n\n\nWarning: There was 1 warning in `stopifnot()`.\nℹ In argument: `wts = st_inverse_distance(nb, geometry, scale = 1, alpha = 1)`.\nCaused by warning in `st_point_on_surface.sfc()`:\n! st_point_on_surface may not give correct results for longitude/latitude data\n\n\n\n\n\nHCSA &lt;- wm_idw %&gt;%\n  mutate(local_Gi = local_gstar_perm(\n    GDPPC, nb, wts, nsim = 99),\n          .before = 1) %&gt;%\n  unnest(local_Gi)\nHCSA\n\nSimple feature collection with 88 features and 18 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n# A tibble: 88 × 19\n    gi_star cluster     e_gi  var_gi std_dev p_value p_sim p_folded_sim skewness\n      &lt;dbl&gt; &lt;fct&gt;      &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n 1  0.261   Low     0.00126  1.07e-7  0.283  7.78e-1  0.66         0.33    0.783\n 2 -0.276   Low     0.000969 4.76e-8 -0.123  9.02e-1  0.98         0.49    0.713\n 3  0.00573 High    0.00156  2.53e-7 -0.0571 9.54e-1  0.78         0.39    0.972\n 4  0.528   High    0.00155  2.97e-7  0.321  7.48e-1  0.56         0.28    0.942\n 5  0.466   High    0.00137  2.76e-7  0.386  7.00e-1  0.52         0.26    1.32 \n 6 -0.445   High    0.000992 7.08e-8 -0.588  5.57e-1  0.68         0.34    0.692\n 7  2.99    High    0.000700 4.05e-8  3.13   1.74e-3  0.04         0.02    0.975\n 8  2.04    High    0.00152  1.58e-7  1.77   7.59e-2  0.16         0.08    1.26 \n 9  4.42    High    0.00130  1.18e-7  4.22   2.39e-5  0.02         0.01    1.20 \n10  1.21    Low     0.00175  1.25e-7  1.49   1.36e-1  0.18         0.09    0.408\n# ℹ 78 more rows\n# ℹ 10 more variables: kurtosis &lt;dbl&gt;, nb &lt;nb&gt;, wts &lt;list&gt;, NAME_2 &lt;chr&gt;,\n#   ID_3 &lt;int&gt;, NAME_3 &lt;chr&gt;, ENGTYPE_3 &lt;chr&gt;, County &lt;chr&gt;, GDPPC &lt;dbl&gt;,\n#   geometry &lt;POLYGON [°]&gt;"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualising-gi",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualising-gi",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "tmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(HCSA) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8))\n\nVariable(s) \"gi_star\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualising-p-value-of-hcsa",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualising-p-value-of-hcsa",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "tmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(HCSA) +\n  tm_fill(\"p_sim\") + \n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\nFor effective comparison, both maps can be plotted next to each other as shown below.\n\n\ntmap mode set to plotting\n\n\nVariable(s) \"gi_star\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#emerging-hotspot",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#emerging-hotspot",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "Plotting the significant (i.e. p-values less than 0.05) hot spot and cold spot areas by using appropriate tmap functions as shown below."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#the-plot-1",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#the-plot-1",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "tmap mode set to plotting\n\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them)."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#the-code-2",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#the-code-2",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "HCSA_sig &lt;- HCSA  %&gt;%\n  filter(p_sim &lt; 0.05)\ntmap_mode(\"plot\")\ntm_shape(HCSA) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(HCSA_sig) +\n  tm_fill(\"cluster\") + \n  tm_borders(alpha = 0.4)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#observations",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#observations",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "The plot reveals that there is one hot spot area and two cold spot areas. Interestingly, the hot spot areas coincide with the High-high cluster identifies by using local Moran’s I method in the earlier sub-section."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "title": "Hands-on Exercise 6: Geographic Segmentation with Spatially Constrained Cluster Analysis",
    "section": "",
    "text": "In this hands-on exercise, the outcome is to gain hands-on experience on how to delineate homogeneous region by using geographically referenced multivariate data. There are two major analysis, namely:\n\nhierarchical cluster analysis; and\nspatially constrained cluster analysis.\n\n\n\nThe outcomes for this hands-on exercise are as follows:\n\nto convert GIS polygon data into R’s simple feature data.frame by using appropriate functions of sf package of R;\nto convert simple feature data.frame into R’s SpatialPolygonDataFrame object by using appropriate sf of package of R;\nto perform cluster analysis by using hclust() of Base R;\nto perform spatially constrained cluster analysis using skater() of Base R; and\nto visualise the analysis output by using ggplot2 and tmap package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#overview",
    "title": "Hands-on Exercise 6: Geographic Segmentation with Spatially Constrained Cluster Analysis",
    "section": "",
    "text": "In this hands-on exercise, the outcome is to gain hands-on experience on how to delineate homogeneous region by using geographically referenced multivariate data. There are two major analysis, namely:\n\nhierarchical cluster analysis; and\nspatially constrained cluster analysis.\n\n\n\nThe outcomes for this hands-on exercise are as follows:\n\nto convert GIS polygon data into R’s simple feature data.frame by using appropriate functions of sf package of R;\nto convert simple feature data.frame into R’s SpatialPolygonDataFrame object by using appropriate sf of package of R;\nto perform cluster analysis by using hclust() of Base R;\nto perform spatially constrained cluster analysis using skater() of Base R; and\nto visualise the analysis output by using ggplot2 and tmap package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#getting-started",
    "title": "Hands-on Exercise 6: Geographic Segmentation with Spatially Constrained Cluster Analysis",
    "section": "2 Getting Started",
    "text": "2 Getting Started\n\n2.1 The analytical question\nIn geobusiness and spatial policy, it is a common practice to delineate the market or planning area into homogeneous regions by using multivariate data. In this hands-on exercise, we are interested to delineate Shan State, Myanmar into homogeneous regions by using multiple Information and Communication technology (ICT) measures, namely: Radio, Television, Land line phone, Mobile phone, Computer, and Internet at home."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#the-data",
    "title": "Hands-on Exercise 6: Geographic Segmentation with Spatially Constrained Cluster Analysis",
    "section": "3 The data",
    "text": "3 The data\nTwo data sets will be used in this study. They are:\n\nMyanmar Township Boundary Data (i.e. myanmar_township_boundaries) : This is a GIS data in ESRI shapefile format. It consists of township boundary information of Myanmar. The spatial data are captured in polygon features.\nShan-ICT.csv: This is an extract of The 2014 Myanmar Population and Housing Census Myanmar at the township level.\n\nBoth data sets are downloaded from Myanmar Information Management Unit (MIMU)\n\n3.1 Installing and loading R packages\nBefore we get started, it is important for us to install the necessary R packages into R and launch these R packages into the R environment.\nThe R packages needed for carrying out specific functions for this exercise are as follows:\n\nSpatial data handling\n\nsf, rgdal and spdep\n\nAttribute data handling\n\ntidyverse, especially readr, ggplot2 and dplyr\n\nChoropleth mapping\n\ntmap\n\nMultivariate data visualisation and analysis\n\ncoorplot, ggpubr, and heatmaply\n\nCluster analysis\n\ncluster\nClustGeo\n\n\nThe code chunk below loads and launches these R packages into R environment.\n\npacman::p_load(sf, spdep, tmap, tidyverse, ClustGeo,\n               cluster, factoextra, NbClust, heatmaply,\n               corrplot, psych, GGally, ggpubr)\n\n\n\n\n\n\n\nNote:\n\n\n\nWith tidyverse, we do not have to install readr, ggplot2 and dplyr packages separately. In fact, tidyverse also installs other very useful R packages such as tidyr."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#data-import-and-prepatation",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#data-import-and-prepatation",
    "title": "Hands-on Exercise 6: Geographic Segmentation with Spatially Constrained Cluster Analysis",
    "section": "4 Data Import and Prepatation",
    "text": "4 Data Import and Prepatation\n\n4.1 Importing geospatial data into R environment\nIn this section, we will import Myanmar Township Boundary GIS data and its associated attribute table into R environment.\nThe Myanmar Township Boundary GIS data is in ESRI shapefile format. It will be imported into R environment by using the st_read() function of sf.\nThe code chunk used is shown below:\n\nshan_sf &lt;- st_read(dsn = \"data/geospatial\",\n                   layer = \"myanmar_township_boundaries\") %&gt;%\n  filter(ST %in% c(\"Shan (East)\", \"Shan (North)\", \"Shan (South)\")) %&gt;%\n  select(c(2:7))\n\nReading layer `myanmar_township_boundaries' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex06\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 330 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.17275 ymin: 9.671252 xmax: 101.1699 ymax: 28.54554\nGeodetic CRS:  WGS 84\n\n\nThe imported township boundary object is called shan_sf. It is saved in simple feature data.frame format. We can view the content of the newly created shan_sf simple features data.frame by using the code chunk below.\n\nshan_sf\n\nSimple feature collection with 55 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 96.15107 ymin: 19.29932 xmax: 101.1699 ymax: 24.15907\nGeodetic CRS:  WGS 84\nFirst 10 features:\n             ST ST_PCODE       DT   DT_PCODE        TS  TS_PCODE\n1  Shan (North)   MMR015  Mongmit MMR015D008   Mongmit MMR015017\n2  Shan (South)   MMR014 Taunggyi MMR014D001   Pindaya MMR014006\n3  Shan (South)   MMR014 Taunggyi MMR014D001   Ywangan MMR014007\n4  Shan (South)   MMR014 Taunggyi MMR014D001  Pinlaung MMR014009\n5  Shan (North)   MMR015  Mongmit MMR015D008    Mabein MMR015018\n6  Shan (South)   MMR014 Taunggyi MMR014D001     Kalaw MMR014005\n7  Shan (South)   MMR014 Taunggyi MMR014D001     Pekon MMR014010\n8  Shan (South)   MMR014 Taunggyi MMR014D001  Lawksawk MMR014008\n9  Shan (North)   MMR015  Kyaukme MMR015D003 Nawnghkio MMR015013\n10 Shan (North)   MMR015  Kyaukme MMR015D003   Kyaukme MMR015012\n                         geometry\n1  MULTIPOLYGON (((96.96001 23...\n2  MULTIPOLYGON (((96.7731 21....\n3  MULTIPOLYGON (((96.78483 21...\n4  MULTIPOLYGON (((96.49518 20...\n5  MULTIPOLYGON (((96.66306 24...\n6  MULTIPOLYGON (((96.49518 20...\n7  MULTIPOLYGON (((97.14738 19...\n8  MULTIPOLYGON (((96.94981 22...\n9  MULTIPOLYGON (((96.75648 22...\n10 MULTIPOLYGON (((96.95498 22...\n\n\nNotice that sf.data.frame conforms to Hardy Wickham’s tidy framework.\nSince shan_sf is conformed to tidy framework, we can also use glimpse() to reveal the data type of it’s fields.\n\nglimpse(shan_sf)\n\nRows: 55\nColumns: 7\n$ ST       &lt;chr&gt; \"Shan (North)\", \"Shan (South)\", \"Shan (South)\", \"Shan (South)…\n$ ST_PCODE &lt;chr&gt; \"MMR015\", \"MMR014\", \"MMR014\", \"MMR014\", \"MMR015\", \"MMR014\", \"…\n$ DT       &lt;chr&gt; \"Mongmit\", \"Taunggyi\", \"Taunggyi\", \"Taunggyi\", \"Mongmit\", \"Ta…\n$ DT_PCODE &lt;chr&gt; \"MMR015D008\", \"MMR014D001\", \"MMR014D001\", \"MMR014D001\", \"MMR0…\n$ TS       &lt;chr&gt; \"Mongmit\", \"Pindaya\", \"Ywangan\", \"Pinlaung\", \"Mabein\", \"Kalaw…\n$ TS_PCODE &lt;chr&gt; \"MMR015017\", \"MMR014006\", \"MMR014007\", \"MMR014009\", \"MMR01501…\n$ geometry &lt;MULTIPOLYGON [°]&gt; MULTIPOLYGON (((96.96001 23..., MULTIPOLYGON (((…\n\n\n\n\n4.2 Importing aspatial data into R environment\nThe csv file will be imported using read_csv function of readr package.\nThe code chunk used is shown below:\n\nict &lt;- read_csv(\"data/aspatial/Shan-ICT.csv\")\n\nRows: 55 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): District Pcode, District Name, Township Pcode, Township Name\ndbl (7): Total households, Radio, Television, Land line phone, Mobile phone,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nThe imported InfoComm variables are extracted from The 2014 Myanmar Population and Housing Census Myanmar. The attribute data set is called ict. It is saved in R’s * tibble data.frame* format.\nThe code chunk below reveals the summary statistics of the ict data.frame.\n\nsummary(ict)\n\n District Pcode     District Name      Township Pcode     Township Name     \n Length:55          Length:55          Length:55          Length:55         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n Total households     Radio         Television    Land line phone \n Min.   : 3318    Min.   :  115   Min.   :  728   Min.   :  20.0  \n 1st Qu.: 8711    1st Qu.: 1260   1st Qu.: 3744   1st Qu.: 266.5  \n Median :13685    Median : 2497   Median : 6117   Median : 695.0  \n Mean   :18369    Mean   : 4487   Mean   :10183   Mean   : 929.9  \n 3rd Qu.:23471    3rd Qu.: 6192   3rd Qu.:13906   3rd Qu.:1082.5  \n Max.   :82604    Max.   :30176   Max.   :62388   Max.   :6736.0  \n  Mobile phone      Computer      Internet at home\n Min.   :  150   Min.   :  20.0   Min.   :   8.0  \n 1st Qu.: 2037   1st Qu.: 121.0   1st Qu.:  88.0  \n Median : 3559   Median : 244.0   Median : 316.0  \n Mean   : 6470   Mean   : 575.5   Mean   : 760.2  \n 3rd Qu.: 7177   3rd Qu.: 507.0   3rd Qu.: 630.5  \n Max.   :48461   Max.   :6705.0   Max.   :9746.0  \n\n\nThere are a total of eleven fields and 55 observation in the ict tibble data.frame.\n\n\n4.3 Deriving new variables using dplyr package\nThe unit of measurement of the values are number of households. Using these values directly will be bias towards the underlying total number of households. In general, the townships with relatively higher total number of households will also have higher number of households owning radio, TV, etc.\nIn order to overcome this problem, we will derive the penetration rate of each ICT variable by using the code chunk below.\n\nict_derived &lt;- ict %&gt;%\n  mutate(`RADIO_PR` = `Radio`/`Total households` * 1000) %&gt;%\n  mutate(`TV_PR` = `Television`/`Total households` * 1000) %&gt;%\n  mutate(`LLPHONE_PR` = `Land line phone`/`Total households` * 1000) %&gt;%\n  mutate(`MPHONE_PR` = `Mobile phone`/`Total households` * 1000) %&gt;%\n  mutate(`COMPUTER_PR` = `Computer`/`Total households` * 1000) %&gt;%\n  mutate(`INTERNET_PR` = `Internet at home`/`Total households` * 1000) %&gt;%\n  rename(`DT_PCODE` = `District Pcode`, `DT` = `District Name`,\n         `TS_PCODE` = `Township Pcode`, `TS` = `Township Name`,\n         `TT_HOUSEHOLDS` = `Total households`,\n         `RADIO` = `Radio`, `TV` = `Television`,\n         `LLPHONE` = `Land line phone`, `MPHONE` = `Mobile phone`,\n         `COMPUTER` = `Computer`, `INTERNET` = `Internet at home`)\n\nUsing the summary() function to review the summary statistics of the newly derived penetration rates using the code chunk below.\n\nsummary(ict_derived)\n\n   DT_PCODE              DT              TS_PCODE              TS           \n Length:55          Length:55          Length:55          Length:55         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n TT_HOUSEHOLDS       RADIO             TV           LLPHONE      \n Min.   : 3318   Min.   :  115   Min.   :  728   Min.   :  20.0  \n 1st Qu.: 8711   1st Qu.: 1260   1st Qu.: 3744   1st Qu.: 266.5  \n Median :13685   Median : 2497   Median : 6117   Median : 695.0  \n Mean   :18369   Mean   : 4487   Mean   :10183   Mean   : 929.9  \n 3rd Qu.:23471   3rd Qu.: 6192   3rd Qu.:13906   3rd Qu.:1082.5  \n Max.   :82604   Max.   :30176   Max.   :62388   Max.   :6736.0  \n     MPHONE         COMPUTER         INTERNET         RADIO_PR     \n Min.   :  150   Min.   :  20.0   Min.   :   8.0   Min.   : 21.05  \n 1st Qu.: 2037   1st Qu.: 121.0   1st Qu.:  88.0   1st Qu.:138.95  \n Median : 3559   Median : 244.0   Median : 316.0   Median :210.95  \n Mean   : 6470   Mean   : 575.5   Mean   : 760.2   Mean   :215.68  \n 3rd Qu.: 7177   3rd Qu.: 507.0   3rd Qu.: 630.5   3rd Qu.:268.07  \n Max.   :48461   Max.   :6705.0   Max.   :9746.0   Max.   :484.52  \n     TV_PR         LLPHONE_PR       MPHONE_PR       COMPUTER_PR    \n Min.   :116.0   Min.   :  2.78   Min.   : 36.42   Min.   : 3.278  \n 1st Qu.:450.2   1st Qu.: 22.84   1st Qu.:190.14   1st Qu.:11.832  \n Median :517.2   Median : 37.59   Median :305.27   Median :18.970  \n Mean   :509.5   Mean   : 51.09   Mean   :314.05   Mean   :24.393  \n 3rd Qu.:606.4   3rd Qu.: 69.72   3rd Qu.:428.43   3rd Qu.:29.897  \n Max.   :842.5   Max.   :181.49   Max.   :735.43   Max.   :92.402  \n  INTERNET_PR     \n Min.   :  1.041  \n 1st Qu.:  8.617  \n Median : 22.829  \n Mean   : 30.644  \n 3rd Qu.: 41.281  \n Max.   :117.985  \n\n\n\n\n\n\n\n\nNote\n\n\n\nNotice that six new fields have been added into the data.frame. They are RADIO_PR, TV_PR, LLPHONE_PR, MPHONE_PR, COMPUTER_PR, and INTERNET_PR. Additionally the initial observations of Radio, Television, Land line phone, Mobile phone, Computer and Internet at home have been converted to uppercase and some are also renamed to match the naming convention of the new fields."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#exploratory-data-analysis-eda",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#exploratory-data-analysis-eda",
    "title": "Hands-on Exercise 6: Geographic Segmentation with Spatially Constrained Cluster Analysis",
    "section": "5 Exploratory Data Analysis (EDA)",
    "text": "5 Exploratory Data Analysis (EDA)\n\n5.1 EDA using statistical graphics\nExploratory Data Analysis (EDA) will now be performed by plotting the distribution of the variables (i.e. Number of households with radio) by using appropriate EDA as shown in the code chunk below.\nA histogram is useful to identify the overall distribution of the data values (i.e. left skewed, right skewed or a normal distribution)\n\nggplot(data = ict_derived,\n       aes(x = `RADIO`)) +\n  geom_histogram(bins = 20,\n                 color = \"black\",\n                 fill = \"light blue\")\n\n\n\n\n\n\n\n\nA boxplot is used to detect for outliers\n\nggplot(data = ict_derived,\n       aes(x = `RADIO`)) +\n  geom_boxplot(color = \"black\",\n               fill = \"light blue\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBased on the distributions revealed in the histogram and boxplot for RADIO\n\n\n\n\nHistogram: The distribution of the RADIO variable is highly skewed to the left, with a large number of observations concentrated near the lower end (close to zero). This suggests that most values for RADIO are relatively small, with only a few larger values.\nBoxplot: The boxplot confirms the presence of a few significant outliers on the right side (positive direction), indicating a small number of very high RADIO values. The majority of the data is clustered close to zero, with the median being close to the lower end of the scale. There are several outliers between 10,000 and 30,000, showing a long tail.\n\n\n\nNext, the distribution of the newly derived variables (i.e. Radio penetration rate) will be plotted by using the code chunk below. Similarly, they will be plotted as a histogram and boxplot to observe for skewness and outliers.\n\nggplot(data = ict_derived,\n       aes(x = `RADIO_PR`)) +\n  geom_histogram(bins = 20,\n                 color = \"black\",\n                 fill = \"salmon\")\n\n\n\n\n\n\n\n\n\nggplot(data = ict_derived,\n       aes(x = `RADIO_PR`)) +\n  geom_boxplot(color = \"black\",\n               fill = \"salmon\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nBased on the distributions revealed in the histogram and boxplot forRADIO_PR\n\nHistogram: The RADIO_PR variable exhibits a more symmetric distribution, though it appears slightly skewed to the left. The data seems to be more evenly spread out compared to the RADIO variable, with no extreme spikes at the lower end.\nBoxplot: The boxplot for RADIO_PR suggests a more balanced distribution without significant outliers, except for one potential outlier near the upper bound (around 500). The interquartile range (IQR) appears wider, indicating that the middle 50% of the data is more dispersed compared to the RADIO variable.\n\n\n\nMultiple histograms are plotted in the figure below to reveal the distribution of the selected variables in the ict_derived data.frame.\nThe code chunks below are used to create the data visualisation. They consist of two main parts. First, the individual histograms will be created using the code chunks below.\n\nradio &lt;- ggplot(data = ict_derived,\n                aes(x = `RADIO_PR`)) +\n  geom_histogram(bins = 20,\n                 color = \"black\",\n                 fill = \"light blue\")\n\n\ntv &lt;- ggplot(data = ict_derived,\n                aes(x = `TV_PR`)) +\n  geom_histogram(bins = 20,\n                 color = \"black\",\n                 fill = \"light blue\")\n\n\nllphone &lt;- ggplot(data = ict_derived,\n                aes(x = `LLPHONE_PR`)) +\n  geom_histogram(bins = 20,\n                 color = \"black\",\n                 fill = \"light blue\")\n\n\nmphone &lt;- ggplot(data = ict_derived,\n                aes(x = `MPHONE_PR`)) +\n  geom_histogram(bins = 20,\n                 color = \"black\",\n                 fill = \"light blue\")\n\n\ncomputer &lt;- ggplot(data = ict_derived,\n                aes(x = `COMPUTER_PR`)) +\n  geom_histogram(bins = 20,\n                 color = \"black\",\n                 fill = \"light blue\")\n\n\ninternet &lt;- ggplot(data = ict_derived,\n                aes(x = `INTERNET_PR`)) +\n  geom_histogram(bins = 20,\n                 color = \"black\",\n                 fill = \"light blue\")\n\nNext, the ggarrange() function of ggpubr package is used to group these histograms together.\n\nggarrange(radio, tv, llphone, mphone, computer, internet,\n          ncol = 3,\n          nrow = 2)\n\n\n\n\n\n\n\n\n\n\n5.2 EDA using choropleth map\n\n5.2.1 Joining geospatial data with aspatial data\nBefore the choropleth map can be prepared, we first need to combine both the geospatial data object (i.e. shan_sf) and aspatial data.frame object (i.e. ict_derived) into one. This will be performed by using the left_join function of dplyr package.\nThe shan_sf simple feature data.frame will be used as the base data object and the ict_derived data.frame will be used as the join table.\n\nThe code chunk below is used to perform the task. The unique identifier used to join both data objects is TS_PCODE.\n\nshan_sf &lt;- left_join(shan_sf,\n                      ict_derived, by = c(\"TS_PCODE\" = \"TS_PCODE\"))\n\nwrite_rds(shan_sf, \"data/rds/shan_sf.rds\")\n\n\nThe code chunk above shows that TS_PCODE field is the common field used to perform the left-join.\n\nIt is important to note that there is no new output data being created. Instead, the data fields from ict_derived data frame are now updated into the data frame of shan_sf.\n\nshan_sf &lt;- read_rds(\"data/rds/shan_sf.rds\")\n\n\n\n5.2.2 Plotting the choropleth map\nTo have a quick look at the distribution of Radio penetration rate of Shan State at the township level, a choropleth map will be prepared.\nThe code chunks below are used to prepare the choropleth map by using the qtm() function of tmap package.\n\nqtm(shan_sf, \"RADIO_PR\")\n\n\n\n\n\n\n\n\nThe choropleth map for the other variables of TV_PR, LLPHONE_PR, MPHONE_PR, COMPUTER_PR, INTERNET_PR are also plotted to have a quick sense of their penetration rates.\n\nRADIOLAND LINE PHONEMOBILE PHONECOMPUTERINTERNET AT HOME\n\n\n\nqtm(shan_sf, \"TV_PR\")\n\n\n\n\n\n\n\n\n\n\n\nqtm(shan_sf, \"LLPHONE_PR\")\n\n\n\n\n\n\n\n\n\n\n\nqtm(shan_sf, \"MPHONE_PR\")\n\n\n\n\n\n\n\n\n\n\n\nqtm(shan_sf, \"COMPUTER_PR\")\n\n\n\n\n\n\n\n\n\n\n\nqtm(shan_sf, \"INTERNET_PR\")\n\n\n\n\n\n\n\n\n\n\n\nIn order to reveal that the distributions shown in the choropleth map above are bias to the underlying total number of households at the townships, we will create two choropleth maps. One for the total number of households (i.e. TT_HOUSEHOLDS.map) and one for the total number of household with Radio (RADIO.map) by using the code chunk below.\n\nTT_HOUSEHOLDS.map &lt;- tm_shape(shan_sf) +\n  tm_fill(col = \"TT_HOUSEHOLDS\",\n          n = 5,\n          style = \"jenks\",\n          title = \"Total Households\") +\n  tm_borders(alpha = 0.5)\n\nRADIO.map &lt;- tm_shape(shan_sf) +\n  tm_fill(col = \"RADIO\",\n          n = 5,\n          style = \"jenks\",\n          title = \"Number of Households\\nwith Radio\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(TT_HOUSEHOLDS.map, RADIO.map,\n             asp = NA, ncol = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNotice that the choropleth maps above clearly show that townships with relatively larger number households are also showing relatively higher number of radio ownership.\n\n\n Now let us plot the choropleth maps showing the distribution of total number of households and Radio penetration rate by using the code chunk below.\n\ntm_shape(shan_sf) +\n  tm_polygons(c(\"TT_HOUSEHOLDS\", \"RADIO_PR\"),\n              style = \"jenks\") +\n  tm_facets(sync = TRUE, ncol = 2) +\n tm_legend(legend.position = c(\"right\", \"bottom\")) +\n tm_layout(outer.margins = 0, asp = 0)\n\n\n\n\n\n\n\n\n\n\nFor the first choropleth map: Absolute numbers of households with radios are shown, leading to a biased view, as regions with more households naturally show higher radio ownership.\n\nFor the second choropleth map: Adjusted for the number of households, offering a better representation of radio ownership density. This allows for a clearer comparison of radio access independent of total household counts and better highlights areas with either strong or weak relative radio penetration."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#correlation-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#correlation-analysis",
    "title": "Hands-on Exercise 6: Geographic Segmentation with Spatially Constrained Cluster Analysis",
    "section": "6 Correlation Analysis",
    "text": "6 Correlation Analysis\nBefore performing cluster analysis, it is important for us to ensure that the cluster variables are not highly correlated.\nIn this section, we will learn how to use corrplot.mixed() function of corrplot package to visualise and analyse the correlation of the input variables.\n\ncluster_vars.cor = cor(ict_derived[,12:17])\ncorrplot.mixed(cluster_vars.cor,\n         lower = \"ellipse\",\n         upper = \"number\",\n         tl.pos = \"lt\",\n         diag = \"l\",\n         tl.col = \"black\")\n\n\n\n\n\n\n\n\nFrom the correlation plot above, it shows that COMPUTER_PR and INTERNET_PR are highly correlated. This suggests that only one of them should be used in the cluster analysis instead of both."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#hierarchy-cluster-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#hierarchy-cluster-analysis",
    "title": "Hands-on Exercise 6: Geographic Segmentation with Spatially Constrained Cluster Analysis",
    "section": "7 Hierarchy Cluster Analysis",
    "text": "7 Hierarchy Cluster Analysis\nIn this section, hierarchical cluster analysis will be performed. The analysis consists of four major steps:\n\nExtracting Clustering Variables\nData Standardisation\nMin-Max standardisation\nZ-score standardisation\n\n\n7.1 Extracting clustering variables\nThe code chunk below will be used to extract the clustering variables from the shan_sf simple feature object into a data.frame.\n\ncluster_vars &lt;- shan_sf %&gt;%\n  st_set_geometry(NULL) %&gt;%\n  select(\"TS.x\", \"RADIO_PR\", \"TV_PR\", \"LLPHONE_PR\", \"MPHONE_PR\", \"COMPUTER_PR\")\nhead(cluster_vars, 10) \n\n        TS.x RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\n1    Mongmit 286.1852 554.1313   35.30618  260.6944    12.15939\n2    Pindaya 417.4647 505.1300   19.83584  162.3917    12.88190\n3    Ywangan 484.5215 260.5734   11.93591  120.2856     4.41465\n4   Pinlaung 231.6499 541.7189   28.54454  249.4903    13.76255\n5     Mabein 449.4903 708.6423   72.75255  392.6089    16.45042\n6      Kalaw 280.7624 611.6204   42.06478  408.7951    29.63160\n7      Pekon 318.6118 535.8494   39.83270  214.8476    18.97032\n8   Lawksawk 387.1017 630.0035   31.51366  320.5686    21.76677\n9  Nawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\n10   Kyaukme 210.9548 601.1773   39.58267  372.4930    30.94709\n\n\n\n\n\n\n\n\nNote\n\n\n\nNotice that the final clustering variables list does not include INTERNET_PR because it is highly correlated with variable COMPUTER_PR.\n\n\nNext, to change the rows by township name instead of row number by using the code chunk below:\n\nrow.names(cluster_vars) &lt;- cluster_vars$\"TS.x\"\nhead(cluster_vars, 10)\n\n               TS.x RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\nMongmit     Mongmit 286.1852 554.1313   35.30618  260.6944    12.15939\nPindaya     Pindaya 417.4647 505.1300   19.83584  162.3917    12.88190\nYwangan     Ywangan 484.5215 260.5734   11.93591  120.2856     4.41465\nPinlaung   Pinlaung 231.6499 541.7189   28.54454  249.4903    13.76255\nMabein       Mabein 449.4903 708.6423   72.75255  392.6089    16.45042\nKalaw         Kalaw 280.7624 611.6204   42.06478  408.7951    29.63160\nPekon         Pekon 318.6118 535.8494   39.83270  214.8476    18.97032\nLawksawk   Lawksawk 387.1017 630.0035   31.51366  320.5686    21.76677\nNawnghkio Nawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\nKyaukme     Kyaukme 210.9548 601.1773   39.58267  372.4930    30.94709\n\n\n\n\n\n\n\n\nNote\n\n\n\nNotice that the row number has been replaced into the township name.\n\n\nThe TS.x field will be deleted by using the code chunk below.\n\nshan_ict &lt;- select(cluster_vars, c(2:6))\nhead(shan_ict, 10)\n\n          RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\nMongmit   286.1852 554.1313   35.30618  260.6944    12.15939\nPindaya   417.4647 505.1300   19.83584  162.3917    12.88190\nYwangan   484.5215 260.5734   11.93591  120.2856     4.41465\nPinlaung  231.6499 541.7189   28.54454  249.4903    13.76255\nMabein    449.4903 708.6423   72.75255  392.6089    16.45042\nKalaw     280.7624 611.6204   42.06478  408.7951    29.63160\nPekon     318.6118 535.8494   39.83270  214.8476    18.97032\nLawksawk  387.1017 630.0035   31.51366  320.5686    21.76677\nNawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\nKyaukme   210.9548 601.1773   39.58267  372.4930    30.94709\n\n\n\n\n7.2 Data Standardisation\nIn general, multiple variables will be used in cluster analysis. Hence, it will not be unusual for their values range to be different. In order to avoid the cluster analysis result being biased to clustering variables with large values, it is useful to standardise the input variables before performing cluster analysis.\n\n\n7.3 Min-Max standardisation\nIn the code chunk below, normalize() of heatmaply package is used to standardisation to the clustering variables by using Min-Max method. The summary() is then used to display the summary statistics of the standardised clustering variables.\n\nshan_ict.std &lt;- normalize(shan_ict)\nsummary(shan_ict.std)\n\n    RADIO_PR          TV_PR          LLPHONE_PR       MPHONE_PR     \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.2544   1st Qu.:0.4600   1st Qu.:0.1123   1st Qu.:0.2199  \n Median :0.4097   Median :0.5523   Median :0.1948   Median :0.3846  \n Mean   :0.4199   Mean   :0.5416   Mean   :0.2703   Mean   :0.3972  \n 3rd Qu.:0.5330   3rd Qu.:0.6750   3rd Qu.:0.3746   3rd Qu.:0.5608  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n  COMPUTER_PR     \n Min.   :0.00000  \n 1st Qu.:0.09598  \n Median :0.17607  \n Mean   :0.23692  \n 3rd Qu.:0.29868  \n Max.   :1.00000  \n\n\n\nNotice that the values range of the Min-max standardised clustering variables are 0-1 now.\n\n\n\n7.4 Z-score standardisation\nZ-score standardisation can be performed easily by using scale() of Base R. The code chunk below will be used to standardise the clustering variables by using Z-score method.\n\nshan_ict.z &lt;- scale(shan_ict)\ndescribe(shan_ict.z)\n\n            vars  n mean sd median trimmed  mad   min  max range  skew kurtosis\nRADIO_PR       1 55    0  1  -0.04   -0.06 0.94 -1.85 2.55  4.40  0.48    -0.27\nTV_PR          2 55    0  1   0.05    0.04 0.78 -2.47 2.09  4.56 -0.38    -0.23\nLLPHONE_PR     3 55    0  1  -0.33   -0.15 0.68 -1.19 3.20  4.39  1.37     1.49\nMPHONE_PR      4 55    0  1  -0.05   -0.06 1.01 -1.58 2.40  3.98  0.48    -0.34\nCOMPUTER_PR    5 55    0  1  -0.26   -0.18 0.64 -1.03 3.31  4.34  1.80     2.96\n              se\nRADIO_PR    0.13\nTV_PR       0.13\nLLPHONE_PR  0.13\nMPHONE_PR   0.13\nCOMPUTER_PR 0.13\n\n\nNotice that the mean and standard deviation of the Z-score standardised clustering variables are 0 and 1 respectively.\nNote: describe() of psych package is used here instead of summary() of Base R because the formal provides standard deviation.\n\n\n\n\n\n\nWarning\n\n\n\nZ-score standardisation method should only be used if we would assume all variables come from normal distribution.\n\n\n\n\n7.5 Visualising the standardised clustering variables\n\n7.5.1 Histograms\nBesides reviewing the summary statistics of the standardised clustering variables, it is also a good practice to visualise their distribution graphically.\nThe code chunk below plots the scaled Radio_PR field.\n\nr &lt;- ggplot(data = ict_derived,\n            aes(x = `RADIO_PR`)) +\n  geom_histogram(bins = 20,\n                 color = \"black\",\n                 fill = \"light blue\") +\n  ggtitle(\"Raw values without Standardisation\")\n\nshan_ict_std_df &lt;- as.data.frame(shan_ict.std)\ns &lt;- ggplot(data = shan_ict_std_df,\n            aes(x = `RADIO_PR`)) +\n  geom_histogram(bins = 20,\n                 color = \"black\",\n                 fill = \"light blue\") +\n  ggtitle(\"Min-Max Standardisation\")\n\nshan_ict_z_df &lt;- as.data.frame(shan_ict.z)\nz &lt;- ggplot(data = shan_ict_z_df,\n            aes(x = `RADIO_PR`)) +\n  geom_histogram(bins = 20,\n                 color = \"black\",\n                 fill = \"light blue\") +\n  ggtitle(\"Z - Score Standardisation\")\n\nggarrange(r, s, z,\n          ncol = 3, nrow = 1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStatistical Conclusions\n\n\n\n\nThe overall distribution of RADIO_PR without standardisation is slightly left-skewed across all standardization methods, which suggests that more townships have a low to moderate number of radios per household, but there are some with very high values.\nMin-Max Standardization compresses the data into a fixed range, which is useful when comparing different variables on the same scale. However, it does not change the distribution’s shape or provide information about variability in terms of standard deviations.\nZ-Score Standardization provides a clearer understanding of the spread and the concentration of values around the mean, especially in terms of standard deviations. This can help in identifying extreme values or outliers more effectively.\n\n\n\n\n\n7.5.2 Geom Density Plots\n\nr &lt;- ggplot(data = ict_derived,\n            aes(x = `RADIO_PR`)) +\n  geom_density(bins = 20,\n                 color = \"black\",\n                 fill = \"salmon\") +\n  ggtitle(\"Raw values without Standardisation\")\n\nWarning in geom_density(bins = 20, color = \"black\", fill = \"salmon\"): Ignoring\nunknown parameters: `bins`\n\nshan_ict_std_df &lt;- as.data.frame(shan_ict.std)\ns &lt;- ggplot(data = shan_ict_std_df,\n            aes(x = `RADIO_PR`)) +\n  geom_density(bins = 20,\n                 color = \"black\",\n                 fill = \"salmon\") +\n  ggtitle(\"Min-Max Standardisation\")\n\nWarning in geom_density(bins = 20, color = \"black\", fill = \"salmon\"): Ignoring\nunknown parameters: `bins`\n\nshan_ict_z_df &lt;- as.data.frame(shan_ict.z)\nz &lt;- ggplot(data = shan_ict_z_df,\n            aes(x = `RADIO_PR`)) +\n  geom_density(bins = 20,\n                 color = \"black\",\n                 fill = \"salmon\") +\n  ggtitle(\"Z - Score Standardisation\")\n\nWarning in geom_density(bins = 20, color = \"black\", fill = \"salmon\"): Ignoring\nunknown parameters: `bins`\n\nggarrange(r, s, z,\n          ncol = 3, nrow = 1)\n\n\n\n\n\n\n\n\n\n\n\n7.6 Computing proximity matrix\nIn R, many packages provide functions to calculate distance matrix. In this section the proximity matrix will be computed by using dist() of R.\ndist() supports six distance proximity calculations, they are: euclidean, maximum, manhattan, canberra, binary and minkowski. The default is euclidean proximity matrix.\nThe code chunk below is used to compute the proximity matrix using euclidean method.\n\nproxmat &lt;- dist(shan_ict, method = \"euclidean\")\n\nThe code chunk below is used to list the content of proxmat for visual inspection.\n\nproxmat\n\n             Mongmit   Pindaya   Ywangan  Pinlaung    Mabein     Kalaw\nPindaya    171.86828                                                  \nYwangan    381.88259 257.31610                                        \nPinlaung    57.46286 208.63519 400.05492                              \nMabein     263.37099 313.45776 529.14689 312.66966                    \nKalaw      160.05997 302.51785 499.53297 181.96406 198.14085          \nPekon       59.61977 117.91580 336.50410  94.61225 282.26877 211.91531\nLawksawk   140.11550 204.32952 432.16535 192.57320 130.36525 140.01101\nNawnghkio   89.07103 180.64047 377.87702 139.27495 204.63154 127.74787\nKyaukme    144.02475 311.01487 505.89191 139.67966 264.88283  79.42225\nMuse       563.01629 704.11252 899.44137 571.58335 453.27410 412.46033\nLaihka     141.87227 298.61288 491.83321 101.10150 345.00222 197.34633\nMongnai    115.86190 258.49346 422.71934  64.52387 358.86053 200.34668\nMawkmai    434.92968 437.99577 397.03752 398.11227 693.24602 562.59200\nKutkai      97.61092 212.81775 360.11861  78.07733 340.55064 204.93018\nMongton    192.67961 283.35574 361.23257 163.42143 425.16902 267.87522\nMongyai    256.72744 287.41816 333.12853 220.56339 516.40426 386.74701\nMongkaing  503.61965 481.71125 364.98429 476.29056 747.17454 625.24500\nLashio     251.29457 398.98167 602.17475 262.51735 231.28227 106.69059\nMongpan    193.32063 335.72896 483.68125 192.78316 301.52942 114.69105\nMatman     401.25041 354.39039 255.22031 382.40610 637.53975 537.63884\nTachileik  529.63213 635.51774 807.44220 555.01039 365.32538 373.64459\nNarphan    406.15714 474.50209 452.95769 371.26895 630.34312 463.53759\nMongkhet   349.45980 391.74783 408.97731 305.86058 610.30557 465.52013\nHsipaw     118.18050 245.98884 388.63147  76.55260 366.42787 212.36711\nMonghsat   214.20854 314.71506 432.98028 160.44703 470.48135 317.96188\nMongmao    242.54541 402.21719 542.85957 217.58854 384.91867 195.18913\nNansang    104.91839 275.44246 472.77637  85.49572 287.92364 124.30500\nLaukkaing  568.27732 726.85355 908.82520 563.81750 520.67373 427.77791\nPangsang   272.67383 428.24958 556.82263 244.47146 418.54016 224.03998\nNamtu      179.62251 225.40822 444.66868 170.04533 366.16094 307.27427\nMonghpyak  177.76325 221.30579 367.44835 222.20020 212.69450 167.08436\nKonkyan    403.39082 500.86933 528.12533 365.44693 613.51206 444.75859\nMongping   265.12574 310.64850 337.94020 229.75261 518.16310 375.64739\nHopong     136.93111 223.06050 352.85844  98.14855 398.00917 264.16294\nNyaungshwe  99.38590 216.52463 407.11649 138.12050 210.21337  95.66782\nHsihseng   131.49728 172.00796 342.91035 111.61846 381.20187 287.11074\nMongla     384.30076 549.42389 728.16301 372.59678 406.09124 260.26411\nHseni      189.37188 337.98982 534.44679 204.47572 213.61240  38.52842\nKunlong    224.12169 355.47066 531.63089 194.76257 396.61508 273.01375\nHopang     281.05362 443.26362 596.19312 265.96924 368.55167 185.14704\nNamhkan    386.02794 543.81859 714.43173 382.78835 379.56035 246.39577\nKengtung   246.45691 385.68322 573.23173 263.48638 219.47071  88.29335\nLangkho    164.26299 323.28133 507.78892 168.44228 253.84371  67.19580\nMonghsu    109.15790 198.35391 340.42789  80.86834 367.19820 237.34578\nTaunggyi   399.84278 503.75471 697.98323 429.54386 226.24011 252.26066\nPangwaun   381.51246 512.13162 580.13146 356.37963 523.44632 338.35194\nKyethi     202.92551 175.54012 287.29358 189.47065 442.07679 360.17247\nLoilen     145.48666 293.61143 469.51621  91.56527 375.06406 217.19877\nManton     430.64070 402.42888 306.16379 405.83081 674.01120 560.16577\nMongyang   309.51302 475.93982 630.71590 286.03834 411.88352 233.56349\nKunhing    173.50424 318.23811 449.67218 141.58836 375.82140 197.63683\nMongyawng  214.21738 332.92193 570.56521 235.55497 193.49994 173.43078\nTangyan    195.92520 208.43740 324.77002 169.50567 448.59948 348.06617\nNamhsan    237.78494 228.41073 286.16305 214.33352 488.33873 385.88676\n               Pekon  Lawksawk Nawnghkio   Kyaukme      Muse    Laihka\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk   157.51129                                                  \nNawnghkio  113.15370  90.82891                                        \nKyaukme    202.12206 186.29066 157.04230                              \nMuse       614.56144 510.13288 533.68806 434.75768                    \nLaihka     182.23667 246.74469 211.88187 128.24979 526.65211          \nMongnai    151.60031 241.71260 182.21245 142.45669 571.97975 100.53457\nMawkmai    416.00669 567.52693 495.15047 512.02846 926.93007 429.96554\nKutkai     114.98048 224.64646 147.44053 170.93318 592.90743 144.67198\nMongton    208.14888 311.07742 225.81118 229.28509 634.71074 212.07320\nMongyai    242.52301 391.26989 319.57938 339.27780 763.91399 264.13364\nMongkaing  480.23965 625.18712 546.69447 586.05094 995.66496 522.96309\nLashio     303.80011 220.75270 230.55346 129.95255 313.15288 238.64533\nMongpan    243.30037 228.54223 172.84425 110.37831 447.49969 210.76951\nMatman     368.25761 515.39711 444.05061 505.52285 929.11283 443.25453\nTachileik  573.39528 441.82621 470.45533 429.15493 221.19950 549.08985\nNarphan    416.84901 523.69580 435.59661 420.30003 770.40234 392.32592\nMongkhet   342.08722 487.41102 414.10280 409.03553 816.44931 324.97428\nHsipaw     145.37542 249.35081 176.09570 163.95741 591.03355 128.42987\nMonghsat   225.64279 352.31496 289.83220 253.25370 663.76026 158.93517\nMongmao    293.70625 314.64777 257.76465 146.09228 451.82530 185.99082\nNansang    160.37607 188.78869 151.13185  60.32773 489.35308  78.78999\nLaukkaing  624.82399 548.83928 552.65554 428.74978 149.26996 507.39700\nPangsang   321.81214 345.91486 287.10769 175.35273 460.24292 214.19291\nNamtu      165.02707 260.95300 257.52713 270.87277 659.16927 185.86794\nMonghpyak  190.93173 142.31691  93.03711 217.64419 539.43485 293.22640\nKonkyan    421.48797 520.31264 439.34272 393.79911 704.86973 351.75354\nMongping   259.68288 396.47081 316.14719 330.28984 744.44948 272.82761\nHopong     138.86577 274.91604 204.88286 218.84211 648.68011 157.48857\nNyaungshwe 139.31874 104.17830  43.26545 126.50414 505.88581 201.71653\nHsihseng   105.30573 257.11202 209.88026 250.27059 677.66886 175.89761\nMongla     441.20998 393.18472 381.40808 241.58966 256.80556 315.93218\nHseni      243.98001 171.50398 164.05304  81.20593 381.30567 204.49010\nKunlong    249.36301 318.30406 285.04608 215.63037 547.24297 122.68682\nHopang     336.38582 321.16462 279.84188 154.91633 377.44407 230.78652\nNamhkan    442.77120 379.41126 367.33575 247.81990 238.67060 342.43665\nKengtung   297.67761 209.38215 208.29647 136.23356 330.08211 258.23950\nLangkho    219.21623 190.30257 156.51662  51.67279 413.64173 160.94435\nMonghsu    113.84636 242.04063 170.09168 200.77712 633.21624 163.28926\nTaunggyi   440.66133 304.96838 344.79200 312.60547 250.81471 425.36916\nPangwaun   423.81347 453.02765 381.67478 308.31407 541.97887 351.78203\nKyethi     162.43575 317.74604 267.21607 328.14177 757.16745 255.83275\nLoilen     181.94596 265.29318 219.26405 146.92675 560.43400  59.69478\nManton     403.82131 551.13000 475.77296 522.86003 941.49778 458.30232\nMongyang   363.58788 363.37684 323.32123 188.59489 389.59919 229.71502\nKunhing    213.46379 278.68953 206.15773 145.00266 533.00162 142.03682\nMongyawng  248.43910 179.07229 220.61209 181.55295 422.37358 211.99976\nTangyan    167.79937 323.14701 269.07880 306.78359 736.93741 224.29176\nNamhsan    207.16559 362.84062 299.74967 347.85944 778.52971 273.79672\n             Mongnai   Mawkmai    Kutkai   Mongton   Mongyai Mongkaing\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai    374.50873                                                  \nKutkai      91.15307 364.95519                                        \nMongton    131.67061 313.35220 107.06341                              \nMongyai    203.23607 178.70499 188.94166 159.79790                    \nMongkaing  456.00842 133.29995 428.96133 365.50032 262.84016          \nLashio     270.86983 638.60773 289.82513 347.11584 466.36472 708.65819\nMongpan    178.09554 509.99632 185.18173 200.31803 346.39710 563.56780\nMatman     376.33870 147.83545 340.86349 303.04574 186.95158 135.51424\nTachileik  563.95232 919.38755 568.99109 608.76740 750.29555 967.14087\nNarphan    329.31700 273.75350 314.27683 215.97925 248.82845 285.65085\nMongkhet   275.76855 115.58388 273.91673 223.22828 104.98924 222.60577\nHsipaw      52.68195 351.34601  51.46282  90.69766 177.33790 423.77868\nMonghsat   125.25968 275.09705 154.32012 150.98053 127.35225 375.60376\nMongmao    188.29603 485.52853 204.69232 206.57001 335.61300 552.31959\nNansang     92.79567 462.41938 130.04549 199.58124 288.55962 542.16609\nLaukkaing  551.56800 882.51110 580.38112 604.66190 732.68347 954.11795\nPangsang   204.25746 484.14757 228.33583 210.77938 343.30638 548.40662\nNamtu      209.35473 427.95451 225.28268 308.71751 278.02761 525.04057\nMonghpyak  253.26470 536.71695 206.61627 258.04282 370.01575 568.21089\nKonkyan    328.82831 339.01411 310.60810 248.25265 287.87384 380.92091\nMongping   202.99615 194.31049 182.75266 119.86993  65.38727 257.18572\nHopong      91.53795 302.84362  73.45899 106.21031 124.62791 379.37916\nNyaungshwe 169.63695 502.99026 152.15482 219.72196 327.13541 557.32112\nHsihseng   142.36728 329.29477 128.21054 194.64317 162.27126 411.59788\nMongla     354.10985 686.88950 388.40984 411.06668 535.28615 761.48327\nHseni      216.81639 582.53670 229.37894 286.75945 408.23212 648.04408\nKunlong    202.92529 446.53763 204.54010 270.02165 299.36066 539.91284\nHopang     243.00945 561.24281 263.31986 273.50305 408.73288 626.17673\nNamhkan    370.05669 706.47792 392.48568 414.53594 550.62819 771.39688\nKengtung   272.28711 632.54638 279.19573 329.38387 460.39706 692.74693\nLangkho    174.67678 531.08019 180.51419 236.70878 358.95672 597.42714\nMonghsu     84.11238 332.07962  62.60859 107.04894 154.86049 400.71816\nTaunggyi   448.55282 810.74692 450.33382 508.40925 635.94105 866.21117\nPangwaun   312.13429 500.68857 321.80465 257.50434 394.07696 536.95736\nKyethi     210.50453 278.85535 184.23422 222.52947 137.79420 352.06533\nLoilen      58.41263 388.73386 131.56529 176.16001 224.79239 482.18190\nManton     391.54062 109.08779 361.82684 310.20581 195.59882  81.75337\nMongyang   260.39387 558.83162 285.33223 295.60023 414.31237 631.91325\nKunhing    110.55197 398.43973 108.84990 114.03609 238.99570 465.03971\nMongyawng  275.77546 620.04321 281.03383 375.22688 445.78964 700.98284\nTangyan    180.37471 262.66006 166.61820 198.88460 109.08506 348.56123\nNamhsan    218.10003 215.19289 191.32762 196.76188  77.35900 288.66231\n              Lashio   Mongpan    Matman Tachileik   Narphan  Mongkhet\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan    172.33279                                                  \nMatman     628.11049 494.81014                                        \nTachileik  311.95286 411.03849 890.12935                              \nNarphan    525.63854 371.13393 312.05193 760.29566                    \nMongkhet   534.44463 412.17123 203.02855 820.50164 217.28718          \nHsipaw     290.86435 179.52054 344.45451 576.18780 295.40170 253.80950\nMonghsat   377.86793 283.30992 313.59911 677.09508 278.21548 167.98445\nMongmao    214.23677 131.59966 501.59903 472.95568 331.42618 375.35820\nNansang    184.47950 144.77393 458.06573 486.77266 398.13308 360.99219\nLaukkaing  334.65738 435.58047 903.72094 325.06329 708.82887 769.06406\nPangsang   236.72516 140.23910 506.29940 481.31907 316.30314 375.58139\nNamtu      365.88437 352.91394 416.65397 659.56458 494.36143 355.99713\nMonghpyak  262.09281 187.85699 470.46845 444.04411 448.40651 462.63265\nKonkyan    485.51312 365.87588 392.40306 730.92980 158.82353 254.24424\nMongping   454.52548 318.47482 201.65224 727.08969 188.64567 113.80917\nHopong     345.31042 239.43845 291.84351 632.45718 294.40441 212.99485\nNyaungshwe 201.58191 137.29734 460.91883 445.81335 427.94086 417.08639\nHsihseng   369.00833 295.87811 304.02806 658.87060 377.52977 256.70338\nMongla     179.95877 253.20001 708.17595 347.33155 531.46949 574.40292\nHseni       79.41836 120.66550 564.64051 354.90063 474.12297 481.88406\nKunlong    295.23103 288.03320 468.27436 595.70536 413.07823 341.68641\nHopang     170.63913 135.62913 573.55355 403.82035 397.85908 451.51070\nNamhkan    173.27153 240.34131 715.42102 295.91660 536.85519 596.19944\nKengtung    59.85893 142.21554 613.01033 295.90429 505.40025 531.35998\nLangkho    115.18145  94.98486 518.86151 402.33622 420.65204 428.08061\nMonghsu    325.71557 216.25326 308.13805 605.02113 311.92379 247.73318\nTaunggyi   195.14541 319.81385 778.45810 150.84117 684.20905 712.80752\nPangwaun   362.45608 232.52209 523.43600 540.60474 264.64997 407.02947\nKyethi     447.10266 358.89620 233.83079 728.87329 374.90376 233.25039\nLoilen     268.92310 207.25000 406.56282 573.75476 354.79137 284.76895\nManton     646.66493 507.96808  59.52318 910.23039 280.26395 181.33894\nMongyang   209.33700 194.93467 585.61776 448.79027 401.39475 445.40621\nKunhing    255.10832 137.85278 403.66587 532.26397 281.62645 292.49814\nMongyawng  172.70139 275.15989 601.80824 432.10118 572.76394 522.91815\nTangyan    429.84475 340.39128 242.78233 719.84066 348.84991 201.49393\nNamhsan    472.04024 364.77086 180.09747 754.03913 316.54695 170.90848\n              Hsipaw  Monghsat   Mongmao   Nansang Laukkaing  Pangsang\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat   121.78922                                                  \nMongmao    185.99483 247.17708                                        \nNansang    120.24428 201.92690 164.99494                              \nLaukkaing  569.06099 626.44910 404.00848 480.60074                    \nPangsang   205.04337 256.37933  57.60801 193.36162 408.04016          \nNamtu      229.44658 231.78673 365.03882 217.61884 664.06286 392.97391\nMonghpyak  237.67919 356.84917 291.88846 227.52638 565.84279 315.11651\nKonkyan    296.74316 268.25060 281.87425 374.70456 635.92043 274.81900\nMongping   168.92101 140.95392 305.57166 287.36626 708.13447 308.33123\nHopong      62.86179 100.45714 244.16253 167.66291 628.48557 261.51075\nNyaungshwe 169.92664 286.37238 230.45003 131.18943 520.24345 257.77823\nHsihseng   136.54610 153.49551 311.98001 193.53779 670.74564 335.52974\nMongla     373.47509 429.00536 216.24705 289.45119 202.55831 217.88123\nHseni      231.48538 331.22632 184.67099 136.45492 391.74585 214.66375\nKunlong    205.10051 202.31862 224.43391 183.01388 521.88657 258.49342\nHopang     248.72536 317.64824  78.29342 196.47091 331.67199  92.57672\nNamhkan    382.79302 455.10875 223.32205 302.89487 196.46063 231.38484\nKengtung   284.08582 383.72138 207.58055 193.67980 351.48520 229.85484\nLangkho    183.05109 279.52329 134.50170  99.39859 410.41270 167.65920\nMonghsu     58.55724 137.24737 242.43599 153.59962 619.01766 260.52971\nTaunggyi   462.31183 562.88102 387.33906 365.04897 345.98041 405.59730\nPangwaun   298.12447 343.53898 187.40057 326.12960 470.63605 157.48757\nKyethi     195.17677 190.50609 377.89657 273.02385 749.99415 396.89963\nLoilen      98.04789 118.65144 190.26490  94.23028 535.57527 207.94433\nManton     359.60008 317.15603 503.79786 476.55544 907.38406 504.75214\nMongyang   267.10497 312.64797  91.06281 218.49285 326.19219 108.37735\nKunhing     90.77517 165.38834 103.91040 128.20940 500.41640 123.18870\nMongyawng  294.70967 364.40429 296.40789 191.11990 454.80044 336.16703\nTangyan    167.69794 144.59626 347.14183 249.70235 722.40954 364.76893\nNamhsan    194.47928 169.56962 371.71448 294.16284 760.45960 385.65526\n               Namtu Monghpyak   Konkyan  Mongping    Hopong Nyaungshwe\nPindaya                                                                \nYwangan                                                                \nPinlaung                                                               \nMabein                                                                 \nKalaw                                                                  \nPekon                                                                  \nLawksawk                                                               \nNawnghkio                                                              \nKyaukme                                                                \nMuse                                                                   \nLaihka                                                                 \nMongnai                                                                \nMawkmai                                                                \nKutkai                                                                 \nMongton                                                                \nMongyai                                                                \nMongkaing                                                              \nLashio                                                                 \nMongpan                                                                \nMatman                                                                 \nTachileik                                                              \nNarphan                                                                \nMongkhet                                                               \nHsipaw                                                                 \nMonghsat                                                               \nMongmao                                                                \nNansang                                                                \nLaukkaing                                                              \nPangsang                                                               \nNamtu                                                                  \nMonghpyak  346.57799                                                   \nKonkyan    478.37690 463.39594                                         \nMongping   321.66441 354.76537 242.02901                               \nHopong     206.82668 267.95563 304.49287 134.00139                     \nNyaungshwe 271.41464 103.97300 432.35040 319.32583 209.32532           \nHsihseng   131.89940 285.37627 383.49700 199.64389  91.65458  225.80242\nMongla     483.49434 408.03397 468.09747 512.61580 432.31105  347.60273\nHseni      327.41448 200.26876 448.84563 395.58453 286.41193  130.86310\nKunlong    233.60474 357.44661 329.11433 309.05385 219.06817  285.13095\nHopang     408.24516 304.26577 348.18522 379.27212 309.77356  247.19891\nNamhkan    506.32466 379.50202 481.59596 523.74815 444.13246  333.32428\nKengtung   385.33554 221.47613 474.82621 442.80821 340.47382  177.75714\nLangkho    305.03473 200.27496 386.95022 343.96455 239.63685  128.26577\nMonghsu    209.64684 232.17823 331.72187 158.90478  43.40665  173.82799\nTaunggyi   518.72748 334.17439 650.56905 621.53039 513.76415  325.09619\nPangwaun   517.03554 381.95144 263.97576 340.37881 346.00673  352.92324\nKyethi     186.90932 328.16234 400.10989 187.43974 136.49038  288.06872\nLoilen     194.24075 296.99681 334.19820 231.99959 124.74445  206.40432\nManton     448.58230 502.20840 366.66876 200.48082 310.58885  488.79874\nMongyang   413.26052 358.17599 329.39338 387.80686 323.35704  294.29500\nKunhing    296.43996 250.74435 253.74202 212.59619 145.15617  189.97131\nMongyawng  262.24331 285.56475 522.38580 455.59190 326.59925  218.12104\nTangyan    178.69483 335.26416 367.46064 161.67411 106.82328  284.14692\nNamhsan    240.95555 352.70492 352.20115 130.23777 132.70541  315.91750\n            Hsihseng    Mongla     Hseni   Kunlong    Hopang   Namhkan\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat                                                              \nMongmao                                                               \nNansang                                                               \nLaukkaing                                                             \nPangsang                                                              \nNamtu                                                                 \nMonghpyak                                                             \nKonkyan                                                               \nMongping                                                              \nHopong                                                                \nNyaungshwe                                                            \nHsihseng                                                              \nMongla     478.66210                                                  \nHseni      312.74375 226.82048                                        \nKunlong    231.85967 346.46200 276.19175                              \nHopang     370.01334 147.02444 162.80878 271.34451                    \nNamhkan    492.09476  77.21355 212.11323 375.73885 146.18632          \nKengtung   370.72441 202.45004  66.12817 317.14187 164.29921 175.63015\nLangkho    276.27441 229.01675  66.66133 224.52741 134.24847 224.40029\nMonghsu     97.82470 424.51868 262.28462 239.89665 301.84458 431.32637\nTaunggyi   528.14240 297.09863 238.19389 471.29032 329.95252 257.29147\nPangwaun   433.06326 319.18643 330.70182 392.45403 206.98364 310.44067\nKyethi      84.04049 556.02500 388.33498 298.55859 440.48114 567.86202\nLoilen     158.84853 338.67408 227.10984 166.53599 242.89326 364.90647\nManton     334.87758 712.51416 584.63341 479.76855 577.52046 721.86149\nMongyang   382.59743 146.66661 210.19929 247.22785  69.25859 167.72448\nKunhing    220.15490 306.47566 206.47448 193.77551 172.96164 314.92119\nMongyawng  309.51462 315.57550 173.86004 240.39800 290.51360 321.21112\nTangyan     70.27241 526.80849 373.07575 268.07983 412.22167 542.64078\nNamhsan    125.74240 564.02740 411.96125 310.40560 440.51555 576.42717\n            Kengtung   Langkho   Monghsu  Taunggyi  Pangwaun    Kyethi\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat                                                              \nMongmao                                                               \nNansang                                                               \nLaukkaing                                                             \nPangsang                                                              \nNamtu                                                                 \nMonghpyak                                                             \nKonkyan                                                               \nMongping                                                              \nHopong                                                                \nNyaungshwe                                                            \nHsihseng                                                              \nMongla                                                                \nHseni                                                                 \nKunlong                                                               \nHopang                                                                \nNamhkan                                                               \nKengtung                                                              \nLangkho    107.16213                                                  \nMonghsu    316.91914 221.84918                                        \nTaunggyi   186.28225 288.27478 486.91951                              \nPangwaun   337.48335 295.38434 343.38498 497.61245                    \nKyethi     444.26274 350.91512 146.61572 599.57407 476.62610          \nLoilen     282.22935 184.10672 131.55208 455.91617 331.69981 232.32965\nManton     631.99123 535.95620 330.76503 803.08034 510.79265 272.03299\nMongyang   217.08047 175.35413 323.95988 374.58247 225.25026 453.86726\nKunhing    245.95083 146.38284 146.78891 429.98509 229.09986 278.95182\nMongyawng  203.87199 186.11584 312.85089 287.73864 475.33116 387.71518\nTangyan    429.95076 332.02048 127.42203 592.65262 447.05580  47.79331\nNamhsan    466.20497 368.20978 153.22576 631.49232 448.58030  68.67929\n              Loilen    Manton  Mongyang   Kunhing Mongyawng   Tangyan\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat                                                              \nMongmao                                                               \nNansang                                                               \nLaukkaing                                                             \nPangsang                                                              \nNamtu                                                                 \nMonghpyak                                                             \nKonkyan                                                               \nMongping                                                              \nHopong                                                                \nNyaungshwe                                                            \nHsihseng                                                              \nMongla                                                                \nHseni                                                                 \nKunlong                                                               \nHopang                                                                \nNamhkan                                                               \nKengtung                                                              \nLangkho                                                               \nMonghsu                                                               \nTaunggyi                                                              \nPangwaun                                                              \nKyethi                                                                \nLoilen                                                                \nManton     419.06087                                                  \nMongyang   246.76592 585.70558                                        \nKunhing    130.39336 410.49230 188.89405                              \nMongyawng  261.75211 629.43339 304.21734 295.35984                    \nTangyan    196.60826 271.82672 421.06366 249.74161 377.52279          \nNamhsan    242.15271 210.48485 450.97869 270.79121 430.02019  63.67613\n\n\n\n\n7.7 Computing hierarchical clustering\nIn R, there are several packages providing hierarchical clustering function. In this hands-on exercise, hclust() of R stats will be used.\nhclust() employs agglomeration method to compute the cluster. Eight clustering algorithms are supported, they are: ward.D, ward.D2, single, complete, average(UPGMA), mcquitty(WPGMA), median(WPGMC) and centroid(UPGMC).\nThe code chunk below performs hierarchical clustering analysis using ward.D method. The hierarchical clustering output is stored in an object of class hclust which describes the tree produced by the clustering process.\n\nhclust_ward &lt;- hclust(proxmat, method = 'ward.D')\n\nThe tree is then plotted by using plot() of R Graphics as shown in the code chunk below.\n\nplot(hclust_ward, cex = 0.6)\n\n\n\n\n\n\n\n\n\n\n7.8 Selecting the optimal clustering algorithm\nOne of the challenges in performing hierarchical clustering is to identify stronger clustering structures. The issue can be solved by using using agnes() function of cluster package.\nIt functions like hclus(), however, with the agnes() function it also gets the agglomerative coefficient, which measures the amount of clustering structure found (values closer to 1 suggesting strong clustering structure).\nThe code chunk below will be used to compute the agglomerative coefficients of all hierarchical clustering algorithms.\n\nm &lt;- c(\"average\", \"single\", \"complete\", \"ward\")\nnames(m) &lt;- c(\"average\", \"single\", \"complete\", \"ward\")\n\nac &lt;- function(x) {\n  agnes(shan_ict, method = x)$ac\n}\n\nmap_dbl(m, ac)\n\n  average    single  complete      ward \n0.8131144 0.6628705 0.8950702 0.9427730 \n\n\nWith reference to the output above, we can see that Ward’s method provides the strongest clustering structure (0.9427730 ) among the four methods assessed. Hence, in the subsequent analysis, only Ward’s method will be used.\n\n\n7.9 Determining Optimal Clusters\nAnother technical challenge faced in performing clustering analysis is to determine the optimal clusters to retain.\nThere are three commonly used methods to determine the optimal clusters, they are:\n\nElbow Method\nAverage Silhouette Method\nGap Statistic Method\n\n\n7.9.1 Gap Statistic Method\nThe gap statistic compares the total within intra-cluster variation for different values of k with their expected values under null reference distribution of the data. The estimate of the optimal clusters will be the value that maximize the gap statistic (i.e., that yields the largest gap statistic). This means that the clustering structure is far away from the random uniform distribution of points.\nTo compute the gap statistic, clusGap() of cluster package will be used.\n\nset.seed(1234)\ngap_stat &lt;- clusGap(shan_ict,\n                    FUN = hcut,\n                    nstart = 25,\n                    K.max = 10,\n                    B = 50)\n\n# Extract the gap statistic values\ngap_data &lt;- as.data.frame(gap_stat$Tab)\ngap_data$k &lt;- 1:nrow(gap_data)\n\n# Printing Result\nprint(gap_stat, method = \"firstmax\")\n\nClustering Gap statistic [\"clusGap\"] from call:\nclusGap(x = shan_ict, FUNcluster = hcut, K.max = 10, B = 50, nstart = 25)\nB=50 simulated reference sets, k = 1..10; spaceH0=\"scaledPCA\"\n --&gt; Number of clusters (method 'firstmax'): 1\n          logW   E.logW       gap     SE.sim\n [1,] 8.407129 8.677830 0.2707006 0.03692273\n [2,] 8.130029 8.346462 0.2164322 0.04088387\n [3,] 7.992265 8.200253 0.2079877 0.03762167\n [4,] 7.862224 8.079170 0.2169462 0.04018998\n [5,] 7.756461 7.977981 0.2215201 0.04229538\n [6,] 7.665594 7.890134 0.2245409 0.04501316\n [7,] 7.590919 7.812990 0.2220709 0.04364077\n [8,] 7.526680 7.739537 0.2128575 0.04477188\n [9,] 7.458024 7.670476 0.2124519 0.04623855\n[10,] 7.377412 7.603947 0.2265346 0.04762720\n\n\nAlso note that the hcut function used is from factoextra package.\nNext, we can visualise the plot by using fviz_gap_stat() of factoextra package.\n\n# Plot with labels using ggplot\np &lt;- fviz_gap_stat(gap_stat) +\n  geom_text(aes(x = gap_data$k, y = gap_data$gap, label = round(gap_data$gap, 4)), \n            vjust = -0.5, \n            size = 3)\n\n# Display the plot\nprint(p)\n\n\n\n\n\n\n\n\n\nfviz_gap_stat(gap_stat)\n\n\n\n\n\n\n\n\nWith reference to the gap statistic graph above, the recommended number of cluster to retain is 1. However, it is not logical to retain only one cluster. By examining the gap statistic graph, the 6-cluster gives the largest gap statistic and should be the next best cluster to pick.\nNote: In addition to these commonly used approaches, the NbClust package, published by Charrad et al., 2014, provides 30 indices for determining the relevant number of clusters and proposes to users the best clustering scheme from the different results obtained by varying all combinations of number of clusters, distance measures, and clustering methods.\n\n\n\n7.10 Interpreting the dendrograms\nIn the dendrogram displayed above, each leaf corresponds to one observation. As we move up the tree, observations that are similar to each other are combined into branches, which are themselves fused at a higher height.\nThe height of the fusion, provided on the vertical axis, indicates the (dis)similarity between two observations. The higher the height of the fusion, the less similar the observations are. Note that, conclusions about the proximity of two observations can be drawn only based on the height where branches containing those two observations first are fused. We cannot use the proximity of two observations along the horizontal axis as a criteria of their similarity.\nIt’s also possible to draw the dendrogram with a border around the selected clusters by using rect.hclust() of R stats. The argument border is used to specify the border colours for the rectangles.\n\nplot(hclust_ward, cex = 0.6)\nrect.hclust(hclust_ward,\n            k = 6,\n            border = 2:5)\n\n\n\n\n\n\n\n\n\n\n7.11 Visually-driven hierarchical clustering analysis\nIn this section, it will demonstrate how to perform visually-driven hierarchical clustering analysis by using heatmaply package.\nWith heatmaply, we are able to build both highly interactive cluster heatmap or static cluster heatmap.\n\n7.11.1 Transforming the data frame into a matrix\nThe data was loaded into a data frame, but it has to be a data matrix to make the heatmap.\nThe code chunk below will be used to transform shan_ict data frame into a data matrix.\n\nshan_ict_mat &lt;- data.matrix(shan_ict)\n\n\n\n7.11.2 Plotting interactive cluster heatmap using heatmaply()\nIn the code chunk below, the heatmaply() of heatmaply package is used to build an interactive cluster heatmap.\n\nheatmaply(normalize(shan_ict_mat),\n          Colv = NA,\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\",\n          seriate = \"OLO\",\n          colors = Blues,\n          k_row = 6,\n          margins = c(NA, 200, 60, NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main = \"Geographics Segmentation of Shan State by ICT Indicators\",\n          xlab = \"ICT Indicators\",\n          ylab = \"Townships of Shan State\")\n\n\n\n\n\n\n\n\n7.12 Mapping the clusters formed\nUpon examination of the dendragram above, we have decided to retain six clusters.\ncutree() of R Base will be used in the code chunk below to derive a 6-cluster model.\n\ngroups &lt;- as.factor(cutree(hclust_ward, k = 6))\n\nThe output is labelled as groups. It is a list object.\nIn order to visualise the clusters, the groups object needs to be appended onto shan_sf simple feature object.\nThe code chunk below form the join in three steps:\n\nthe groups list object will be converted into a matrix;\ncbind() is used to append groups matrix onto shan_sf to produce an output simple feature object called shan_sf_cluster; and\nrename of dplyr package is used to rename as.matrix.groups field as CLUSTER.\n\n\nshan_sf_cluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;%\n  rename(`CLUSTER` = `as.matrix.groups.`)\n\nNext, qtm() of tmap package is used to plot the choropleth map showing the clusters formed.\n\nqtm(shan_sf_cluster, \"CLUSTER\")\n\n\n\n\n\n\n\n\nThe choropleth map above reveals that the clusters are very fragmented. The is one of the major limitations when non-spatial clustering algorithm such as hierarchical cluster analysis method is used."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#spatially-constrained-clustering-skater-approach",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#spatially-constrained-clustering-skater-approach",
    "title": "Hands-on Exercise 6: Geographic Segmentation with Spatially Constrained Cluster Analysis",
    "section": "8 Spatially Constrained Clustering: SKATER approach",
    "text": "8 Spatially Constrained Clustering: SKATER approach\nIn this section, we will learn how to derive spatially constrained clusters by using skater() method of spdep package.\n\n8.1 Converting into SpatialPolygonsDataFrame\nFirst, we need to convert shan_sf into SpatialPolygonsDataFrame. This is because SKATER function only supports sp objects such as SpatialPolygonDataFrame.\nThe code chunk below uses as_Spatial() of sf package to convert shan_sf into a SpatialPolygonDataFrame called shan_sp.\n\nshan_sp &lt;- as_Spatial(shan_sf)\n\n\n\n8.2 Computing Neighbour List\nNext, poly2nb() of spdep package will be used to compute the neighbours list from polygon list.\n\nshan.nb &lt;- poly2nb(shan_sp)\nsummary(shan.nb)\n\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\n\nWe can plot the neighbours list on shan_sp by using the code chunk below.\nSince we now can plot the community area boundaries as well, we can then plot this graph on top of the map. The first plot command gives the boundaries. This is followed by the plot of the neighbour list object, with coordinates applied to the original SpatialPolygonDataFrame (Shan state township boundaries) to extract the centroids of the polygons. These are used as the nodes for the graph representation. We also set the color to blue and specify add = TRUE to plot the network on top of the boundaries.\n\ncoords &lt;- st_coordinates(\n  st_centroid(st_geometry(shan_sf)))\n\n\nplot(st_geometry(shan_sf),\n     border = grey(.5))\nplot(shan.nb,\n     coords,\n     col = \"blue\",\n     add = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf the network is plotted first and then the boundaries, some of the areas will be clipped. This is because the plotting area is determined by the characteristics of the first plot. In this example, because the boundary map extends further than the graph, we plot it first.\n\n\n\n\n8.3 Computing minimum spanning tree\n\n8.3.1 Calculating edge costs\nNext, nbcosts() of spdep package is used to compute the cost of each edge. It is the distance between its nodes. This function computes this distance using a data.frame with observations vector in each node.\nThe code chunk below is used to compute the cost of each edge.\n\nlcosts &lt;- nbcosts(shan.nb, shan_ict)\n\nFor each observation, this gives the pairwise dissimilarity between its values on the five variables and the values for the neighbouring observation (from the neighbour list). Basically, this is the notion of a generalised weight for a spatial weights matrix.\nNext, We will incorporate these costs into a weights object in the same way as we did in the calculation of inverse of distance weights. In other words, we convert the neighbour list to a list weights object by specifying the just computed lcosts as the weights.\nIn order to achieve this, nb2listw() of spdep package is used as shown in the code chunk below.\nNote that we specify the style as B to make sure the cost values are not row-standardised.\n\nshan.w &lt;- nb2listw(shan.nb,\n                   lcosts,\n                   style = \"B\")\n\nsummary(shan.w)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\nWeights style: B \nWeights constants summary:\n   n   nn       S0       S1        S2\nB 55 3025 76267.65 58260785 522016004\n\n\n\n\n\n8.4 Computing minimum spanning tree (MST)\nThe minimum spanning tree is computed by using the mean of the mstree() of spdep package as shown in the code chunk below.\n\nshan.mst &lt;- mstree(shan.w)\n\nAfter computing the MST, we can check its class and dimension by using the code chunk below.\n\nclass(shan.mst)\n\n[1] \"mst\"    \"matrix\"\n\ndim(shan.mst)\n\n[1] 54  3\n\n\nNote that the dimension is 54 and not 55. This is because the minimum spanning tree consists of n-1 edges (links) in order to traverse all the nodes.\nWe can display the content of shan.mst by using head() as shown in the code chunk below.\n\nhead(shan.mst)\n\n     [,1] [,2]      [,3]\n[1,]    3    2 257.31610\n[2,]    2    8 204.32952\n[3,]    8    9  90.82891\n[4,]    8    6 140.01101\n[5,]    6   36  95.66782\n[6,]   36    4 138.12050\n\n\nThe plot method for the MST includes a way to show the observation numbers of the nodes in addition to the edge. As before, we can plot this together with the township boundaries. We can see how the initial neighbour list is simplified to just one edge connecting each of the nodes, while passing through all the nodes.\n\nplot(st_geometry(shan_sf),\n                 border = gray(.5))\nplot.mst(shan.mst,\n         coords,\n         col = \"blue\",\n         cex.lab = 0.7,\n         cex.circles = 0.005,\n         add = TRUE)\n\n\n\n\n\n\n\n\n\n\n8.5 Computing spatially constrained clusters using SKATER method\nThe code chunk below computes the spatially constrained cluster using skater() of spdep package.\n\nclust6 &lt;- spdep::skater(edges = shan.mst[,1:2],\n                 data = shan_ict,\n                 method = \"euclidean\",\n                 ncuts = 5)\n\nThe skater() takes three mandatory arguments: - the first two columns of the MST matrix (i.e. not the cost), - the data matrix (to update the costs as units are being grouped), and - the number of cuts. Note: It is set to one less than the number of clusters. So, the value specified is not the number of clusters, but the number of cuts in the graph, one less than the number of clusters.\nThe result of the skater() is an object of class skater. We can examine its contents by using the code chunk below.\n\nstr(clust6)\n\nList of 8\n $ groups      : num [1:55] 6 6 1 6 6 6 6 6 6 6 ...\n $ edges.groups:List of 6\n  ..$ :List of 3\n  .. ..$ node: num 3\n  .. ..$ edge: num[0 , 1:3] \n  .. ..$ ssw : num 0\n  ..$ :List of 3\n  .. ..$ node: num [1:18] 47 27 53 38 42 15 41 51 43 32 ...\n  .. ..$ edge: num [1:17, 1:3] 53 15 42 38 41 51 15 27 15 43 ...\n  .. ..$ ssw : num 3759\n  ..$ :List of 3\n  .. ..$ node: num [1:22] 13 48 54 55 45 37 34 16 25 52 ...\n  .. ..$ edge: num [1:21, 1:3] 48 55 54 37 34 16 45 25 13 13 ...\n  .. ..$ ssw : num 3423\n  ..$ :List of 3\n  .. ..$ node: num [1:2] 44 20\n  .. ..$ edge: num [1, 1:3] 44 20 95\n  .. ..$ ssw : num 95\n  ..$ :List of 3\n  .. ..$ node: num 23\n  .. ..$ edge: num[0 , 1:3] \n  .. ..$ ssw : num 0\n  ..$ :List of 3\n  .. ..$ node: num [1:11] 6 2 1 36 4 9 10 8 46 5 ...\n  .. ..$ edge: num [1:10, 1:3] 6 1 2 36 4 6 8 9 10 8 ...\n  .. ..$ ssw : num 1458\n $ not.prune   : NULL\n $ candidates  : int [1:6] 1 2 3 4 5 6\n $ ssto        : num 12613\n $ ssw         : num [1:6] 12613 10977 9962 9540 9123 ...\n $ crit        : num [1:2] 1 Inf\n $ vec.crit    : num [1:55] 1 1 1 1 1 1 1 1 1 1 ...\n - attr(*, \"class\")= chr \"skater\"\n\n\nThe most interesting component of this list structure is the groups vector containing the labels of the cluster to which each observation belongs (as before, the label itself is arbitrary). This is followed by a detailed summary for each of the clusters in the edges.groups list. Sum of squares measures are given as ssto for the total and ssw to show the effect of each of the cuts on the overall criterion.\nWe can check the cluster assignment by using the code chunk below.\n\nccs6 &lt;- clust6$groups\n\nccs6\n\n [1] 6 6 1 6 6 6 6 6 6 6 2 3 3 3 2 3 3 3 2 4 3 2 5 3 3 3 2 3 2 2 3 2 2 3 3 6 3 2\n[39] 2 2 2 2 2 4 3 6 2 3 3 3 2 3 2 3 3\n\n\nWe can find out how many observations are in each cluster by means of the table command. Parenthetically, we can also find this as the dimension of each vector in the lists contained in edges.groups. For example, the first list has node with dimension 12, which is also the number of observations in the first cluster.\n\ntable(ccs6)\n\nccs6\n 1  2  3  4  5  6 \n 1 18 22  2  1 11 \n\n\nLastly, we can also plot the pruned tree that shows the six clusters on top of the townshop area.\n\nplot(st_geometry(shan_sf),\n     border = gray(.5))\nplot(clust6,\n     coords,\n     cex.lab = .7,\n     groups.colors = c(\"red\", \"green\", \"blue\", \"brown\", \"pink\", \"black\"),\n     cex.circles = 0.005,\n     add = TRUE)\n\nWarning in segments(coords[id1, 1], coords[id1, 2], coords[id2, 1], coords[id2,\n: \"add\" is not a graphical parameter\nWarning in segments(coords[id1, 1], coords[id1, 2], coords[id2, 1], coords[id2,\n: \"add\" is not a graphical parameter\nWarning in segments(coords[id1, 1], coords[id1, 2], coords[id2, 1], coords[id2,\n: \"add\" is not a graphical parameter\nWarning in segments(coords[id1, 1], coords[id1, 2], coords[id2, 1], coords[id2,\n: \"add\" is not a graphical parameter\n\n\n\n\n\n\n\n\n\n\n\n8.6 Visualising the clusters in choropleth map\nThe code chunk below is used to plot the newly derived clusters by using SKATER method.\n\ngroups_mat &lt;- as.matrix(clust6$groups)\nshan_sf_spatialcluster &lt;- cbind(shan_sf_cluster, as.factor(groups_mat)) %&gt;%\n  rename(`SP_CLUSTER` = `as.factor.groups_mat.`)\nqtm(shan_sf_spatialcluster, \"SP_CLUSTER\")\n\n\n\n\n\n\n\n\nFor an easy comparison, it will be better to place both the hierarchical clustering and spatially constrained hierarchical clustering maps next to each other.\n\nhclust.map &lt;- qtm(shan_sf_cluster,\n                  \"CLUSTER\") +\n  tm_borders(alpha = 0.5)\n\nshclust.map &lt;- qtm(shan_sf_spatialcluster,\n                   \"SP_CLUSTER\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(hclust.map, shclust.map,\n             asp = NA, ncol = 2)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them)."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#spatially-constrained-clustering-clustgeo-method",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#spatially-constrained-clustering-clustgeo-method",
    "title": "Hands-on Exercise 6: Geographic Segmentation with Spatially Constrained Cluster Analysis",
    "section": "9 Spatially Constrained Clustering: ClustGeo Method",
    "text": "9 Spatially Constrained Clustering: ClustGeo Method\nIn this section, it focuses on gaining hands-on experience on using functions provided by ClustGeo package to perform non-spatially constrained hierarchical cluster analysis and spatially constrained cluster analysis.\n\n9.1 A short note about ClustGeo package\nClustGeo package is an R package specially designed to support the need of performing spatially constrained cluster analysis. More specifically, it provides a Ward-like hierarchical clustering algorithm called hclustgeo() including spatial/geographical constraints.\nIn the nutshell, the algorithm uses two dissimilarity matrices D0 and D1 along with a mixing parameter alpha, whereby the value of alpha must be a real number between [0, 1]. D0 can be non-Euclidean and the weights of the observations can be non-uniform. It gives the dissimilarities in the attribute/clustering variable space. D1, on the other hand, gives the dissimilarities in the constraint space. The criterion minimised at each stage is a convex combination of the homogeneity criterion calculated with D0 and the homogeneity criterion calculated with D1.\nThe idea is then to determine a value of alpha which increases the spatial contiguity without deteriorating too much the quality of the solution based on the variables of interest. This need is supported by a function called choicealpha().\n\n\n9.2 Ward-like hierarchical clustering: ClustGeo\nClustGeo package provides function called hclustgeo() to perform a typical Ward-like hierarchical clustering just like hclust() you learned in previous section.\nTo perform non-spatially constrained hierarchical clustering, we only need to provide the function a dissimilarity matrix as shown in the code chunk below.\n\nnongeo_cluster &lt;- hclustgeo(proxmat)\nplot(nongeo_cluster, cex = 0.5)\nrect.hclust(nongeo_cluster,\n            k = 6,\n            border = 2:5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote that the dissimilarity matrix must be an object of class dist, i.e. an object obtained with the function dist(). For sample code chunk, please refer to Computing proximity matrix\n\n\n\n9.2.1 Mapping the clusters formed\nSimilarly, we can plot the clusters on a categorical area shaded map by using the steps we learned from - Mapping the clusters formed.\n\ngroups &lt;- as.factor(cutree(nongeo_cluster, k = 6))\n\n\nshan_sf_ngeo_cluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;%\n  rename(`CLUSTER` = `as.matrix.groups.`)\n\n\nqtm(shan_sf_ngeo_cluster, \"CLUSTER\")\n\n\n\n\n\n\n\n\n\n\n\n9.3 Spatially Constrained Hierarchical Clustering\nBefore we can perform spatially constrained hierarchical clustering, a spatial distance matrix will be derived by using st_distance() of sf package.\n\ndist &lt;- st_distance(shan_sf, shan_sf)\ndistmat &lt;- as.dist(dist)\n\n\n\n\n\n\n\nNote\n\n\n\nNotice that as.dist() is used to convert the data frame into matrix.\n\n\nNext, choicealpha() will be used to determine a suitable value for the mixing parameter alpha as shown in the code chunk below.\n\ncr &lt;- choicealpha(proxmat, distmat, range.alpha = seq(0, 1, 0.1), K=6, graph = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWith reference to the graphs above, alpha = 0.3 will be used as shown in the code chunk below.\n\nclustG &lt;- hclustgeo(proxmat, distmat, alpha = 0.3)\n\nNext, the cutree() function is used to derive the cluster object.\n\ngroups &lt;- as.factor(cutree(clustG, k=6))\n\ngroups will then be joined back to the group list with shan_sf polygon feature data frame by using the code chunk below.\n\nshan_sf_Gcluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;%\n  rename(`CLUSTER` = `as.matrix.groups.`)\n\nTo plot the map of the newly delineated spatially constrained clusters.\n\nqtm(shan_sf_Gcluster, \"CLUSTER\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#visual-interpretation-of-clusters",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#visual-interpretation-of-clusters",
    "title": "Hands-on Exercise 6: Geographic Segmentation with Spatially Constrained Cluster Analysis",
    "section": "10 Visual Interpretation of Clusters",
    "text": "10 Visual Interpretation of Clusters\n\n10.1 Visualising individual clustering variable\nCode chunk below is used to reveal the distribution of a clustering variable (i.e RADIO_PR) by cluster.\n\nggplot(data = shan_sf_ngeo_cluster,\n       aes(x = CLUSTER, y = RADIO_PR)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\nThe boxplot reveals that Cluster 3 displays the highest mean Radio Ownership Per Thousand Household. Is it then followed by Cluster 2, 1, 4, 6 and 5.\n\n\n10.2 Multivariate Visualisation\nPast studies have shown that parallel coordinates plot can be used to reveal clustering variables by clusters very effectively. In the code chunk below, ggparcoord() of GGally package is used.\n\nscale = “globalminmax”scale = “uniminmax”scale = “std”\n\n\n\nggparcoord(data = shan_sf_ngeo_cluster, \n           columns = c(17:21), \n           scale = \"globalminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of ICT Variables by Cluster\") +\n  facet_grid(~ CLUSTER) + \n  theme(axis.text.x = element_text(angle = 45, size = 8))\n\n\n\n\n\n\n\n\nThe parallel coordinate plot above reveals that households in Cluster 4 townships tend to own the highest number of TV and mobile phones. On the other hand, households in Cluster 5 tend to own the lowest of all the five ICT.\n\n\n\nggparcoord(data = shan_sf_ngeo_cluster, \n           columns = c(17:21), \n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of ICT Variables by Cluster\") +\n  facet_grid(~ CLUSTER) + \n  theme(axis.text.x = element_text(angle = 45, size = 8))\n\n\n\n\n\n\n\n\n\n\n\nggparcoord(data = shan_sf_ngeo_cluster, \n           columns = c(17:21), \n           scale = \"std\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of ICT Variables by Cluster\") +\n  facet_grid(~ CLUSTER) + \n  theme(axis.text.x = element_text(angle = 45, size = 8))\n\n\n\n\n\n\n\n\n\n\n\nNote that the scale argument of ggparcoor() provide several methods to scale the clustering variables. They are:\n\nstd: univariately, subtract mean and divide by standard deviation.\nrobust: univariately, subtract median and divide by median absolute deviation.\nuniminmax: univariately, scale so the minimum of the variable is zero, and the maximum is one.\nglobalminmax: no scaling is done; the range of the graphs is defined by the global minimum and the global maximum.\ncenter: use uniminmax to standardize vertical height, then center each variable at a value specified by the scaleSummary param.\ncenterObs: use uniminmax to standardize vertical height, then center each variable at the value of the observation specified by the centerObsID param\n\nThere is no one best scaling method to use. You should explore them and select the one that best meet your analysis need.\nLast but not least, we can also compute the summary statistics such as mean, median and standard deviation to complement the visual interpretation.\nIn the code chunk below, group_by() and summarise() of dplyr are used to derive mean values of the clustering variables.\n\nshan_sf_ngeo_cluster %&gt;% \n  st_set_geometry(NULL) %&gt;%\n  group_by(CLUSTER) %&gt;%\n  summarise(mean_RADIO_PR = mean(RADIO_PR),\n            mean_TV_PR = mean(TV_PR),\n            mean_LLPHONE_PR = mean(LLPHONE_PR),\n            mean_MPHONE_PR = mean(MPHONE_PR),\n            mean_COMPUTER_PR = mean(COMPUTER_PR))\n\n# A tibble: 6 × 6\n  CLUSTER mean_RADIO_PR mean_TV_PR mean_LLPHONE_PR mean_MPHONE_PR\n  &lt;chr&gt;           &lt;dbl&gt;      &lt;dbl&gt;           &lt;dbl&gt;          &lt;dbl&gt;\n1 1               221.        521.            44.2           246.\n2 2               237.        402.            23.9           134.\n3 3               300.        611.            52.2           392.\n4 4               196.        744.            99.0           651.\n5 5               124.        224.            38.0           132.\n6 6                98.6       499.            74.5           468.\n# ℹ 1 more variable: mean_COMPUTER_PR &lt;dbl&gt;\n\n\nEND"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#preparing-the-datasets",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#preparing-the-datasets",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "",
    "text": "This project will focus on the Bangkok Metropolitan Region (BMR) which comprises of five provinces surrounding Bangkok, namely, Samut Prakan, Pathum Thani, Nakhon Pathom, Samut Sakhon, and Nonthaburi. These areas are referred to as the Five Provinces and the Vicinity. Together with the Bangkok Metropolitan Area (BMA), they have become the Bangkok Metropolitan Region (BMR) Source%2C%20or%20Greater%20Bangkok.).\nThe code chunk below will be used to facilitate the extraction of the BMR for the datasets to avoid unnecessary provinces to be read and putting a strain on computing resources.\n\nbmr_provinces &lt;- c(\"Bangkok\", \"Samut Prakan\", \"Pathum Thani\", \"Nakhon Pathom\", \"Samut Sakhon\", \"Nonthaburi\")\n\n\n\n\nThe thai_road_accident_2019_2022 data set is csv file format, read_csv() of the readr package will be used to import thai_road_accident_2019_2022.csv as shown from the code chunk below. The output R Object is called rdacc as is a tibble data frame.\n\nrdacc &lt;- read_csv(\"data/rawdata/thai_road_accident_2019_2022.csv\")\n\nUpon some initial observation of the data set, it is observed that there are missing / NA values in the latitude & longitude columns which will have to be removed as it will not be suitable to do any spatial analysis on this observations. Following which there is also an incident_datetime column spanning from years 2019 to 2022 which will be utilised to identify the date and time occurrences of accidents. As such that column will be transformed for the date and time to be used for analysis.\nAdditionally to further set the scene (timings typically from 7 – 9 AM and 4 – 7 PM on weekdays while considering weekends to be peak throughout) will also be as pre-determined for Bangkok’s rush hours otherwise known as peak hours traffic.\nThe code chunk below also converts rdacc data frame into a simple feature data frame by using st_as_sf() of sf packages.\n\nrdacc_sf &lt;- rdacc %&gt;%\n  filter(!is.na(longitude) & longitude != \"\", \n         !is.na(latitude) & latitude != \"\") %&gt;%\n  mutate(Day_num = day(incident_datetime)) %&gt;%\n  mutate(Dayofweek = wday(incident_datetime, label = TRUE, week_start = 1)) %&gt;%\n  mutate(Month_num = month(incident_datetime)) %&gt;%\n  mutate(Month_fac = month(incident_datetime,\n                       label = TRUE,\n                       abbr = TRUE)) %&gt;%\n  mutate(Year = year(incident_datetime)) %&gt;%\n  mutate(Hour_of_day = hour(incident_datetime)) %&gt;%\n  st_as_sf(coords = c(\"longitude\", \"latitude\"),\n           crs = 4326) %&gt;%\n  st_transform(crs = 32647)\n\n\n\n\nrdacc_sf_bmr &lt;- rdacc_sf %&gt;%\n    filter(province_en %in% bmr_provinces)\n\nThe simple feature data frame is saved into a physical file for usage. By doing so the need to repeat the steps above is not needed when running the quarto document.\n\nwrite_rds(rdacc_sf_bmr, \"data/rds/rdacc_sf_bmr.rds\")\n\nTo retrieve file\n\nrdacc_sf_bmr &lt;- read_rds(\"data/rds/rdacc_sf_bmr.rds\")\n\n\n\n\n\nst_geometry(rdacc_sf_bmr)\n\nGeometry set for 12986 features \nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 591277.5 ymin: 1486846 xmax: 710166.1 ymax: 1576520\nProjected CRS: WGS 84 / UTM zone 47N\nFirst 5 geometries:\n\n\n\n\n\n\n\nThailand Roads (OpenStreetMap Export)Assigning EPSG code and projection transformationViewing the road_sf data frameFinal CheckSelecting the relevant highway classifications\n\n\nThis dataset is in shp format and the code chunk below is used to read the file into the R environment.\n\nroad_sf &lt;- st_read(dsn = \"data/rawdata\", \n                   layer = \"hotosm_tha_roads_lines_shp\")\n\nReading layer `hotosm_tha_roads_lines_shp' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Take-home_Ex\\Take-home_Ex01\\data\\rawdata' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2792590 features and 14 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 97.34457 ymin: 5.643645 xmax: 105.6528 ymax: 20.47168\nCRS:           NA\n\n\n\n\nUpon importing the OSM Export, it is observed from the results that the CRS field shows NA. Hence, we will set the CRS to WGS84 with the default EPSG code of 4326 using st_set_crs() of sf package.\n\nroad_sf &lt;- st_set_crs(road_sf, 4326)\n\nNow, to check the CSR again by using the code chunk below.\n\nst_crs(road_sf)\n\nCoordinate Reference System:\n  User input: EPSG:4326 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n        MEMBER[\"World Geodetic System 1984 (Transit)\"],\n        MEMBER[\"World Geodetic System 1984 (G730)\"],\n        MEMBER[\"World Geodetic System 1984 (G873)\"],\n        MEMBER[\"World Geodetic System 1984 (G1150)\"],\n        MEMBER[\"World Geodetic System 1984 (G1674)\"],\n        MEMBER[\"World Geodetic System 1984 (G1762)\"],\n        MEMBER[\"World Geodetic System 1984 (G2139)\"],\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]],\n        ENSEMBLEACCURACY[2.0]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    USAGE[\n        SCOPE[\"Horizontal component of 3D system.\"],\n        AREA[\"World.\"],\n        BBOX[-90,-180,90,180]],\n    ID[\"EPSG\",4326]]\n\n\nFollowing which, we can utilise st_transform() of sf package to re-project road_sf from one coordinate system to another coordinate system mathematically.\n\nroad_sf &lt;- st_transform(road_sf,\n                        crs = 32647)\n\n\n\nNext, let us display the content of road_sf sf data frame as shown in the code chunk below using st_geometry() and glimpse() functions.\n\nst_geometry(road_sf)\n\nGeometry set for 2792590 features \nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 325313.7 ymin: 624248.4 xmax: 1215576 ymax: 2263968\nProjected CRS: WGS 84 / UTM zone 47N\nFirst 5 geometries:\n\n\n\nglimpse(road_sf)\n\nRows: 2,792,590\nColumns: 15\n$ name       &lt;chr&gt; \"ถนนฉลองกรุง\", \"ซอยฉลองกรุง 1/1\", NA, NA, \"ถนนฉลองกรุง\", NA, \"…\n$ name_en    &lt;chr&gt; \"Chalong Krung Road\", \"Soi Chalong Krung 1/1\", NA, NA, \"Cha…\n$ highway    &lt;chr&gt; \"secondary\", \"residential\", \"secondary_link\", \"service\", \"s…\n$ surface    &lt;chr&gt; \"paved\", NA, NA, NA, \"concrete\", NA, NA, \"unpaved\", NA, NA,…\n$ smoothness &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ width      &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ lanes      &lt;chr&gt; NA, NA, NA, NA, \"2\", NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ oneway     &lt;chr&gt; \"yes\", NA, \"yes\", NA, \"yes\", NA, NA, NA, NA, NA, NA, NA, NA…\n$ bridge     &lt;chr&gt; NA, NA, NA, NA, \"yes\", NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ layer      &lt;chr&gt; NA, NA, NA, NA, \"1\", NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ source     &lt;chr&gt; NA, NA, NA, NA, \"Bing\", NA, NA, \"GPS\", NA, NA, NA, NA, NA, …\n$ name_th    &lt;chr&gt; \"ถนนฉลองกรุง\", \"ซอยฉลองกรุง 1/1\", NA, NA, \"ถนนฉลองกรุง\", NA, \"…\n$ osm_id     &lt;dbl&gt; 1125681229, 594401607, 472283206, 594401608, 116847248, 317…\n$ osm_type   &lt;chr&gt; \"ways_line\", \"ways_line\", \"ways_line\", \"ways_line\", \"ways_l…\n$ geometry   &lt;MULTILINESTRING [m]&gt; MULTILINESTRING ((693686.1 ..., MULTILINEST…\n\n\n\n\nTo check the CSR again by using the code chunk below.\n\nst_crs(road_sf)\n\nCoordinate Reference System:\n  User input: EPSG:32647 \n  wkt:\nPROJCRS[\"WGS 84 / UTM zone 47N\",\n    BASEGEOGCRS[\"WGS 84\",\n        ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n            MEMBER[\"World Geodetic System 1984 (Transit)\"],\n            MEMBER[\"World Geodetic System 1984 (G730)\"],\n            MEMBER[\"World Geodetic System 1984 (G873)\"],\n            MEMBER[\"World Geodetic System 1984 (G1150)\"],\n            MEMBER[\"World Geodetic System 1984 (G1674)\"],\n            MEMBER[\"World Geodetic System 1984 (G1762)\"],\n            MEMBER[\"World Geodetic System 1984 (G2139)\"],\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ENSEMBLEACCURACY[2.0]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4326]],\n    CONVERSION[\"UTM zone 47N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",99,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Navigation and medium accuracy spatial referencing.\"],\n        AREA[\"Between 96°E and 102°E, northern hemisphere between equator and 84°N, onshore and offshore. China. Indonesia. Laos. Malaysia - West Malaysia. Mongolia. Myanmar (Burma). Russian Federation. Thailand.\"],\n        BBOX[0,96,84,102]],\n    ID[\"EPSG\",32647]]\n\n\n\n\nAs the road data set provided by OSM is very comprehensive it will increase the computation times a lot and some of the classes might not be useful for analysis. Hence, we will explore what are the classes included and selecting those relevant ones based on the Highway Classification.\n\nunique(road_sf$highway)\n\n [1] \"secondary\"      \"residential\"    \"secondary_link\" \"service\"       \n [5] \"tertiary\"       \"path\"           \"footway\"        \"track\"         \n [9] \"unclassified\"   \"trunk\"          \"trunk_link\"     \"primary\"       \n[13] \"primary_link\"   \"steps\"          \"motorway_link\"  \"cycleway\"      \n[17] \"pedestrian\"     \"tertiary_link\"  \"motorway\"       \"construction\"  \n[21] \"road\"           \"raceway\"        \"corridor\"       \"living_street\" \n[25] \"escape\"         \"proposed\"       \"busway\"         \"bridleway\"     \n[29] \"abandoned\"      \"parth\"          \"barrier\"        \"paved\"         \n\n\nThe code chunk below is used to filter only the relevant highways based on the classification and selecting other relevant columns that will be used.\n\nroad_sf &lt;- road_sf %&gt;%\n    filter(highway %in% c(\"motorway\", \"trunk\", \"primary\", \"secondary\", \"tertiary\", \"unclassified\",\n                          \"residential\", \"service\")) %&gt;%\n    select(highway, osm_id, osm_type, geometry)\n\n\n\n\nwrite_rds(road_sf, \"data/rds/road_sf.rds\")\n\nTo retrieve file\n\nroad_sf &lt;- read_rds(\"data/rds/road_sf.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#deriving-the-intersection-of-bmr-on-the-province-level",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#deriving-the-intersection-of-bmr-on-the-province-level",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "",
    "text": "In this step, the code chunk uses st_intersection() at the province level and saved as an RDS file.\n\nth_bmr_province &lt;- st_intersection(thadm_bmr, road_sf)\n\nFollowing the earlier steps, this will be saved as an RDS file in order to improve computational efficiency.\n\nwrite_rds(th_bmr_province, \"data/rds/th_bmr_province.rds\") \n\nTo retrieve file\n\nth_bmr_province &lt;- read_rds(\"data/rds/th_bmr_province.rds\")\n\nIn this following step, st_intersection() function is applied at the district level and saved as an RDS file.\n\nth_bmr_network &lt;- st_intersection(thadm2_bmr, th_bmr_province)\n\n\nwrite_rds(th_bmr_network,\"data/rds/th_bmr_network.rds\")\n\nTo retrieve file\n\nth_bmr_network &lt;- read_rds(\"data/rds/th_bmr_network.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#exploratory-data-analysis-eda",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#exploratory-data-analysis-eda",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "",
    "text": "We will proceed to do some initial visualisation of the data to get a better sense of the accident data.\nThe barplot while not classified under as a spatial EDA kick-starts the EDA process.\n\nggplot(rdacc_sf_bmr, aes(x = province_en)) +\n  geom_bar(fill = \"salmon\", color = \"black\", bins = 20) +\n  geom_text(stat = \"count\", aes(label = after_stat(count)), vjust = -0.5) +\n  labs(title = \"Count of Accidents by Province within BMR\",\n       x = \"Province\",\n       y = \"Count of Accidents\")\n\n\n\n\n\n\n\n\nFrom the barplot it can be observed that out of the 6 provinces in the BMR, Bangkok has the highest count of accidents followed by Samut Prakan and Pathum Thani.\n\n\n\nThe elements of tmap are utilised in the code chunk below to plat a cartographic map to supplement the initial observations in the bar plot.\nMaking use of the view mode it presents details for each accident point in the BMR, stating the presumed_cause, accident_type, weather and road conditions as well as shown in a snippet below.\nSnapshot of an accident point\n\ntmap_mode(\"plot\")\n\ntm_shape(thadm2_bmr) +\n  tm_borders(alpha = 1, col = \"black\") +\n  tm_fill(\"ADM1_EN\") +\n  \ntm_shape(rdacc_sf_bmr) +\n  tm_dots(col = \"darkred\", alpha = 0.5, size = 0.05) +\n  tm_layout(frame = FALSE) +\n  tm_compass(type = \"4star\", size = 2)\n\n\n\n\n\n\n\n\nBased on the plot above, some observations can be inferred from the map visual where accidents tend to be more concentrated in the provinces of Bangkok, Samut Prakan and Pathum Thani.\n\n\n\nA series of time factors ranging from years to hours are also shown in relation to accident occurences.\n\nYearsMonthsDaysHours\n\n\n\nggplot(rdacc_sf_bmr, aes(x = Year)) +\n  geom_bar(fill = \"blue\", color = \"black\") +\n labs(x = \"Month\", y = \"Count\", title = \"Barplot of Accidents in BMR across Years\")\n\n\n\n\n\n\n\n\nBased on the year observations the accidents seem relatively even with the exception of year 2022 surpassing a 3500 accident count.\n\n\n\nggplot(rdacc_sf_bmr, aes(x = Month_fac)) +\n  geom_bar(fill = \"blue\", color = \"black\") +\n labs(x = \"Month\", y = \"Count\", title = \"Barplot of Accidents in BMR across Months\")\n\n\n\n\n\n\n\n\nFor a month period, we can observe that the Months of January, April, October and December stand out amongst the rest of the months. A simple explanation could be:\n\nJanuary (New Year celebrations, Chinese New Year)\nApril (Songkran)\nOctober (Festivals - King Chulalongkorn Day etc. or Increasing tourist visits in Q4)\nDecember (Chrismas and End of Year celebrations)\n\nNote that this are some assumptions based on occurring events/festivals that occur in Thailand.\n\n\n\nggplot(rdacc_sf_bmr, aes(x = Dayofweek)) +\n  geom_bar(fill = \"blue\", color = \"black\") +\n labs(x = \"Month\", y = \"Count\", title = \"Barplot of Accidents in BMR across Days\")\n\n\n\n\n\n\n\n\n\n\n\nggplot(rdacc_sf_bmr, aes(x = Hour_of_day)) +\n  geom_bar(fill = \"blue\", color = \"black\") +\n labs(x = \"Hour of Day\", y = \"Count\", title = \"Barplot of Accidents in BMR across 24 hours\")\n\n\n\n\n\n\n\n\nHigher occurence of accidents occuring during the following hours:\n\n7am - 11am\n1pm - 4pm\n7pm"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#geospatial-analysis",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#geospatial-analysis",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "",
    "text": "Moving to geospatial analysis, the packages require the input geospatial data in sp’s Spatial* classes. In this section, simple feature data frame will be converted to sp’s Spatial* class.\n\n\nThe code chunk below uses as_Spatial() of sf package to convert the geospatial data from simple feature data frame to sp’s Spatial class.\n\nbmr_accidents &lt;- as_Spatial(rdacc_sf_bmr)\nbmr &lt;- as_Spatial(thadm_bmr)\n\nDisplaying the information of the Spatial* classes as shown in the code chunk below.\n\nbmr_accidents\n\nclass       : SpatialPointsDataFrame \nfeatures    : 12986 \nextent      : 591277.5, 710166.1, 1486846, 1576520  (xmin, xmax, ymin, ymax)\ncrs         : +proj=utm +zone=47 +datum=WGS84 +units=m +no_defs \nvariables   : 22\nnames       : acc_code, incident_datetime, report_datetime,   province_th,  province_en,                           agency,                                       route,         vehicle_type,        presumed_cause,                    accident_type, number_of_vehicles_involved, number_of_fatalities, number_of_injuries, weather_condition,           road_description, ... \nmin values  :   571882,        1546309500,      1546311900,  กรุงเทพมหานคร,      Bangkok,           department of highways,        เชื่อมทางหลวงท้องถิ่นบางเสาธง - บ้านช้างตาย, 4-wheel pickup truck,    abrupt lane change, collision at intersection corner,                           0,                    0,                  0,             clear, connecting to private area, ... \nmax values  :  7570954,        1672528260,      1674726540,      สมุทรสาคร, Samut Sakhon, expressway authority of thailand,                          อุดมสุข - สมุทรปราการ,                  van, worn-out/tire blowout,     turning/retreating collision,                          12,                   13,                 51,             rainy,             y-intersection, ... \n\n\n\nbmr\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 6 \nextent      : 587893.5, 712440.5, 1484414, 1579076  (xmin, xmax, ymin, ymax)\ncrs         : +proj=utm +zone=47 +datum=WGS84 +units=m +no_defs \nvariables   : 16\nnames       :    Shape_Leng,      Shape_Area,      ADM1_EN,       ADM1_TH, ADM1_PCODE, ADM1_REF, ADM1ALT1EN, ADM1ALT2EN, ADM1ALT1TH, ADM1ALT2TH,  ADM0_EN,   ADM0_TH, ADM0_PCODE,  date, validOn, ... \nmin values  : 1.25111117749, 0.0532376597241,      Bangkok,  กรุงเทพมหานคร,       TH10,       NA,         NA,         NA,         NA,         NA, Thailand, ประเทศไทย,         TH, 17945,   19014, ... \nmax values  : 2.46303035967,  0.178914199749, Samut Sakhon,      สมุทรสาคร,       TH74,       NA,         NA,         NA,         NA,         NA, Thailand, ประเทศไทย,         TH, 17945,   19014, ... \n\n\n\n\n\n\nbmr_accidents_sp &lt;- as(bmr_accidents, \"SpatialPoints\")\n\nbmr_sp &lt;- as(bmr, \"SpatialPolygons\")\n\nDisplaying the sp objects properties as shown below.\n\nbmr_accidents_sp\n\nclass       : SpatialPoints \nfeatures    : 12986 \nextent      : 591277.5, 710166.1, 1486846, 1576520  (xmin, xmax, ymin, ymax)\ncrs         : +proj=utm +zone=47 +datum=WGS84 +units=m +no_defs \n\n\n\nbmr_sp\n\nclass       : SpatialPolygons \nfeatures    : 6 \nextent      : 587893.5, 712440.5, 1484414, 1579076  (xmin, xmax, ymin, ymax)\ncrs         : +proj=utm +zone=47 +datum=WGS84 +units=m +no_defs \n\n\n\n\n\nNext, as.ppp() function of spatstat will be used to convert the spatial data into spatstat’s ppp object format.\n\nbmr_accidents_ppp &lt;- as.ppp(rdacc_sf_bmr)\n\nbmr_accidents_ppp\n\nMarked planar point pattern: 12986 points\nmarks are numeric, of storage type  'double'\nwindow: rectangle = [591277.5, 710166.1] x [1486845.7, 1576520.5] units\n\n\n\nplot(bmr_accidents_ppp)\n\n\n\n\n\n\n\n\nUsing the summary() function allows a preview of the summary statistics of the newly created ppp object.\n\nsummary(bmr_accidents_ppp)\n\nMarked planar point pattern:  12986 points\nAverage intensity 1.218049e-06 points per square unit\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 571882 3788970 3834532 4314457 6092694 7570954 \n\nWindow: rectangle = [591277.5, 710166.1] x [1486845.7, 1576520.5] units\n                    (118900 x 89670 units)\nWindow area = 10661300000 square units\n\n\n\n\nBefore any further evaluation, the ppp object will be checked for duplicates using the code chunk below.\n\nany(duplicated(bmr_accidents_ppp))\n\n[1] FALSE\n\n\nUpon running the code chunk it gives a result of FALSE indicating no duplicated observations.\nTo count the number of co-incidence points, the multiplicity() function will be used as shown in the code chunk below.\n\nmultiplicity(bmr_accidents_ppp)\n\n    [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n   [37] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n   [73] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [109] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [145] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [181] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [217] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [253] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [289] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [325] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [361] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [397] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [433] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [469] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [505] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [541] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [577] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [613] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [649] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [685] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [721] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [757] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [793] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [829] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [865] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [901] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [937] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [973] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [1009] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [1045] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [1081] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [1117] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [1153] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [1189] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [1225] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [1261] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [1297] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [1333] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [1369] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [1405] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [1441] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [1477] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [1513] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [1549] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [1585] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [1621] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [1657] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [1693] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [1729] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [1765] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [1801] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [1837] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [1873] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [1909] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [1945] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [1981] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [2017] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [2053] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [2089] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [2125] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [2161] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [2197] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [2233] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [2269] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [2305] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [2341] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [2377] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [2413] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [2449] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [2485] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [2521] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [2557] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [2593] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [2629] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [2665] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [2701] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [2737] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [2773] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [2809] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [2845] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [2881] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [2917] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [2953] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [2989] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [3025] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [3061] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [3097] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [3133] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [3169] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [3205] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [3241] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [3277] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [3313] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [3349] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [3385] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [3421] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [3457] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [3493] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [3529] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [3565] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [3601] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [3637] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [3673] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [3709] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [3745] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [3781] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [3817] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [3853] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [3889] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [3925] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [3961] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [3997] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [4033] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [4069] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [4105] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [4141] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [4177] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [4213] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [4249] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [4285] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [4321] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [4357] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [4393] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [4429] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [4465] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [4501] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [4537] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [4573] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [4609] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [4645] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [4681] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [4717] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [4753] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [4789] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [4825] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [4861] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [4897] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [4933] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [4969] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [5005] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [5041] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [5077] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [5113] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [5149] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [5185] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [5221] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [5257] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [5293] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [5329] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [5365] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [5401] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [5437] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [5473] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [5509] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [5545] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [5581] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [5617] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [5653] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [5689] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [5725] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [5761] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [5797] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [5833] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [5869] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [5905] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [5941] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [5977] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [6013] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [6049] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [6085] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [6121] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [6157] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [6193] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [6229] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [6265] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [6301] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [6337] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [6373] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [6409] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [6445] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [6481] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [6517] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [6553] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [6589] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [6625] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [6661] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [6697] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [6733] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [6769] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [6805] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [6841] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [6877] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [6913] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [6949] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [6985] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [7021] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [7057] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [7093] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [7129] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [7165] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [7201] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [7237] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [7273] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [7309] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [7345] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [7381] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [7417] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [7453] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [7489] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [7525] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [7561] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [7597] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [7633] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [7669] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [7705] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [7741] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [7777] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [7813] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [7849] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [7885] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [7921] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [7957] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [7993] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [8029] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [8065] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [8101] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [8137] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [8173] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [8209] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [8245] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [8281] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [8317] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [8353] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [8389] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [8425] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [8461] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [8497] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [8533] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [8569] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [8605] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [8641] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [8677] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [8713] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [8749] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [8785] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [8821] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [8857] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [8893] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [8929] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [8965] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [9001] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [9037] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [9073] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [9109] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [9145] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [9181] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [9217] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [9253] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [9289] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [9325] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [9361] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [9397] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [9433] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [9469] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [9505] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [9541] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [9577] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [9613] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [9649] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [9685] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [9721] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [9757] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [9793] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [9829] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [9865] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [9901] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [9937] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [9973] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[10009] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[10045] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[10081] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[10117] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[10153] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[10189] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[10225] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[10261] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[10297] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[10333] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[10369] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[10405] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[10441] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[10477] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[10513] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[10549] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[10585] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[10621] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[10657] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[10693] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[10729] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[10765] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[10801] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[10837] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[10873] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[10909] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[10945] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[10981] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[11017] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[11053] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[11089] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[11125] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[11161] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[11197] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[11233] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[11269] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[11305] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[11341] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[11377] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[11413] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[11449] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[11485] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[11521] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[11557] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[11593] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[11629] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[11665] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[11701] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[11737] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[11773] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[11809] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[11845] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[11881] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[11917] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[11953] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[11989] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[12025] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[12061] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[12097] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[12133] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[12169] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[12205] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[12241] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[12277] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[12313] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[12349] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[12385] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[12421] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[12457] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[12493] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[12529] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[12565] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[12601] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[12637] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[12673] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[12709] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[12745] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[12781] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[12817] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[12853] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[12889] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[12925] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[12961] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n\n\nFollowing which to know how many locations have more than one point event, the code chunk below can be used.\n\nsum(multiplicity(bmr_accidents_ppp) &gt; 1)\n\n[1] 0\n\n\nThe output shows that there 0 duplicated point events.\nThe code chunk below is used to view the point events and plot the rdacc_sf_bmr data with the code chunk below.\n\ntmap_mode(\"plot\")\ntm_shape(rdacc_sf_bmr) +\n  tm_dots(alpha = 0.5,\n          size = 0.05)\n\n\n\n\n\n\n\n\nAdditionally, the code chunk below is used to plot a map to show spatial patterns of the accidents.\n\ntm_shape(thadm_bmr) +\n  tm_polygons() +\ntm_shape(thadm2_bmr) +\n  tm_polygons() +\ntm_shape(rdacc_sf_bmr)+\n  tm_dots()\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn the next step of spatial point patterns analysis, is to confine the analysis with a geographical area (etc. like Singapore boundary) and in the case for this exercise the BMR. In spatstat, an object called owin is specially designed to help represent this polygonal region.\nThe code chunk below is used to covert bmr_sp SpatialPolygon object into owin object of spatstat and subsequently the plot with a summary() function of Base R.\n\nbmr_owin &lt;- as.owin(thadm2_bmr)\n\n\nplot(bmr_owin)\n\n\n\n\n\n\n\n\n\nsummary(bmr_owin)\n\nWindow: polygonal boundary\nsingle connected closed polygon with 13779 vertices\nenclosing rectangle: [587893.5, 712440.5] x [1484413.7, 1579076.3] units\n                     (124500 x 94660 units)\nWindow area = 7668990000 square units\nFraction of frame area: 0.65\n\n\n\n\n\nIn the final stage of geospatial data wrangling, we will extract the accident events that are located within the BMR by using the code chunk below.\nThe output object combines both the point and polygon features in one ppp object class as shown below.\n\nbmr_accidents_ppp = bmr_accidents_ppp[bmr_owin]\n\n\nsummary(bmr_accidents_ppp)\n\nMarked planar point pattern:  12986 points\nAverage intensity 1.693312e-06 points per square unit\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 571882 3788970 3834532 4314457 6092694 7570954 \n\nWindow: polygonal boundary\nsingle connected closed polygon with 13779 vertices\nenclosing rectangle: [587893.5, 712440.5] x [1484413.7, 1579076.3] units\n                     (124500 x 94660 units)\nWindow area = 7668990000 square units\nFraction of frame area: 0.65\n\n\nThe newly derived bmr_accidents_ppp is plotted below.\n\nplot(bmr_accidents_ppp)\n\n\n\n\n\n\n\n\n\n\n\nIn this section,first-order SPPA will be performed by using spatstat package. The kernel density estimation (KDE) layer for visualising and exploring the intensity of point processes of accident data will be derived before performing Confirmatory Spatial Point Patterns Analysis by using Nearest Neighbour statistics.\n\n\n\nThe computation of kernel density estimation (KDE) of accident spots in BMR. The code chunk below computeskernel density by using the following configurations of density() of spatstat:\n\n\n\n\n\n\nNote\n\n\n\n\nbw.diggle() automatic bandwidth selection method. Primarily because the primary focus is identifying detailed accident hotspots, where fine-scale resolution is important, bw.diggle() is a solid choice since it provides more granular bandwidth selection, allowing for the identification of localized patterns in the data.\nThe smoothing kernel used is gaussian, which is the default. Other smoothing methods are: “epanechnikov”, “quartic” or “disc”.\n\n\n\n\nkde_bmr_accidents_bw &lt;- density(bmr_accidents_ppp,\n                                sigma = bw.diggle,\n                                edge = TRUE,\n                                kernel = \"gaussian\")\nplot(kde_bmr_accidents_bw)\n\n\n\n\n\n\n\n\nFrom the plot, we can observe that the output range from 0 to 0.00015 which are too small to comprehend. This due to the unit of measurement in metres, implying that the density values computed is in the unit of “number of points per square meter”.\nCode chunk below retrieves the bandwidth used to compute the kde layer.\n\nbw &lt;- bw.diggle(bmr_accidents_ppp)\nbw\n\n   sigma \n13.41546 \n\n\n\n\nThe rescale.ppp() function of the spatstat package is then used to convert the unit of measurement from metres to kilometres.\n\nbmr_accidents_ppp.km &lt;- rescale.ppp(bmr_accidents_ppp, 1000, \"km\")\n\nUpon rescaling, the density() can be re-run with the rescaled data and plotting the output again.\n\nkde_bmr_accidents.bw &lt;- density(bmr_accidents_ppp.km,\n                                sigma = bw.diggle,\n                                edge = TRUE,\n                                kernel = \"gaussian\")\nplot(kde_bmr_accidents.bw)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNotice that the output plot is identical to the earlier version, the only changes are the data values in the legend.\n\n\n\n\n\n\n\n\nIn this section, the KDE layer will be computed with a bandwidth of 1000 metres.\n\nIn the code chunk below, the sigma value used is 1 as the unit of measurement for bmr_accidents_ppp.km is in kilometres. (e.g. 1000m = 1km)\n\n\nkde_bmr_accidents_1 &lt;- density(bmr_accidents_ppp.km,\n                               sigma=1,\n                               edge=TRUE,\n                               kernel=\"gaussian\")\nplot(kde_bmr_accidents_1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n\nThe plot seems to highlight several concentrated accident hotspots along major roads and highways. This fine-level resolution will further aid in identifying detailed spatial trends in accident occurrences, which is important for urban traffic management.\nThe next steps involve validating these findings with confirmatory spatial analysis (such as nearest neighbour statistics) or possibly further refining bandwidth selection to ensure that hotspots are accurately represented across various road types or urban zones.\n\n\n\n\n\n\nWith how the plot seems to show concentrated accident hotspots, due to how a fixed bandwidth method is very sensitive to highly skewed distribution of spatial point patterns over geographical units for example urban versus rural.\nOne way to overcome this problem is by using adaptive bandwidth instead. In this section, adaptive kernel density estimation will be derived by using density.adaptive()of spatstat.\n\nkde_bmr_accidents_adaptive &lt;- adaptive.density(bmr_accidents_ppp.km,\n                                               method=\"kernel\")\n\n\nplot(kde_bmr_accidents_adaptive)\n\n\n\n\n\n\n\n\nComparing the fixed and adaptive kernel density estimation outputs by using the code chunk below:\n\npar(mfrow=c(1,2))\nplot(kde_bmr_accidents.bw, main = \"Fixed bandwidth\")\nplot(kde_bmr_accidents_adaptive, main = \"Adaptive bandwidth\")\n\n\n\n\n\n\n\n\n\n\nNext, the gridded kernel density objects will be converted into RasterLayer object by using raster() of raster package.\n\nkde_bmr_accidents_bw_raster &lt;- raster(kde_bmr_accidents.bw)\n\nkde_bmr_accidents_bw_raster # Checking the properties of the RasterLayer\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.973023, 0.7395512  (x, y)\nextent     : 587.8935, 712.4405, 1484.414, 1579.076  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : layer \nvalues     : -4.760739e-14, 233.4629  (min, max)\n\n\nFrom the results, the CRS property is stated as NA.\n\n\n\nCode chunk below will be used to include the CRS information on kde_bmr_accidents_bw_raster RasterLayer.\n\nprojection(kde_bmr_accidents_bw_raster) &lt;- CRS(\"+init=EPSG:32647\")\nkde_bmr_accidents_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.973023, 0.7395512  (x, y)\nextent     : 587.8935, 712.4405, 1484.414, 1579.076  (xmin, xmax, ymin, ymax)\ncrs        : +proj=utm +zone=47 +datum=WGS84 +units=m +no_defs \nsource     : memory\nnames      : layer \nvalues     : -4.760739e-14, 233.4629  (min, max)\n\n\n\ntm_shape(kde_bmr_accidents_bw_raster) + \n  tm_raster(\"layer\", palette = \"viridis\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)\n\n\n\n\n\n\n\n\n\nbk &lt;- thadm2_bmr %&gt;%\n  filter(ADM1_EN == \"Bangkok\")\nsp &lt;- thadm2_bmr %&gt;%\n  filter(ADM1_EN == \"Samut Prakan\")\npt &lt;- thadm2_bmr %&gt;%\n  filter(ADM1_EN == \"Pathum Thani\")\nnp &lt;- thadm2_bmr %&gt;%\n  filter(ADM1_EN == \"Nakhon Pathom\")\nss &lt;- thadm2_bmr %&gt;%\n  filter(ADM1_EN == \"Samut Sakhon\")\nnt &lt;- thadm2_bmr %&gt;%\n  filter(ADM1_EN == \"Nonthaburi\")\n\n\npar(mfrow=c(2,2))\nplot(bk, main = \"Bangkok\")\n\n\n\n\n\n\n\n\n\npar(mfrow=c(2,2))\nplot(sp, main = \"Samut Prakan\")\n\n\n\n\n\n\n\n\n\npar(mfrow=c(2,2))\nplot(pt, main = \"Pathum Thani\")\n\n\n\n\n\n\n\n\n\npar(mfrow=c(2,2))\nplot(np, main = \"Nakhon Pathom\")\n\n\n\n\n\n\n\n\n\npar(mfrow=c(3,3))\nplot(ss, main = \"Samut Sakhon\")\n\n\n\n\n\n\n\n\n\npar(mfrow=c(2,2))\nplot(nt, main = \"Nonthaburi\")\n\n\n\n\n\n\n\n\n\n\n\nSimilarly, now we will convert these sf objects into owin objects that is required by spatstat.\n\nbk_owin = as.owin(bk)\nsp_owin = as.owin(sp)\npt_owin = as.owin(pt)\nnp_owin = as.owin(np)\nss_owin = as.owin(ss)\nnt_owin = as.owin(nt)\n\n\n\n\n\nbmr_accidents_bk_ppp = bmr_accidents_ppp[bk_owin]\nbmr_accidents_sp_ppp = bmr_accidents_ppp[sp_owin]\nbmr_accidents_pt_ppp = bmr_accidents_ppp[pt_owin]\nbmr_accidents_np_ppp = bmr_accidents_ppp[np_owin]\nbmr_accidents_ss_ppp = bmr_accidents_ppp[ss_owin]\nbmr_accidents_nt_ppp = bmr_accidents_ppp[nt_owin]\n\nFollowing which, rescale.ppp() function is used to transform the unit of measurement from metres to kilometres similar to what was done in the section above.\n\nbmr_accidents_bk_ppp.km = rescale.ppp(bmr_accidents_bk_ppp, 1000, \"km\")\nbmr_accidents_sp_ppp.km = rescale.ppp(bmr_accidents_sp_ppp, 1000, \"km\")\nbmr_accidents_pt_ppp.km = rescale.ppp(bmr_accidents_pt_ppp, 1000, \"km\")\nbmr_accidents_np_ppp.km = rescale.ppp(bmr_accidents_np_ppp, 1000, \"km\")\nbmr_accidents_ss_ppp.km = rescale.ppp(bmr_accidents_ss_ppp, 1000, \"km\")\nbmr_accidents_nt_ppp.km = rescale.ppp(bmr_accidents_nt_ppp, 1000, \"km\")\n\nThe code chunk below is used to plot these six study areas (provinces) within the BMR and the location of incidents of the road accidents.\n\npar(mfrow=c(2,3))\nplot(bmr_accidents_bk_ppp.km, main=\"Bangkok\")\nplot(bmr_accidents_sp_ppp.km, main=\"Samut Prakan\")\nplot(bmr_accidents_pt_ppp.km, main=\"Pathum Thani\")\nplot(bmr_accidents_np_ppp.km, main=\"Nakhon Pathom\")\nplot(bmr_accidents_ss_ppp.km, main=\"Samut Sakhon\")\nplot(bmr_accidents_nt_ppp.km, main=\"Nonthaburi\")\n\n\n\n\n\n\n\n\n\n\n\n\npar(mfrow=c(2,3))\nplot(density(bmr_accidents_bk_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n             main=\"Bangkok\")\nplot(density(bmr_accidents_sp_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n             main=\"Samut Prakan\")\nplot(density(bmr_accidents_pt_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n             main=\"Pathum Thani\")\nplot(density(bmr_accidents_np_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n             main=\"Nakhon Pathom\")\nplot(density(bmr_accidents_ss_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n             main=\"Samut Sakhon\")\nplot(density(bmr_accidents_nt_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n             main=\"Nonthaburi\")\n\n\n\n\n\n\n\n\n\n\n\nIn this section, the Clark-Evans test of aggregation for a spatial point patternv will be performed by using clarkevans.test() of statspat.\nThe test hypothesis are:\nHo = The distribution of accident spots in BMR are randomly distributed.\nH1= The distribution of accident spots in BMR are not randomly distributed.\nA 95% confidence interval will be used.\n\nclarkevans.test(bmr_accidents_ppp,\n                correction=\"none\",\n                clipregion=\"bmr_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  bmr_accidents_ppp\nR = 0.19109, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\n\n\n\n\n\n\nConclusions from the test result\n\n\n\nGiven the test result (R = 0.19109) and the very small p-value, we reject the null hypothesis (Ho) at the 95% confidence level. The conclusion is that the distribution of accident spots in BMR is not randomly distributed; instead, the accidents are significantly clustered in certain areas.\nThis suggests that accident spots in BMR are more likely to be found around other accident spots, potentially due to factors: like roads having high curves, intersections and driver behaviour of speeding and unsafe lane changing.\n\n\n\n\n\n\nBangkokSamut PrakanPathum ThaniNakhon PathomSamut SakhonNonthaburi\n\n\n\nclarkevans.test(bmr_accidents_bk_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  bmr_accidents_bk_ppp\nR = 0.12115, p-value &lt; 2.2e-16\nalternative hypothesis: two-sided\n\n\n\n\n\nclarkevans.test(bmr_accidents_sp_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  bmr_accidents_sp_ppp\nR = 0.14367, p-value &lt; 2.2e-16\nalternative hypothesis: two-sided\n\n\n\n\n\nclarkevans.test(bmr_accidents_pt_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  bmr_accidents_pt_ppp\nR = 0.24798, p-value &lt; 2.2e-16\nalternative hypothesis: two-sided\n\n\n\n\n\nclarkevans.test(bmr_accidents_np_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  bmr_accidents_np_ppp\nR = 0.28949, p-value &lt; 2.2e-16\nalternative hypothesis: two-sided\n\n\n\n\n\nclarkevans.test(bmr_accidents_ss_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  bmr_accidents_ss_ppp\nR = 0.23989, p-value &lt; 2.2e-16\nalternative hypothesis: two-sided\n\n\n\n\n\nclarkevans.test(bmr_accidents_nt_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  bmr_accidents_nt_ppp\nR = 0.38919, p-value &lt; 2.2e-16\nalternative hypothesis: two-sided\n\n\n\n\n\nFrom the test results from each province their R Values are also of very small p-value, this further helps in the analysis that we reject the null hypothesis (Ho) at the 95% confidence level. The hypothesis that the distribution of accident spots in the provinces are also not randomly distributed; instead, the accidents are significantly clustered in certain areas."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html",
    "title": "In-class Exercise 6",
    "section": "",
    "text": "Emerging Hot Spot Analysis (EHSA) is a spatio-temporal analysis method for revealing and describing how hot spot and cold spot areas evolve over time. The analysis consist of four main steps:\n\nBuilding the space-time cube ,\nUsind data to perform Getis-Ord local Gi* statistic for each bin by using an FDR correction,\nEvaluating hot and cold spot trends by using Mann-Kendall trend test,\nCategorising each study area location based on the z-score and p-value for each location with data, and with the hot spot z-score and p-value for each bin. Sieving away those that do not conform to the significance level.\n\n\n\n\n\n\npacman::p_load(sf, sfdep, tmap, plotly, tidyverse)\n\n\n\n\n\n\nHunan, a geospatial data set in ESRI shapefile format, and\nHunan_GDPPC, an attribute data set in csv format.\n\n\n\n\nIn the code chunk below, st_read() of sf package is used to import Hunan shapefile into R.\n\nhunan &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\zjho008\\ISSS626-GAA\\In-class_Ex\\In-class_Ex06\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n\nIn the code chunk below, read_csv() of readr is used to import Hunan_GDPPC.csv into R.\n\nGDPPC &lt;- read_csv(\"data/aspatial/Hunan_GDPPC.csv\")\n\nRows: 1496 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): County\ndbl (2): Year, GDPPC\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nspacetime and spacetime cubes illustrates the basic concept of spatio-temporal cube and its implementation in sfdep package.\nSpacetime cube is useful for fixed administrative boundary, planning area, planing subzone etc but not applicable for dynamic space events such as forest areas, flooding for instance.\nIn the code chunk below, spacetime() of sfdep is used to create a spatio-temporal cube.\n\nGDPPC_st &lt;- spacetime(GDPPC, hunan,  # two data files: spatial and attribute\n                      .loc_col = \"County\", # indicating which field is spatial\n                      .time_col = \"Year\") # indicating which field is the attribute\n\n\n\n\n\n\n\nNote\n\n\n\nOriginal time/date field cannot be used as it is in continuous form Hence, date has to be converted to integer or to drop away the time to have a continuous Day/Month/Year indicators.\n\n\nNext, is_spacetime_cube() of sfdep package which will be used to verify if GDPPC_st is indeed a space-time cube object.\n\nis_spacetime_cube(GDPPC_st)\n\n[1] TRUE\n\n\nThe TRUE return confirms that GDPPC_st object is indeed an time-space cube.\n\n\n\nIn this section we will compute the local Gi* statistics.\n\nGDPPC_nb &lt;- GDPPC_st %&gt;%\n  activate(\"geometry\") %&gt;% # to use the geometric layer and exclude the attributes; this line is needed before computing the weight matrix\n  \n  mutate(nb = include_self(st_contiguity(geometry)), # include_self function \n    \n# parsing tp calculate the spatial weight - using mutate to attain the two columns \n         wt = st_inverse_distance(nb, geometry,\n                                  scale = 1, \n                                  alpha = 1), # extra parameters to emphasise distance decay\n         .before = 1) %&gt;%\n  set_nbs(\"nb\") %&gt;% # for the data to be arranged in time-sequence\n  set_wts(\"wt\")\n\n! Polygon provided. Using point on surface.\n\n\nWarning: There was 1 warning in `stopifnot()`.\nℹ In argument: `wt = st_inverse_distance(nb, geometry, scale = 1, alpha = 1)`.\nCaused by warning in `st_point_on_surface.sfc()`:\n! st_point_on_surface may not give correct results for longitude/latitude data\n\n\n\nSorting should not be done after time-space cube is calculated\n\nNote that this dataset now has neighbours and weights for each time-slice.\nUsing head() function\n\nhead(GDPPC_nb)\n\nspacetime ────\n\n\nContext:`data`\n\n\n88 locations `County`\n\n\n17 time periods `Year`\n\n\n── data context ────────────────────────────────────────────────────────────────\n\n\n# A tibble: 6 × 5\n   Year County  GDPPC nb        wt       \n  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;list&gt;    &lt;list&gt;   \n1  2005 Anxiang  8184 &lt;int [6]&gt; &lt;dbl [6]&gt;\n2  2005 Hanshou  6560 &lt;int [6]&gt; &lt;dbl [6]&gt;\n3  2005 Jinshi   9956 &lt;int [5]&gt; &lt;dbl [5]&gt;\n4  2005 Li       8394 &lt;int [5]&gt; &lt;dbl [5]&gt;\n5  2005 Linli    8850 &lt;int [5]&gt; &lt;dbl [5]&gt;\n6  2005 Shimen   9244 &lt;int [6]&gt; &lt;dbl [6]&gt;\n\n\n\n\n\nNow to utilise th new columns to manually calculate the local Gi* for each location. We can do this by grouping by Year and using local_gstar_perm() of sfdep package.\nAfter which, we use unnest() to unnest gi_star column of the newly created gi_starts data.frame.\n\ngi_stars &lt;- GDPPC_nb %&gt;% \n  group_by(Year) %&gt;% \n  mutate(gi_star = local_gstar_perm(\n    GDPPC, nb, wt)) %&gt;% \n  tidyr::unnest(gi_star)\n\n\n\n\nTo perform confirmatory analysis whether there is a monotonic (meaning there is no trend) or no monotonic trend\nWith Gi* measures calculated the next step is to evaluate each location for a trend using the Mann-Kendall test. The code chunk below uses the Changsha county.\n\ncbg &lt;- gi_stars %&gt;% \n  ungroup() %&gt;% # since it is a 'cube' to filter away the other county\n  filter(County == \"Changsha\") |&gt; \n  select(County, Year, gi_star)\n\nPlotting the result by using ggplot2 functions.\n\nggplot(data = cbg, \n       aes(x = Year, \n           y = gi_star)) +\n  geom_line() +\n  theme_light()\n\n\n\n\n\n\n\n\nFrom the plot, we can are unable to interpret much as it is static.\n\n\nCreating an interactive plot by using ggplotly() of plotly package.\n\np &lt;- ggplot(data = cbg, \n       aes(x = Year, \n           y = gi_star)) +\n  geom_line() +\n  theme_light()\n\nggplotly(p)\n\n\n\n\n\nFor such a test it is advisable to have at least 10 years of data.\n\n\n\nReject the null-hypothesis null if the p-value is smaller than the alpha value (i.e. 1-confidence level)\n\n\n\nKendall package is a special package to run this calculation\n\ncbg %&gt;%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %&gt;% \n  tidyr::unnest_wider(mk)  # to generate the report\n\n# A tibble: 1 × 5\n    tau      sl     S     D  varS\n  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 0.485 0.00742    66  136.  589.\n\n\nIn the above result, sl is the p-value. This result tells us that there is a slight upward but insignificant trend.\nTo attain the p-values for some of which are closer or further away from one.\nstrong close to 1\n\n\n\nWe can replicate this for each location by using group_by() of dplyr package.\n\nehsa &lt;- gi_stars %&gt;%\n  group_by(County) %&gt;%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %&gt;%\n  tidyr::unnest_wider(mk)\n\n\nhead(ehsa)\n\n# A tibble: 6 × 6\n  County        tau        sl     S     D  varS\n  &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Anhua      0.191  0.303        26  136.  589.\n2 Anren     -0.294  0.108       -40  136.  589.\n3 Anxiang    0      1             0  136.  589.\n4 Baojing   -0.691  0.000128    -94  136.  589.\n5 Chaling   -0.0882 0.650       -12  136.  589.\n6 Changning -0.750  0.0000318  -102  136.  589.\n\n\n\n\n\nWe can also sort to show significant emerging hot/cold spots\n\nemerging &lt;- ehsa %&gt;% \n  arrange(sl, abs(tau)) %&gt;% \n  slice(1:10)\nhead(emerging)\n\n# A tibble: 6 × 6\n  County        tau         sl     S     D  varS\n  &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Shuangfeng  0.868 0.00000143   118  136.  589.\n2 Xiangtan    0.868 0.00000143   118  136.  589.\n3 Xiangxiang  0.868 0.00000143   118  136.  589.\n4 Chengbu    -0.824 0.00000482  -112  136.  589.\n5 Dongan     -0.824 0.00000482  -112  136.  589.\n6 Wugang     -0.809 0.00000712  -110  136.  589.\n\n\n\n\n\n\nLastly, we will perform EHSA analysis by using emerging_hotspot_analysis() of sfdep package.\nIt takes a spacetime object x (i.e. GDPPC_st), and the quoted name of the variable of interest (i.e. GDPPC) for .var argument. The k argument is used to specify the number of time lags which is set to 1 by default. Lastly, nsim map numbers of simulation to be performed.\n\nehsa &lt;- emerging_hotspot_analysis(\n  x = GDPPC_st, \n  .var = \"GDPPC\", \n  k = 1, \n  nsim = 99 #no of simulations is 100\n)\n\n\n\nIn the code chunk below, ggplot2 functions are used to reveal the distribution of EHSA classes using a bar chart.\n\nggplot(data = ehsa,\n       aes(x = classification)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nThe bar chart above shows that sporadic cold spots class has the highest number of counties.\n\nNote that the p-value is calculated here and some of them are not statistically significant despite the representation of the bar chart.\n\n\n\n\nIn this section, it illustrates how to visualise the geographic distribution EHSA classes. However, before we can do so, we need to join both hunan and ehsa together by using the code chunk below.\n\nhunan_ehsa &lt;- hunan %&gt;%\n  left_join(ehsa,\n            by = join_by(County == location))\n\ntmap functions are used to plot a categorical choropleth map by using the code chunk below:\n\n\nCode\nehsa_sig &lt;- hunan_ehsa  %&gt;%\n  filter(p_value &lt; 0.05)\ntmap_mode(\"plot\")\n\n\ntmap mode set to plotting\n\n\nCode\ntm_shape(hunan_ehsa) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(ehsa_sig) +\n  tm_fill(\"classification\") + \n  tm_borders(alpha = 0.4)\n\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\n\n\n\n\n\n\n\nWe can backtrack to cbg whether it is an oscillating hotspot and compare with the chart."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#installing-and-loading-the-r-packages",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#installing-and-loading-the-r-packages",
    "title": "In-class Exercise 6",
    "section": "7.1 Installing and Loading the R Packages",
    "text": "7.1 Installing and Loading the R Packages\n\npacman::p_load(sf, sfdep, tmap, plotly, tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#the-data",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#the-data",
    "title": "In-class Exercise 6",
    "section": "",
    "text": "Hunan, a geospatial data set in ESRI shapefile format, and\nHunan_GDPPC, an attribute data set in csv format."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#importing-geospatial-data",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#importing-geospatial-data",
    "title": "In-class Exercise 6",
    "section": "",
    "text": "In the code chunk below, st_read() of sf package is used to import Hunan shapefile into R.\n\nhunan &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\zjho008\\ISSS626-GAA\\In-class_Ex\\In-class_Ex06\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#importing-attribute-table",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#importing-attribute-table",
    "title": "In-class Exercise 6",
    "section": "",
    "text": "In the code chunk below, read_csv() of readr is used to import Hunan_GDPPC.csv into R.\n\nGDPPC &lt;- read_csv(\"data/aspatial/Hunan_GDPPC.csv\")\n\nRows: 1496 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): County\ndbl (2): Year, GDPPC\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "title": "Take-home Exercise 2: Geospatial Analytics in Thailand Tourism Sector (Pre, During, Post COVID-19)",
    "section": "",
    "text": "Tourism plays a significant role in Thailand’s economy, contributing about 20% of the country’s GDP. In 2019, Thailand generated 90 billion USD from both domestic and international tourism, but the COVID-19 pandemic led to a drastic drop in revenues down to 24 billion USD in 2020.\nThe figure below illustrates the total revenue from the tourism sector from January 2019 to February 2023, highlighting a gradual recovery in tourism revenue starting in September 2021.\n\nNonetheless, it is important to point out that the tourism economy of Thailand does not have an even distribution. The figures below illustrate that the tourism economy of Thailand mainly revolves around 5 provinces: Bangkok, Phuket, Chiang Mai, Sukhothai & Phetchaburi.\n\nThe main aim of this initiative is to discover the impacts of COVID-19 on Thailand’s tourism economy using spatial and spatio-temporal statistics.\n\n\nThe objectives are to explore the following:\n\nWhether the key indicators of Thailand’s tourism economy are independent of spatial and spatio-temporal factors.\nIf dependencies exist, aim to identify the clusters, outliers, and emerging hot or cold spots within the tourism economy.\n\nThe specific tasks for this exercise are:\n\nUsing appropriate sf and tidyverse functions, prepare the following geospatial data layers:\n\nA study area layer in sf polygon format, covering provinces in Thailand, including Bangkok.\nA tourism economy indicators layer for the study area in sf polygon format.\nA derived tourism economy indicator layer in the spatio-temporal s3 class of sfdep, with a monthly and yearly time series.\n\nUsing the extracted data, conduct the following analyses using sfdep methods:\n\nGlobal spatial autocorrelation analysis\nLocal spatial autocorrelation analysis\nEmerging hotspot analysis\n\nDescribe the spatial patterns identified through these analyses.\n\n\n\n\n\n\nThe following R packages will be launched into the R environment using p_load() from pacman package below.\nThe R packages needed for this exercise are as follows:\n\nSpatial data handling\n\nsf, spdep and sfdep\n\nAttribute data handling\n\ntidyverse, especially readr, ggplot2 and dplyr\n\nChoropleth mapping\n\ntmap\n\n\n\npacman::p_load(sf, spdep, sfdep,tmap,\n               tidyverse, plotly, Kendall)\nset.seed(1234) # setting seed to ensure reproducibility\n\n\n\n\n\nFor this exercise, two data sets will be utilised. They are:\n\nThailand Domestic Tourism Statistics at Kaggle.\nThailand - Subnational Administrative Boundaries at HDX. the province boundary data set is used for this exercise.\n\n\n\nThere are 2 versions of this dataset thailand_domestic_tourism_2019_2023.csv & thailand_domestic_tourism_2019_2023_ver2.csv. Version 2 will be used for this exercise. The csv file will be imported using read_csv function of readr package.\n\ntourism_stats &lt;- read_csv(\"data/aspatial/thailand_domestic_tourism_2019_2023_ver2.csv\") \n\nglimpse() is used to have a brief overview of the data. This will enable us to see the columns and their respective data types.\n\nglimpse(tourism_stats)\n\nRows: 30,800\nColumns: 7\n$ date          &lt;chr&gt; \"1 01 2019\", \"1 01 2019\", \"1 01 2019\", \"1 01 2019\", \"1 0…\n$ province_thai &lt;chr&gt; \"กรุงเทพมหานคร\", \"ลพบุรี\", \"พระนครศรีอยุธยา\", \"สระบุรี\", \"ชัยนาท…\n$ province_eng  &lt;chr&gt; \"Bangkok\", \"Lopburi\", \"Phra Nakhon Si Ayutthaya\", \"Sarab…\n$ region_thai   &lt;chr&gt; \"ภาคกลาง\", \"ภาคกลาง\", \"ภาคกลาง\", \"ภาคกลาง\", \"ภาคกลาง\", \"…\n$ region_eng    &lt;chr&gt; \"central\", \"central\", \"central\", \"central\", \"central\", \"…\n$ variable      &lt;chr&gt; \"ratio_tourist_stay\", \"ratio_tourist_stay\", \"ratio_touri…\n$ value         &lt;dbl&gt; 93.37, 61.32, 73.37, 67.33, 79.31, 71.70, 64.65, 71.21, …\n\n\n\n\nThis dataset contains statistics on tourism in Thailand from Jan 2019 to Feb 2023, broken down by province. The dataset includes information on the number of tourists, the occupancy rate, and the profits generated by tourism in each province, as well as the\nSourced from raw data provided by the Official Ministry of Tourism and Sports Statistics, which was manually entered into Excel files.\nThe author has pre-processed the data using Python with the intention of making it more accessible in the appropriate format which has the potential to provide valuable insights into the domestic tourism industry in Thailand, including trends and patterns across different provinces over time. Researchers, analysts, and policy-makers with an interest in the domestic tourism sector in Thailand may find this dataset useful for their work. Source: (Thailand Domestic Tourism Statistics by Thaweewat R)\nThe description for some of the variables have been re-phrased for a more accurate alignment of understanding in line with the variables.\n\nR Packages\n\n\n\n\n\n\nColumn\nDescription\n\n\n\n\ndate\nThe month and year in which the statistics were recorded. The dataset covers the years 2019-2023.\n\n\nprovince_thai\nThe name of the province in Thailand, in the Thai language.\n\n\nprovince_eng\nThe name of the province in Thailand, in English.\n\n\nregion_thai\nThe name of the region in Thailand to which the province belongs, in the Thai language.\n\n\nregion_eng\nThe name of the region in Thailand to which the province belongs, in English.\n\n\nvariable\nThe 8 types of data being recorded, such as the number of tourists or the occupancy rate.\n\n\n\nno_tourist_all The total number of tourists (domestic & foreign) who visited the province\n\n\n\nno_tourist_foreign The number of foreign tourists who visited the province\n\n\n\nno_tourist_thai The number of Thai tourists (domestic) who visited the province\n\n\n\nno_tourist_occupied -&gt; no_tourist_stay The total number of occupied hotel rooms in the province\n\n\n\noccupancy_rate -&gt; ratio_tourist_stay The percentage of occupied travel accommodation in the province\n\n\n\nrevenue_all The revenue generated by the tourism industry in the province, in Thai Baht\n\n\n\nrevenue_foreign The revenue generated by foreign tourists in the province, in Thai Baht\n\n\n\nrevenue_thai The revenue generated by Thai tourists in the province, in Thai Baht\n\n\nvalue\nThe value of the data being recorded.\n\n\n\nFrom the description above, we can identify the columns to be selected for analysis. For this exercise, the columns: date, province_eng, variable and value will be selected.\n\n\n\nThe two following code chunks are utilised to check for any duplicated or missing values in each column\n\nany(duplicated(tourism_stats))\n\n[1] FALSE\n\n\n\nsum(is.na(tourism_stats))\n\n[1] 0\n\n\nThe results above tell us that there are no duplicated and missing values.\n\n\n\nThe relevant columns that will be used for analysis are then selected using the code chunk below.Additionally, the province_eng column will be renamed to province since we are only taking this particular column and not the column labelled province_thai.\n\ntourism_stats_selected &lt;- tourism_stats %&gt;%\n  select(date, province_eng, variable, value) %&gt;%\n  rename(province = province_eng)\n\n\n# Grouping by province and year, then summarizing total tourist count\ntourism_stats_grouped &lt;- tourism_stats %&gt;%\n  group_by(province_eng, variable) %&gt;%\n  rename(province = province_eng) %&gt;%\n  summarise(total_value = sum(value, na.rm = TRUE))\n\n\n\n\nExploratory data analysis (EDA) will be carried out in this section using statistical graphic functions of ggplot2 package. The variables are plotted to get a sense of the distribution.\n\n\n\ntourism_stats_selected %&gt;%\n  filter(variable == \"revenue_all\") %&gt;% \n  ggplot(aes(value,fill = variable)) +\n  geom_histogram(bins = 20) +\n  theme(legend.position=\"none\")\n\n\n\n\n\n\n\n\nIt can be observed that the revenue generated by tourism is right skewed as such in can also be interpreted that a number of provinces are the ones generating majority of the revenue for Thailand’s tourism.\n\nDomestic TourismForeign Tourism\n\n\n\ntourism_stats_selected %&gt;%\n  filter(variable == \"revenue_thai\") %&gt;% \n  ggplot(aes(value,fill = variable)) +\n  geom_histogram(bins = 20) +\n  theme(legend.position=\"none\")\n\n\n\n\n\n\n\n\n\n\n\ntourism_stats_selected %&gt;%\n  filter(variable == \"revenue_foreign\") %&gt;% \n  ggplot(aes(value,fill = variable)) +\n  geom_histogram(bins = 20) +\n  theme(legend.position=\"none\")\n\n\n\n\n\n\n\n\n\n\n\nSimilarly, when looking at domestic and foreign tourism revenue individually the plots are also showing a right skew.\n\n\n\n\ntourism_stats_selected %&gt;%\n  filter(variable == \"ratio_tourist_stay\") %&gt;% \n  ggplot(aes(value,fill = variable)) +\n  geom_histogram(bins = 20) +\n  theme(legend.position=\"none\")\n\n\n\n\n\n\n\n\n\n\n\n\ntourism_stats_selected %&gt;%\n  filter(variable == \"no_tourist_all\") %&gt;% \n  ggplot(aes(value,fill = variable)) +\n  geom_histogram(bins = 20) +\n  theme(legend.position=\"none\")\n\n\n\n\n\n\n\n\nFrom the above histogram plots, the variables of revenue generated by tourism and total number of tourists are right-skewed which can be interpreted as the vast majority of data points being concentrated near zero. This is indeed consistent with the table shown in the overview where a few provinces in Thailand dominate tourist visits and revenue while most of the other provinces contribute less.\nFor ratio_tourist_stay the histogram appears to be relatively symmetric with a slight skew to the right.\n\n\n\n\n\nThe code chunk below is used to import the Sub-national Administrative Boundaries of Thailand. Level 1 will be used as it represents the province boundary as seen in the HDX website.\n\n\nthadmin &lt;- st_read(dsn = \"data/geospatial\", \n                   layer = \"tha_admbnda_adm1_rtsd_20220121\")\n\nReading layer `tha_admbnda_adm1_rtsd_20220121' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Take-home_Ex\\Take-home_Ex02\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 77 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nGeodetic CRS:  WGS 84\n\n\nThe message above reveals that the geospatial objects are multi-polygon features. There are a total of 77 multipolygon feature representing the different provinces in Thailand and 16 fields in thadmin (Thailand Administrative) simple feature data frame. thadmin is in WGS84 Geodetic coordinates system. The bounding box provides the x extend and y extend of the data.\nTo learn more about the simple features object, we can apply glimpse() of dplyr package.\n\nglimpse(thadmin)\n\nRows: 77\nColumns: 17\n$ Shape_Leng &lt;dbl&gt; 2.417227, 1.695100, 1.251111, 1.884945, 3.041716, 1.739908,…\n$ Shape_Area &lt;dbl&gt; 0.13133873, 0.07926199, 0.05323766, 0.12698345, 0.21393797,…\n$ ADM1_EN    &lt;chr&gt; \"Bangkok\", \"Samut Prakan\", \"Nonthaburi\", \"Pathum Thani\", \"P…\n$ ADM1_TH    &lt;chr&gt; \"กรุงเทพมหานคร\", \"สมุทรปราการ\", \"นนทบุรี\", \"ปทุมธานี\", \"พระนครศรีอ…\n$ ADM1_PCODE &lt;chr&gt; \"TH10\", \"TH11\", \"TH12\", \"TH13\", \"TH14\", \"TH15\", \"TH16\", \"TH…\n$ ADM1_REF   &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ ADM1ALT1EN &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ ADM1ALT2EN &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ ADM1ALT1TH &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ ADM1ALT2TH &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ ADM0_EN    &lt;chr&gt; \"Thailand\", \"Thailand\", \"Thailand\", \"Thailand\", \"Thailand\",…\n$ ADM0_TH    &lt;chr&gt; \"ประเทศไทย\", \"ประเทศไทย\", \"ประเทศไทย\", \"ประเทศไทย\", \"ประเทศ…\n$ ADM0_PCODE &lt;chr&gt; \"TH\", \"TH\", \"TH\", \"TH\", \"TH\", \"TH\", \"TH\", \"TH\", \"TH\", \"TH\",…\n$ date       &lt;date&gt; 2019-02-18, 2019-02-18, 2019-02-18, 2019-02-18, 2019-02-18…\n$ validOn    &lt;date&gt; 2022-01-22, 2022-01-22, 2022-01-22, 2022-01-22, 2022-01-22…\n$ validTo    &lt;date&gt; -001-11-30, -001-11-30, -001-11-30, -001-11-30, -001-11-30…\n$ geometry   &lt;MULTIPOLYGON [°]&gt; MULTIPOLYGON (((100.6139 13..., MULTIPOLYGON (…\n\n\n\n\nFor ease of reference similar to what was done with the attribute data, ADM1_EN is renamed to province.\n\nthadmin &lt;- thadmin %&gt;%\n  rename(province = ADM1_EN)\n\n\n\n\nIn this step, st_crs() function of the sf package will be utilised to check the CRS information. If the CRS is not reflecting 32647, the EPSG code of Thailand st_transform() function can be used to transform the EPSG code.\n\n\n\n\n\n\nNote\n\n\n\nThe projected coordinate system of Thailand is WGS 84 / UTM zone 47N and the EPSG code is 32647.\n\n\n\nst_crs(thadmin)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\nFrom the results above, we can see that the EPSG is 4326. Hence, st_transform() will be used to perform transformation.\n\nthadmin &lt;- st_transform(thadmin, crs =32647)\n\nst_crs() will be used for confirmation if the transformation has been done correctly.\n\nst_crs(thadmin)\n\nCoordinate Reference System:\n  User input: EPSG:32647 \n  wkt:\nPROJCRS[\"WGS 84 / UTM zone 47N\",\n    BASEGEOGCRS[\"WGS 84\",\n        ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n            MEMBER[\"World Geodetic System 1984 (Transit)\"],\n            MEMBER[\"World Geodetic System 1984 (G730)\"],\n            MEMBER[\"World Geodetic System 1984 (G873)\"],\n            MEMBER[\"World Geodetic System 1984 (G1150)\"],\n            MEMBER[\"World Geodetic System 1984 (G1674)\"],\n            MEMBER[\"World Geodetic System 1984 (G1762)\"],\n            MEMBER[\"World Geodetic System 1984 (G2139)\"],\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ENSEMBLEACCURACY[2.0]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4326]],\n    CONVERSION[\"UTM zone 47N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",99,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Navigation and medium accuracy spatial referencing.\"],\n        AREA[\"Between 96°E and 102°E, northern hemisphere between equator and 84°N, onshore and offshore. China. Indonesia. Laos. Malaysia - West Malaysia. Mongolia. Myanmar (Burma). Russian Federation. Thailand.\"],\n        BBOX[0,96,84,102]],\n    ID[\"EPSG\",32647]]\n\n\n\n\n\n\nColumn 3 (province) and 17 (geometry) will be selected as the relevant columns.\n\nthadmin &lt;- thadmin %&gt;%\n  select(3, 17)\n\n\n\n\nUpon running through some observations with the thadmin simple feature data frame with thai_tourism it is observed that there are inconsistencies in the naming terminologies of the provinces.\n\n\nHDX_province_names &lt;- unique(thadmin$province)\nHDX_province_names\n\n [1] \"Bangkok\"                  \"Samut Prakan\"            \n [3] \"Nonthaburi\"               \"Pathum Thani\"            \n [5] \"Phra Nakhon Si Ayutthaya\" \"Ang Thong\"               \n [7] \"Lop Buri\"                 \"Sing Buri\"               \n [9] \"Chai Nat\"                 \"Saraburi\"                \n[11] \"Chon Buri\"                \"Rayong\"                  \n[13] \"Chanthaburi\"              \"Trat\"                    \n[15] \"Chachoengsao\"             \"Prachin Buri\"            \n[17] \"Nakhon Nayok\"             \"Sa Kaeo\"                 \n[19] \"Nakhon Ratchasima\"        \"Buri Ram\"                \n[21] \"Surin\"                    \"Si Sa Ket\"               \n[23] \"Ubon Ratchathani\"         \"Yasothon\"                \n[25] \"Chaiyaphum\"               \"Amnat Charoen\"           \n[27] \"Bueng Kan\"                \"Nong Bua Lam Phu\"        \n[29] \"Khon Kaen\"                \"Udon Thani\"              \n[31] \"Loei\"                     \"Nong Khai\"               \n[33] \"Maha Sarakham\"            \"Roi Et\"                  \n[35] \"Kalasin\"                  \"Sakon Nakhon\"            \n[37] \"Nakhon Phanom\"            \"Mukdahan\"                \n[39] \"Chiang Mai\"               \"Lamphun\"                 \n[41] \"Lampang\"                  \"Uttaradit\"               \n[43] \"Phrae\"                    \"Nan\"                     \n[45] \"Phayao\"                   \"Chiang Rai\"              \n[47] \"Mae Hong Son\"             \"Nakhon Sawan\"            \n[49] \"Uthai Thani\"              \"Kamphaeng Phet\"          \n[51] \"Tak\"                      \"Sukhothai\"               \n[53] \"Phitsanulok\"              \"Phichit\"                 \n[55] \"Phetchabun\"               \"Ratchaburi\"              \n[57] \"Kanchanaburi\"             \"Suphan Buri\"             \n[59] \"Nakhon Pathom\"            \"Samut Sakhon\"            \n[61] \"Samut Songkhram\"          \"Phetchaburi\"             \n[63] \"Prachuap Khiri Khan\"      \"Nakhon Si Thammarat\"     \n[65] \"Krabi\"                    \"Phangnga\"                \n[67] \"Phuket\"                   \"Surat Thani\"             \n[69] \"Ranong\"                   \"Chumphon\"                \n[71] \"Songkhla\"                 \"Satun\"                   \n[73] \"Trang\"                    \"Phatthalung\"             \n[75] \"Pattani\"                  \"Yala\"                    \n[77] \"Narathiwat\"              \n\n\n\nkaggle_province_names &lt;- unique(tourism_stats_grouped$province)\nkaggle_province_names\n\n [1] \"Amnat Charoen\"            \"Ang Thong\"               \n [3] \"Bangkok\"                  \"Bueng Kan\"               \n [5] \"Buriram\"                  \"Chachoengsao\"            \n [7] \"Chainat\"                  \"Chaiyaphum\"              \n [9] \"Chanthaburi\"              \"Chiang Mai\"              \n[11] \"Chiang Rai\"               \"Chonburi\"                \n[13] \"Chumphon\"                 \"Kalasin\"                 \n[15] \"Kamphaeng Phet\"           \"Kanchanaburi\"            \n[17] \"Khon Kaen\"                \"Krabi\"                   \n[19] \"Lampang\"                  \"Lamphun\"                 \n[21] \"Loei\"                     \"Lopburi\"                 \n[23] \"Mae Hong Son\"             \"Maha Sarakham\"           \n[25] \"Mukdahan\"                 \"Nakhon Nayok\"            \n[27] \"Nakhon Pathom\"            \"Nakhon Phanom\"           \n[29] \"Nakhon Ratchasima\"        \"Nakhon Sawan\"            \n[31] \"Nakhon Si Thammarat\"      \"Nan\"                     \n[33] \"Narathiwat\"               \"Nong Bua Lamphu\"         \n[35] \"Nong Khai\"                \"Nonthaburi\"              \n[37] \"Pathum Thani\"             \"Pattani\"                 \n[39] \"Phang Nga\"                \"Phatthalung\"             \n[41] \"Phayao\"                   \"Phetchabun\"              \n[43] \"Phetchaburi\"              \"Phichit\"                 \n[45] \"Phitsanulok\"              \"Phra Nakhon Si Ayutthaya\"\n[47] \"Phrae\"                    \"Phuket\"                  \n[49] \"Prachinburi\"              \"Prachuap Khiri Khan\"     \n[51] \"Ranong\"                   \"Ratchaburi\"              \n[53] \"Rayong\"                   \"Roi Et\"                  \n[55] \"Sa Kaeo\"                  \"Sakon Nakhon\"            \n[57] \"Samut Prakan\"             \"Samut Sakhon\"            \n[59] \"Samut Songkhram\"          \"Saraburi\"                \n[61] \"Satun\"                    \"Sing Buri\"               \n[63] \"Sisaket\"                  \"Songkhla\"                \n[65] \"Sukhothai\"                \"Suphan Buri\"             \n[67] \"Surat Thani\"              \"Surin\"                   \n[69] \"Tak\"                      \"Trang\"                   \n[71] \"Trat\"                     \"Ubon Ratchathani\"        \n[73] \"Udon Thani\"               \"Uthai Thani\"             \n[75] \"Uttaradit\"                \"Yala\"                    \n[77] \"Yasothon\"                \n\n\n\nR Packages {.striped .hover tbl-colwidths=“[25,75]”} Nong Bua Lam Phu\n\n\ntourism_stats\nthadmin\n\n\n\n\nLopburi\nLop Buri\n\n\nChainat\nChai Nat\n\n\nChonburi\nChon Buri\n\n\nPrachinburi\nPrachin Buri\n\n\nPhang Nga\nPhangnga\n\n\nSisaket\nSi Sa Ket\n\n\nBuriram\nBuri Ram\n\n\nNong Bua Lamphu\nNong Bua Lam Phu\n\n\n\nOn the right side of the table are the 8 provinces from thadmin that are inconsistent with the naming conventions from tourism_stats\nThe gsub() function from Base R will be used to for string substitution to modify the provinces that are not consistent. The naming convention from tourism_stats will be used.\n\n# Create a vector of old and new province names\nrename &lt;- c(\"Lopburi\", \"Chainat\", \"Chonburi\", \"Prachinburi\", \"Phang Nga\", \"Sisaket\", \"Buriram\", \"Nong Bua Lamphu\")\nold_names &lt;- c(\"Lop Buri\", \"Chai Nat\", \"Chon Buri\", \"Prachin Buri\", \"Phangnga\", \"Si Sa Ket\", \"Buri Ram\", \"Nong Bua Lam Phu\")\n\n# Loop through the old and new names and apply gsub for each replacement\nfor(i in seq_along(old_names)) {\n  thadmin$province &lt;- gsub(old_names[i], rename[i], thadmin$province)\n}\n\n# Check the updated province names\nhead(thadmin$province, n = 77)\n\n [1] \"Bangkok\"                  \"Samut Prakan\"            \n [3] \"Nonthaburi\"               \"Pathum Thani\"            \n [5] \"Phra Nakhon Si Ayutthaya\" \"Ang Thong\"               \n [7] \"Lopburi\"                  \"Sing Buri\"               \n [9] \"Chainat\"                  \"Saraburi\"                \n[11] \"Chonburi\"                 \"Rayong\"                  \n[13] \"Chanthaburi\"              \"Trat\"                    \n[15] \"Chachoengsao\"             \"Prachinburi\"             \n[17] \"Nakhon Nayok\"             \"Sa Kaeo\"                 \n[19] \"Nakhon Ratchasima\"        \"Buriram\"                 \n[21] \"Surin\"                    \"Sisaket\"                 \n[23] \"Ubon Ratchathani\"         \"Yasothon\"                \n[25] \"Chaiyaphum\"               \"Amnat Charoen\"           \n[27] \"Bueng Kan\"                \"Nong Bua Lamphu\"         \n[29] \"Khon Kaen\"                \"Udon Thani\"              \n[31] \"Loei\"                     \"Nong Khai\"               \n[33] \"Maha Sarakham\"            \"Roi Et\"                  \n[35] \"Kalasin\"                  \"Sakon Nakhon\"            \n[37] \"Nakhon Phanom\"            \"Mukdahan\"                \n[39] \"Chiang Mai\"               \"Lamphun\"                 \n[41] \"Lampang\"                  \"Uttaradit\"               \n[43] \"Phrae\"                    \"Nan\"                     \n[45] \"Phayao\"                   \"Chiang Rai\"              \n[47] \"Mae Hong Son\"             \"Nakhon Sawan\"            \n[49] \"Uthai Thani\"              \"Kamphaeng Phet\"          \n[51] \"Tak\"                      \"Sukhothai\"               \n[53] \"Phitsanulok\"              \"Phichit\"                 \n[55] \"Phetchabun\"               \"Ratchaburi\"              \n[57] \"Kanchanaburi\"             \"Suphan Buri\"             \n[59] \"Nakhon Pathom\"            \"Samut Sakhon\"            \n[61] \"Samut Songkhram\"          \"Phetchaburi\"             \n[63] \"Prachuap Khiri Khan\"      \"Nakhon Si Thammarat\"     \n[65] \"Krabi\"                    \"Phang Nga\"               \n[67] \"Phuket\"                   \"Surat Thani\"             \n[69] \"Ranong\"                   \"Chumphon\"                \n[71] \"Songkhla\"                 \"Satun\"                   \n[73] \"Trang\"                    \"Phatthalung\"             \n[75] \"Pattani\"                  \"Yala\"                    \n[77] \"Narathiwat\"              \n\n\n\n\n\nThe code chunk below is used to join the aspatial and geospatial data by using the left_join() function.\n\nthailand_tourism &lt;- left_join(thadmin,\n                              tourism_stats_grouped, by = c(\"province\" = \"province\"))\n\n\n\n\nIn the following code chunk, write_rds() of readr package is used to save the extracted attribute data thailand_tourism into an output file in rds format. The output file is saved in the rds folder.\n\nwrite_rds(thailand_tourism,\n          \"data/rds/thailand_tourism.rds\")\n\nThe saved file can then be retrieved using the code chunk below:\n\nthailand_tourism &lt;- read_rds(\"data/rds/thailand_tourism.rds\")\n\n\n\n\n\n\n\n\nA basemap will be prepared to show the distribution of the number of tourists in the provinces of Thailand.\n\nbasemap &lt;- tm_shape(thailand_tourism) +\n  tm_polygons() +\n  tm_text(\"province\", size = 0.5)\n\nbasemap\n\n\n\n\n\n\n\n\n\n\n\nall_tourists = thailand_tourism%&gt;%\n  filter(variable =='no_tourist_all')\n\nbasemap01 &lt;- tm_shape(all_tourists) +\n  tm_polygons(col = \"total_value\", palette = \"Oranges\", style='quantile') +\n  tm_text(\"province\", size = 0.5)\n\nbasemap01\n\n\n\n\n\n\n\n\n\n\n\n\nforeign_tourists = thailand_tourism%&gt;%\n  filter(variable =='no_tourist_foreign')\n\nbasemap02 &lt;- tm_shape(foreign_tourists) +\n  tm_polygons(col = \"total_value\", palette = \"Oranges\", style='quantile') +\n  tm_text(\"province\", size = 0.5)\n\nbasemap02\n\n\n\n\n\n\n\n\n\n\n\n\ndomestic_tourists = thailand_tourism%&gt;%\n  filter(variable =='no_tourist_thai')\n\nbasemap03 &lt;- tm_shape(domestic_tourists) +\n  tm_polygons(col = \"total_value\", palette = \"Oranges\", style='quantile') +\n  tm_text(\"province\", size = 0.5)\n\nbasemap03\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nall_revenue = thailand_tourism%&gt;%\n  filter(variable =='revenue_all')\n\nbasemap1 &lt;- tm_shape(all_revenue) +\n  tm_polygons(col = \"total_value\", palette = \"Greens\", style='quantile') +\n  tm_text(\"province\", size = 0.5)\n\nbasemap1\n\n\n\n\n\n\n\n\n\n\n\n\nforeign_revenue = thailand_tourism%&gt;%\n  filter(variable =='revenue_foreign')\n\nbasemap2 &lt;- tm_shape(foreign_revenue) +\n  tm_polygons(col = \"total_value\", palette = \"Greens\", style='quantile') +\n  tm_text(\"province\", size = 0.5)\n\nbasemap2\n\n\n\n\n\n\n\n\n\n\n\n\nthai_revenue = thailand_tourism%&gt;%\n  filter(variable =='revenue_thai')\n\nbasemap3 &lt;- tm_shape(thai_revenue) +\n  tm_polygons(col = \"total_value\", palette = \"Greens\", style='quantile') +\n  tm_text(\"province\", size = 0.5)\n\nbasemap3\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn this section, poly2nb() of spdep package is used to compute contiguity weight matrices for the study area.\n\n\nThe code chunk below is used to compute Queen contiguity weight matrix for revenue.\n\nRevenue Generated by TourismRevenue Generated by ForeignersRevenue Generated by Thais\n\n\n\nwm_q &lt;- poly2nb(all_revenue, queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 77 \nNumber of nonzero links: 352 \nPercentage nonzero weights: 5.93692 \nAverage number of links: 4.571429 \n1 region with no links:\n67\n2 disjoint connected subgraphs\nLink number distribution:\n\n 0  1  2  3  4  5  6  7  8  9 \n 1  1  5 17 15 17 10  5  4  2 \n1 least connected region:\n14 with 1 link\n2 most connected regions:\n29 51 with 9 links\n\n\nThe summary report above shows that there are 77 area units in Thailand which represent the provinces. There are 2 most connected area units eacah with 9 neighbours. There is only 1 area unit with only one neighbour.\nFor each polygon in our polygon object, wm_q lists all neighbouring polygons. For example, to see the neighbours for the 51 polygon in the object, type:\n\nall_revenue$province[51]\n\n[1] \"Tak\"\n\n\nThe output reveals that Polygon ID = 51 is Tak province.\nTo reveal the provinces of the nine neighbouring polygons, the code chunk will be used:\n\nall_revenue$province[c(19,20,25,28,30,31,33,35,55)]\n\n[1] \"Nakhon Ratchasima\" \"Buriram\"           \"Chaiyaphum\"       \n[4] \"Nong Bua Lamphu\"   \"Udon Thani\"        \"Loei\"             \n[7] \"Maha Sarakham\"     \"Kalasin\"           \"Phetchabun\"       \n\n\nWe can retrieve the revenue of these nine provinces by using the code chunk below.\n\nnb51 &lt;- wm_q[[51]]\nnb51 &lt;- all_revenue$total_value[nb51]\nnb51\n\n[1] 260045700000   4810760000  13421950000  14370950000  12339730000\n[6]   4098740000   4543780000   8988760000  77869050000\n\n\nThe printed output above shows that the revenue of the nine nearest neighbours based on Queen’s method are 260045700000, 4810760000, 13421950000, 14370950000, 12339730000, 4098740000, 4543780000, 8988760000 and 77869050000 respectively.\nWe can display the complete weight matrix by using str().\n\nstr(wm_q)\n\nList of 77\n $ : int [1:6] 2 3 4 15 59 60\n $ : int [1:2] 1 15\n $ : int [1:4] 1 4 5 59\n $ : int [1:6] 1 3 5 10 15 17\n $ : int [1:7] 3 4 6 7 10 58 59\n $ : int [1:4] 5 7 8 58\n $ : int [1:8] 5 6 8 10 19 25 48 55\n $ : int [1:5] 6 7 9 48 58\n $ : int [1:4] 8 48 49 58\n $ : int [1:5] 4 5 7 17 19\n $ : int [1:3] 12 13 15\n $ : int [1:2] 11 13\n $ : int [1:5] 11 12 14 15 18\n $ : int 13\n $ : int [1:8] 1 2 4 11 13 16 17 18\n $ : int [1:4] 15 17 18 19\n $ : int [1:5] 4 10 15 16 19\n $ : int [1:5] 13 15 16 19 20\n $ : int [1:8] 7 10 16 17 18 20 25 29\n $ : int [1:5] 18 19 21 29 33\n $ : int [1:4] 20 22 33 34\n $ : int [1:4] 21 23 24 34\n $ : int [1:3] 22 24 26\n $ : int [1:5] 22 23 26 34 38\n $ : int [1:4] 7 19 29 55\n $ : int [1:3] 23 24 38\n $ : int [1:3] 32 36 37\n $ : int [1:3] 29 30 31\n $ : int [1:9] 19 20 25 28 30 31 33 35 55\n $ : int [1:6] 28 29 31 32 35 36\n $ : int [1:6] 28 29 30 32 53 55\n $ : int [1:4] 27 30 31 36\n $ : int [1:5] 20 21 29 34 35\n $ : int [1:6] 21 22 24 33 35 38\n $ : int [1:6] 29 30 33 34 36 38\n $ : int [1:6] 27 30 32 35 37 38\n $ : int [1:3] 27 36 38\n $ : int [1:6] 24 26 34 35 36 37\n $ : int [1:5] 40 41 46 47 51\n $ : int [1:3] 39 41 51\n $ : int [1:7] 39 40 43 45 46 51 52\n $ : int [1:4] 43 44 52 53\n $ : int [1:5] 41 42 44 45 52\n $ : int [1:3] 42 43 45\n $ : int [1:4] 41 43 44 46\n $ : int [1:3] 39 41 45\n $ : int [1:2] 39 51\n $ : int [1:8] 7 8 9 49 50 51 54 55\n $ : int [1:5] 9 48 51 57 58\n $ : int [1:5] 48 51 52 53 54\n $ : int [1:9] 39 40 41 47 48 49 50 52 57\n $ : int [1:6] 41 42 43 50 51 53\n $ : int [1:6] 31 42 50 52 54 55\n $ : int [1:4] 48 50 53 55\n $ : int [1:7] 7 25 29 31 48 53 54\n $ : int [1:5] 57 59 60 61 62\n $ : int [1:5] 49 51 56 58 59\n $ : int [1:7] 5 6 8 9 49 57 59\n $ : int [1:7] 1 3 5 56 57 58 60\n $ : int [1:4] 1 56 59 61\n $ : int [1:3] 56 60 62\n $ : int [1:3] 56 61 63\n $ : int [1:2] 62 70\n $ : int [1:5] 65 68 71 73 74\n $ : int [1:4] 64 66 68 73\n $ : int [1:3] 65 68 69\n $ : int 0\n $ : int [1:5] 64 65 66 69 70\n $ : int [1:3] 66 68 70\n $ : int [1:3] 63 68 69\n $ : int [1:5] 64 72 74 75 76\n $ : int [1:3] 71 73 74\n $ : int [1:4] 64 65 72 74\n $ : int [1:4] 64 71 72 73\n $ : int [1:3] 71 76 77\n $ : int [1:3] 71 75 77\n $ : int [1:2] 75 76\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:77] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language poly2nb(pl = all_revenue, queen = TRUE)\n - attr(*, \"type\")= chr \"queen\"\n - attr(*, \"sym\")= logi TRUE\n\n\n\n\n\nwm_q_foreign &lt;- poly2nb(foreign_revenue, queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 77 \nNumber of nonzero links: 352 \nPercentage nonzero weights: 5.93692 \nAverage number of links: 4.571429 \n1 region with no links:\n67\n2 disjoint connected subgraphs\nLink number distribution:\n\n 0  1  2  3  4  5  6  7  8  9 \n 1  1  5 17 15 17 10  5  4  2 \n1 least connected region:\n14 with 1 link\n2 most connected regions:\n29 51 with 9 links\n\n\n\n\n\nwm_q_thais &lt;- poly2nb(thai_revenue, queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 77 \nNumber of nonzero links: 352 \nPercentage nonzero weights: 5.93692 \nAverage number of links: 4.571429 \n1 region with no links:\n67\n2 disjoint connected subgraphs\nLink number distribution:\n\n 0  1  2  3  4  5  6  7  8  9 \n 1  1  5 17 15 17 10  5  4  2 \n1 least connected region:\n14 with 1 link\n2 most connected regions:\n29 51 with 9 links\n\n\n\n\n\n\n\n\nThe code chunk below is used to compute Rook contiguity weight matrix.\n\nwm_r &lt;- poly2nb(all_revenue, queen = FALSE)\nsummary(wm_r)\n\nNeighbour list object:\nNumber of regions: 77 \nNumber of nonzero links: 352 \nPercentage nonzero weights: 5.93692 \nAverage number of links: 4.571429 \n1 region with no links:\n67\n2 disjoint connected subgraphs\nLink number distribution:\n\n 0  1  2  3  4  5  6  7  8  9 \n 1  1  5 17 15 17 10  5  4  2 \n1 least connected region:\n14 with 1 link\n2 most connected regions:\n29 51 with 9 links\n\n\n\n\n\nTo create a connectivity graph for polygons, we first need to obtain points that represent each polygon. The most common method for this is to calculate the centroids of the polygons. Using the sf package in R, the centroid for each polygon can be calculated. However, rather than simply applying st_centroid() directly on the geometry column, the coordinates of these centroids need to be extracted into a separate data frame.\nTo achieve this, a mapping function will be used to apply st_centroid() to each polygon in the geometry column. The map_dbl() function from the purrr package will be used to handle this, as it applies a function to each element of a vector and returns a vector of the same length, which can then be used for further graph construction.\nTo get our longitude values we map the st_centroid function over the geometry column of us.bound and access the longitude value through double bracket notation [[]] and 1. This allows us to get only the longitude, which is the first value in each centroid.\n\nlongitude &lt;- map_dbl(all_revenue$geometry, ~st_centroid(.x)[[1]])\n\nWe do the same for latitude with one key difference. We access the second value per each centroid with [[2]].\n\nlatitude &lt;- map_dbl(all_revenue$geometry, ~st_centroid(.x)[[2]])\n\nNow that we have latitude and longitude, we use cbind to put longitude and latitude into the same object.\n\ncoords &lt;- cbind(longitude, latitude)\n\nWe check the first few observations to see if things are formatted correctly.\n\nhead(coords)\n\n     longitude latitude\n[1,]  675514.6  1523087\n[2,]  685033.7  1503755\n[3,]  650477.2  1539777\n[4,]  681656.0  1555581\n[5,]  664627.1  1586462\n[6,]  645239.0  1617118\n\n\n\n\n\nplot(all_revenue$geometry, border=\"lightgrey\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\n\n\n\n\n\n\n\n\n\n\n\n\nplot(all_revenue$geometry, border=\"lightgrey\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\n\n\n\n\n\n\n\n\n\n\n\n\npar(mfrow=c(1,2))\nplot(all_revenue$geometry, border=\"lightgrey\", main=\"Queen Contiguity\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\nplot(all_revenue$geometry, border=\"lightgrey\", main=\"Rook Contiguity\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#personal-notes",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#personal-notes",
    "title": "Take-home Exercise 2: Geospatial Analytics for Public Good",
    "section": "",
    "text": "Data covers several years and have several attributes\ngeospatial data - high res - has small multiple islands - have to note the small islands - probably remove or have it in one of the territory\npre , during , post covid (three temporal terms) changes in revenue and other measures to be investigated.\nUneven spatial distributions\nIf key indicators (multiple indicators to look out for) are independent from - space, space & time (cross sectional - pre, etc during post covid)\nIf it is indeed spatial and spatial temporal dependent\ncluster - outliers - hotspots - local moran I to detect cluster and outlier G* statistics to discover hot and cold spots.\nEmerging hotspots - have to be continuous - for 3 years, 4 years, months etc. Note for this data set what is the constraint to see the data continuously.\nsfdep - advantages -\nspacetime cube - created by sfdep\npoints below the teen birth rate is about LISA\nhave to recode the date\nRefer to hands on ex - hunan case - maybe the GPD -"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#computing-gi",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#computing-gi",
    "title": "In-class Exercise 6",
    "section": "",
    "text": "In this section we will compute the local Gi* statistics.\n\nGDPPC_nb &lt;- GDPPC_st %&gt;%\n  activate(\"geometry\") %&gt;% # to use the geometric layer and exclude the attributes; this line is needed before computing the weight matrix\n  \n  mutate(nb = include_self(st_contiguity(geometry)), # include_self function \n    \n# parsing tp calculate the spatial weight - using mutate to attain the two columns \n         wt = st_inverse_distance(nb, geometry,\n                                  scale = 1, \n                                  alpha = 1), # extra parameters to emphasise distance decay\n         .before = 1) %&gt;%\n  set_nbs(\"nb\") %&gt;% # for the data to be arranged in time-sequence\n  set_wts(\"wt\")\n\n! Polygon provided. Using point on surface.\n\n\nWarning: There was 1 warning in `stopifnot()`.\nℹ In argument: `wt = st_inverse_distance(nb, geometry, scale = 1, alpha = 1)`.\nCaused by warning in `st_point_on_surface.sfc()`:\n! st_point_on_surface may not give correct results for longitude/latitude data\n\n\n\nSorting should not be done after time-space cube is calculated\n\nNote that this dataset now has neighbours and weights for each time-slice.\nUsing head() function\n\nhead(GDPPC_nb)\n\nspacetime ────\n\n\nContext:`data`\n\n\n88 locations `County`\n\n\n17 time periods `Year`\n\n\n── data context ────────────────────────────────────────────────────────────────\n\n\n# A tibble: 6 × 5\n   Year County  GDPPC nb        wt       \n  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;list&gt;    &lt;list&gt;   \n1  2005 Anxiang  8184 &lt;int [6]&gt; &lt;dbl [6]&gt;\n2  2005 Hanshou  6560 &lt;int [6]&gt; &lt;dbl [6]&gt;\n3  2005 Jinshi   9956 &lt;int [5]&gt; &lt;dbl [5]&gt;\n4  2005 Li       8394 &lt;int [5]&gt; &lt;dbl [5]&gt;\n5  2005 Linli    8850 &lt;int [5]&gt; &lt;dbl [5]&gt;\n6  2005 Shimen   9244 &lt;int [6]&gt; &lt;dbl [6]&gt;"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#computing-gi-1",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#computing-gi-1",
    "title": "In-class Exercise 6",
    "section": "",
    "text": "Now to utilise th new columns to manually calculate the local Gi* for each location. We can do this by grouping by Year and using local_gstar_perm() of sfdep package.\nAfter which, we use unnest() to unnest gi_star column of the newly created gi_starts data.frame.\n\ngi_stars &lt;- GDPPC_nb %&gt;% \n  group_by(Year) %&gt;% \n  mutate(gi_star = local_gstar_perm(\n    GDPPC, nb, wt)) %&gt;% \n  tidyr::unnest(gi_star)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#interacitve-mann-kendall-plot",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#interacitve-mann-kendall-plot",
    "title": "In-class Exercise 6",
    "section": "9.1 Interacitve Mann-Kendall Plot",
    "text": "9.1 Interacitve Mann-Kendall Plot\nCreating an interactive plot by using ggplotly() of plotly package.\n\np &lt;- ggplot(data = cbg, \n       aes(x = Year, \n           y = gi_star)) +\n  geom_line() +\n  theme_light()\n\nggplotly(p)\n\n\n\n\n\nFor such a test it is advisable to have at least 10 years of data.\n\n9.1.1 Mann-Kendall Test\nReject the null-hypothesis null if the p-value is smaller than the alpha value (i.e. 1-confidence level)\n\n\n9.1.2 Printing Mann-Kendall Test Report\nKendall package is a special package to run this calculation\n\ncbg %&gt;%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %&gt;% \n  tidyr::unnest_wider(mk)  # to generate the report\n\n# A tibble: 1 × 5\n    tau      sl     S     D  varS\n  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 0.485 0.00742    66  136.  589.\n\n\nIn the above result, sl is the p-value. This result tells us that there is a slight upward but insignificant trend.\nTo attain the p-values for some of which are closer or further away from one.\nstrong close to 1"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#mann-kendall-test-data.frame",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#mann-kendall-test-data.frame",
    "title": "In-class Exercise 6",
    "section": "9.2 Mann-Kendall test data.frame",
    "text": "9.2 Mann-Kendall test data.frame\nWe can replicate this for each location by using group_by() of dplyr package.\n\nehsa &lt;- gi_stars %&gt;%\n  group_by(County) %&gt;%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %&gt;%\n  tidyr::unnest_wider(mk)\n\n\nhead(ehsa)\n\n# A tibble: 6 × 6\n  County        tau        sl     S     D  varS\n  &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Anhua      0.191  0.303        26  136.  589.\n2 Anren     -0.294  0.108       -40  136.  589.\n3 Anxiang    0      1             0  136.  589.\n4 Baojing   -0.691  0.000128    -94  136.  589.\n5 Chaling   -0.0882 0.650       -12  136.  589.\n6 Changning -0.750  0.0000318  -102  136.  589.\n\n\n\n9.2.1 Mann-Kendall test data.frame\nWe can also sort to show significant emerging hot/cold spots\n\nemerging &lt;- ehsa %&gt;% \n  arrange(sl, abs(tau)) %&gt;% \n  slice(1:10)\nhead(emerging)\n\n# A tibble: 6 × 6\n  County        tau         sl     S     D  varS\n  &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Shuangfeng  0.868 0.00000143   118  136.  589.\n2 Xiangtan    0.868 0.00000143   118  136.  589.\n3 Xiangxiang  0.868 0.00000143   118  136.  589.\n4 Chengbu    -0.824 0.00000482  -112  136.  589.\n5 Dongan     -0.824 0.00000482  -112  136.  589.\n6 Wugang     -0.809 0.00000712  -110  136.  589."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#performing-emerging-hotspot-analysis-to-confirm-on-the-classification",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#performing-emerging-hotspot-analysis-to-confirm-on-the-classification",
    "title": "In-class Exercise 6",
    "section": "",
    "text": "Lastly, we will perform EHSA analysis by using emerging_hotspot_analysis() of sfdep package.\nIt takes a spacetime object x (i.e. GDPPC_st), and the quoted name of the variable of interest (i.e. GDPPC) for .var argument. The k argument is used to specify the number of time lags which is set to 1 by default. Lastly, nsim map numbers of simulation to be performed.\n\nehsa &lt;- emerging_hotspot_analysis(\n  x = GDPPC_st, \n  .var = \"GDPPC\", \n  k = 1, \n  nsim = 99 #no of simulations is 100\n)\n\n\n\nIn the code chunk below, ggplot2 functions are used to reveal the distribution of EHSA classes using a bar chart.\n\nggplot(data = ehsa,\n       aes(x = classification)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nThe bar chart above shows that sporadic cold spots class has the highest number of counties.\n\nNote that the p-value is calculated here and some of them are not statistically significant despite the representation of the bar chart.\n\n\n\n\nIn this section, it illustrates how to visualise the geographic distribution EHSA classes. However, before we can do so, we need to join both hunan and ehsa together by using the code chunk below.\n\nhunan_ehsa &lt;- hunan %&gt;%\n  left_join(ehsa,\n            by = join_by(County == location))\n\ntmap functions are used to plot a categorical choropleth map by using the code chunk below:\n\n\nCode\nehsa_sig &lt;- hunan_ehsa  %&gt;%\n  filter(p_value &lt; 0.05)\ntmap_mode(\"plot\")\n\n\ntmap mode set to plotting\n\n\nCode\ntm_shape(hunan_ehsa) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(ehsa_sig) +\n  tm_fill(\"classification\") + \n  tm_borders(alpha = 0.4)\n\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\n\n\n\n\n\n\n\nWe can backtrack to cbg whether it is an oscillating hotspot and compare with the chart."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#getting-started",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#getting-started",
    "title": "Take-home Exercise 2: Geospatial Analytics in Thailand Tourism Sector (Pre, During, Post COVID-19)",
    "section": "",
    "text": "The following R packages will be launched into the R environment using p_load() from pacman package below.\nThe R packages needed for this exercise are as follows:\n\nSpatial data handling\n\nsf, spdep and sfdep\n\nAttribute data handling\n\ntidyverse, especially readr, ggplot2 and dplyr\n\nChoropleth mapping\n\ntmap\n\n\n\npacman::p_load(sf, spdep, sfdep,tmap,\n               tidyverse, plotly, Kendall)\nset.seed(1234) # setting seed to ensure reproducibility"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#personal-notes-to-be-removed",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#personal-notes-to-be-removed",
    "title": "Take-home Exercise 2: Geospatial Analytics in Thailand Tourism Sector (Pre, During, Post COVID-19)",
    "section": "",
    "text": "Data covers several years and have several attributes\ngeospatial data - is in high res - has small multiple islands - have to note the small islands - probably remove or have it in one of the territory\npre , during , post covid (three temporal terms) changes in revenue and other measures to be investigated.\nUneven spatial distributions\nIf key indicators (multiple indicators to look out for) are independent from - space, space & time (cross sectional - pre, etc during post covid)\nIf it is indeed spatial and spatial temporal dependent\ncluster - outliers - hotspots - local moran I to detect cluster and outlier G* statistics to discover hot and cold spots.\nEmerging hotspots - have to be continuous - for 3 years, 4 years, months etc. Note for this data set what is the constraint to see the data continuously.\nsfdep - advantages -\nspacetime cube - created by sfdep\npoints below the teen birth rate is about LISA\nhave to recode the date\nRefer to hands on ex - hunan case - maybe the GPD -"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#getting-started",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#getting-started",
    "title": "In-class Exercise 6",
    "section": "",
    "text": "pacman::p_load(sf, sfdep, tmap, plotly, tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#creating-a-time-series-cube",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#creating-a-time-series-cube",
    "title": "In-class Exercise 6",
    "section": "",
    "text": "spacetime and spacetime cubes illustrates the basic concept of spatio-temporal cube and its implementation in sfdep package.\nSpacetime cube is useful for fixed administrative boundary, planning area, planing subzone etc but not applicable for dynamic space events such as forest areas, flooding for instance.\nIn the code chunk below, spacetime() of sfdep is used to create a spatio-temporal cube.\n\nGDPPC_st &lt;- spacetime(GDPPC, hunan,  # two data files: spatial and attribute\n                      .loc_col = \"County\", # indicating which field is spatial\n                      .time_col = \"Year\") # indicating which field is the attribute\n\n\n\n\n\n\n\nNote\n\n\n\nOriginal time/date field cannot be used as it is in continuous form Hence, date has to be converted to integer or to drop away the time to have a continuous Day/Month/Year indicators.\n\n\nNext, is_spacetime_cube() of sfdep package which will be used to verify if GDPPC_st is indeed a space-time cube object.\n\nis_spacetime_cube(GDPPC_st)\n\n[1] TRUE\n\n\nThe TRUE return confirms that GDPPC_st object is indeed an time-space cube."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#mann-kendall-test",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#mann-kendall-test",
    "title": "In-class Exercise 6",
    "section": "",
    "text": "To perform confirmatory analysis whether there is a monotonic (meaning there is no trend) or no monotonic trend\nWith Gi* measures calculated the next step is to evaluate each location for a trend using the Mann-Kendall test. The code chunk below uses the Changsha county.\n\ncbg &lt;- gi_stars %&gt;% \n  ungroup() %&gt;% # since it is a 'cube' to filter away the other county\n  filter(County == \"Changsha\") |&gt; \n  select(County, Year, gi_star)\n\nPlotting the result by using ggplot2 functions.\n\nggplot(data = cbg, \n       aes(x = Year, \n           y = gi_star)) +\n  geom_line() +\n  theme_light()\n\n\n\n\n\n\n\n\nFrom the plot, we can are unable to interpret much as it is static.\n\n\nCreating an interactive plot by using ggplotly() of plotly package.\n\np &lt;- ggplot(data = cbg, \n       aes(x = Year, \n           y = gi_star)) +\n  geom_line() +\n  theme_light()\n\nggplotly(p)\n\n\n\n\n\nFor such a test it is advisable to have at least 10 years of data.\n\n\n\nReject the null-hypothesis null if the p-value is smaller than the alpha value (i.e. 1-confidence level)\n\n\n\nKendall package is a special package to run this calculation\n\ncbg %&gt;%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %&gt;% \n  tidyr::unnest_wider(mk)  # to generate the report\n\n# A tibble: 1 × 5\n    tau      sl     S     D  varS\n  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 0.485 0.00742    66  136.  589.\n\n\nIn the above result, sl is the p-value. This result tells us that there is a slight upward but insignificant trend.\nTo attain the p-values for some of which are closer or further away from one.\nstrong close to 1\n\n\n\nWe can replicate this for each location by using group_by() of dplyr package.\n\nehsa &lt;- gi_stars %&gt;%\n  group_by(County) %&gt;%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %&gt;%\n  tidyr::unnest_wider(mk)\n\n\nhead(ehsa)\n\n# A tibble: 6 × 6\n  County        tau        sl     S     D  varS\n  &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Anhua      0.191  0.303        26  136.  589.\n2 Anren     -0.294  0.108       -40  136.  589.\n3 Anxiang    0      1             0  136.  589.\n4 Baojing   -0.691  0.000128    -94  136.  589.\n5 Chaling   -0.0882 0.650       -12  136.  589.\n6 Changning -0.750  0.0000318  -102  136.  589.\n\n\n\n\n\nWe can also sort to show significant emerging hot/cold spots\n\nemerging &lt;- ehsa %&gt;% \n  arrange(sl, abs(tau)) %&gt;% \n  slice(1:10)\nhead(emerging)\n\n# A tibble: 6 × 6\n  County        tau         sl     S     D  varS\n  &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Shuangfeng  0.868 0.00000143   118  136.  589.\n2 Xiangtan    0.868 0.00000143   118  136.  589.\n3 Xiangxiang  0.868 0.00000143   118  136.  589.\n4 Chengbu    -0.824 0.00000482  -112  136.  589.\n5 Dongan     -0.824 0.00000482  -112  136.  589.\n6 Wugang     -0.809 0.00000712  -110  136.  589."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#the-task",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#the-task",
    "title": "Take-home Exercise 2: Geospatial Analytics in Thailand Tourism Sector (Pre, During, Post COVID-19)",
    "section": "",
    "text": "The objectives are to explore the following:\n\nWhether the key indicators of Thailand’s tourism economy are independent of spatial and spatio-temporal factors.\nIf dependencies exist, aim to identify the clusters, outliers, and emerging hot or cold spots within the tourism economy.\n\nThe specific tasks for this exercise are:\n\nUsing appropriate sf and tidyverse functions, prepare the following geospatial data layers:\n\nA study area layer in sf polygon format, covering provinces in Thailand, including Bangkok.\nA tourism economy indicators layer for the study area in sf polygon format.\nA derived tourism economy indicator layer in the spatio-temporal s3 class of sfdep, with a monthly and yearly time series.\n\nUsing the extracted data, conduct the following analyses using sfdep methods:\n\nGlobal spatial autocorrelation analysis\nLocal spatial autocorrelation analysis\nEmerging hotspot analysis\n\nDescribe the spatial patterns identified through these analyses."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#the-data",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#the-data",
    "title": "Take-home Exercise 2: Geospatial Analytics in Thailand Tourism Sector (Pre, During, Post COVID-19)",
    "section": "",
    "text": "For this exercise, two data sets will be utilised. They are:\n\nThailand Domestic Tourism Statistics at Kaggle.\nThailand - Subnational Administrative Boundaries at HDX. the province boundary data set is used for this exercise.\n\n\n\nThere are 2 versions of this dataset thailand_domestic_tourism_2019_2023.csv & thailand_domestic_tourism_2019_2023_ver2.csv. Version 2 will be used for this exercise. The csv file will be imported using read_csv function of readr package.\n\ntourism_stats &lt;- read_csv(\"data/aspatial/thailand_domestic_tourism_2019_2023_ver2.csv\") \n\nglimpse() is used to have a brief overview of the data. This will enable us to see the columns and their respective data types.\n\nglimpse(tourism_stats)\n\nRows: 30,800\nColumns: 7\n$ date          &lt;chr&gt; \"1 01 2019\", \"1 01 2019\", \"1 01 2019\", \"1 01 2019\", \"1 0…\n$ province_thai &lt;chr&gt; \"กรุงเทพมหานคร\", \"ลพบุรี\", \"พระนครศรีอยุธยา\", \"สระบุรี\", \"ชัยนาท…\n$ province_eng  &lt;chr&gt; \"Bangkok\", \"Lopburi\", \"Phra Nakhon Si Ayutthaya\", \"Sarab…\n$ region_thai   &lt;chr&gt; \"ภาคกลาง\", \"ภาคกลาง\", \"ภาคกลาง\", \"ภาคกลาง\", \"ภาคกลาง\", \"…\n$ region_eng    &lt;chr&gt; \"central\", \"central\", \"central\", \"central\", \"central\", \"…\n$ variable      &lt;chr&gt; \"ratio_tourist_stay\", \"ratio_tourist_stay\", \"ratio_touri…\n$ value         &lt;dbl&gt; 93.37, 61.32, 73.37, 67.33, 79.31, 71.70, 64.65, 71.21, …\n\n\n\n\nThis dataset contains statistics on tourism in Thailand from Jan 2019 to Feb 2023, broken down by province. The dataset includes information on the number of tourists, the occupancy rate, and the profits generated by tourism in each province, as well as the\nSourced from raw data provided by the Official Ministry of Tourism and Sports Statistics, which was manually entered into Excel files.\nThe author has pre-processed the data using Python with the intention of making it more accessible in the appropriate format which has the potential to provide valuable insights into the domestic tourism industry in Thailand, including trends and patterns across different provinces over time. Researchers, analysts, and policy-makers with an interest in the domestic tourism sector in Thailand may find this dataset useful for their work. Source: (Thailand Domestic Tourism Statistics by Thaweewat R)\nThe description for some of the variables have been re-phrased for a more accurate alignment of understanding in line with the variables.\n\nR Packages\n\n\n\n\n\n\nColumn\nDescription\n\n\n\n\ndate\nThe month and year in which the statistics were recorded. The dataset covers the years 2019-2023.\n\n\nprovince_thai\nThe name of the province in Thailand, in the Thai language.\n\n\nprovince_eng\nThe name of the province in Thailand, in English.\n\n\nregion_thai\nThe name of the region in Thailand to which the province belongs, in the Thai language.\n\n\nregion_eng\nThe name of the region in Thailand to which the province belongs, in English.\n\n\nvariable\nThe 8 types of data being recorded, such as the number of tourists or the occupancy rate.\n\n\n\nno_tourist_all The total number of tourists (domestic & foreign) who visited the province\n\n\n\nno_tourist_foreign The number of foreign tourists who visited the province\n\n\n\nno_tourist_thai The number of Thai tourists (domestic) who visited the province\n\n\n\nno_tourist_occupied -&gt; no_tourist_stay The total number of occupied hotel rooms in the province\n\n\n\noccupancy_rate -&gt; ratio_tourist_stay The percentage of occupied travel accommodation in the province\n\n\n\nrevenue_all The revenue generated by the tourism industry in the province, in Thai Baht\n\n\n\nrevenue_foreign The revenue generated by foreign tourists in the province, in Thai Baht\n\n\n\nrevenue_thai The revenue generated by Thai tourists in the province, in Thai Baht\n\n\nvalue\nThe value of the data being recorded.\n\n\n\nFrom the description above, we can identify the columns to be selected for analysis. For this exercise, the columns: date, province_eng, variable and value will be selected.\n\n\n\nThe two following code chunks are utilised to check for any duplicated or missing values in each column\n\nany(duplicated(tourism_stats))\n\n[1] FALSE\n\n\n\nsum(is.na(tourism_stats))\n\n[1] 0\n\n\nThe results above tell us that there are no duplicated and missing values.\n\n\n\nThe relevant columns that will be used for analysis are then selected using the code chunk below.Additionally, the province_eng column will be renamed to province since we are only taking this particular column and not the column labelled province_thai.\n\ntourism_stats_selected &lt;- tourism_stats %&gt;%\n  select(date, province_eng, variable, value) %&gt;%\n  rename(province = province_eng)\n\n\n# Grouping by province and year, then summarizing total tourist count\ntourism_stats_grouped &lt;- tourism_stats %&gt;%\n  group_by(province_eng, variable) %&gt;%\n  rename(province = province_eng) %&gt;%\n  summarise(total_value = sum(value, na.rm = TRUE))\n\n\n\n\nExploratory data analysis (EDA) will be carried out in this section using statistical graphic functions of ggplot2 package. The variables are plotted to get a sense of the distribution.\n\n\n\ntourism_stats_selected %&gt;%\n  filter(variable == \"revenue_all\") %&gt;% \n  ggplot(aes(value,fill = variable)) +\n  geom_histogram(bins = 20) +\n  theme(legend.position=\"none\")\n\n\n\n\n\n\n\n\nIt can be observed that the revenue generated by tourism is right skewed as such in can also be interpreted that a number of provinces are the ones generating majority of the revenue for Thailand’s tourism.\n\nDomestic TourismForeign Tourism\n\n\n\ntourism_stats_selected %&gt;%\n  filter(variable == \"revenue_thai\") %&gt;% \n  ggplot(aes(value,fill = variable)) +\n  geom_histogram(bins = 20) +\n  theme(legend.position=\"none\")\n\n\n\n\n\n\n\n\n\n\n\ntourism_stats_selected %&gt;%\n  filter(variable == \"revenue_foreign\") %&gt;% \n  ggplot(aes(value,fill = variable)) +\n  geom_histogram(bins = 20) +\n  theme(legend.position=\"none\")\n\n\n\n\n\n\n\n\n\n\n\nSimilarly, when looking at domestic and foreign tourism revenue individually the plots are also showing a right skew.\n\n\n\n\ntourism_stats_selected %&gt;%\n  filter(variable == \"ratio_tourist_stay\") %&gt;% \n  ggplot(aes(value,fill = variable)) +\n  geom_histogram(bins = 20) +\n  theme(legend.position=\"none\")\n\n\n\n\n\n\n\n\n\n\n\n\ntourism_stats_selected %&gt;%\n  filter(variable == \"no_tourist_all\") %&gt;% \n  ggplot(aes(value,fill = variable)) +\n  geom_histogram(bins = 20) +\n  theme(legend.position=\"none\")\n\n\n\n\n\n\n\n\nFrom the above histogram plots, the variables of revenue generated by tourism and total number of tourists are right-skewed which can be interpreted as the vast majority of data points being concentrated near zero. This is indeed consistent with the table shown in the overview where a few provinces in Thailand dominate tourist visits and revenue while most of the other provinces contribute less.\nFor ratio_tourist_stay the histogram appears to be relatively symmetric with a slight skew to the right.\n\n\n\n\n\nThe code chunk below is used to import the Sub-national Administrative Boundaries of Thailand. Level 1 will be used as it represents the province boundary as seen in the HDX website.\n\n\nthadmin &lt;- st_read(dsn = \"data/geospatial\", \n                   layer = \"tha_admbnda_adm1_rtsd_20220121\")\n\nReading layer `tha_admbnda_adm1_rtsd_20220121' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Take-home_Ex\\Take-home_Ex02\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 77 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nGeodetic CRS:  WGS 84\n\n\nThe message above reveals that the geospatial objects are multi-polygon features. There are a total of 77 multipolygon feature representing the different provinces in Thailand and 16 fields in thadmin (Thailand Administrative) simple feature data frame. thadmin is in WGS84 Geodetic coordinates system. The bounding box provides the x extend and y extend of the data.\nTo learn more about the simple features object, we can apply glimpse() of dplyr package.\n\nglimpse(thadmin)\n\nRows: 77\nColumns: 17\n$ Shape_Leng &lt;dbl&gt; 2.417227, 1.695100, 1.251111, 1.884945, 3.041716, 1.739908,…\n$ Shape_Area &lt;dbl&gt; 0.13133873, 0.07926199, 0.05323766, 0.12698345, 0.21393797,…\n$ ADM1_EN    &lt;chr&gt; \"Bangkok\", \"Samut Prakan\", \"Nonthaburi\", \"Pathum Thani\", \"P…\n$ ADM1_TH    &lt;chr&gt; \"กรุงเทพมหานคร\", \"สมุทรปราการ\", \"นนทบุรี\", \"ปทุมธานี\", \"พระนครศรีอ…\n$ ADM1_PCODE &lt;chr&gt; \"TH10\", \"TH11\", \"TH12\", \"TH13\", \"TH14\", \"TH15\", \"TH16\", \"TH…\n$ ADM1_REF   &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ ADM1ALT1EN &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ ADM1ALT2EN &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ ADM1ALT1TH &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ ADM1ALT2TH &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ ADM0_EN    &lt;chr&gt; \"Thailand\", \"Thailand\", \"Thailand\", \"Thailand\", \"Thailand\",…\n$ ADM0_TH    &lt;chr&gt; \"ประเทศไทย\", \"ประเทศไทย\", \"ประเทศไทย\", \"ประเทศไทย\", \"ประเทศ…\n$ ADM0_PCODE &lt;chr&gt; \"TH\", \"TH\", \"TH\", \"TH\", \"TH\", \"TH\", \"TH\", \"TH\", \"TH\", \"TH\",…\n$ date       &lt;date&gt; 2019-02-18, 2019-02-18, 2019-02-18, 2019-02-18, 2019-02-18…\n$ validOn    &lt;date&gt; 2022-01-22, 2022-01-22, 2022-01-22, 2022-01-22, 2022-01-22…\n$ validTo    &lt;date&gt; -001-11-30, -001-11-30, -001-11-30, -001-11-30, -001-11-30…\n$ geometry   &lt;MULTIPOLYGON [°]&gt; MULTIPOLYGON (((100.6139 13..., MULTIPOLYGON (…\n\n\n\n\nFor ease of reference similar to what was done with the attribute data, ADM1_EN is renamed to province.\n\nthadmin &lt;- thadmin %&gt;%\n  rename(province = ADM1_EN)\n\n\n\n\nIn this step, st_crs() function of the sf package will be utilised to check the CRS information. If the CRS is not reflecting 32647, the EPSG code of Thailand st_transform() function can be used to transform the EPSG code.\n\n\n\n\n\n\nNote\n\n\n\nThe projected coordinate system of Thailand is WGS 84 / UTM zone 47N and the EPSG code is 32647.\n\n\n\nst_crs(thadmin)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\nFrom the results above, we can see that the EPSG is 4326. Hence, st_transform() will be used to perform transformation.\n\nthadmin &lt;- st_transform(thadmin, crs =32647)\n\nst_crs() will be used for confirmation if the transformation has been done correctly.\n\nst_crs(thadmin)\n\nCoordinate Reference System:\n  User input: EPSG:32647 \n  wkt:\nPROJCRS[\"WGS 84 / UTM zone 47N\",\n    BASEGEOGCRS[\"WGS 84\",\n        ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n            MEMBER[\"World Geodetic System 1984 (Transit)\"],\n            MEMBER[\"World Geodetic System 1984 (G730)\"],\n            MEMBER[\"World Geodetic System 1984 (G873)\"],\n            MEMBER[\"World Geodetic System 1984 (G1150)\"],\n            MEMBER[\"World Geodetic System 1984 (G1674)\"],\n            MEMBER[\"World Geodetic System 1984 (G1762)\"],\n            MEMBER[\"World Geodetic System 1984 (G2139)\"],\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ENSEMBLEACCURACY[2.0]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4326]],\n    CONVERSION[\"UTM zone 47N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",99,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Navigation and medium accuracy spatial referencing.\"],\n        AREA[\"Between 96°E and 102°E, northern hemisphere between equator and 84°N, onshore and offshore. China. Indonesia. Laos. Malaysia - West Malaysia. Mongolia. Myanmar (Burma). Russian Federation. Thailand.\"],\n        BBOX[0,96,84,102]],\n    ID[\"EPSG\",32647]]\n\n\n\n\n\n\nColumn 3 (province) and 17 (geometry) will be selected as the relevant columns.\n\nthadmin &lt;- thadmin %&gt;%\n  select(3, 17)\n\n\n\n\nUpon running through some observations with the thadmin simple feature data frame with thai_tourism it is observed that there are inconsistencies in the naming terminologies of the provinces.\n\n\nHDX_province_names &lt;- unique(thadmin$province)\nHDX_province_names\n\n [1] \"Bangkok\"                  \"Samut Prakan\"            \n [3] \"Nonthaburi\"               \"Pathum Thani\"            \n [5] \"Phra Nakhon Si Ayutthaya\" \"Ang Thong\"               \n [7] \"Lop Buri\"                 \"Sing Buri\"               \n [9] \"Chai Nat\"                 \"Saraburi\"                \n[11] \"Chon Buri\"                \"Rayong\"                  \n[13] \"Chanthaburi\"              \"Trat\"                    \n[15] \"Chachoengsao\"             \"Prachin Buri\"            \n[17] \"Nakhon Nayok\"             \"Sa Kaeo\"                 \n[19] \"Nakhon Ratchasima\"        \"Buri Ram\"                \n[21] \"Surin\"                    \"Si Sa Ket\"               \n[23] \"Ubon Ratchathani\"         \"Yasothon\"                \n[25] \"Chaiyaphum\"               \"Amnat Charoen\"           \n[27] \"Bueng Kan\"                \"Nong Bua Lam Phu\"        \n[29] \"Khon Kaen\"                \"Udon Thani\"              \n[31] \"Loei\"                     \"Nong Khai\"               \n[33] \"Maha Sarakham\"            \"Roi Et\"                  \n[35] \"Kalasin\"                  \"Sakon Nakhon\"            \n[37] \"Nakhon Phanom\"            \"Mukdahan\"                \n[39] \"Chiang Mai\"               \"Lamphun\"                 \n[41] \"Lampang\"                  \"Uttaradit\"               \n[43] \"Phrae\"                    \"Nan\"                     \n[45] \"Phayao\"                   \"Chiang Rai\"              \n[47] \"Mae Hong Son\"             \"Nakhon Sawan\"            \n[49] \"Uthai Thani\"              \"Kamphaeng Phet\"          \n[51] \"Tak\"                      \"Sukhothai\"               \n[53] \"Phitsanulok\"              \"Phichit\"                 \n[55] \"Phetchabun\"               \"Ratchaburi\"              \n[57] \"Kanchanaburi\"             \"Suphan Buri\"             \n[59] \"Nakhon Pathom\"            \"Samut Sakhon\"            \n[61] \"Samut Songkhram\"          \"Phetchaburi\"             \n[63] \"Prachuap Khiri Khan\"      \"Nakhon Si Thammarat\"     \n[65] \"Krabi\"                    \"Phangnga\"                \n[67] \"Phuket\"                   \"Surat Thani\"             \n[69] \"Ranong\"                   \"Chumphon\"                \n[71] \"Songkhla\"                 \"Satun\"                   \n[73] \"Trang\"                    \"Phatthalung\"             \n[75] \"Pattani\"                  \"Yala\"                    \n[77] \"Narathiwat\"              \n\n\n\nkaggle_province_names &lt;- unique(tourism_stats_grouped$province)\nkaggle_province_names\n\n [1] \"Amnat Charoen\"            \"Ang Thong\"               \n [3] \"Bangkok\"                  \"Bueng Kan\"               \n [5] \"Buriram\"                  \"Chachoengsao\"            \n [7] \"Chainat\"                  \"Chaiyaphum\"              \n [9] \"Chanthaburi\"              \"Chiang Mai\"              \n[11] \"Chiang Rai\"               \"Chonburi\"                \n[13] \"Chumphon\"                 \"Kalasin\"                 \n[15] \"Kamphaeng Phet\"           \"Kanchanaburi\"            \n[17] \"Khon Kaen\"                \"Krabi\"                   \n[19] \"Lampang\"                  \"Lamphun\"                 \n[21] \"Loei\"                     \"Lopburi\"                 \n[23] \"Mae Hong Son\"             \"Maha Sarakham\"           \n[25] \"Mukdahan\"                 \"Nakhon Nayok\"            \n[27] \"Nakhon Pathom\"            \"Nakhon Phanom\"           \n[29] \"Nakhon Ratchasima\"        \"Nakhon Sawan\"            \n[31] \"Nakhon Si Thammarat\"      \"Nan\"                     \n[33] \"Narathiwat\"               \"Nong Bua Lamphu\"         \n[35] \"Nong Khai\"                \"Nonthaburi\"              \n[37] \"Pathum Thani\"             \"Pattani\"                 \n[39] \"Phang Nga\"                \"Phatthalung\"             \n[41] \"Phayao\"                   \"Phetchabun\"              \n[43] \"Phetchaburi\"              \"Phichit\"                 \n[45] \"Phitsanulok\"              \"Phra Nakhon Si Ayutthaya\"\n[47] \"Phrae\"                    \"Phuket\"                  \n[49] \"Prachinburi\"              \"Prachuap Khiri Khan\"     \n[51] \"Ranong\"                   \"Ratchaburi\"              \n[53] \"Rayong\"                   \"Roi Et\"                  \n[55] \"Sa Kaeo\"                  \"Sakon Nakhon\"            \n[57] \"Samut Prakan\"             \"Samut Sakhon\"            \n[59] \"Samut Songkhram\"          \"Saraburi\"                \n[61] \"Satun\"                    \"Sing Buri\"               \n[63] \"Sisaket\"                  \"Songkhla\"                \n[65] \"Sukhothai\"                \"Suphan Buri\"             \n[67] \"Surat Thani\"              \"Surin\"                   \n[69] \"Tak\"                      \"Trang\"                   \n[71] \"Trat\"                     \"Ubon Ratchathani\"        \n[73] \"Udon Thani\"               \"Uthai Thani\"             \n[75] \"Uttaradit\"                \"Yala\"                    \n[77] \"Yasothon\"                \n\n\n\nR Packages {.striped .hover tbl-colwidths=“[25,75]”} Nong Bua Lam Phu\n\n\ntourism_stats\nthadmin\n\n\n\n\nLopburi\nLop Buri\n\n\nChainat\nChai Nat\n\n\nChonburi\nChon Buri\n\n\nPrachinburi\nPrachin Buri\n\n\nPhang Nga\nPhangnga\n\n\nSisaket\nSi Sa Ket\n\n\nBuriram\nBuri Ram\n\n\nNong Bua Lamphu\nNong Bua Lam Phu\n\n\n\nOn the right side of the table are the 8 provinces from thadmin that are inconsistent with the naming conventions from tourism_stats\nThe gsub() function from Base R will be used to for string substitution to modify the provinces that are not consistent. The naming convention from tourism_stats will be used.\n\n# Create a vector of old and new province names\nrename &lt;- c(\"Lopburi\", \"Chainat\", \"Chonburi\", \"Prachinburi\", \"Phang Nga\", \"Sisaket\", \"Buriram\", \"Nong Bua Lamphu\")\nold_names &lt;- c(\"Lop Buri\", \"Chai Nat\", \"Chon Buri\", \"Prachin Buri\", \"Phangnga\", \"Si Sa Ket\", \"Buri Ram\", \"Nong Bua Lam Phu\")\n\n# Loop through the old and new names and apply gsub for each replacement\nfor(i in seq_along(old_names)) {\n  thadmin$province &lt;- gsub(old_names[i], rename[i], thadmin$province)\n}\n\n# Check the updated province names\nhead(thadmin$province, n = 77)\n\n [1] \"Bangkok\"                  \"Samut Prakan\"            \n [3] \"Nonthaburi\"               \"Pathum Thani\"            \n [5] \"Phra Nakhon Si Ayutthaya\" \"Ang Thong\"               \n [7] \"Lopburi\"                  \"Sing Buri\"               \n [9] \"Chainat\"                  \"Saraburi\"                \n[11] \"Chonburi\"                 \"Rayong\"                  \n[13] \"Chanthaburi\"              \"Trat\"                    \n[15] \"Chachoengsao\"             \"Prachinburi\"             \n[17] \"Nakhon Nayok\"             \"Sa Kaeo\"                 \n[19] \"Nakhon Ratchasima\"        \"Buriram\"                 \n[21] \"Surin\"                    \"Sisaket\"                 \n[23] \"Ubon Ratchathani\"         \"Yasothon\"                \n[25] \"Chaiyaphum\"               \"Amnat Charoen\"           \n[27] \"Bueng Kan\"                \"Nong Bua Lamphu\"         \n[29] \"Khon Kaen\"                \"Udon Thani\"              \n[31] \"Loei\"                     \"Nong Khai\"               \n[33] \"Maha Sarakham\"            \"Roi Et\"                  \n[35] \"Kalasin\"                  \"Sakon Nakhon\"            \n[37] \"Nakhon Phanom\"            \"Mukdahan\"                \n[39] \"Chiang Mai\"               \"Lamphun\"                 \n[41] \"Lampang\"                  \"Uttaradit\"               \n[43] \"Phrae\"                    \"Nan\"                     \n[45] \"Phayao\"                   \"Chiang Rai\"              \n[47] \"Mae Hong Son\"             \"Nakhon Sawan\"            \n[49] \"Uthai Thani\"              \"Kamphaeng Phet\"          \n[51] \"Tak\"                      \"Sukhothai\"               \n[53] \"Phitsanulok\"              \"Phichit\"                 \n[55] \"Phetchabun\"               \"Ratchaburi\"              \n[57] \"Kanchanaburi\"             \"Suphan Buri\"             \n[59] \"Nakhon Pathom\"            \"Samut Sakhon\"            \n[61] \"Samut Songkhram\"          \"Phetchaburi\"             \n[63] \"Prachuap Khiri Khan\"      \"Nakhon Si Thammarat\"     \n[65] \"Krabi\"                    \"Phang Nga\"               \n[67] \"Phuket\"                   \"Surat Thani\"             \n[69] \"Ranong\"                   \"Chumphon\"                \n[71] \"Songkhla\"                 \"Satun\"                   \n[73] \"Trang\"                    \"Phatthalung\"             \n[75] \"Pattani\"                  \"Yala\"                    \n[77] \"Narathiwat\"              \n\n\n\n\n\nThe code chunk below is used to join the aspatial and geospatial data by using the left_join() function.\n\nthailand_tourism &lt;- left_join(thadmin,\n                              tourism_stats_grouped, by = c(\"province\" = \"province\"))\n\n\n\n\nIn the following code chunk, write_rds() of readr package is used to save the extracted attribute data thailand_tourism into an output file in rds format. The output file is saved in the rds folder.\n\nwrite_rds(thailand_tourism,\n          \"data/rds/thailand_tourism.rds\")\n\nThe saved file can then be retrieved using the code chunk below:\n\nthailand_tourism &lt;- read_rds(\"data/rds/thailand_tourism.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html",
    "title": "Hands-on Exercise 7: Geographically Weighted Regression (GWR)",
    "section": "",
    "text": "Geographically weighted regression (GWR) is a spatial statistical technique that takes non-stationary variables into consideration (e.g., climate; demographic factors; physical environment characteristics) and models the local relationships between these independent variables and as an outcome of interest (also known as dependent variable). In this hands-on exercise, we will learn how to build hedonic pricing models by using GWR methods. The dependent variable is the resale prices of condominium in 2015. The independent variables are divided into either structural and/or locational."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#overview-calibrating-hedonic-pricing-model-for-private-highrise-properties-with-gwr-method",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#overview-calibrating-hedonic-pricing-model-for-private-highrise-properties-with-gwr-method",
    "title": "Hands-on Exercise 7: Geographically Weighted Regression (GWR)",
    "section": "",
    "text": "Geographically weighted regression (GWR) is a spatial statistical technique that takes non-stationary variables into consideration (e.g., climate; demographic factors; physical environment characteristics) and models the local relationships between these independent variables and as an outcome of interest (also known as dependent variable). In this hands-on exercise, we will learn how to build hedonic pricing models by using GWR methods. The dependent variable is the resale prices of condominium in 2015. The independent variables are divided into either structural and/or locational."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#the-data",
    "title": "Hands-on Exercise 7: Geographically Weighted Regression (GWR)",
    "section": "2 The Data",
    "text": "2 The Data\nTwo data sets will be used in this model building exercise, they are:\n\nURA Master Plan subzone boundary in shapefile format (i.e. MP14_SUBZONE_WEB_PL) AND\ncondo_resale_2015 in csv format (i.e. condo_resale_2015.csv)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#getting-started",
    "title": "Hands-on Exercise 7: Geographically Weighted Regression (GWR)",
    "section": "3 Getting Started",
    "text": "3 Getting Started\nBefore getting started, it is important to install the necessary R packages into R and launch these R packages into the R environment.\nThe R packages needed for this exercise are as follows:\n\nR package for building Ordinary Least Squares regression (OLS) and performing diagnostics tests\n\nolsrr\n\nR package for calibrating geographical weighted family of models\n\nGWmodel\n\nR package for multivariate data visualisation and analysis\n\ncorrplot\n\nSpatial data handling\n\nsf\n\nAttribute data handling\n\ntidyverse, especially readr, ggplot2 and dplyr\n\nChoropleth mapping\n\ntmap\n\nPresentation-Ready Data Summary and Analytic Result Tables\n\ngtsummary\n\n\nThe code chunk below installs and launches these R packages into R environment.\n\npacman::p_load(olsrr, GWmodel, corrplot, ggpubr, sf, spdep, tidyverse, tmap, gtsummary, broom.helpers)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#short-note-about-gwmodel",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#short-note-about-gwmodel",
    "title": "Hands-on Exercise 7: Geographically Weighted Regression (GWR)",
    "section": "4 Short note about GWmodel",
    "text": "4 Short note about GWmodel\nGWmodel package provides a collection of localised spatial statistical methods, namely: GW summary statistics, GW principal components analysis, GW discriminant analysis and various forms of GW regression; some of which are provided in basic and robust (outlier resistant) forms. More commonly, outputs or parameters of the GWmodel are mapped to provide a useful exploratory tool, which can often precede (and direct) a more traditional or sophisticated statistical analysis.\nIn regression models - there is an intercept component where the line cuts through from an intercept. E.g. when a floor unit area is zero - obviously no unit exists.\nBeta(1) value can be +ve/-ve eg sq area vs age of property."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#geospatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#geospatial-data-wrangling",
    "title": "Hands-on Exercise 7: Geographically Weighted Regression (GWR)",
    "section": "5 Geospatial Data Wrangling",
    "text": "5 Geospatial Data Wrangling\n\n5.1 Importing geospatial data\nThe geospatial data used in this hands-on exercise is called MP14_SUBZONE_WEB_PL. It is in ESRI shapefile format. The shapefile consists of URA Master Plan 2014’s planning subzone boundaries. Polygon features are used to represent these geographic boundaries. The GIS data is in svy21 projected coordinates systems.\nThe code chunk below is used to import MP_SUBZONE_WEB_PL shapefile by using st_read() of sf packages.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\",\n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex07\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe result above shows that the R object used to contain the imported MP14_SUBZONE_WEB_PL shapefile is called mpsz and it is a simple feature object. The geometry type is MULTIPOLYGON. it is also important to note that the mpsz simple feature object does not have EPSG information.\n\n\n\n\n5.2 Updating CRS information\nThe code chunk below updates the newly imported mpsz sf object with the correct ESPG code (i.e. 3414)\n\nmpsz_svy21 &lt;- st_transform(mpsz, 3414)\n\n\n# Check validity of geometries\nsf::st_is_valid(mpsz_svy21)\n\n  [1]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n [13]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE  TRUE  TRUE  TRUE FALSE\n [25]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n [37]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n [49]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n [61]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n [73]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n [85]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n [97]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[109]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[121]  TRUE FALSE FALSE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE\n[133]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[145]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[157]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[169]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[181]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[193]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[205]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[217]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[229]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[241]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[253]  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[265]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[277]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[289]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[301]  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[313]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE\n\n# Attempt to fix invalid geometries\nmpsz_svy21 &lt;- sf::st_make_valid(mpsz_svy21)\n\nAfter transforming the object, verification of the projection on the newly transformed mpsz_svy21 is done by using st_crs() of sf package.\nThe code chunk below is used to verify the newly transformed mpsz_svy21.\n\nst_crs(mpsz_svy21)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nNotice that the EPSG: is indicated as 3414 now.\nNext, the extent of mpsz_svy21 is revealed by using st_bbox() of sf package.\n\nst_bbox(mpsz_svy21)\n\n     xmin      ymin      xmax      ymax \n 2667.538 15748.721 56396.440 50256.334 \n\n\nThe extent of mpsz_svy21 is illustrated from the results above."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#aspatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#aspatial-data-wrangling",
    "title": "Hands-on Exercise 7: Geographically Weighted Regression (GWR)",
    "section": "6 Aspatial Data Wrangling",
    "text": "6 Aspatial Data Wrangling\n\n6.1 Importing the aspatial data\nThe condo_resale_2015 is in csv file format. The codes chunk below uses read_csv() function of readr package to import condo_resale_2015 into R as a tibble data frame called condo_resale.\n\ncondo_resale &lt;- read_csv(\"data/aspatial/Condo_resale_2015.csv\")\n\nRows: 1436 Columns: 23\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (23): LATITUDE, LONGITUDE, POSTCODE, SELLING_PRICE, AREA_SQM, AGE, PROX_...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nAfter importing the aspatial data file into R, it is important to examine if the data file has been imported correctly.\nThe codes chunks below uses glimpse() and head() to display the data structure.\n\nglimpse(condo_resale)\n\nRows: 1,436\nColumns: 23\n$ LATITUDE             &lt;dbl&gt; 1.287145, 1.328698, 1.313727, 1.308563, 1.321437,…\n$ LONGITUDE            &lt;dbl&gt; 103.7802, 103.8123, 103.7971, 103.8247, 103.9505,…\n$ POSTCODE             &lt;dbl&gt; 118635, 288420, 267833, 258380, 467169, 466472, 3…\n$ SELLING_PRICE        &lt;dbl&gt; 3000000, 3880000, 3325000, 4250000, 1400000, 1320…\n$ AREA_SQM             &lt;dbl&gt; 309, 290, 248, 127, 145, 139, 218, 141, 165, 168,…\n$ AGE                  &lt;dbl&gt; 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22, 6,…\n$ PROX_CBD             &lt;dbl&gt; 7.941259, 6.609797, 6.898000, 4.038861, 11.783402…\n$ PROX_CHILDCARE       &lt;dbl&gt; 0.16597932, 0.28027246, 0.42922669, 0.39473543, 0…\n$ PROX_ELDERLYCARE     &lt;dbl&gt; 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.121…\n$ PROX_URA_GROWTH_AREA &lt;dbl&gt; 6.618741, 7.505109, 6.463887, 4.906512, 6.410632,…\n$ PROX_HAWKER_MARKET   &lt;dbl&gt; 1.76542207, 0.54507614, 0.37789301, 1.68259969, 0…\n$ PROX_KINDERGARTEN    &lt;dbl&gt; 0.05835552, 0.61592412, 0.14120309, 0.38200076, 0…\n$ PROX_MRT             &lt;dbl&gt; 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.528…\n$ PROX_PARK            &lt;dbl&gt; 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.116…\n$ PROX_PRIMARY_SCH     &lt;dbl&gt; 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.709…\n$ PROX_TOP_PRIMARY_SCH &lt;dbl&gt; 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.709…\n$ PROX_SHOPPING_MALL   &lt;dbl&gt; 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.307…\n$ PROX_SUPERMARKET     &lt;dbl&gt; 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.581…\n$ PROX_BUS_STOP        &lt;dbl&gt; 0.10336166, 0.28673408, 0.28504777, 0.29872340, 0…\n$ NO_Of_UNITS          &lt;dbl&gt; 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34, 3…\n$ FAMILY_FRIENDLY      &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD             &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\n\n\nhead(condo_resale$LONGITUDE) # to see the data in XCOORD column\n\n[1] 103.7802 103.8123 103.7971 103.8247 103.9505 103.9386\n\nhead(condo_resale$LATITUDE) # to see the data in YCOORD column\n\n[1] 1.287145 1.328698 1.313727 1.308563 1.321437 1.314198\n\n\nFollowing which, summary() of base R is used to display the summary statistics of cond_resale tibble data frame.\n\nsummary(condo_resale)\n\n    LATITUDE       LONGITUDE        POSTCODE      SELLING_PRICE     \n Min.   :1.240   Min.   :103.7   Min.   : 18965   Min.   :  540000  \n 1st Qu.:1.309   1st Qu.:103.8   1st Qu.:259849   1st Qu.: 1100000  \n Median :1.328   Median :103.8   Median :469298   Median : 1383222  \n Mean   :1.334   Mean   :103.8   Mean   :440439   Mean   : 1751211  \n 3rd Qu.:1.357   3rd Qu.:103.9   3rd Qu.:589486   3rd Qu.: 1950000  \n Max.   :1.454   Max.   :104.0   Max.   :828833   Max.   :18000000  \n    AREA_SQM          AGE           PROX_CBD       PROX_CHILDCARE    \n Min.   : 34.0   Min.   : 0.00   Min.   : 0.3869   Min.   :0.004927  \n 1st Qu.:103.0   1st Qu.: 5.00   1st Qu.: 5.5574   1st Qu.:0.174481  \n Median :121.0   Median :11.00   Median : 9.3567   Median :0.258135  \n Mean   :136.5   Mean   :12.14   Mean   : 9.3254   Mean   :0.326313  \n 3rd Qu.:156.0   3rd Qu.:18.00   3rd Qu.:12.6661   3rd Qu.:0.368293  \n Max.   :619.0   Max.   :37.00   Max.   :19.1804   Max.   :3.465726  \n PROX_ELDERLYCARE  PROX_URA_GROWTH_AREA PROX_HAWKER_MARKET PROX_KINDERGARTEN \n Min.   :0.05451   Min.   :0.2145       Min.   :0.05182    Min.   :0.004927  \n 1st Qu.:0.61254   1st Qu.:3.1643       1st Qu.:0.55245    1st Qu.:0.276345  \n Median :0.94179   Median :4.6186       Median :0.90842    Median :0.413385  \n Mean   :1.05351   Mean   :4.5981       Mean   :1.27987    Mean   :0.458903  \n 3rd Qu.:1.35122   3rd Qu.:5.7550       3rd Qu.:1.68578    3rd Qu.:0.578474  \n Max.   :3.94916   Max.   :9.1554       Max.   :5.37435    Max.   :2.229045  \n    PROX_MRT         PROX_PARK       PROX_PRIMARY_SCH  PROX_TOP_PRIMARY_SCH\n Min.   :0.05278   Min.   :0.02906   Min.   :0.07711   Min.   :0.07711     \n 1st Qu.:0.34646   1st Qu.:0.26211   1st Qu.:0.44024   1st Qu.:1.34451     \n Median :0.57430   Median :0.39926   Median :0.63505   Median :1.88213     \n Mean   :0.67316   Mean   :0.49802   Mean   :0.75471   Mean   :2.27347     \n 3rd Qu.:0.84844   3rd Qu.:0.65592   3rd Qu.:0.95104   3rd Qu.:2.90954     \n Max.   :3.48037   Max.   :2.16105   Max.   :3.92899   Max.   :6.74819     \n PROX_SHOPPING_MALL PROX_SUPERMARKET PROX_BUS_STOP       NO_Of_UNITS    \n Min.   :0.0000     Min.   :0.0000   Min.   :0.001595   Min.   :  18.0  \n 1st Qu.:0.5258     1st Qu.:0.3695   1st Qu.:0.098356   1st Qu.: 188.8  \n Median :0.9357     Median :0.5687   Median :0.151710   Median : 360.0  \n Mean   :1.0455     Mean   :0.6141   Mean   :0.193974   Mean   : 409.2  \n 3rd Qu.:1.3994     3rd Qu.:0.7862   3rd Qu.:0.220466   3rd Qu.: 590.0  \n Max.   :3.4774     Max.   :2.2441   Max.   :2.476639   Max.   :1703.0  \n FAMILY_FRIENDLY     FREEHOLD      LEASEHOLD_99YR  \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.0000   Median :0.0000   Median :0.0000  \n Mean   :0.4868   Mean   :0.4227   Mean   :0.4882  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n\n\n\n\n6.2 Converting aspatial data frame into a sf object\nThe condo_resale tibble data frame is an aspatial data. We will convert it to a sf object. The code chunk below converts condo_resale data frame into a simple feature data frame by using st_as_sf() of sf packages.\n\ncondo_resale.sf &lt;- st_as_sf(condo_resale,\n         coords = c(\"LONGITUDE\", \"LATITUDE\"),\n         crs = 4326) %&gt;% \n  st_transform(crs = 3414)\n\n\ncondo_resale.sf\n\nSimple feature collection with 1436 features and 21 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 14940.85 ymin: 24765.67 xmax: 43352.45 ymax: 48382.81\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 1,436 × 22\n   POSTCODE SELLING_PRICE AREA_SQM   AGE PROX_CBD PROX_CHILDCARE\n *    &lt;dbl&gt;         &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;          &lt;dbl&gt;\n 1   118635       3000000      309    30     7.94          0.166\n 2   288420       3880000      290    32     6.61          0.280\n 3   267833       3325000      248    33     6.90          0.429\n 4   258380       4250000      127     7     4.04          0.395\n 5   467169       1400000      145    28    11.8           0.119\n 6   466472       1320000      139    22    10.3           0.125\n 7   309502       3410000      218    24     4.24          0.326\n 8   468497       1420000      141    24    11.6           0.162\n 9   118450       2025000      165    27     6.46          0.123\n10   268157       2550000      168    31     6.52          0.609\n# ℹ 1,426 more rows\n# ℹ 16 more variables: PROX_ELDERLYCARE &lt;dbl&gt;, PROX_URA_GROWTH_AREA &lt;dbl&gt;,\n#   PROX_HAWKER_MARKET &lt;dbl&gt;, PROX_KINDERGARTEN &lt;dbl&gt;, PROX_MRT &lt;dbl&gt;,\n#   PROX_PARK &lt;dbl&gt;, PROX_PRIMARY_SCH &lt;dbl&gt;, PROX_TOP_PRIMARY_SCH &lt;dbl&gt;,\n#   PROX_SHOPPING_MALL &lt;dbl&gt;, PROX_SUPERMARKET &lt;dbl&gt;, PROX_BUS_STOP &lt;dbl&gt;,\n#   NO_Of_UNITS &lt;dbl&gt;, FAMILY_FRIENDLY &lt;dbl&gt;, FREEHOLD &lt;dbl&gt;,\n#   LEASEHOLD_99YR &lt;dbl&gt;, geometry &lt;POINT [m]&gt;\n\n\n\n\n\n\n\n\nNote\n\n\n\nNotice that st_transform() of sf package is used to convert the coordinates from wgs84 (i.e. crs:4326) to svy21 (i.e. crs=3414).\n\n\nNext, head() is used to list the contents of condo_resale.sf object.\n\nhead(condo_resale.sf)\n\nSimple feature collection with 6 features and 21 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 22085.12 ymin: 29951.54 xmax: 41042.56 ymax: 34546.2\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 6 × 22\n  POSTCODE SELLING_PRICE AREA_SQM   AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE\n     &lt;dbl&gt;         &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;          &lt;dbl&gt;            &lt;dbl&gt;\n1   118635       3000000      309    30     7.94          0.166            2.52 \n2   288420       3880000      290    32     6.61          0.280            1.93 \n3   267833       3325000      248    33     6.90          0.429            0.502\n4   258380       4250000      127     7     4.04          0.395            1.99 \n5   467169       1400000      145    28    11.8           0.119            1.12 \n6   466472       1320000      139    22    10.3           0.125            0.789\n# ℹ 15 more variables: PROX_URA_GROWTH_AREA &lt;dbl&gt;, PROX_HAWKER_MARKET &lt;dbl&gt;,\n#   PROX_KINDERGARTEN &lt;dbl&gt;, PROX_MRT &lt;dbl&gt;, PROX_PARK &lt;dbl&gt;,\n#   PROX_PRIMARY_SCH &lt;dbl&gt;, PROX_TOP_PRIMARY_SCH &lt;dbl&gt;,\n#   PROX_SHOPPING_MALL &lt;dbl&gt;, PROX_SUPERMARKET &lt;dbl&gt;, PROX_BUS_STOP &lt;dbl&gt;,\n#   NO_Of_UNITS &lt;dbl&gt;, FAMILY_FRIENDLY &lt;dbl&gt;, FREEHOLD &lt;dbl&gt;,\n#   LEASEHOLD_99YR &lt;dbl&gt;, geometry &lt;POINT [m]&gt;\n\n\n\n\n\n\n\n\nNote\n\n\n\nNotice that the output is in a point feature data frame.\n\nGeometry type: POINT"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#exploratory-data-analysis-eda",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#exploratory-data-analysis-eda",
    "title": "Hands-on Exercise 7: Geographically Weighted Regression (GWR)",
    "section": "7 Exploratory Data Analysis (EDA)",
    "text": "7 Exploratory Data Analysis (EDA)\nIn the section, we will learn how to use statistical graphic functions of ggplot2 package to perform EDA.\n\n7.1 EDA using statistical graphics\nWe can plot the distribution of AREA_SQM by using appropriate Exploratory Data Analysis (EDA) as shown in the code chunk below.\n\nggplot(data = condo_resale.sf,\n       aes(x = `AREA_SQM`)) +\n  geom_histogram(bins = 20,\n                 color = \"black\",\n                 fill = \"light blue\")\n\n\n\n\n\n\n\n\nWe can plot the distribution of SELLING_PRICE by using appropriate Exploratory Data Analysis (EDA) as shown in the code chunk below.\n\nggplot(data = condo_resale.sf,\n       aes(x = `SELLING_PRICE`)) +\n  geom_histogram(bins = 20,\n                 color = \"black\",\n                 fill = \"salmon\")\n\n\n\n\n\n\n\n\nThe figure above reveals a right-skewed distribution. This means that more condominium units were transacted at relatively lower prices.\nStatistically, the skewed distribution can be normalised by using log transformation. The code chunk below is used to derive a new variable called LOG_SELLING_PRICE by using a log transformation on the variable SELLING_PRICE. It is performed using mutate() of dplyr package.\n\ncondo_resale.sf &lt;- condo_resale.sf %&gt;%\n  mutate(`LOG_SELLING_PRICE` = log(SELLING_PRICE))\n\nPlotting the LOG_SELLING_PRICE using the code chunk below.\n\nggplot(data = condo_resale.sf,\n       aes(x = `LOG_SELLING_PRICE`)) +\n  geom_histogram(bins = 20,\n                 color = \"black\",\n                 fill = \"salmon\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe distribution is relatively less skewed after the transformation.\n\n\n\n\n7.2 Multiple Histogram Plots distribution of variables\nIn this section, we will learn how to plot multiple small histograms (also known as a trellis plot) by using ggarrange() of ggpubr package.\nThe code chunk below is used to create 15 histograms. Then, ggarrange() is used to organised these histograms into a 3 columns by 5 rows small multiple plot.\n\nAREA_SQM &lt;- ggplot(data = condo_resale.sf, aes(x = `AREA_SQM`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"#56B4E9\")\n\nAGE &lt;- ggplot(data = condo_resale.sf, aes(x = `AGE`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"#56B4E9\")\n\nPROX_CBD &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_CBD`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"#56B4E9\")\n\nPROX_CHILDCARE &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_CHILDCARE`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"#56B4E9\")\n\nPROX_ELDERLYCARE &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_ELDERLYCARE`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"#56B4E9\")\n\nPROX_URA_GROWTH_AREA &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_URA_GROWTH_AREA`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"#56B4E9\")\n\nPROX_HAWKER_MARKET &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_HAWKER_MARKET`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"#56B4E9\")\n\nPROX_KINDERGARTEN &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_KINDERGARTEN`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"#56B4E9\")\n\nPROX_MRT &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_MRT`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"#56B4E9\")\n\nPROX_PARK &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_PARK`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"#56B4E9\")\n\nPROX_PRIMARY_SCH &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_PRIMARY_SCH`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"#56B4E9\")\n\nPROX_TOP_PRIMARY_SCH &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_TOP_PRIMARY_SCH`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"#56B4E9\")\n\nPROX_SHOPPING_MALL &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_SHOPPING_MALL`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"#56B4E9\")\n\nPROX_SUPERMARKET &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_SUPERMARKET`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"#56B4E9\")\n\nPROX_BUS_STOP &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_BUS_STOP`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"#56B4E9\")\n\nggarrange(AREA_SQM, AGE, PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE,\n          PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN,\n          PROX_MRT, PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH,\n          PROX_SHOPPING_MALL, PROX_SUPERMARKET, PROX_BUS_STOP,\n          ncol = 3, nrow = 5)\n\n\n\n\n\n\n\n\n\n\n7.3 Drawing Statistical Point Map\nLastly, to reveal the geospatial distribution of condominium resale prices in Singapore. This will be done by plotting a map which will be prepared by using tmap package. Visually this can allow us to see a representation of which planning subzones might have higher or lower confominium resale prices.\nFirst, we will turn on the interactive mode of tmap by using the code chunk below.\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\n\nNext, the code chunk below is used to create an interactive point symbol map.\n\n# Set the tmap option to automatically check and fix invalid geometries\ntmap_options(check.and.fix = TRUE)\n\ntm_shape(mpsz_svy21) +\n  tm_polygons(alpha = 0.4) +\ntm_shape(condo_resale.sf) +\n  tm_dots(col = \"SELLING_PRICE\",\n          alpha = 0.6,\n          style = \"quantile\") +\n  tm_view(set.zoom.limits = c(11,14))\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\n\nBefore moving on to the next section, the code above will be used to turn R display into plot mode.\n\n\n\n\n\n\nNote\n\n\n\n\nNotice that tm_dots() is used instead of tm_bubbles().\nset.zoom.limits argument of tm_view() sets the minimum and maximum zoom levels to 11 and 14 respectively."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#hedonic-pricing-modelling-in-r",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#hedonic-pricing-modelling-in-r",
    "title": "Hands-on Exercise 7: Geographically Weighted Regression (GWR)",
    "section": "8 Hedonic Pricing Modelling in R",
    "text": "8 Hedonic Pricing Modelling in R\nIn this section, it will illustrate how to build hedonic pricing models for condominium resale units using lm() of R base.\n\n8.1 Simple Linear Regression Method\nFirst, we will build a simple linear regression model by using SELLING_PRICE as the dependent variable and AREA_SQM as the independent variable.\n\ncondo.slr &lt;- lm(formula = SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\n\nlm() returns an object of class “lm” or for multiple responses of class c(“mlm”, “lm”).\nThe functions summary() and anova() can be used to obtain and print a summary and analysis of aa variance table of the results. The generic accessors functions coefficients, effects, fitted.values and residuals extract various useful features of the value returned by lm.\n\nsummary(condo.slr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3695815  -391764   -87517   258900 13503875 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -258121.1    63517.2  -4.064 5.09e-05 ***\nAREA_SQM      14719.0      428.1  34.381  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 942700 on 1434 degrees of freedom\nMultiple R-squared:  0.4518,    Adjusted R-squared:  0.4515 \nF-statistic:  1182 on 1 and 1434 DF,  p-value: &lt; 2.2e-16\n\n\nThe output report reveals that the SELLING_PRICE can be explained by using the formula:\n      *y = -258121.1 + 14719x1*\nThe Multiple R-squared: 0.4518 reveals that the simple regression model built is able to explain about 45% of the resale prices.\nSince p-value is much smaller than 0.0001 (p-value: &lt; 2.2e-16 ), we will reject the null hypothesis that the mean is a good estimator of SELLING_PRICE. This will allow us to infer that simple linear regression model above is a good estimator of SELLING_PRICE.\nThe Coefficients: section of the report reveals that the p-values of both the estimates of the Intercept and ARA_SQM are smaller than 0.001. In view of this, the null hypothesis of the B0 and B1 are equal to 0 will be rejected. As a result, we will be able to infer that the B0 and B1 are good parameter estimates.\nTo visualise the best fit curve on a scatter plot, we can incorporate lm() as a method function in ggplot’s geometry as shown in the code chunk below.\n\nggplot(data = condo_resale.sf,  \n       aes(x =`AREA_SQM`, y =`SELLING_PRICE`)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nthe figure above reveals that there are a few statistical outliers with relatively high selling prices.\n\n\n8.2 Multiple Linear Regression Method\n\n8.2.1 Visualising the relationships of the independent variables\nBefore building a multiple regression model, it is important to ensure that the independent variables used are not highly correlated to each other. If highly correlated independent variables are used in building a regression model, the quality of the model will be compromised. This phenomenon is known as multicollinearity in statistics.\nCorrelation matrix is commonly used to visualise the relationships between the independent variables. Besides the pairs() of R, there are many packages supporting the display of a correlation matrix. In this section, the corrplot package will be used.\nThe code chunk below is used to plot a scatter plot matrix of the relationship between the independent variables in condo_resale data.frame.\n\ncorrplot(cor(condo_resale[, 5:23]), diag = FALSE, order = \"AOE\",\n         tl.pos = \"td\", tl.cex = 0.5, method = \"number\", type = \"upper\")\n\n\n\n\n\n\n\n\nA matrix reorder is very important for mining the hidden structure and patterns in the matrix. There are four methods in corrplot (parameter order), named: “AOE”, “FPC”, “hclust”, “alphabet”.\nIn the code chunk above, AOE order is used. It orders the variables by using the angular order of the eigenvectors method suggested by Michael Friendly.\nFrom the scatterplot matrix, it is clear that Freehold is highly correlated to LEASE_99YEAR. In view of this, it gives reason to include only either one of them in the subsequent model building.\nIn this case, LEASE_99YEAR is excluded in the subsequent model building.\n\n\n\n8.3 Building a hedonic pricing model using multiple linear regression method\nThe code chunk below uses lm() to calibrate the multiple linear regression model.\n\ncondo.mlr &lt;- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE    + \n                  PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                  PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + PROX_KINDERGARTEN + \n                  PROX_MRT  + PROX_PARK + PROX_PRIMARY_SCH + \n                  PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n                  PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                  data = condo_resale.sf)\nsummary(condo.mlr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + PROX_CHILDCARE + \n    PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + \n    PROX_KINDERGARTEN + PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + \n    PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3475964  -293923   -23069   241043 12260381 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           481728.40  121441.01   3.967 7.65e-05 ***\nAREA_SQM               12708.32     369.59  34.385  &lt; 2e-16 ***\nAGE                   -24440.82    2763.16  -8.845  &lt; 2e-16 ***\nPROX_CBD              -78669.78    6768.97 -11.622  &lt; 2e-16 ***\nPROX_CHILDCARE       -351617.91  109467.25  -3.212  0.00135 ** \nPROX_ELDERLYCARE      171029.42   42110.51   4.061 5.14e-05 ***\nPROX_URA_GROWTH_AREA   38474.53   12523.57   3.072  0.00217 ** \nPROX_HAWKER_MARKET     23746.10   29299.76   0.810  0.41782    \nPROX_KINDERGARTEN     147468.99   82668.87   1.784  0.07466 .  \nPROX_MRT             -314599.68   57947.44  -5.429 6.66e-08 ***\nPROX_PARK             563280.50   66551.68   8.464  &lt; 2e-16 ***\nPROX_PRIMARY_SCH      180186.08   65237.95   2.762  0.00582 ** \nPROX_TOP_PRIMARY_SCH    2280.04   20410.43   0.112  0.91107    \nPROX_SHOPPING_MALL   -206604.06   42840.60  -4.823 1.57e-06 ***\nPROX_SUPERMARKET      -44991.80   77082.64  -0.584  0.55953    \nPROX_BUS_STOP         683121.35  138353.28   4.938 8.85e-07 ***\nNO_Of_UNITS             -231.18      89.03  -2.597  0.00951 ** \nFAMILY_FRIENDLY       140340.77   47020.55   2.985  0.00289 ** \nFREEHOLD              359913.01   49220.22   7.312 4.38e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 755800 on 1417 degrees of freedom\nMultiple R-squared:  0.6518,    Adjusted R-squared:  0.6474 \nF-statistic: 147.4 on 18 and 1417 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n8.4 Preparing Publication Quality Table: olsrr method\nWith reference to the report in the previous section, it is clear that not all the independent variables are statistically significant. The model can be revised by removing those variables which are not statistically significant.\nThe removed variables are: PROX_HAWKER_MARKET, PROX_KINDERGARTEN, PROX_TOP_PRIMARY_SCH, PROX_SUPERMARKET\nThe revised model is calibrated by using the code chunk below.\n\ncondo.mlr1 &lt;- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                   PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                   PROX_URA_GROWTH_AREA + PROX_MRT  + PROX_PARK + \n                   PROX_PRIMARY_SCH + PROX_SHOPPING_MALL    + PROX_BUS_STOP + \n                   NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD,\n                 data=condo_resale.sf)\nols_regress(condo.mlr1)\n\n                                Model Summary                                 \n-----------------------------------------------------------------------------\nR                            0.807       RMSE                     751998.679 \nR-Squared                    0.651       MSE                571471422208.591 \nAdj. R-Squared               0.647       Coef. Var                    43.168 \nPred R-Squared               0.638       AIC                       42966.758 \nMAE                     414819.628       SBC                       43051.072 \n-----------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n AIC: Akaike Information Criteria \n SBC: Schwarz Bayesian Criteria \n\n                                     ANOVA                                       \n--------------------------------------------------------------------------------\n                    Sum of                                                      \n                   Squares          DF         Mean Square       F         Sig. \n--------------------------------------------------------------------------------\nRegression    1.512586e+15          14        1.080418e+14    189.059    0.0000 \nResidual      8.120609e+14        1421    571471422208.591                      \nTotal         2.324647e+15        1435                                          \n--------------------------------------------------------------------------------\n\n                                               Parameter Estimates                                                \n-----------------------------------------------------------------------------------------------------------------\n               model           Beta    Std. Error    Std. Beta       t        Sig           lower          upper \n-----------------------------------------------------------------------------------------------------------------\n         (Intercept)     527633.222    108183.223                   4.877    0.000     315417.244     739849.200 \n            AREA_SQM      12777.523       367.479        0.584     34.771    0.000      12056.663      13498.382 \n                 AGE     -24687.739      2754.845       -0.167     -8.962    0.000     -30091.739     -19283.740 \n            PROX_CBD     -77131.323      5763.125       -0.263    -13.384    0.000     -88436.469     -65826.176 \n      PROX_CHILDCARE    -318472.751    107959.512       -0.084     -2.950    0.003    -530249.889    -106695.613 \n    PROX_ELDERLYCARE     185575.623     39901.864        0.090      4.651    0.000     107302.737     263848.510 \nPROX_URA_GROWTH_AREA      39163.254     11754.829        0.060      3.332    0.001      16104.571      62221.936 \n            PROX_MRT    -294745.107     56916.367       -0.112     -5.179    0.000    -406394.234    -183095.980 \n           PROX_PARK     570504.807     65507.029        0.150      8.709    0.000     442003.938     699005.677 \n    PROX_PRIMARY_SCH     159856.136     60234.599        0.062      2.654    0.008      41697.849     278014.424 \n  PROX_SHOPPING_MALL    -220947.251     36561.832       -0.115     -6.043    0.000    -292668.213    -149226.288 \n       PROX_BUS_STOP     682482.221    134513.243        0.134      5.074    0.000     418616.359     946348.082 \n         NO_Of_UNITS       -245.480        87.947       -0.053     -2.791    0.005       -418.000        -72.961 \n     FAMILY_FRIENDLY     146307.576     46893.021        0.057      3.120    0.002      54320.593     238294.560 \n            FREEHOLD     350599.812     48506.485        0.136      7.228    0.000     255447.802     445751.821 \n-----------------------------------------------------------------------------------------------------------------\n\n\n\n\n8.5 Preparing Publication Quality Table: gtsummary method\nThe gtsummary package provides an elegant and flexible way to create publication-ready summary tables in R.\nThe code chunk below using tbl_regression() is used to create a well formatted regression report.\n\ntbl_regression(condo.mlr1, intercept = TRUE)\n\n\n\n\n\n\n\nCharacteristic\nBeta\n95% CI1\np-value\n\n\n\n\n(Intercept)\n527,633\n315,417, 739,849\n&lt;0.001\n\n\nAREA_SQM\n12,778\n12,057, 13,498\n&lt;0.001\n\n\nAGE\n-24,688\n-30,092, -19,284\n&lt;0.001\n\n\nPROX_CBD\n-77,131\n-88,436, -65,826\n&lt;0.001\n\n\nPROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n\n\nPROX_ELDERLYCARE\n185,576\n107,303, 263,849\n&lt;0.001\n\n\nPROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n&lt;0.001\n\n\nPROX_MRT\n-294,745\n-406,394, -183,096\n&lt;0.001\n\n\nPROX_PARK\n570,505\n442,004, 699,006\n&lt;0.001\n\n\nPROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n\n\nPROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n&lt;0.001\n\n\nPROX_BUS_STOP\n682,482\n418,616, 946,348\n&lt;0.001\n\n\nNO_Of_UNITS\n-245\n-418, -73\n0.005\n\n\nFAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n\n\nFREEHOLD\n350,600\n255,448, 445,752\n&lt;0.001\n\n\n\n1 CI = Confidence Interval\n\n\n\n\n\n\n\n\nWith gtsummary package, model statistics can be included in the report by either appending them to the report table by using add_glance_table() or adding the model statistics as a table source note by using add_glance_source_note() as shown in the code chunk below.\n\ntbl_regression(condo.mlr1, \n               intercept = TRUE) %&gt;% \n  add_glance_source_note(\n    label = list(sigma ~ \"U03C3\"),\n    include = c(r.squared, adj.r.squared, \n                AIC, statistic,\n                p.value, sigma))\n\n\n\n\n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n527,633\n315,417, 739,849\n&lt;0.001\n    AREA_SQM\n12,778\n12,057, 13,498\n&lt;0.001\n    AGE\n-24,688\n-30,092, -19,284\n&lt;0.001\n    PROX_CBD\n-77,131\n-88,436, -65,826\n&lt;0.001\n    PROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n    PROX_ELDERLYCARE\n185,576\n107,303, 263,849\n&lt;0.001\n    PROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n&lt;0.001\n    PROX_MRT\n-294,745\n-406,394, -183,096\n&lt;0.001\n    PROX_PARK\n570,505\n442,004, 699,006\n&lt;0.001\n    PROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n    PROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n&lt;0.001\n    PROX_BUS_STOP\n682,482\n418,616, 946,348\n&lt;0.001\n    NO_Of_UNITS\n-245\n-418, -73\n0.005\n    FAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n    FREEHOLD\n350,600\n255,448, 445,752\n&lt;0.001\n  \n  \n    \n      R² = 0.651; Adjusted R² = 0.647; AIC = 42,967; Statistic = 189; p-value = &lt;0.001; U03C3 = 755,957\n    \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\n\nFor more customisation options, refer to Tutorial: tbl_regression\n\n\n8.5.1 Checking for multicolinearity\nIn this section, it will introduce a R package specially programmed for performing OLS regression. It is called olsrr. It provides a collection of very useful methods for building better multiple linear regression models:\n\ncomprehensive regression output\nresidual diagnostics\nmeasures of influence\nheteroskedasticity tests\ncollinearity diagnostics\nmodel fit assessment\nvariable contribution assessment\nvariable selection procedures\n\nIn the code chunk below, the ols_vif_tol() function of olsrr package is used to test if there are signs of multicollinearity.\n\nols_vif_tol(condo.mlr1)\n\n              Variables Tolerance      VIF\n1              AREA_SQM 0.8728554 1.145665\n2                   AGE 0.7071275 1.414172\n3              PROX_CBD 0.6356147 1.573280\n4        PROX_CHILDCARE 0.3066019 3.261559\n5      PROX_ELDERLYCARE 0.6598479 1.515501\n6  PROX_URA_GROWTH_AREA 0.7510311 1.331503\n7              PROX_MRT 0.5236090 1.909822\n8             PROX_PARK 0.8279261 1.207837\n9      PROX_PRIMARY_SCH 0.4524628 2.210126\n10   PROX_SHOPPING_MALL 0.6738795 1.483945\n11        PROX_BUS_STOP 0.3514118 2.845664\n12          NO_Of_UNITS 0.6901036 1.449058\n13      FAMILY_FRIENDLY 0.7244157 1.380423\n14             FREEHOLD 0.6931163 1.442759\n\n\nSince the VIF of the independent variables are all less than 10. We can safely conclude that there are no signs of multicollinearity among the independent variables.\n\n\n8.5.2 Test for Non-Linearity\nIn multiple linear regression, it is important to test the assumption of linearity and additivity of the relationship between dependent and independent variables.\nIn the code chunk below, the ols_plot_resid_fit() of olsrr package is used to perform a linearity assumption test.\n\nols_plot_resid_fit(condo.mlr1)\n\n\n\n\n\n\n\n\nThe figure above reveals that most of the data points are scattered around the 0 line, hence it is safe to conclude that the relationships between the dependent variable and independent variables are linear.\n\n\n8.5.3 Test for Normality Assumption\nLastly, the code chunk below uses ols_plot_resid_hist() of olsrr package to perform a normality assumption test.\n\nols_plot_resid_hist(condo.mlr1)\n\n\n\n\n\n\n\n\nThe figure above reveals that the residual of the multiple linear regression model (i.e. condo.mlr1) is resembling a normal distribution.\nFor formal statistical test methods, the ols_test_normality() of olsrr package can be used as shown in the code chunk below.\n\nols_test_normality(condo.mlr1)\n\nWarning in ks.test.default(y, \"pnorm\", mean(y), sd(y)): ties should not be\npresent for the one-sample Kolmogorov-Smirnov test\n\n\n-----------------------------------------------\n       Test             Statistic       pvalue  \n-----------------------------------------------\nShapiro-Wilk              0.6856         0.0000 \nKolmogorov-Smirnov        0.1366         0.0000 \nCramer-von Mises         121.0768        0.0000 \nAnderson-Darling         67.9551         0.0000 \n-----------------------------------------------\n\n\nThe summary table above reveals that the p-values for all four tests are smaller than the alpha value of 0.05. Hence we will reject the null hypothesis and infer that there is statistical evidence that the residual are not normally distributed.\n\n\n8.5.4 Testing for Spatial Autocorrelation\nThe hedonic model to be built is done by using geographically referenced attributes, hence it is also important for us to visualise the residual of the hedonic pricing model.\nIn order to perform spatial autocorrelation test, we need to convert condo_resale.sf from sf data frame into a SpatialPointsDataFrame.\nFirst, we will export the residual of the hedonic pricing model and save it as a data frame.\n\nmlr.output &lt;- as.data.frame(condo.mlr1$residuals)\n\nNext, to join the newly created data frame with condo_resale.sf object.\n\ncondo_resale.res.sf &lt;- cbind(condo_resale.sf, \n                        condo.mlr1$residuals) %&gt;%\nrename(`MLR_RES` = `condo.mlr1.residuals`)\n\nNext, to convert condo_resale.res.sf from simple feature object into a SpatialPointsDataFrame because spdep package can only process sp conformed spatial data objects.\nThe code chunk below will be used to perform the data conversion process.\n\ncondo_resale.sp &lt;- as_Spatial(condo_resale.res.sf)\ncondo_resale.sp\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1436 \nextent      : 14940.85, 43352.45, 24765.67, 48382.81  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 23\nnames       : POSTCODE, SELLING_PRICE, AREA_SQM, AGE,    PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN,    PROX_MRT,   PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH, PROX_SHOPPING_MALL, ... \nmin values  :    18965,        540000,       34,   0, 0.386916393,    0.004927023,      0.054508623,          0.214539508,        0.051817113,       0.004927023, 0.052779424, 0.029064164,      0.077106132,          0.077106132,                  0, ... \nmax values  :   828833,       1.8e+07,      619,  37, 19.18042832,     3.46572633,      3.949157205,           9.15540001,        5.374348075,       2.229045366,  3.48037319,  2.16104919,      3.928989144,          6.748192062,        3.477433767, ... \n\n\nFolowing which, the tmap package is used to display the distribution of the residuals on an interactive map.\nThe code churn below will turn on the interactive mode of tmap.\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\n\nThe code chunks below is used to create an interactive point symbol map.\n\ntm_shape(mpsz_svy21)+\n  tmap_options(check.and.fix = TRUE) +\n  tm_polygons(alpha = 0.4) +\ntm_shape(condo_resale.res.sf) +  \n  tm_dots(col = \"MLR_RES\",\n          alpha = 0.6,\n          style =\"quantile\") +\n  tm_view(set.zoom.limits = c(11,14))\n\nVariable(s) \"MLR_RES\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\n\n\nNote to switch back to “plot” mode before continuing as shown in the code chunk above.\n\nThe figure above revealed that there are signs of spatial autocorrelation.\nTo proof that this observation is indeed true, the Moran’s I test will be performed\nThe distance-based weight matrix will be computed by using dnearneigh() function of spdep.\n\nnb &lt;- dnearneigh(coordinates(condo_resale.sp), 0, 1500, longlat = FALSE)\nsummary(nb)\n\nNeighbour list object:\nNumber of regions: 1436 \nNumber of nonzero links: 66266 \nPercentage nonzero weights: 3.213526 \nAverage number of links: 46.14624 \n10 disjoint connected subgraphs\nLink number distribution:\n\n  1   3   5   7   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24 \n  3   3   9   4   3  15  10  19  17  45  19   5  14  29  19   6  35  45  18  47 \n 25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44 \n 16  43  22  26  21  11   9  23  22  13  16  25  21  37  16  18   8  21   4  12 \n 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64 \n  8  36  18  14  14  43  11  12   8  13  12  13   4   5   6  12  11  20  29  33 \n 65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84 \n 15  20  10  14  15  15  11  16  12  10   8  19  12  14   9   8   4  13  11   6 \n 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 \n  4   9   4   4   4   6   2  16   9   4   5   9   3   9   4   2   1   2   1   1 \n105 106 107 108 109 110 112 116 125 \n  1   5   9   2   1   3   1   1   1 \n3 least connected regions:\n193 194 277 with 1 link\n1 most connected region:\n285 with 125 links\n\n\nSubsequently, nb2listw() of spdep package will be used to convert the output neighbours lists (i.e. nb) into a spatial weights.\n\nnb_lw &lt;- nb2listw(nb, style = 'W')\nsummary(nb_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 1436 \nNumber of nonzero links: 66266 \nPercentage nonzero weights: 3.213526 \nAverage number of links: 46.14624 \n10 disjoint connected subgraphs\nLink number distribution:\n\n  1   3   5   7   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24 \n  3   3   9   4   3  15  10  19  17  45  19   5  14  29  19   6  35  45  18  47 \n 25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44 \n 16  43  22  26  21  11   9  23  22  13  16  25  21  37  16  18   8  21   4  12 \n 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64 \n  8  36  18  14  14  43  11  12   8  13  12  13   4   5   6  12  11  20  29  33 \n 65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84 \n 15  20  10  14  15  15  11  16  12  10   8  19  12  14   9   8   4  13  11   6 \n 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 \n  4   9   4   4   4   6   2  16   9   4   5   9   3   9   4   2   1   2   1   1 \n105 106 107 108 109 110 112 116 125 \n  1   5   9   2   1   3   1   1   1 \n3 least connected regions:\n193 194 277 with 1 link\n1 most connected region:\n285 with 125 links\n\nWeights style: W \nWeights constants summary:\n     n      nn   S0       S1       S2\nW 1436 2062096 1436 94.81916 5798.341\n\n\nThe lm.morantest() of spdep package will be used to perform Moran’s I test for residual spatial autocorrelation\n\nlm.morantest(condo.mlr1, nb_lw)\n\n\n    Global Moran I for regression residuals\n\ndata:  \nmodel: lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD +\nPROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_MRT +\nPROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP +\nNO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, data = condo_resale.sf)\nweights: nb_lw\n\nMoran I statistic standard deviate = 24.366, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nObserved Moran I      Expectation         Variance \n    1.438876e-01    -5.487594e-03     3.758259e-05 \n\n\nThe Global Moran’s I test for residual spatial autocorrelation shows that it’s p-value is less than 0.00000000000000022 which is less than the alpha value of 0.05. Hence, we can conclude to reject the null hypothesis that the residuals are randomly distributed.\nSince the Observed Global Moran I = 0.1438876 which is greater than 0, we can infer that the residuals resemble cluster distribution."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#building-hedonic-pricing-models-using-gwmodel",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#building-hedonic-pricing-models-using-gwmodel",
    "title": "Hands-on Exercise 7: Geographically Weighted Regression (GWR)",
    "section": "9 Building Hedonic Pricing Models using GWmodel",
    "text": "9 Building Hedonic Pricing Models using GWmodel\nIn this section, it illustrates how to model a hedonic pricing using both the fixed and adaptive bandwidth schemes\n\n9.1 Building Fixed Bandwidth GWR Model\n\n9.1.1 Computing fixed bandwith\nIn the code chunk below bw.gwr() of GWModel package is used to determine the optimal fixed bandwidth to use in the model.\n\n\n\n\n\n\nNote\n\n\n\nNotice that the argument adaptive is set to FALSE indicates that we are interested to compute the fixed bandwidth.\n\n\nThere are two possible approaches can be used to determine the stopping rule, they are: CV cross-validation approach and AIC corrected (AICc) approach. We define the stopping rule by using the approach agreement.\n\nbw.fixed &lt;- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n                     PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + \n                     PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + \n                     PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + \n                     FAMILY_FRIENDLY + FREEHOLD, \n                   data = condo_resale.sp, \n                   approach = \"CV\", \n                   kernel = \"gaussian\", \n                   adaptive = FALSE, \n                   longlat = FALSE)\n\nFixed bandwidth: 17660.96 CV score: 8.259118e+14 \nFixed bandwidth: 10917.26 CV score: 7.970454e+14 \nFixed bandwidth: 6749.419 CV score: 7.273273e+14 \nFixed bandwidth: 4173.553 CV score: 6.300006e+14 \nFixed bandwidth: 2581.58 CV score: 5.404958e+14 \nFixed bandwidth: 1597.687 CV score: 4.857515e+14 \nFixed bandwidth: 989.6077 CV score: 4.722431e+14 \nFixed bandwidth: 613.7939 CV score: 1.378294e+16 \nFixed bandwidth: 1221.873 CV score: 4.778717e+14 \nFixed bandwidth: 846.0596 CV score: 4.791629e+14 \nFixed bandwidth: 1078.325 CV score: 4.751406e+14 \nFixed bandwidth: 934.7772 CV score: 4.72518e+14 \nFixed bandwidth: 1023.495 CV score: 4.730305e+14 \nFixed bandwidth: 968.6643 CV score: 4.721317e+14 \nFixed bandwidth: 955.7206 CV score: 4.722072e+14 \nFixed bandwidth: 976.6639 CV score: 4.721387e+14 \nFixed bandwidth: 963.7202 CV score: 4.721484e+14 \nFixed bandwidth: 971.7199 CV score: 4.721293e+14 \nFixed bandwidth: 973.6083 CV score: 4.721309e+14 \nFixed bandwidth: 970.5527 CV score: 4.721295e+14 \nFixed bandwidth: 972.4412 CV score: 4.721296e+14 \nFixed bandwidth: 971.2741 CV score: 4.721292e+14 \nFixed bandwidth: 970.9985 CV score: 4.721293e+14 \nFixed bandwidth: 971.4443 CV score: 4.721292e+14 \nFixed bandwidth: 971.5496 CV score: 4.721293e+14 \nFixed bandwidth: 971.3793 CV score: 4.721292e+14 \nFixed bandwidth: 971.3391 CV score: 4.721292e+14 \nFixed bandwidth: 971.3143 CV score: 4.721292e+14 \nFixed bandwidth: 971.3545 CV score: 4.721292e+14 \nFixed bandwidth: 971.3296 CV score: 4.721292e+14 \nFixed bandwidth: 971.345 CV score: 4.721292e+14 \nFixed bandwidth: 971.3355 CV score: 4.721292e+14 \nFixed bandwidth: 971.3413 CV score: 4.721292e+14 \nFixed bandwidth: 971.3377 CV score: 4.721292e+14 \nFixed bandwidth: 971.34 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3408 CV score: 4.721292e+14 \nFixed bandwidth: 971.3403 CV score: 4.721292e+14 \nFixed bandwidth: 971.3406 CV score: 4.721292e+14 \nFixed bandwidth: 971.3404 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \n\n\nThe result shows that the recommended bandwidth is 971.3405 metres.\n\nQuestion - Why is the bandwidth shown in metres?\n\n\n\n9.1.2 GWModel method - fixed bandwith\nNow we can use the code chunk below to calibrate the gwr model using fixed bandwidth and gaussian kernel.\n\ngwr.fixed &lt;- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n                         PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + \n                         PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + \n                         PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + \n                         FAMILY_FRIENDLY + FREEHOLD, \n                       data = condo_resale.sp, \n                       bw = bw.fixed, \n                       kernel = 'gaussian', \n                       longlat = FALSE)\n\nThe output is saved in a list of class “gwrm”. The code below can be used to display the model output.\n\ngwr.fixed\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2024-10-17 04:00:55.563918 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sp, bw = bw.fixed, kernel = \"gaussian\", \n    longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  &lt; 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  &lt; 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  &lt; 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  &lt; 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Fixed bandwidth: 971.3405 \n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -3.5988e+07 -5.1998e+05  7.6780e+05  1.7412e+06\n   AREA_SQM              1.0003e+03  5.2758e+03  7.4740e+03  1.2301e+04\n   AGE                  -1.3475e+05 -2.0813e+04 -8.6260e+03 -3.7784e+03\n   PROX_CBD             -7.7047e+07 -2.3608e+05 -8.3600e+04  3.4646e+04\n   PROX_CHILDCARE       -6.0097e+06 -3.3667e+05 -9.7425e+04  2.9007e+05\n   PROX_ELDERLYCARE     -3.5000e+06 -1.5970e+05  3.1971e+04  1.9577e+05\n   PROX_URA_GROWTH_AREA -3.0170e+06 -8.2013e+04  7.0749e+04  2.2612e+05\n   PROX_MRT             -3.5282e+06 -6.5836e+05 -1.8833e+05  3.6922e+04\n   PROX_PARK            -1.2062e+06 -2.1732e+05  3.5383e+04  4.1335e+05\n   PROX_PRIMARY_SCH     -2.2695e+07 -1.7066e+05  4.8472e+04  5.1555e+05\n   PROX_SHOPPING_MALL   -7.2585e+06 -1.6684e+05 -1.0517e+04  1.5923e+05\n   PROX_BUS_STOP        -1.4676e+06 -4.5207e+04  3.7601e+05  1.1664e+06\n   NO_Of_UNITS          -1.3170e+03 -2.4822e+02 -3.0846e+01  2.5496e+02\n   FAMILY_FRIENDLY      -2.2749e+06 -1.1140e+05  7.6214e+03  1.6107e+05\n   FREEHOLD             -9.2067e+06  3.8073e+04  1.5169e+05  3.7528e+05\n                             Max.\n   Intercept            112793548\n   AREA_SQM                 21575\n   AGE                     434201\n   PROX_CBD               2704596\n   PROX_CHILDCARE         1654087\n   PROX_ELDERLYCARE      38867814\n   PROX_URA_GROWTH_AREA  78515730\n   PROX_MRT               3124316\n   PROX_PARK             18122425\n   PROX_PRIMARY_SCH       4637503\n   PROX_SHOPPING_MALL     1529952\n   PROX_BUS_STOP         11342182\n   NO_Of_UNITS              12907\n   FAMILY_FRIENDLY        1720744\n   FREEHOLD               6073636\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 438.3804 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 997.6196 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 42263.61 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41632.36 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 42515.71 \n   Residual sum of squares: 2.53407e+14 \n   R-square value:  0.8909912 \n   Adjusted R-square value:  0.8430417 \n\n   ***********************************************************************\n   Program stops at: 2024-10-17 04:00:56.30773 \n\n\nThe report shows that the AICc of the gwr is 42263.61 which is significantly smaller than the global multiple linear regression model of 42967.1.\n\n\n\n9.2 Building Adaptive Bandwidth GWR Model\nIn this section, we will calibrate the gwr-based hedonic pricing model by using adaptive bandwidth approach.\n\n9.2.1 Computing the adaptive bandwidth\nSimilar to the earlier section, we will first use bw.gwr() to determine the recommended data point to use.\nThe code chunk used look very similar to the one used to compute the fixed bandwidth except the adaptive argument has changed to TRUE.\n\nbw.adaptive &lt;- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE  + \n                        PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE    + \n                        PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                        PROX_PRIMARY_SCH + PROX_SHOPPING_MALL   + PROX_BUS_STOP + \n                        NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                      data = condo_resale.sp, \n                      approach = \"CV\", \n                      kernel = \"gaussian\", \n                      adaptive = TRUE, \n                      longlat = FALSE)\n\nAdaptive bandwidth: 895 CV score: 7.952401e+14 \nAdaptive bandwidth: 561 CV score: 7.667364e+14 \nAdaptive bandwidth: 354 CV score: 6.953454e+14 \nAdaptive bandwidth: 226 CV score: 6.15223e+14 \nAdaptive bandwidth: 147 CV score: 5.674373e+14 \nAdaptive bandwidth: 98 CV score: 5.426745e+14 \nAdaptive bandwidth: 68 CV score: 5.168117e+14 \nAdaptive bandwidth: 49 CV score: 4.859631e+14 \nAdaptive bandwidth: 37 CV score: 4.646518e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \nAdaptive bandwidth: 25 CV score: 4.430816e+14 \nAdaptive bandwidth: 32 CV score: 4.505602e+14 \nAdaptive bandwidth: 27 CV score: 4.462172e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \n\n\nThe result shows that the 30 is the recommended number of data points to be used.\n\n\n9.2.2 Constructing the adaptive bandwidth gwr model\nNow, we can go ahead to calibrate the gwr-based hedonic pricing model by using adaptive bandwidth and gaussian kernel as shown in the code chunk below.\n\ngwr.adaptive &lt;- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                            PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE + \n                            PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                            PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP + \n                            NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                          data = condo_resale.sp, bw=bw.adaptive, \n                          kernel = 'gaussian', \n                          adaptive=TRUE, \n                          longlat = FALSE)\n\nThe code below can be used to display the model output.\n\ngwr.adaptive\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2024-10-17 04:01:02.49513 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sp, bw = bw.adaptive, kernel = \"gaussian\", \n    adaptive = TRUE, longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  &lt; 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  &lt; 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  &lt; 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  &lt; 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Adaptive bandwidth: 30 (number of nearest neighbours)\n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -1.3487e+08 -2.4669e+05  7.7928e+05  1.6194e+06\n   AREA_SQM              3.3188e+03  5.6285e+03  7.7825e+03  1.2738e+04\n   AGE                  -9.6746e+04 -2.9288e+04 -1.4043e+04 -5.6119e+03\n   PROX_CBD             -2.5330e+06 -1.6256e+05 -7.7242e+04  2.6624e+03\n   PROX_CHILDCARE       -1.2790e+06 -2.0175e+05  8.7158e+03  3.7778e+05\n   PROX_ELDERLYCARE     -1.6212e+06 -9.2050e+04  6.1029e+04  2.8184e+05\n   PROX_URA_GROWTH_AREA -7.2686e+06 -3.0350e+04  4.5869e+04  2.4613e+05\n   PROX_MRT             -4.3781e+07 -6.7282e+05 -2.2115e+05 -7.4593e+04\n   PROX_PARK            -2.9020e+06 -1.6782e+05  1.1601e+05  4.6572e+05\n   PROX_PRIMARY_SCH     -8.6418e+05 -1.6627e+05 -7.7853e+03  4.3222e+05\n   PROX_SHOPPING_MALL   -1.8272e+06 -1.3175e+05 -1.4049e+04  1.3799e+05\n   PROX_BUS_STOP        -2.0579e+06 -7.1461e+04  4.1104e+05  1.2071e+06\n   NO_Of_UNITS          -2.1993e+03 -2.3685e+02 -3.4699e+01  1.1657e+02\n   FAMILY_FRIENDLY      -5.9879e+05 -5.0927e+04  2.6173e+04  2.2481e+05\n   FREEHOLD             -1.6340e+05  4.0765e+04  1.9023e+05  3.7960e+05\n                            Max.\n   Intercept            18758355\n   AREA_SQM                23064\n   AGE                     13303\n   PROX_CBD             11346650\n   PROX_CHILDCARE        2892127\n   PROX_ELDERLYCARE      2465671\n   PROX_URA_GROWTH_AREA  7384059\n   PROX_MRT              1186242\n   PROX_PARK             2588497\n   PROX_PRIMARY_SCH      3381462\n   PROX_SHOPPING_MALL   38038564\n   PROX_BUS_STOP        12081592\n   NO_Of_UNITS              1010\n   FAMILY_FRIENDLY       2072414\n   FREEHOLD              1813995\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 350.3088 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 1085.691 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 41982.22 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41546.74 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 41914.08 \n   Residual sum of squares: 2.528227e+14 \n   R-square value:  0.8912425 \n   Adjusted R-square value:  0.8561185 \n\n   ***********************************************************************\n   Program stops at: 2024-10-17 04:01:03.792712 \n\n\nThe report shows that the AICc the adaptive distance gwr is 41982.22 which is even smaller than the AICc of the fixed distance gwr of 42263.61.\n\n\n\n9.3 Visualising GWR Output\nIn addition to regression residuals, the output feature class table includes fields for observed and predicted y values, condition number (cond), Local R2, residuals, and explanatory variable coefficients and standard errors:\n\nCondition Number: this diagnostic evaluates local collinearity. In the presence of strong local collinearity, results become unstable. Results associated with condition numbers larger than 30, may be unreliable.\nLocal R2: these values range between 0.0 and 1.0 and indicate how well the local regression model fits observed y values. Very low values indicate the local model is performing poorly. Mapping the Local R2 values to see where GWR predicts well and where it predicts poorly may provide clues about important variables that may be missing from the regression model.\nPredicted: these are the estimated (or fitted) y values 3. computed by GWR.\nResiduals: to obtain the residual values, the fitted y values are subtracted from the observed y values. Standardized residuals have a mean of zero and a standard deviation of 1. A cold-to-hot rendered map of standardized residuals can be produce by using these values.\nCoefficient Standard Error: these values measure the reliability of each coefficient estimate. Confidence in those estimates are higher when standard errors are small in relation to the actual coefficient values. Large standard errors may indicate problems with local collinearity.\n\nThey are all stored in a SpatialPointsDataFrame or SpatialPolygonsDataFrame object integrated with fit.points, GWR coefficient estimates, y value, predicted values, coefficient standard errors and t-values in its “data” slot in an object called SDF of the output list.\n\n\n9.4 Converting SDF into sf data.frame\nTo visualise the fields in SDF, we need to first covert it into sf data.frame by using the code chunk below.\n\ncondo_resale.sf.adaptive &lt;- st_as_sf(gwr.adaptive$SDF) %&gt;%\n  st_transform(crs=3414)\n\n\ncondo_resale.sf.adaptive.svy21 &lt;- st_transform(condo_resale.sf.adaptive, 3414)\ncondo_resale.sf.adaptive.svy21  \n\nSimple feature collection with 1436 features and 51 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 14940.85 ymin: 24765.67 xmax: 43352.45 ymax: 48382.81\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n    Intercept  AREA_SQM        AGE  PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE\n1   2050011.7  9561.892  -9514.634 -120681.9      319266.92       -393417.79\n2   1633128.2 16576.853 -58185.479 -149434.2      441102.18        325188.74\n3   3433608.2 13091.861 -26707.386 -259397.8     -120116.82        535855.81\n4    234358.9 20730.601 -93308.988 2426853.7      480825.28        314783.72\n5   2285804.9  6722.836 -17608.018 -316835.5       90764.78       -137384.61\n6  -3568877.4  6039.581 -26535.592  327306.1     -152531.19       -700392.85\n7  -2874842.4 16843.575 -59166.727 -983577.2     -177810.50       -122384.02\n8   2038086.0  6905.135 -17681.897 -285076.6       70259.40        -96012.78\n9   1718478.4  9580.703 -14401.128  105803.4     -657698.02       -123276.00\n10  3457054.0 14072.011 -31579.884 -234895.4       79961.45        548581.04\n   PROX_URA_GROWTH_AREA    PROX_MRT  PROX_PARK PROX_PRIMARY_SCH\n1            -159980.20  -299742.96 -172104.47        242668.03\n2            -142290.39 -2510522.23  523379.72       1106830.66\n3            -253621.21  -936853.28  209099.85        571462.33\n4           -2679297.89 -2039479.50 -759153.26       3127477.21\n5             303714.81   -44567.05  -10284.62         30413.56\n6             -28051.25   733566.47 1511488.92        320878.23\n7            1397676.38 -2745430.34  710114.74       1786570.95\n8             269368.71   -14552.99   73533.34         53359.73\n9            -361974.72  -476785.32 -132067.59        -40128.92\n10           -150024.38 -1503835.53  574155.47        108996.67\n   PROX_SHOPPING_MALL PROX_BUS_STOP  NO_Of_UNITS FAMILY_FRIENDLY  FREEHOLD\n1          300881.390     1210615.4  104.8290640       -9075.370  303955.6\n2          -87693.378     1843587.2 -288.3441183      310074.664  396221.3\n3         -126732.712     1411924.9   -9.5532945        5949.746  168821.7\n4          -29593.342     7225577.5 -161.3551620     1556178.531 1212515.6\n5           -7490.586      677577.0   42.2659674       58986.951  328175.2\n6          258583.881     1086012.6 -214.3671271      201992.641  471873.1\n7         -384251.210     5094060.5   -0.9212521      359659.512  408871.9\n8          -39634.902      735767.1   30.1741069       55602.506  347075.0\n9          276718.757     2815772.4  675.1615559      -30453.297  503872.8\n10        -454726.822     2123557.0  -21.3044311     -100935.586  213324.6\n         y    yhat    residual CV_Score Stud_residual Intercept_SE AREA_SQM_SE\n1  3000000 2886532   113468.16        0    0.38207013     516105.5    823.2860\n2  3880000 3466801   413198.52        0    1.01433140     488083.5    825.2380\n3  3325000 3616527  -291527.20        0   -0.83780678     963711.4    988.2240\n4  4250000 5435482 -1185481.63        0   -2.84614670     444185.5    617.4007\n5  1400000 1388166    11834.26        0    0.03404453    2119620.6   1376.2778\n6  1320000 1516702  -196701.94        0   -0.72065800   28572883.7   2348.0091\n7  3410000 3266881   143118.77        0    0.41291992     679546.6    893.5893\n8  1420000 1431955   -11955.27        0   -0.03033109    2217773.1   1415.2604\n9  2025000 1832799   192200.83        0    0.52018109     814281.8    943.8434\n10 2550000 2223364   326635.53        0    1.10559735    2410252.0   1271.4073\n      AGE_SE PROX_CBD_SE PROX_CHILDCARE_SE PROX_ELDERLYCARE_SE\n1   5889.782    37411.22          319111.1           120633.34\n2   6226.916    23615.06          299705.3            84546.69\n3   6510.236    56103.77          349128.5           129687.07\n4   6010.511   469337.41          304965.2           127150.69\n5   8180.361   410644.47          698720.6           327371.55\n6  14601.909  5272846.47         1141599.8          1653002.19\n7   8970.629   346164.20          530101.1           148598.71\n8   8661.309   438035.69          742532.8           399221.05\n9  11791.208    89148.35          704630.7           329683.30\n10  9941.980   173532.77          500976.2           281876.74\n   PROX_URA_GROWTH_AREA_SE PROX_MRT_SE PROX_PARK_SE PROX_PRIMARY_SCH_SE\n1                 56207.39    185181.3     205499.6            152400.7\n2                 76956.50    281133.9     229358.7            165150.7\n3                 95774.60    275483.7     314124.3            196662.6\n4                470762.12    279877.1     227249.4            240878.9\n5                474339.56    363830.0     364580.9            249087.7\n6               5496627.21    730453.2    1741712.0            683265.5\n7                371692.97    375511.9     297400.9            344602.8\n8                517977.91    423155.4     440984.4            261251.2\n9                153436.22    285325.4     304998.4            278258.5\n10               239182.57    571355.7     599131.8            331284.8\n   PROX_SHOPPING_MALL_SE PROX_BUS_STOP_SE NO_Of_UNITS_SE FAMILY_FRIENDLY_SE\n1               109268.8         600668.6       218.1258           131474.7\n2                98906.8         410222.1       208.9410           114989.1\n3               119913.3         464156.7       210.9828           146607.2\n4               177104.1         562810.8       361.7767           108726.6\n5               301032.9         740922.4       299.5034           160663.7\n6              2931208.6        1418333.3       602.5571           331727.0\n7               249969.5         821236.4       532.1978           129241.2\n8               351634.0         775038.4       338.6777           171895.1\n9               289872.7         850095.5       439.9037           220223.4\n10              265529.7         631399.2       259.0169           189125.5\n   FREEHOLD_SE Intercept_TV AREA_SQM_TV     AGE_TV PROX_CBD_TV\n1     115954.0    3.9720784   11.614302  -1.615447 -3.22582173\n2     130110.0    3.3460017   20.087361  -9.344188 -6.32792021\n3     141031.5    3.5629010   13.247868  -4.102368 -4.62353528\n4     138239.1    0.5276150   33.577223 -15.524302  5.17080808\n5     210641.1    1.0784029    4.884795  -2.152474 -0.77155660\n6     374347.3   -0.1249043    2.572214  -1.817269  0.06207388\n7     182216.9   -4.2305303   18.849348  -6.595605 -2.84136028\n8     216649.4    0.9189786    4.879056  -2.041481 -0.65080678\n9     220473.7    2.1104224   10.150733  -1.221345  1.18682383\n10    206346.2    1.4343123   11.068059  -3.176418 -1.35360852\n   PROX_CHILDCARE_TV PROX_ELDERLYCARE_TV PROX_URA_GROWTH_AREA_TV PROX_MRT_TV\n1         1.00048819          -3.2612693            -2.846248368 -1.61864578\n2         1.47178634           3.8462625            -1.848971738 -8.92998600\n3        -0.34404755           4.1319138            -2.648105057 -3.40075727\n4         1.57665606           2.4756745            -5.691404992 -7.28705261\n5         0.12990138          -0.4196596             0.640289855 -0.12249416\n6        -0.13361179          -0.4237096            -0.005103357  1.00426206\n7        -0.33542751          -0.8235874             3.760298131 -7.31116712\n8         0.09462126          -0.2405003             0.520038994 -0.03439159\n9        -0.93339393          -0.3739225            -2.359121712 -1.67102293\n10        0.15961128           1.9461735            -0.627237944 -2.63204802\n   PROX_PARK_TV PROX_PRIMARY_SCH_TV PROX_SHOPPING_MALL_TV PROX_BUS_STOP_TV\n1   -0.83749312           1.5923022            2.75358842        2.0154464\n2    2.28192684           6.7019454           -0.88662640        4.4941192\n3    0.66565951           2.9058009           -1.05686949        3.0419145\n4   -3.34061770          12.9836105           -0.16709578       12.8383775\n5   -0.02820944           0.1220998           -0.02488294        0.9145046\n6    0.86781794           0.4696245            0.08821750        0.7656963\n7    2.38773567           5.1844351           -1.53719231        6.2029165\n8    0.16674816           0.2042469           -0.11271635        0.9493299\n9   -0.43301073          -0.1442145            0.95462153        3.3123012\n10   0.95831249           0.3290120           -1.71252687        3.3632555\n   NO_Of_UNITS_TV FAMILY_FRIENDLY_TV FREEHOLD_TV  Local_R2\n1     0.480589953        -0.06902748    2.621347 0.8846744\n2    -1.380026395         2.69655779    3.045280 0.8899773\n3    -0.045279967         0.04058290    1.197050 0.8947007\n4    -0.446007570        14.31276425    8.771149 0.9073605\n5     0.141120178         0.36714544    1.557983 0.9510057\n6    -0.355762335         0.60891234    1.260522 0.9247586\n7    -0.001731033         2.78285441    2.243875 0.8310458\n8     0.089093858         0.32346758    1.602012 0.9463936\n9     1.534793921        -0.13828365    2.285410 0.8380365\n10   -0.082251138        -0.53369623    1.033819 0.9080753\n                    geometry\n1  POINT (22085.12 29951.54)\n2   POINT (25656.84 34546.2)\n3   POINT (23963.99 32890.8)\n4  POINT (27044.28 32319.77)\n5  POINT (41042.56 33743.64)\n6   POINT (39717.04 32943.1)\n7   POINT (28419.1 33513.37)\n8  POINT (40763.57 33879.61)\n9  POINT (23595.63 28884.78)\n10 POINT (24586.56 33194.31)\n\n\n\ngwr.adaptive.output &lt;- as.data.frame(gwr.adaptive$SDF)\ncondo_resale.sf.adaptive &lt;- cbind(condo_resale.res.sf, as.matrix(gwr.adaptive.output))\n\nNext, glimpse() is used to display the content of condo_resale.sf.adaptive sf data frame.\n\nglimpse(condo_resale.sf.adaptive)\n\nRows: 1,436\nColumns: 77\n$ POSTCODE                &lt;dbl&gt; 118635, 288420, 267833, 258380, 467169, 466472…\n$ SELLING_PRICE           &lt;dbl&gt; 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ AREA_SQM                &lt;dbl&gt; 309, 290, 248, 127, 145, 139, 218, 141, 165, 1…\n$ AGE                     &lt;dbl&gt; 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22,…\n$ PROX_CBD                &lt;dbl&gt; 7.941259, 6.609797, 6.898000, 4.038861, 11.783…\n$ PROX_CHILDCARE          &lt;dbl&gt; 0.16597932, 0.28027246, 0.42922669, 0.39473543…\n$ PROX_ELDERLYCARE        &lt;dbl&gt; 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.…\n$ PROX_URA_GROWTH_AREA    &lt;dbl&gt; 6.618741, 7.505109, 6.463887, 4.906512, 6.4106…\n$ PROX_HAWKER_MARKET      &lt;dbl&gt; 1.76542207, 0.54507614, 0.37789301, 1.68259969…\n$ PROX_KINDERGARTEN       &lt;dbl&gt; 0.05835552, 0.61592412, 0.14120309, 0.38200076…\n$ PROX_MRT                &lt;dbl&gt; 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.…\n$ PROX_PARK               &lt;dbl&gt; 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.…\n$ PROX_PRIMARY_SCH        &lt;dbl&gt; 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.…\n$ PROX_TOP_PRIMARY_SCH    &lt;dbl&gt; 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.…\n$ PROX_SHOPPING_MALL      &lt;dbl&gt; 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.…\n$ PROX_SUPERMARKET        &lt;dbl&gt; 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.…\n$ PROX_BUS_STOP           &lt;dbl&gt; 0.10336166, 0.28673408, 0.28504777, 0.29872340…\n$ NO_Of_UNITS             &lt;dbl&gt; 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34…\n$ FAMILY_FRIENDLY         &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD                &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR          &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ LOG_SELLING_PRICE       &lt;dbl&gt; 14.91412, 15.17135, 15.01698, 15.26243, 14.151…\n$ MLR_RES                 &lt;dbl&gt; -1489099.55, 415494.57, 194129.69, 1088992.71,…\n$ Intercept               &lt;dbl&gt; 2050011.67, 1633128.24, 3433608.17, 234358.91,…\n$ AREA_SQM.1              &lt;dbl&gt; 9561.892, 16576.853, 13091.861, 20730.601, 672…\n$ AGE.1                   &lt;dbl&gt; -9514.634, -58185.479, -26707.386, -93308.988,…\n$ PROX_CBD.1              &lt;dbl&gt; -120681.94, -149434.22, -259397.77, 2426853.66…\n$ PROX_CHILDCARE.1        &lt;dbl&gt; 319266.925, 441102.177, -120116.816, 480825.28…\n$ PROX_ELDERLYCARE.1      &lt;dbl&gt; -393417.795, 325188.741, 535855.806, 314783.72…\n$ PROX_URA_GROWTH_AREA.1  &lt;dbl&gt; -159980.203, -142290.389, -253621.206, -267929…\n$ PROX_MRT.1              &lt;dbl&gt; -299742.96, -2510522.23, -936853.28, -2039479.…\n$ PROX_PARK.1             &lt;dbl&gt; -172104.47, 523379.72, 209099.85, -759153.26, …\n$ PROX_PRIMARY_SCH.1      &lt;dbl&gt; 242668.03, 1106830.66, 571462.33, 3127477.21, …\n$ PROX_SHOPPING_MALL.1    &lt;dbl&gt; 300881.390, -87693.378, -126732.712, -29593.34…\n$ PROX_BUS_STOP.1         &lt;dbl&gt; 1210615.44, 1843587.22, 1411924.90, 7225577.51…\n$ NO_Of_UNITS.1           &lt;dbl&gt; 104.8290640, -288.3441183, -9.5532945, -161.35…\n$ FAMILY_FRIENDLY.1       &lt;dbl&gt; -9075.370, 310074.664, 5949.746, 1556178.531, …\n$ FREEHOLD.1              &lt;dbl&gt; 303955.61, 396221.27, 168821.75, 1212515.58, 3…\n$ y                       &lt;dbl&gt; 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ yhat                    &lt;dbl&gt; 2886531.8, 3466801.5, 3616527.2, 5435481.6, 13…\n$ residual                &lt;dbl&gt; 113468.16, 413198.52, -291527.20, -1185481.63,…\n$ CV_Score                &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Stud_residual           &lt;dbl&gt; 0.38207013, 1.01433140, -0.83780678, -2.846146…\n$ Intercept_SE            &lt;dbl&gt; 516105.5, 488083.5, 963711.4, 444185.5, 211962…\n$ AREA_SQM_SE             &lt;dbl&gt; 823.2860, 825.2380, 988.2240, 617.4007, 1376.2…\n$ AGE_SE                  &lt;dbl&gt; 5889.782, 6226.916, 6510.236, 6010.511, 8180.3…\n$ PROX_CBD_SE             &lt;dbl&gt; 37411.22, 23615.06, 56103.77, 469337.41, 41064…\n$ PROX_CHILDCARE_SE       &lt;dbl&gt; 319111.1, 299705.3, 349128.5, 304965.2, 698720…\n$ PROX_ELDERLYCARE_SE     &lt;dbl&gt; 120633.34, 84546.69, 129687.07, 127150.69, 327…\n$ PROX_URA_GROWTH_AREA_SE &lt;dbl&gt; 56207.39, 76956.50, 95774.60, 470762.12, 47433…\n$ PROX_MRT_SE             &lt;dbl&gt; 185181.3, 281133.9, 275483.7, 279877.1, 363830…\n$ PROX_PARK_SE            &lt;dbl&gt; 205499.6, 229358.7, 314124.3, 227249.4, 364580…\n$ PROX_PRIMARY_SCH_SE     &lt;dbl&gt; 152400.7, 165150.7, 196662.6, 240878.9, 249087…\n$ PROX_SHOPPING_MALL_SE   &lt;dbl&gt; 109268.8, 98906.8, 119913.3, 177104.1, 301032.…\n$ PROX_BUS_STOP_SE        &lt;dbl&gt; 600668.6, 410222.1, 464156.7, 562810.8, 740922…\n$ NO_Of_UNITS_SE          &lt;dbl&gt; 218.1258, 208.9410, 210.9828, 361.7767, 299.50…\n$ FAMILY_FRIENDLY_SE      &lt;dbl&gt; 131474.73, 114989.07, 146607.22, 108726.62, 16…\n$ FREEHOLD_SE             &lt;dbl&gt; 115954.0, 130110.0, 141031.5, 138239.1, 210641…\n$ Intercept_TV            &lt;dbl&gt; 3.9720784, 3.3460017, 3.5629010, 0.5276150, 1.…\n$ AREA_SQM_TV             &lt;dbl&gt; 11.614302, 20.087361, 13.247868, 33.577223, 4.…\n$ AGE_TV                  &lt;dbl&gt; -1.6154474, -9.3441881, -4.1023685, -15.524301…\n$ PROX_CBD_TV             &lt;dbl&gt; -3.22582173, -6.32792021, -4.62353528, 5.17080…\n$ PROX_CHILDCARE_TV       &lt;dbl&gt; 1.000488185, 1.471786337, -0.344047555, 1.5766…\n$ PROX_ELDERLYCARE_TV     &lt;dbl&gt; -3.26126929, 3.84626245, 4.13191383, 2.4756745…\n$ PROX_URA_GROWTH_AREA_TV &lt;dbl&gt; -2.846248368, -1.848971738, -2.648105057, -5.6…\n$ PROX_MRT_TV             &lt;dbl&gt; -1.61864578, -8.92998600, -3.40075727, -7.2870…\n$ PROX_PARK_TV            &lt;dbl&gt; -0.83749312, 2.28192684, 0.66565951, -3.340617…\n$ PROX_PRIMARY_SCH_TV     &lt;dbl&gt; 1.59230221, 6.70194543, 2.90580089, 12.9836104…\n$ PROX_SHOPPING_MALL_TV   &lt;dbl&gt; 2.753588422, -0.886626400, -1.056869486, -0.16…\n$ PROX_BUS_STOP_TV        &lt;dbl&gt; 2.0154464, 4.4941192, 3.0419145, 12.8383775, 0…\n$ NO_Of_UNITS_TV          &lt;dbl&gt; 0.480589953, -1.380026395, -0.045279967, -0.44…\n$ FAMILY_FRIENDLY_TV      &lt;dbl&gt; -0.06902748, 2.69655779, 0.04058290, 14.312764…\n$ FREEHOLD_TV             &lt;dbl&gt; 2.6213469, 3.0452799, 1.1970499, 8.7711485, 1.…\n$ Local_R2                &lt;dbl&gt; 0.8846744, 0.8899773, 0.8947007, 0.9073605, 0.…\n$ coords.x1               &lt;dbl&gt; 22085.12, 25656.84, 23963.99, 27044.28, 41042.…\n$ coords.x2               &lt;dbl&gt; 29951.54, 34546.20, 32890.80, 32319.77, 33743.…\n$ geometry                &lt;POINT [m]&gt; POINT (22085.12 29951.54), POINT (25656.…\n\n\n\nsummary(gwr.adaptive$SDF$yhat)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n  171347  1102001  1385528  1751842  1982307 13887901 \n\n\n\n\n9.5 Visualising local R2\nThe code chunk below is used to create an interactive point symbol map.\n\ntm_shape(mpsz_svy21) +\n  tmap_options(check.and.fix = TRUE) +\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"Local_R2\",\n          border.col = \"gray50\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\n\n\n\n9.6 Visualising coefficient estimates\nThe code chunks below are used to create an interactive point symbol map.\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\nAREA_SQM_SE &lt;- tm_shape(mpsz_svy21) +\n  tmap_options(check.and.fix = TRUE) +\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"AREA_SQM_SE\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\nAREA_SQM_TV &lt;- tm_shape(mpsz_svy21)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"AREA_SQM_TV\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\ntmap_arrange(AREA_SQM_SE, AREA_SQM_TV, \n             asp=1, ncol=2,\n             sync = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\n\n\n9.6.1 By URA Plannign Region\n\ntmap_options(check.and.fix = TRUE) +\n\ntm_shape(mpsz_svy21[mpsz_svy21$REGION_N==\"CENTRAL REGION\", ]) +\n  tm_polygons()+\ntm_shape(condo_resale.sf.adaptive) + \n  tm_bubbles(col = \"Local_R2\",\n           size = 0.15,\n           border.col = \"gray60\",\n           border.lwd = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#references",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#references",
    "title": "Hands-on Exercise 7: Geographically Weighted Regression (GWR)",
    "section": "10 References",
    "text": "10 References\n\nGollini I, Lu B, Charlton M, Brunsdon C, Harris P (2015) “GWmodel: an R Package for exploring Spatial Heterogeneity using Geographically Weighted Models”. Journal of Statistical Software, 63(17):1-50, http://www.jstatsoft.org/v63/i17/\nLu B, Harris P, Charlton M, Brunsdon C (2014) “The GWmodel R Package: further topics for exploring Spatial Heterogeneity using GeographicallyWeighted Models”. Geo-spatial Information Science 17(2): 85-101, http://www.tandfonline.com/doi/abs/10.1080/1009502.2014.917453\n\nEND"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualing-the-indicators-of-tourism-economy-of-thailand",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualing-the-indicators-of-tourism-economy-of-thailand",
    "title": "Take-home Exercise 2: Geospatial Analytics in Thailand Tourism Sector (Pre, During, Post COVID-19)",
    "section": "",
    "text": "A basemap will be prepared to show the distribution of the number of tourists in the provinces of Thailand.\n\nbasemap &lt;- tm_shape(thailand_tourism) +\n  tm_polygons() +\n  tm_text(\"province\", size = 0.5)\n\nbasemap\n\n\n\n\n\n\n\n\n\n\n\nall_tourists = thailand_tourism%&gt;%\n  filter(variable =='no_tourist_all')\n\nbasemap01 &lt;- tm_shape(all_tourists) +\n  tm_polygons(col = \"total_value\", palette = \"Oranges\", style='quantile') +\n  tm_text(\"province\", size = 0.5)\n\nbasemap01\n\n\n\n\n\n\n\n\n\n\n\n\nforeign_tourists = thailand_tourism%&gt;%\n  filter(variable =='no_tourist_foreign')\n\nbasemap02 &lt;- tm_shape(foreign_tourists) +\n  tm_polygons(col = \"total_value\", palette = \"Oranges\", style='quantile') +\n  tm_text(\"province\", size = 0.5)\n\nbasemap02\n\n\n\n\n\n\n\n\n\n\n\n\ndomestic_tourists = thailand_tourism%&gt;%\n  filter(variable =='no_tourist_thai')\n\nbasemap03 &lt;- tm_shape(domestic_tourists) +\n  tm_polygons(col = \"total_value\", palette = \"Oranges\", style='quantile') +\n  tm_text(\"province\", size = 0.5)\n\nbasemap03\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nall_revenue = thailand_tourism%&gt;%\n  filter(variable =='revenue_all')\n\nbasemap1 &lt;- tm_shape(all_revenue) +\n  tm_polygons(col = \"total_value\", palette = \"Greens\", style='quantile') +\n  tm_text(\"province\", size = 0.5)\n\nbasemap1\n\n\n\n\n\n\n\n\n\n\n\n\nforeign_revenue = thailand_tourism%&gt;%\n  filter(variable =='revenue_foreign')\n\nbasemap2 &lt;- tm_shape(foreign_revenue) +\n  tm_polygons(col = \"total_value\", palette = \"Greens\", style='quantile') +\n  tm_text(\"province\", size = 0.5)\n\nbasemap2\n\n\n\n\n\n\n\n\n\n\n\n\nthai_revenue = thailand_tourism%&gt;%\n  filter(variable =='revenue_thai')\n\nbasemap3 &lt;- tm_shape(thai_revenue) +\n  tm_polygons(col = \"total_value\", palette = \"Greens\", style='quantile') +\n  tm_text(\"province\", size = 0.5)\n\nbasemap3"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#spatial-weights-and-applications",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#spatial-weights-and-applications",
    "title": "Take-home Exercise 2: Geospatial Analytics in Thailand Tourism Sector (Pre, During, Post COVID-19)",
    "section": "",
    "text": "In this section, poly2nb() of spdep package is used to compute contiguity weight matrices for the study area.\n\n\nThe code chunk below is used to compute Queen contiguity weight matrix for revenue.\n\nRevenue Generated by TourismRevenue Generated by ForeignersRevenue Generated by Thais\n\n\n\nwm_q &lt;- poly2nb(all_revenue, queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 77 \nNumber of nonzero links: 352 \nPercentage nonzero weights: 5.93692 \nAverage number of links: 4.571429 \n1 region with no links:\n67\n2 disjoint connected subgraphs\nLink number distribution:\n\n 0  1  2  3  4  5  6  7  8  9 \n 1  1  5 17 15 17 10  5  4  2 \n1 least connected region:\n14 with 1 link\n2 most connected regions:\n29 51 with 9 links\n\n\nThe summary report above shows that there are 77 area units in Thailand which represent the provinces. There are 2 most connected area units eacah with 9 neighbours. There is only 1 area unit with only one neighbour.\nFor each polygon in our polygon object, wm_q lists all neighbouring polygons. For example, to see the neighbours for the 51 polygon in the object, type:\n\nall_revenue$province[51]\n\n[1] \"Tak\"\n\n\nThe output reveals that Polygon ID = 51 is Tak province.\nTo reveal the provinces of the nine neighbouring polygons, the code chunk will be used:\n\nall_revenue$province[c(19,20,25,28,30,31,33,35,55)]\n\n[1] \"Nakhon Ratchasima\" \"Buriram\"           \"Chaiyaphum\"       \n[4] \"Nong Bua Lamphu\"   \"Udon Thani\"        \"Loei\"             \n[7] \"Maha Sarakham\"     \"Kalasin\"           \"Phetchabun\"       \n\n\nWe can retrieve the revenue of these nine provinces by using the code chunk below.\n\nnb51 &lt;- wm_q[[51]]\nnb51 &lt;- all_revenue$total_value[nb51]\nnb51\n\n[1] 260045700000   4810760000  13421950000  14370950000  12339730000\n[6]   4098740000   4543780000   8988760000  77869050000\n\n\nThe printed output above shows that the revenue of the nine nearest neighbours based on Queen’s method are 260045700000, 4810760000, 13421950000, 14370950000, 12339730000, 4098740000, 4543780000, 8988760000 and 77869050000 respectively.\nWe can display the complete weight matrix by using str().\n\nstr(wm_q)\n\nList of 77\n $ : int [1:6] 2 3 4 15 59 60\n $ : int [1:2] 1 15\n $ : int [1:4] 1 4 5 59\n $ : int [1:6] 1 3 5 10 15 17\n $ : int [1:7] 3 4 6 7 10 58 59\n $ : int [1:4] 5 7 8 58\n $ : int [1:8] 5 6 8 10 19 25 48 55\n $ : int [1:5] 6 7 9 48 58\n $ : int [1:4] 8 48 49 58\n $ : int [1:5] 4 5 7 17 19\n $ : int [1:3] 12 13 15\n $ : int [1:2] 11 13\n $ : int [1:5] 11 12 14 15 18\n $ : int 13\n $ : int [1:8] 1 2 4 11 13 16 17 18\n $ : int [1:4] 15 17 18 19\n $ : int [1:5] 4 10 15 16 19\n $ : int [1:5] 13 15 16 19 20\n $ : int [1:8] 7 10 16 17 18 20 25 29\n $ : int [1:5] 18 19 21 29 33\n $ : int [1:4] 20 22 33 34\n $ : int [1:4] 21 23 24 34\n $ : int [1:3] 22 24 26\n $ : int [1:5] 22 23 26 34 38\n $ : int [1:4] 7 19 29 55\n $ : int [1:3] 23 24 38\n $ : int [1:3] 32 36 37\n $ : int [1:3] 29 30 31\n $ : int [1:9] 19 20 25 28 30 31 33 35 55\n $ : int [1:6] 28 29 31 32 35 36\n $ : int [1:6] 28 29 30 32 53 55\n $ : int [1:4] 27 30 31 36\n $ : int [1:5] 20 21 29 34 35\n $ : int [1:6] 21 22 24 33 35 38\n $ : int [1:6] 29 30 33 34 36 38\n $ : int [1:6] 27 30 32 35 37 38\n $ : int [1:3] 27 36 38\n $ : int [1:6] 24 26 34 35 36 37\n $ : int [1:5] 40 41 46 47 51\n $ : int [1:3] 39 41 51\n $ : int [1:7] 39 40 43 45 46 51 52\n $ : int [1:4] 43 44 52 53\n $ : int [1:5] 41 42 44 45 52\n $ : int [1:3] 42 43 45\n $ : int [1:4] 41 43 44 46\n $ : int [1:3] 39 41 45\n $ : int [1:2] 39 51\n $ : int [1:8] 7 8 9 49 50 51 54 55\n $ : int [1:5] 9 48 51 57 58\n $ : int [1:5] 48 51 52 53 54\n $ : int [1:9] 39 40 41 47 48 49 50 52 57\n $ : int [1:6] 41 42 43 50 51 53\n $ : int [1:6] 31 42 50 52 54 55\n $ : int [1:4] 48 50 53 55\n $ : int [1:7] 7 25 29 31 48 53 54\n $ : int [1:5] 57 59 60 61 62\n $ : int [1:5] 49 51 56 58 59\n $ : int [1:7] 5 6 8 9 49 57 59\n $ : int [1:7] 1 3 5 56 57 58 60\n $ : int [1:4] 1 56 59 61\n $ : int [1:3] 56 60 62\n $ : int [1:3] 56 61 63\n $ : int [1:2] 62 70\n $ : int [1:5] 65 68 71 73 74\n $ : int [1:4] 64 66 68 73\n $ : int [1:3] 65 68 69\n $ : int 0\n $ : int [1:5] 64 65 66 69 70\n $ : int [1:3] 66 68 70\n $ : int [1:3] 63 68 69\n $ : int [1:5] 64 72 74 75 76\n $ : int [1:3] 71 73 74\n $ : int [1:4] 64 65 72 74\n $ : int [1:4] 64 71 72 73\n $ : int [1:3] 71 76 77\n $ : int [1:3] 71 75 77\n $ : int [1:2] 75 76\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:77] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language poly2nb(pl = all_revenue, queen = TRUE)\n - attr(*, \"type\")= chr \"queen\"\n - attr(*, \"sym\")= logi TRUE\n\n\n\n\n\nwm_q_foreign &lt;- poly2nb(foreign_revenue, queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 77 \nNumber of nonzero links: 352 \nPercentage nonzero weights: 5.93692 \nAverage number of links: 4.571429 \n1 region with no links:\n67\n2 disjoint connected subgraphs\nLink number distribution:\n\n 0  1  2  3  4  5  6  7  8  9 \n 1  1  5 17 15 17 10  5  4  2 \n1 least connected region:\n14 with 1 link\n2 most connected regions:\n29 51 with 9 links\n\n\n\n\n\nwm_q_thais &lt;- poly2nb(thai_revenue, queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 77 \nNumber of nonzero links: 352 \nPercentage nonzero weights: 5.93692 \nAverage number of links: 4.571429 \n1 region with no links:\n67\n2 disjoint connected subgraphs\nLink number distribution:\n\n 0  1  2  3  4  5  6  7  8  9 \n 1  1  5 17 15 17 10  5  4  2 \n1 least connected region:\n14 with 1 link\n2 most connected regions:\n29 51 with 9 links\n\n\n\n\n\n\n\n\nThe code chunk below is used to compute Rook contiguity weight matrix.\n\nwm_r &lt;- poly2nb(all_revenue, queen = FALSE)\nsummary(wm_r)\n\nNeighbour list object:\nNumber of regions: 77 \nNumber of nonzero links: 352 \nPercentage nonzero weights: 5.93692 \nAverage number of links: 4.571429 \n1 region with no links:\n67\n2 disjoint connected subgraphs\nLink number distribution:\n\n 0  1  2  3  4  5  6  7  8  9 \n 1  1  5 17 15 17 10  5  4  2 \n1 least connected region:\n14 with 1 link\n2 most connected regions:\n29 51 with 9 links\n\n\n\n\n\nTo create a connectivity graph for polygons, we first need to obtain points that represent each polygon. The most common method for this is to calculate the centroids of the polygons. Using the sf package in R, the centroid for each polygon can be calculated. However, rather than simply applying st_centroid() directly on the geometry column, the coordinates of these centroids need to be extracted into a separate data frame.\nTo achieve this, a mapping function will be used to apply st_centroid() to each polygon in the geometry column. The map_dbl() function from the purrr package will be used to handle this, as it applies a function to each element of a vector and returns a vector of the same length, which can then be used for further graph construction.\nTo get our longitude values we map the st_centroid function over the geometry column of us.bound and access the longitude value through double bracket notation [[]] and 1. This allows us to get only the longitude, which is the first value in each centroid.\n\nlongitude &lt;- map_dbl(all_revenue$geometry, ~st_centroid(.x)[[1]])\n\nWe do the same for latitude with one key difference. We access the second value per each centroid with [[2]].\n\nlatitude &lt;- map_dbl(all_revenue$geometry, ~st_centroid(.x)[[2]])\n\nNow that we have latitude and longitude, we use cbind to put longitude and latitude into the same object.\n\ncoords &lt;- cbind(longitude, latitude)\n\nWe check the first few observations to see if things are formatted correctly.\n\nhead(coords)\n\n     longitude latitude\n[1,]  675514.6  1523087\n[2,]  685033.7  1503755\n[3,]  650477.2  1539777\n[4,]  681656.0  1555581\n[5,]  664627.1  1586462\n[6,]  645239.0  1617118\n\n\n\n\n\nplot(all_revenue$geometry, border=\"lightgrey\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\n\n\n\n\n\n\n\n\n\n\n\n\nplot(all_revenue$geometry, border=\"lightgrey\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\n\n\n\n\n\n\n\n\n\n\n\n\npar(mfrow=c(1,2))\nplot(all_revenue$geometry, border=\"lightgrey\", main=\"Queen Contiguity\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\nplot(all_revenue$geometry, border=\"lightgrey\", main=\"Rook Contiguity\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html",
    "title": "In-class Exercise 7: Geographically Weighted Regression (GWR)",
    "section": "",
    "text": "Geographically weighted regression (GWR) is a spatial statistical technique that takes non-stationary variables into consideration (e.g., climate; demographic factors; physical environment characteristics) and models the local relationships between these independent variables and as an outcome of interest (also known as dependent variable). In this hands-on exercise, we will learn how to build hedonic pricing models by using GWR methods. The dependent variable is the resale prices of condominium in 2015. The independent variables are divided into either structural and/or locational."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#overview-calibrating-hedonic-pricing-model-for-private-highrise-properties-with-gwr-method",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#overview-calibrating-hedonic-pricing-model-for-private-highrise-properties-with-gwr-method",
    "title": "In-class Exercise 7: Geographically Weighted Regression (GWR)",
    "section": "",
    "text": "Geographically weighted regression (GWR) is a spatial statistical technique that takes non-stationary variables into consideration (e.g., climate; demographic factors; physical environment characteristics) and models the local relationships between these independent variables and as an outcome of interest (also known as dependent variable). In this hands-on exercise, we will learn how to build hedonic pricing models by using GWR methods. The dependent variable is the resale prices of condominium in 2015. The independent variables are divided into either structural and/or locational."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#the-data",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#the-data",
    "title": "In-class Exercise 7: Geographically Weighted Regression (GWR)",
    "section": "2 The Data",
    "text": "2 The Data\nTwo data sets will be used in this model building exercise, they are:\n\nURA Master Plan subzone boundary in shapefile format (i.e. MP14_SUBZONE_WEB_PL) AND\ncondo_resale_2015 in csv format (i.e. condo_resale_2015.csv)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#getting-started",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#getting-started",
    "title": "In-class Exercise 7: Geographically Weighted Regression (GWR)",
    "section": "3 Getting Started",
    "text": "3 Getting Started\nBefore getting started, it is important to install the necessary R packages into R and launch these R packages into the R environment.\nThe R packages needed for this exercise are as follows:\n\nR package for building Ordinary Least Squares regression (OLS) and performing diagnostics tests\n\nolsrr\n\nR package for calibrating geographical weighted family of models\n\nGWmodel\n\nR package for multivariate data visualisation and analysis\n\ncorrplot\n\nSpatial data handling\n\nsf\n\nAttribute data handling\n\ntidyverse, especially readr, ggplot2 and dplyr\n\nChoropleth mapping\n\ntmap\n\nPresentation-Ready Data Summary and Analytic Result Tables\n\ngtsummary\n\nProvide utilities for computing indices of model quality and goodness of fit\n\nperformance\n\nPublication-ready visualizations for model parameters, predictions, and performance diagnostics.\n\nsee\n\n\nThe code chunk below installs and launches these R packages into R environment.\n\npacman::p_load(olsrr, GWmodel, corrplot, ggpubr, sf, spdep, tidyverse, tmap,\n               gtsummary, broom.helpers, ggstatsplot, performance, sfdep, see)\n\n\ntmap_options(check.and.fix = TRUE)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#short-note-about-gwmodel",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#short-note-about-gwmodel",
    "title": "In-class Exercise 7: Geographically Weighted Regression (GWR)",
    "section": "4 Short note about GWmodel",
    "text": "4 Short note about GWmodel\nGWmodel package provides a collection of localised spatial statistical methods, namely: GW summary statistics, GW principal components analysis, GW discriminant analysis and various forms of GW regression; some of which are provided in basic and robust (outlier resistant) forms. More commonly, outputs or parameters of the GWmodel are mapped to provide a useful exploratory tool, which can often precede (and direct) a more traditional or sophisticated statistical analysis."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#importing-the-data",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#importing-the-data",
    "title": "In-class Exercise 7: Geographically Weighted Regression (GWR)",
    "section": "5 Importing the data",
    "text": "5 Importing the data\n\n5.1 Importing geospatial data\nThe geospatial data used in this hands-on exercise is called MP14_SUBZONE_WEB_PL. It is in ESRI shapefile format. The shapefile consists of URA Master Plan 2014’s planning subzone boundaries. Polygon features are used to represent these geographic boundaries. The GIS data is in svy21 projected coordinates systems.\nThe code chunk below is used to import MP_SUBZONE_WEB_PL shapefile by using st_read() of sf packages. The code chunk below also updates the newly imported mpsz sf object with the correct ESPG code (i.e. 3414)\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\",\n                layer = \"MP14_SUBZONE_WEB_PL\") %&gt;%\n  st_transform(3414)\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\zjho008\\ISSS626-GAA\\In-class_Ex\\In-class_Ex07\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe result above shows that the R object used to contain the imported MP14_SUBZONE_WEB_PL shapefile is called mpsz and it is a simple feature object. The geometry type is MULTIPOLYGON. it is also important to note that the mpsz simple feature object does not have EPSG information.\n\n\nAfter transforming the object, verification of the projection on the newly transformed mpsz_svy21 is done by using st_crs() of sf package.\nThe code chunk below is used to verify the newly transformed mpsz_svy21.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nNotice that the EPSG: is indicated as 3414 now.\nNext, the extent of mpsz is revealed by using st_bbox() of sf package.\n\nst_bbox(mpsz)\n\n     xmin      ymin      xmax      ymax \n 2667.538 15748.721 56396.440 50256.334 \n\n\nThe extent of mpsz is illustrated from the results above.\n\n# Check validity of geometries\nsf::st_is_valid(mpsz)\n\n  [1]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n [13]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE  TRUE  TRUE  TRUE FALSE\n [25]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n [37]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n [49]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n [61]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n [73]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n [85]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n [97]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[109]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[121]  TRUE FALSE FALSE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE\n[133]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[145]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[157]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[169]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[181]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[193]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[205]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[217]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[229]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[241]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[253]  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[265]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[277]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[289]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[301]  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[313]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE\n\n# Attempt to fix invalid geometries\nmpsz &lt;- sf::st_make_valid(mpsz)\n\n\n\n5.2 URA Master Plan 2014 planning subzone boundary\nThe condo_resale_2015 is in csv file format. The codes chunk below uses read_csv() function of readr package to import condo_resale_2015 into R as a tibble data frame called condo_resale.\n\ncondo_resale &lt;- read_csv(\"data/aspatial/Condo_resale_2015.csv\")\n\nRows: 1436 Columns: 23\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (23): LATITUDE, LONGITUDE, POSTCODE, SELLING_PRICE, AREA_SQM, AGE, PROX_...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nAfter importing the aspatial data file into R, it is important to examine if the data file has been imported correctly.\nThe codes chunks below uses glimpse() and head() to display the data structure.\n\nglimpse(condo_resale)\n\nRows: 1,436\nColumns: 23\n$ LATITUDE             &lt;dbl&gt; 1.287145, 1.328698, 1.313727, 1.308563, 1.321437,…\n$ LONGITUDE            &lt;dbl&gt; 103.7802, 103.8123, 103.7971, 103.8247, 103.9505,…\n$ POSTCODE             &lt;dbl&gt; 118635, 288420, 267833, 258380, 467169, 466472, 3…\n$ SELLING_PRICE        &lt;dbl&gt; 3000000, 3880000, 3325000, 4250000, 1400000, 1320…\n$ AREA_SQM             &lt;dbl&gt; 309, 290, 248, 127, 145, 139, 218, 141, 165, 168,…\n$ AGE                  &lt;dbl&gt; 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22, 6,…\n$ PROX_CBD             &lt;dbl&gt; 7.941259, 6.609797, 6.898000, 4.038861, 11.783402…\n$ PROX_CHILDCARE       &lt;dbl&gt; 0.16597932, 0.28027246, 0.42922669, 0.39473543, 0…\n$ PROX_ELDERLYCARE     &lt;dbl&gt; 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.121…\n$ PROX_URA_GROWTH_AREA &lt;dbl&gt; 6.618741, 7.505109, 6.463887, 4.906512, 6.410632,…\n$ PROX_HAWKER_MARKET   &lt;dbl&gt; 1.76542207, 0.54507614, 0.37789301, 1.68259969, 0…\n$ PROX_KINDERGARTEN    &lt;dbl&gt; 0.05835552, 0.61592412, 0.14120309, 0.38200076, 0…\n$ PROX_MRT             &lt;dbl&gt; 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.528…\n$ PROX_PARK            &lt;dbl&gt; 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.116…\n$ PROX_PRIMARY_SCH     &lt;dbl&gt; 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.709…\n$ PROX_TOP_PRIMARY_SCH &lt;dbl&gt; 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.709…\n$ PROX_SHOPPING_MALL   &lt;dbl&gt; 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.307…\n$ PROX_SUPERMARKET     &lt;dbl&gt; 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.581…\n$ PROX_BUS_STOP        &lt;dbl&gt; 0.10336166, 0.28673408, 0.28504777, 0.29872340, 0…\n$ NO_Of_UNITS          &lt;dbl&gt; 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34, 3…\n$ FAMILY_FRIENDLY      &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD             &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\n\n\nhead(condo_resale$LONGITUDE) # to see the data in XCOORD column\n\n[1] 103.7802 103.8123 103.7971 103.8247 103.9505 103.9386\n\nhead(condo_resale$LATITUDE) # to see the data in YCOORD column\n\n[1] 1.287145 1.328698 1.313727 1.308563 1.321437 1.314198\n\n\nFollowing which, summary() of base R is used to display the summary statistics of condo_resale tibble data frame.\n\nsummary(condo_resale)\n\n    LATITUDE       LONGITUDE        POSTCODE      SELLING_PRICE     \n Min.   :1.240   Min.   :103.7   Min.   : 18965   Min.   :  540000  \n 1st Qu.:1.309   1st Qu.:103.8   1st Qu.:259849   1st Qu.: 1100000  \n Median :1.328   Median :103.8   Median :469298   Median : 1383222  \n Mean   :1.334   Mean   :103.8   Mean   :440439   Mean   : 1751211  \n 3rd Qu.:1.357   3rd Qu.:103.9   3rd Qu.:589486   3rd Qu.: 1950000  \n Max.   :1.454   Max.   :104.0   Max.   :828833   Max.   :18000000  \n    AREA_SQM          AGE           PROX_CBD       PROX_CHILDCARE    \n Min.   : 34.0   Min.   : 0.00   Min.   : 0.3869   Min.   :0.004927  \n 1st Qu.:103.0   1st Qu.: 5.00   1st Qu.: 5.5574   1st Qu.:0.174481  \n Median :121.0   Median :11.00   Median : 9.3567   Median :0.258135  \n Mean   :136.5   Mean   :12.14   Mean   : 9.3254   Mean   :0.326313  \n 3rd Qu.:156.0   3rd Qu.:18.00   3rd Qu.:12.6661   3rd Qu.:0.368293  \n Max.   :619.0   Max.   :37.00   Max.   :19.1804   Max.   :3.465726  \n PROX_ELDERLYCARE  PROX_URA_GROWTH_AREA PROX_HAWKER_MARKET PROX_KINDERGARTEN \n Min.   :0.05451   Min.   :0.2145       Min.   :0.05182    Min.   :0.004927  \n 1st Qu.:0.61254   1st Qu.:3.1643       1st Qu.:0.55245    1st Qu.:0.276345  \n Median :0.94179   Median :4.6186       Median :0.90842    Median :0.413385  \n Mean   :1.05351   Mean   :4.5981       Mean   :1.27987    Mean   :0.458903  \n 3rd Qu.:1.35122   3rd Qu.:5.7550       3rd Qu.:1.68578    3rd Qu.:0.578474  \n Max.   :3.94916   Max.   :9.1554       Max.   :5.37435    Max.   :2.229045  \n    PROX_MRT         PROX_PARK       PROX_PRIMARY_SCH  PROX_TOP_PRIMARY_SCH\n Min.   :0.05278   Min.   :0.02906   Min.   :0.07711   Min.   :0.07711     \n 1st Qu.:0.34646   1st Qu.:0.26211   1st Qu.:0.44024   1st Qu.:1.34451     \n Median :0.57430   Median :0.39926   Median :0.63505   Median :1.88213     \n Mean   :0.67316   Mean   :0.49802   Mean   :0.75471   Mean   :2.27347     \n 3rd Qu.:0.84844   3rd Qu.:0.65592   3rd Qu.:0.95104   3rd Qu.:2.90954     \n Max.   :3.48037   Max.   :2.16105   Max.   :3.92899   Max.   :6.74819     \n PROX_SHOPPING_MALL PROX_SUPERMARKET PROX_BUS_STOP       NO_Of_UNITS    \n Min.   :0.0000     Min.   :0.0000   Min.   :0.001595   Min.   :  18.0  \n 1st Qu.:0.5258     1st Qu.:0.3695   1st Qu.:0.098356   1st Qu.: 188.8  \n Median :0.9357     Median :0.5687   Median :0.151710   Median : 360.0  \n Mean   :1.0455     Mean   :0.6141   Mean   :0.193974   Mean   : 409.2  \n 3rd Qu.:1.3994     3rd Qu.:0.7862   3rd Qu.:0.220466   3rd Qu.: 590.0  \n Max.   :3.4774     Max.   :2.2441   Max.   :2.476639   Max.   :1703.0  \n FAMILY_FRIENDLY     FREEHOLD      LEASEHOLD_99YR  \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.0000   Median :0.0000   Median :0.0000  \n Mean   :0.4868   Mean   :0.4227   Mean   :0.4882  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n\n\n\n\n5.3 Converting aspatial data frame into a sf object\nThe condo_resale tibble data frame is an aspatial data. We will convert it to a sf object. The code chunk below converts condo_resale data frame into a simple feature data frame by using st_as_sf() of sf packages.\n\ncondo_resale_sf &lt;- st_as_sf(condo_resale, # to convert condo resale data into simple feature - since it consists of latitude and longitude; note the PRJ format file which gives the Projects Coordinates System\n         coords = c(\"LONGITUDE\", \"LATITUDE\"),\n         crs = 4326) %&gt;% # this CRS will be in WGS84 \"orignal data source\"\n  st_transform(crs = 3414) # to project into svy21 - the projected CRS of Singapore whereby the code is 3414\n\n\ncondo_resale_sf # Condo resale sf data frame\n\nSimple feature collection with 1436 features and 21 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 14940.85 ymin: 24765.67 xmax: 43352.45 ymax: 48382.81\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 1,436 × 22\n   POSTCODE SELLING_PRICE AREA_SQM   AGE PROX_CBD PROX_CHILDCARE\n *    &lt;dbl&gt;         &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;          &lt;dbl&gt;\n 1   118635       3000000      309    30     7.94          0.166\n 2   288420       3880000      290    32     6.61          0.280\n 3   267833       3325000      248    33     6.90          0.429\n 4   258380       4250000      127     7     4.04          0.395\n 5   467169       1400000      145    28    11.8           0.119\n 6   466472       1320000      139    22    10.3           0.125\n 7   309502       3410000      218    24     4.24          0.326\n 8   468497       1420000      141    24    11.6           0.162\n 9   118450       2025000      165    27     6.46          0.123\n10   268157       2550000      168    31     6.52          0.609\n# ℹ 1,426 more rows\n# ℹ 16 more variables: PROX_ELDERLYCARE &lt;dbl&gt;, PROX_URA_GROWTH_AREA &lt;dbl&gt;,\n#   PROX_HAWKER_MARKET &lt;dbl&gt;, PROX_KINDERGARTEN &lt;dbl&gt;, PROX_MRT &lt;dbl&gt;,\n#   PROX_PARK &lt;dbl&gt;, PROX_PRIMARY_SCH &lt;dbl&gt;, PROX_TOP_PRIMARY_SCH &lt;dbl&gt;,\n#   PROX_SHOPPING_MALL &lt;dbl&gt;, PROX_SUPERMARKET &lt;dbl&gt;, PROX_BUS_STOP &lt;dbl&gt;,\n#   NO_Of_UNITS &lt;dbl&gt;, FAMILY_FRIENDLY &lt;dbl&gt;, FREEHOLD &lt;dbl&gt;,\n#   LEASEHOLD_99YR &lt;dbl&gt;, geometry &lt;POINT [m]&gt;\n\n\n\n\n\n\n\n\nNote\n\n\n\nNotice that st_transform() of sf package is used to convert the coordinates from wgs84 (i.e. crs:4326) to svy21 (i.e. crs=3414).\n\n\nNext, head() is used to list the contents of condo_resale.sf object.\n\nhead(condo_resale_sf)\n\nSimple feature collection with 6 features and 21 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 22085.12 ymin: 29951.54 xmax: 41042.56 ymax: 34546.2\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 6 × 22\n  POSTCODE SELLING_PRICE AREA_SQM   AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE\n     &lt;dbl&gt;         &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;          &lt;dbl&gt;            &lt;dbl&gt;\n1   118635       3000000      309    30     7.94          0.166            2.52 \n2   288420       3880000      290    32     6.61          0.280            1.93 \n3   267833       3325000      248    33     6.90          0.429            0.502\n4   258380       4250000      127     7     4.04          0.395            1.99 \n5   467169       1400000      145    28    11.8           0.119            1.12 \n6   466472       1320000      139    22    10.3           0.125            0.789\n# ℹ 15 more variables: PROX_URA_GROWTH_AREA &lt;dbl&gt;, PROX_HAWKER_MARKET &lt;dbl&gt;,\n#   PROX_KINDERGARTEN &lt;dbl&gt;, PROX_MRT &lt;dbl&gt;, PROX_PARK &lt;dbl&gt;,\n#   PROX_PRIMARY_SCH &lt;dbl&gt;, PROX_TOP_PRIMARY_SCH &lt;dbl&gt;,\n#   PROX_SHOPPING_MALL &lt;dbl&gt;, PROX_SUPERMARKET &lt;dbl&gt;, PROX_BUS_STOP &lt;dbl&gt;,\n#   NO_Of_UNITS &lt;dbl&gt;, FAMILY_FRIENDLY &lt;dbl&gt;, FREEHOLD &lt;dbl&gt;,\n#   LEASEHOLD_99YR &lt;dbl&gt;, geometry &lt;POINT [m]&gt;\n\n\n\n\n\n\n\n\nNote\n\n\n\nNotice that the output is in a point feature data frame.\n\nGeometry type: POINT\n\n\n\n\ncondo_resale_sf &lt;- write_rds(condo_resale_sf,\n  \"data/rds/condo_resale_sf.rds\")\n\n\ncondo_resale_sf &lt;- read_rds(\n  \"data/rds/condo_resale_sf.rds\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#correlation-analysis---ggstatsplot-methods",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#correlation-analysis---ggstatsplot-methods",
    "title": "In-class Exercise 7: Geographically Weighted Regression (GWR)",
    "section": "6 Correlation Analysis - ggstatsplot methods",
    "text": "6 Correlation Analysis - ggstatsplot methods\n\n6.0.1 Visualising the relationships of the independent variables\nBefore building a multiple regression model, it is important to ensure that the independent variables used are not highly correlated to each other. If highly correlated independent variables are used in building a regression model, the quality of the model will be compromised. This phenomenon is known as multicollinearity in statistics.\nCorrelation matrix is commonly used to visualise the relationships between the independent variables. Besides the pairs() of R, there are many packages supporting the display of a correlation matrix. In this section, the corrplot package will be used.\nThe code chunk below is used to plot a scatter plot matrix of the relationship between the independent variables in condo_resale data.frame.\n\ncorrplot(cor(condo_resale[, 5:23]), diag = FALSE, order = \"AOE\",\n         tl.pos = \"td\", tl.cex = 0.5, method = \"number\", type = \"upper\")\n\n\n\n\n\n\n\n\nA matrix reorder is very important for mining the hidden structure and patterns in the matrix. There are four methods in corrplot (parameter order), named: “AOE”, “FPC”, “hclust”, “alphabet”.\nIn the code chunk above, AOE order is used. It orders the variables by using the angular order of the eigenvectors method suggested by Michael Friendly.\nFrom the scatterplot matrix, it is clear that Freehold is highly correlated to LEASE_99YEAR. In view of this, it gives reason to include only either one of them in the subsequent model building.\nIn this case, LEASE_99YEAR is excluded in the subsequent model building.\nIn the code chunk below, instead of using corrplot package ggcorrmat() of ggstatsplot is used.\n\nggcorrmat(condo_resale[, 5:23])\n\n\n\n\n\n\n\n\nSimilarly, it is observed that LEASEHOLD_99YR and FREEHOLD is highly correlated."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#building-a-hedonic-pricing-model-using-multiple-linear-regression-method",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#building-a-hedonic-pricing-model-using-multiple-linear-regression-method",
    "title": "In-class Exercise 7: Geographically Weighted Regression (GWR)",
    "section": "7 Building a hedonic pricing model using multiple linear regression method",
    "text": "7 Building a hedonic pricing model using multiple linear regression method\nThe code chunk below uses lm() to calibrate the multiple linear regression model.\n\ncondo_mlr &lt;- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE    + \n                  PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                  PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + PROX_KINDERGARTEN + \n                  PROX_MRT  + PROX_PARK + PROX_PRIMARY_SCH + \n                  PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n                  PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD + LEASEHOLD_99YR,\n                  data = condo_resale_sf)\nsummary(condo_mlr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + PROX_CHILDCARE + \n    PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + \n    PROX_KINDERGARTEN + PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + \n    PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD + \n    LEASEHOLD_99YR, data = condo_resale_sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3471036  -286903   -22426   239412 12254549 \n\nCoefficients:\n                      Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           543071.4   136210.9   3.987 7.03e-05 ***\nAREA_SQM               12688.7      370.1  34.283  &lt; 2e-16 ***\nAGE                   -24566.0     2766.0  -8.881  &lt; 2e-16 ***\nPROX_CBD              -78122.0     6791.4 -11.503  &lt; 2e-16 ***\nPROX_CHILDCARE       -333219.0   111020.3  -3.001 0.002734 ** \nPROX_ELDERLYCARE      170950.0    42110.8   4.060 5.19e-05 ***\nPROX_URA_GROWTH_AREA   38507.6    12523.7   3.075 0.002147 ** \nPROX_HAWKER_MARKET     23801.2    29299.9   0.812 0.416739    \nPROX_KINDERGARTEN     144098.0    82738.7   1.742 0.081795 .  \nPROX_MRT             -322775.9    58528.1  -5.515 4.14e-08 ***\nPROX_PARK             564487.9    66563.0   8.481  &lt; 2e-16 ***\nPROX_PRIMARY_SCH      186170.5    65515.2   2.842 0.004553 ** \nPROX_TOP_PRIMARY_SCH    -477.1    20598.0  -0.023 0.981525    \nPROX_SHOPPING_MALL   -207721.5    42855.5  -4.847 1.39e-06 ***\nPROX_SUPERMARKET      -48074.7    77145.3  -0.623 0.533273    \nPROX_BUS_STOP         675755.0   138552.0   4.877 1.20e-06 ***\nNO_Of_UNITS             -216.2       90.3  -2.394 0.016797 *  \nFAMILY_FRIENDLY       142128.3    47055.1   3.020 0.002569 ** \nFREEHOLD              300646.5    77296.5   3.890 0.000105 ***\nLEASEHOLD_99YR        -77137.4    77570.9  -0.994 0.320192    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 755800 on 1416 degrees of freedom\nMultiple R-squared:  0.652, Adjusted R-squared:  0.6474 \nF-statistic: 139.6 on 19 and 1416 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#model-assessment-olsrr-method",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#model-assessment-olsrr-method",
    "title": "In-class Exercise 7: Geographically Weighted Regression (GWR)",
    "section": "8 Model Assessment: olsrr method",
    "text": "8 Model Assessment: olsrr method\nIn this section, we introduce an excellent R package designed specifically for conducting Ordinary Least Squares (OLS) regression: olsrr. This package offers a comprehensive set of tools to enhance the development of multiple linear regression models. Key features include:\n\nDetailed regression output\nDiagnostic tools for residual analysis\nInfluence measures\nTests for heteroskedasticity\nModel fit evaluation\nAssessment of variable contributions\nProcedures for variable selection\n\nThese functionalities make olsrr a powerful resource for building and refining regression models in R.\n\n8.1 Generating tidy linear regression report\n\nols_regress(condo_mlr) # global model\n\n                                Model Summary                                 \n-----------------------------------------------------------------------------\nR                            0.807       RMSE                     750537.537 \nR-Squared                    0.652       MSE                571262902261.223 \nAdj. R-Squared               0.647       Coef. Var                    43.160 \nPred R-Squared               0.637       AIC                       42971.173 \nMAE                     412117.987       SBC                       43081.835 \n-----------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n AIC: Akaike Information Criteria \n SBC: Schwarz Bayesian Criteria \n\n                                     ANOVA                                       \n--------------------------------------------------------------------------------\n                    Sum of                                                      \n                   Squares          DF         Mean Square       F         Sig. \n--------------------------------------------------------------------------------\nRegression    1.515738e+15          19        7.977571e+13    139.648    0.0000 \nResidual      8.089083e+14        1416    571262902261.223                      \nTotal         2.324647e+15        1435                                          \n--------------------------------------------------------------------------------\n\n                                               Parameter Estimates                                                \n-----------------------------------------------------------------------------------------------------------------\n               model           Beta    Std. Error    Std. Beta       t        Sig           lower          upper \n-----------------------------------------------------------------------------------------------------------------\n         (Intercept)     543071.420    136210.918                   3.987    0.000     275874.535     810268.305 \n            AREA_SQM      12688.669       370.119        0.579     34.283    0.000      11962.627      13414.710 \n                 AGE     -24566.001      2766.041       -0.166     -8.881    0.000     -29991.980     -19140.022 \n            PROX_CBD     -78121.985      6791.377       -0.267    -11.503    0.000     -91444.227     -64799.744 \n      PROX_CHILDCARE    -333219.036    111020.303       -0.087     -3.001    0.003    -551000.984    -115437.089 \n    PROX_ELDERLYCARE     170949.961     42110.748        0.083      4.060    0.000      88343.803     253556.120 \nPROX_URA_GROWTH_AREA      38507.622     12523.661        0.059      3.075    0.002      13940.700      63074.545 \n  PROX_HAWKER_MARKET      23801.197     29299.923        0.019      0.812    0.417     -33674.725      81277.120 \n   PROX_KINDERGARTEN     144097.972     82738.669        0.030      1.742    0.082     -18205.570     306401.514 \n            PROX_MRT    -322775.874     58528.079       -0.123     -5.515    0.000    -437586.937    -207964.811 \n           PROX_PARK     564487.876     66563.011        0.148      8.481    0.000     433915.162     695060.590 \n    PROX_PRIMARY_SCH     186170.524     65515.193        0.072      2.842    0.005      57653.253     314687.795 \nPROX_TOP_PRIMARY_SCH       -477.073     20597.972       -0.001     -0.023    0.982     -40882.894      39928.747 \n  PROX_SHOPPING_MALL    -207721.520     42855.500       -0.109     -4.847    0.000    -291788.613    -123654.427 \n    PROX_SUPERMARKET     -48074.679     77145.257       -0.012     -0.623    0.533    -199405.956     103256.599 \n       PROX_BUS_STOP     675755.044    138551.991        0.133      4.877    0.000     403965.817     947544.272 \n         NO_Of_UNITS       -216.180        90.302       -0.046     -2.394    0.017       -393.320        -39.040 \n     FAMILY_FRIENDLY     142128.272     47055.082        0.056      3.020    0.003      49823.107     234433.438 \n            FREEHOLD     300646.543     77296.529        0.117      3.890    0.000     149018.525     452274.561 \n      LEASEHOLD_99YR     -77137.375     77570.869       -0.030     -0.994    0.320    -229303.551      75028.801 \n-----------------------------------------------------------------------------------------------------------------\n\n\nUsing the ols_regress() function it generates an improved table for our condo_mlr results. We can reject null hypothesis as the p-value is smaller than our alpha value of 0.05. Based on the Adjusted R-Squared value, this multiple linear regression model is able to explain 64.7% of the price variation.\nFor PROX_TOP_PRIMARY_SCH & PROX_SUPERMARKET they are not statistically significant with p-values above 0.05. Which indicates that they can be eliminated from building the model later on.\n\n\n8.2 Multicollinearity\nVariance Inflation Factors (VIF) is calculated in this section after the model is calibrated. Steps done: - Refer to ANOVA table to reject null hypothesis - Adjusted r-square Values - Before going to the parameters\n\nols_vif_tol(condo_mlr)\n\n              Variables Tolerance      VIF\n1              AREA_SQM 0.8601326 1.162611\n2                   AGE 0.7011585 1.426211\n3              PROX_CBD 0.4575471 2.185567\n4        PROX_CHILDCARE 0.2898233 3.450378\n5      PROX_ELDERLYCARE 0.5922238 1.688551\n6  PROX_URA_GROWTH_AREA 0.6614081 1.511926\n7    PROX_HAWKER_MARKET 0.4373874 2.286303\n8     PROX_KINDERGARTEN 0.8356793 1.196631\n9              PROX_MRT 0.4949877 2.020252\n10            PROX_PARK 0.8015728 1.247547\n11     PROX_PRIMARY_SCH 0.3823248 2.615577\n12 PROX_TOP_PRIMARY_SCH 0.4878620 2.049760\n13   PROX_SHOPPING_MALL 0.4903052 2.039546\n14     PROX_SUPERMARKET 0.6142127 1.628100\n15        PROX_BUS_STOP 0.3311024 3.020213\n16          NO_Of_UNITS 0.6543336 1.528272\n17      FAMILY_FRIENDLY 0.7191719 1.390488\n18             FREEHOLD 0.2728521 3.664990\n19       LEASEHOLD_99YR 0.2645988 3.779307\n\n\nBased on the results of the Variance Inflation Factors (VIF) none of the variables are greater than 5. Each of the independent variables are calculated with another independent variable to attain the values above. This shows no need to eliminate the variables.\n\n0 to 5: variables are not correlated\n5 to 10: variables are correlated\nGreater than 10: variables are highly correlated\n\n\nnote that there are binary variables like Y/N options (dummy variables) which have some signs of correlation which are from the variable of lease properties: LEASEHOLD_99YR vs FREEHOLD etc.\n\n\n\n8.3 Variable Selection\nStepwise Regression is being used\nForward Stepwise: All independent variables are outside and the variables are loaded in the model - once variable is added in the R Sq and Adjusted R sq is calculated and checking the criteria (E.g. Confidence Levels - values above 0.05 are rejected. The variables have to be below 0.05 and has to improve the R Squared value )\nBackward Stepwise: Variables are all loaded inside and they are taken out one by one based on how the adjusted R Square decreases and cafeterias such as the P- Value.\n\nNo Replacement once they variables are rejected or added in for an iteration they cannot be placed back in the model\n\nMixed Stepwise - Using the method of forward stepwise but with replacement.\nThe functions are already built in with the olsrr package.\n\ncondo_fw_mlr &lt;- ols_step_forward_p( # Assessment criteria using p-value\n  condo_mlr,\n  p_val = 0.05,\n  details = TRUE) # With details = true it will show all the iterations and the steps + entire report. details = FALSE will not show the individual split but only showing the \n\nForward Selection Method \n------------------------\n\nCandidate Terms: \n\n1. AREA_SQM \n2. AGE \n3. PROX_CBD \n4. PROX_CHILDCARE \n5. PROX_ELDERLYCARE \n6. PROX_URA_GROWTH_AREA \n7. PROX_HAWKER_MARKET \n8. PROX_KINDERGARTEN \n9. PROX_MRT \n10. PROX_PARK \n11. PROX_PRIMARY_SCH \n12. PROX_TOP_PRIMARY_SCH \n13. PROX_SHOPPING_MALL \n14. PROX_SUPERMARKET \n15. PROX_BUS_STOP \n16. NO_Of_UNITS \n17. FAMILY_FRIENDLY \n18. FREEHOLD \n19. LEASEHOLD_99YR \n\n\nStep   =&gt; 0 \nModel  =&gt; SELLING_PRICE ~ 1 \nR2     =&gt; 0 \n\nInitiating stepwise selection... \n\n                          Selection Metrics Table                            \n----------------------------------------------------------------------------\nPredictor               Pr(&gt;|t|)    R-Squared    Adj. R-Squared       AIC    \n----------------------------------------------------------------------------\nAREA_SQM                 0.00000        0.452             0.451    43587.753 \nPROX_CBD                 0.00000        0.243             0.242    44051.772 \nFREEHOLD                 0.00000        0.082             0.081    44328.539 \nLEASEHOLD_99YR           0.00000        0.066             0.065    44353.172 \nPROX_PARK                0.00000        0.049             0.048    44378.817 \nNO_Of_UNITS              0.00000        0.048             0.048    44380.124 \nPROX_PRIMARY_SCH         0.00000        0.032             0.032    44403.847 \nPROX_HAWKER_MARKET       0.00000        0.023             0.022    44417.505 \nPROX_CHILDCARE           0.00000        0.021             0.021    44420.298 \nPROX_ELDERLYCARE         0.00000        0.021             0.020    44420.546 \nPROX_BUS_STOP            0.00000        0.021             0.020    44420.742 \nPROX_KINDERGARTEN          2e-05        0.013             0.012    44432.322 \nPROX_SUPERMARKET         0.00088        0.008             0.007    44439.977 \nPROX_SHOPPING_MALL       0.00154        0.007             0.006    44441.023 \nFAMILY_FRIENDLY          0.00907        0.005             0.004    44444.248 \nPROX_MRT                 0.01071        0.005             0.004    44444.545 \nPROX_URA_GROWTH_AREA     0.13510        0.002             0.001    44448.832 \nPROX_TOP_PRIMARY_SCH     0.23180        0.001             0.000    44449.636 \nAGE                      0.52978        0.000             0.000    44450.673 \n----------------------------------------------------------------------------\n\nStep      =&gt; 1 \nSelected  =&gt; AREA_SQM \nModel     =&gt; SELLING_PRICE ~ AREA_SQM \nR2        =&gt; 0.452 \n\n                          Selection Metrics Table                            \n----------------------------------------------------------------------------\nPredictor               Pr(&gt;|t|)    R-Squared    Adj. R-Squared       AIC    \n----------------------------------------------------------------------------\nPROX_CBD                 0.00000        0.569             0.569    43243.523 \nFREEHOLD                 0.00000        0.487             0.487    43493.627 \nPROX_PARK                0.00000        0.478             0.478    43518.542 \nLEASEHOLD_99YR           0.00000        0.475             0.474    43527.150 \nAGE                      0.00000        0.471             0.470    43538.063 \nPROX_SHOPPING_MALL       0.00000        0.467             0.466    43549.216 \nPROX_HAWKER_MARKET       0.00000        0.465             0.464    43555.065 \nPROX_MRT                 0.00000        0.465             0.464    43556.097 \nNO_Of_UNITS              0.00000        0.464             0.463    43557.089 \nPROX_SUPERMARKET         0.00000        0.461             0.461    43564.792 \nPROX_PRIMARY_SCH           3e-05        0.458             0.458    43572.418 \nPROX_ELDERLYCARE           5e-05        0.458             0.457    43573.203 \nPROX_URA_GROWTH_AREA       9e-05        0.458             0.457    43574.292 \nFAMILY_FRIENDLY          0.00026        0.457             0.456    43576.392 \nPROX_CHILDCARE           0.00275        0.455             0.455    43580.768 \nPROX_BUS_STOP            0.00381        0.455             0.454    43581.362 \nPROX_KINDERGARTEN        0.15757        0.453             0.452    43587.751 \nPROX_TOP_PRIMARY_SCH     0.47485        0.452             0.451    43589.241 \n----------------------------------------------------------------------------\n\nStep      =&gt; 2 \nSelected  =&gt; PROX_CBD \nModel     =&gt; SELLING_PRICE ~ AREA_SQM + PROX_CBD \nR2        =&gt; 0.569 \n\n                          Selection Metrics Table                            \n----------------------------------------------------------------------------\nPredictor               Pr(&gt;|t|)    R-Squared    Adj. R-Squared       AIC    \n----------------------------------------------------------------------------\nPROX_PARK                0.00000        0.589             0.588    43177.691 \nAGE                      0.00000        0.586             0.585    43188.935 \nFREEHOLD                 0.00000        0.579             0.578    43213.005 \nPROX_ELDERLYCARE         0.00000        0.578             0.577    43216.850 \nPROX_TOP_PRIMARY_SCH     0.00000        0.577             0.576    43218.861 \nLEASEHOLD_99YR           0.00000        0.576             0.575    43224.500 \nPROX_HAWKER_MARKET         1e-05        0.575             0.574    43225.123 \nPROX_SHOPPING_MALL         8e-05        0.574             0.573    43229.948 \nPROX_SUPERMARKET         0.00147        0.572             0.571    43235.376 \nPROX_MRT                 0.00613        0.572             0.571    43237.989 \nNO_Of_UNITS              0.01059        0.571             0.570    43238.970 \nPROX_PRIMARY_SCH         0.04530        0.570             0.570    43241.503 \nPROX_BUS_STOP            0.06634        0.570             0.569    43242.142 \nFAMILY_FRIENDLY          0.11212        0.570             0.569    43242.991 \nPROX_CHILDCARE           0.29768        0.570             0.569    43244.435 \nPROX_URA_GROWTH_AREA     0.78658        0.569             0.568    43245.450 \nPROX_KINDERGARTEN        0.80879        0.569             0.568    43245.465 \n----------------------------------------------------------------------------\n\nStep      =&gt; 3 \nSelected  =&gt; PROX_PARK \nModel     =&gt; SELLING_PRICE ~ AREA_SQM + PROX_CBD + PROX_PARK \nR2        =&gt; 0.589 \n\n                          Selection Metrics Table                            \n----------------------------------------------------------------------------\nPredictor               Pr(&gt;|t|)    R-Squared    Adj. R-Squared       AIC    \n----------------------------------------------------------------------------\nFREEHOLD                 0.00000        0.604             0.603    43125.474 \nAGE                      0.00000        0.602             0.601    43132.534 \nLEASEHOLD_99YR           0.00000        0.601             0.600    43138.902 \nPROX_ELDERLYCARE         0.00000        0.596             0.595    43153.932 \nPROX_TOP_PRIMARY_SCH       3e-05        0.594             0.593    43162.363 \nNO_Of_UNITS              0.00013        0.593             0.592    43164.977 \nPROX_SHOPPING_MALL       0.00015        0.593             0.592    43165.286 \nPROX_HAWKER_MARKET         7e-04        0.592             0.591    43168.151 \nPROX_MRT                 0.00250        0.592             0.591    43170.516 \nFAMILY_FRIENDLY          0.02445        0.591             0.589    43174.609 \nPROX_SUPERMARKET         0.02905        0.591             0.589    43174.908 \nPROX_URA_GROWTH_AREA     0.14518        0.590             0.589    43177.560 \nPROX_CHILDCARE           0.31093        0.589             0.588    43178.660 \nPROX_PRIMARY_SCH         0.34515        0.589             0.588    43178.796 \nPROX_BUS_STOP            0.47898        0.589             0.588    43179.188 \nPROX_KINDERGARTEN        0.87351        0.589             0.588    43179.665 \n----------------------------------------------------------------------------\n\nStep      =&gt; 4 \nSelected  =&gt; FREEHOLD \nModel     =&gt; SELLING_PRICE ~ AREA_SQM + PROX_CBD + PROX_PARK + FREEHOLD \nR2        =&gt; 0.604 \n\n                          Selection Metrics Table                            \n----------------------------------------------------------------------------\nPredictor               Pr(&gt;|t|)    R-Squared    Adj. R-Squared       AIC    \n----------------------------------------------------------------------------\nAGE                      0.00000        0.620             0.619    43069.222 \nPROX_SHOPPING_MALL       0.00000        0.611             0.609    43104.195 \nPROX_ELDERLYCARE           5e-05        0.609             0.608    43111.036 \nPROX_TOP_PRIMARY_SCH       7e-05        0.609             0.607    43111.551 \nPROX_HAWKER_MARKET       0.00088        0.607             0.606    43116.360 \nPROX_SUPERMARKET         0.00324        0.607             0.605    43118.765 \nPROX_MRT                 0.00345        0.607             0.605    43118.882 \nPROX_BUS_STOP            0.09204        0.605             0.604    43124.623 \nFAMILY_FRIENDLY          0.11599        0.605             0.604    43124.992 \nPROX_PRIMARY_SCH         0.21752        0.605             0.603    43125.946 \nNO_Of_UNITS              0.25242        0.605             0.603    43126.158 \nPROX_URA_GROWTH_AREA     0.27640        0.605             0.603    43126.284 \nLEASEHOLD_99YR           0.49846        0.605             0.603    43127.014 \nPROX_KINDERGARTEN        0.66364        0.604             0.603    43127.284 \nPROX_CHILDCARE           0.82289        0.604             0.603    43127.424 \n----------------------------------------------------------------------------\n\nStep      =&gt; 5 \nSelected  =&gt; AGE \nModel     =&gt; SELLING_PRICE ~ AREA_SQM + PROX_CBD + PROX_PARK + FREEHOLD + AGE \nR2        =&gt; 0.62 \n\n                          Selection Metrics Table                            \n----------------------------------------------------------------------------\nPredictor               Pr(&gt;|t|)    R-Squared    Adj. R-Squared       AIC    \n----------------------------------------------------------------------------\nPROX_ELDERLYCARE         0.00000        0.627             0.625    43046.515 \nPROX_SHOPPING_MALL       0.00014        0.624             0.622    43056.710 \nPROX_TOP_PRIMARY_SCH     0.00036        0.623             0.622    43058.400 \nPROX_MRT                 0.00118        0.623             0.621    43060.651 \nPROX_HAWKER_MARKET       0.00229        0.623             0.621    43061.874 \nNO_Of_UNITS              0.03614        0.621             0.620    43066.808 \nPROX_SUPERMARKET         0.03902        0.621             0.620    43066.940 \nPROX_PRIMARY_SCH         0.04454        0.621             0.620    43067.165 \nPROX_URA_GROWTH_AREA     0.05538        0.621             0.619    43067.532 \nFAMILY_FRIENDLY          0.06368        0.621             0.619    43067.765 \nPROX_BUS_STOP            0.09258        0.621             0.619    43068.378 \nLEASEHOLD_99YR           0.33191        0.620             0.619    43070.276 \nPROX_KINDERGARTEN        0.54422        0.620             0.619    43070.852 \nPROX_CHILDCARE           0.76117        0.620             0.619    43071.129 \n----------------------------------------------------------------------------\n\nStep      =&gt; 6 \nSelected  =&gt; PROX_ELDERLYCARE \nModel     =&gt; SELLING_PRICE ~ AREA_SQM + PROX_CBD + PROX_PARK + FREEHOLD + AGE + PROX_ELDERLYCARE \nR2        =&gt; 0.627 \n\n                          Selection Metrics Table                            \n----------------------------------------------------------------------------\nPredictor               Pr(&gt;|t|)    R-Squared    Adj. R-Squared       AIC    \n----------------------------------------------------------------------------\nPROX_SHOPPING_MALL       0.00000        0.634             0.632    43020.990 \nPROX_MRT                 0.00000        0.633             0.631    43024.733 \nPROX_SUPERMARKET         0.00311        0.629             0.627    43039.719 \nPROX_CHILDCARE           0.00320        0.629             0.627    43039.776 \nPROX_TOP_PRIMARY_SCH     0.02859        0.628             0.626    43043.694 \nFAMILY_FRIENDLY          0.04001        0.628             0.626    43044.273 \nPROX_URA_GROWTH_AREA     0.06111        0.628             0.626    43044.987 \nPROX_HAWKER_MARKET       0.14370        0.627             0.625    43046.364 \nNO_Of_UNITS              0.21750        0.627             0.625    43046.985 \nLEASEHOLD_99YR           0.33225        0.627             0.625    43047.569 \nPROX_PRIMARY_SCH         0.72554        0.627             0.625    43048.391 \nPROX_BUS_STOP            0.73834        0.627             0.625    43048.403 \nPROX_KINDERGARTEN        0.96832        0.627             0.625    43048.513 \n----------------------------------------------------------------------------\n\nStep      =&gt; 7 \nSelected  =&gt; PROX_SHOPPING_MALL \nModel     =&gt; SELLING_PRICE ~ AREA_SQM + PROX_CBD + PROX_PARK + FREEHOLD + AGE + PROX_ELDERLYCARE + PROX_SHOPPING_MALL \nR2        =&gt; 0.634 \n\n                          Selection Metrics Table                            \n----------------------------------------------------------------------------\nPredictor               Pr(&gt;|t|)    R-Squared    Adj. R-Squared       AIC    \n----------------------------------------------------------------------------\nPROX_URA_GROWTH_AREA       2e-04        0.637             0.635    43009.092 \nPROX_MRT                 0.00038        0.637             0.635    43010.278 \nFAMILY_FRIENDLY          0.09004        0.634             0.632    43020.098 \nNO_Of_UNITS              0.09561        0.634             0.632    43020.195 \nPROX_BUS_STOP            0.10105        0.634             0.632    43020.284 \nPROX_CHILDCARE           0.16782        0.634             0.632    43021.075 \nPROX_PRIMARY_SCH         0.20169        0.634             0.632    43021.349 \nPROX_HAWKER_MARKET       0.28053        0.634             0.632    43021.818 \nPROX_SUPERMARKET         0.39017        0.634             0.632    43022.247 \nLEASEHOLD_99YR           0.41342        0.634             0.632    43022.317 \nPROX_KINDERGARTEN        0.64794        0.634             0.632    43022.781 \nPROX_TOP_PRIMARY_SCH     0.88928        0.634             0.632    43022.971 \n----------------------------------------------------------------------------\n\nStep      =&gt; 8 \nSelected  =&gt; PROX_URA_GROWTH_AREA \nModel     =&gt; SELLING_PRICE ~ AREA_SQM + PROX_CBD + PROX_PARK + FREEHOLD + AGE + PROX_ELDERLYCARE + PROX_SHOPPING_MALL + PROX_URA_GROWTH_AREA \nR2        =&gt; 0.637 \n\n                          Selection Metrics Table                            \n----------------------------------------------------------------------------\nPredictor               Pr(&gt;|t|)    R-Squared    Adj. R-Squared       AIC    \n----------------------------------------------------------------------------\nPROX_MRT                 0.00055        0.640             0.638    42999.058 \nNO_Of_UNITS              0.04357        0.638             0.636    43006.989 \nPROX_BUS_STOP            0.07301        0.638             0.636    43007.854 \nFAMILY_FRIENDLY          0.07751        0.638             0.636    43007.953 \nPROX_CHILDCARE           0.17683        0.638             0.635    43009.255 \nLEASEHOLD_99YR           0.26341        0.638             0.635    43009.832 \nPROX_SUPERMARKET         0.32522        0.637             0.635    43010.117 \nPROX_TOP_PRIMARY_SCH     0.36995        0.637             0.635    43010.282 \nPROX_HAWKER_MARKET       0.48716        0.637             0.635    43010.606 \nPROX_KINDERGARTEN        0.49501        0.637             0.635    43010.623 \nPROX_PRIMARY_SCH         0.60814        0.637             0.635    43010.827 \n----------------------------------------------------------------------------\n\nStep      =&gt; 9 \nSelected  =&gt; PROX_MRT \nModel     =&gt; SELLING_PRICE ~ AREA_SQM + PROX_CBD + PROX_PARK + FREEHOLD + AGE + PROX_ELDERLYCARE + PROX_SHOPPING_MALL + PROX_URA_GROWTH_AREA + PROX_MRT \nR2        =&gt; 0.64 \n\n                          Selection Metrics Table                            \n----------------------------------------------------------------------------\nPredictor               Pr(&gt;|t|)    R-Squared    Adj. R-Squared       AIC    \n----------------------------------------------------------------------------\nPROX_BUS_STOP              6e-05        0.644             0.642    42984.951 \nPROX_PRIMARY_SCH         0.01738        0.642             0.639    42995.355 \nNO_Of_UNITS              0.04105        0.641             0.639    42996.851 \nFAMILY_FRIENDLY          0.06468        0.641             0.639    42997.618 \nPROX_TOP_PRIMARY_SCH     0.16342        0.641             0.638    42999.100 \nLEASEHOLD_99YR           0.16895        0.641             0.638    42999.151 \nPROX_KINDERGARTEN        0.19107        0.641             0.638    42999.335 \nPROX_HAWKER_MARKET       0.19288        0.641             0.638    42999.349 \nPROX_SUPERMARKET         0.45603        0.640             0.638    43000.498 \nPROX_CHILDCARE           0.71809        0.640             0.638    43000.927 \n----------------------------------------------------------------------------\n\nStep      =&gt; 10 \nSelected  =&gt; PROX_BUS_STOP \nModel     =&gt; SELLING_PRICE ~ AREA_SQM + PROX_CBD + PROX_PARK + FREEHOLD + AGE + PROX_ELDERLYCARE + PROX_SHOPPING_MALL + PROX_URA_GROWTH_AREA + PROX_MRT + PROX_BUS_STOP \nR2        =&gt; 0.644 \n\n                          Selection Metrics Table                            \n----------------------------------------------------------------------------\nPredictor               Pr(&gt;|t|)    R-Squared    Adj. R-Squared       AIC    \n----------------------------------------------------------------------------\nFAMILY_FRIENDLY          0.01590        0.646             0.643    42981.085 \nPROX_CHILDCARE           0.02032        0.646             0.643    42981.519 \nNO_Of_UNITS              0.03658        0.645             0.643    42982.543 \nPROX_PRIMARY_SCH         0.06688        0.645             0.642    42983.563 \nPROX_KINDERGARTEN        0.09160        0.645             0.642    42984.080 \nLEASEHOLD_99YR           0.10015        0.645             0.642    42984.224 \nPROX_TOP_PRIMARY_SCH     0.27924        0.645             0.642    42985.770 \nPROX_HAWKER_MARKET       0.53937        0.644             0.642    42986.571 \nPROX_SUPERMARKET         0.91393        0.644             0.641    42986.939 \n----------------------------------------------------------------------------\n\nStep      =&gt; 11 \nSelected  =&gt; FAMILY_FRIENDLY \nModel     =&gt; SELLING_PRICE ~ AREA_SQM + PROX_CBD + PROX_PARK + FREEHOLD + AGE + PROX_ELDERLYCARE + PROX_SHOPPING_MALL + PROX_URA_GROWTH_AREA + PROX_MRT + PROX_BUS_STOP + FAMILY_FRIENDLY \nR2        =&gt; 0.646 \n\n                          Selection Metrics Table                            \n----------------------------------------------------------------------------\nPredictor               Pr(&gt;|t|)    R-Squared    Adj. R-Squared       AIC    \n----------------------------------------------------------------------------\nNO_Of_UNITS              0.00533        0.648             0.645    42975.246 \nPROX_CHILDCARE           0.01908        0.647             0.644    42977.539 \nPROX_PRIMARY_SCH         0.06018        0.647             0.644    42979.519 \nLEASEHOLD_99YR           0.06704        0.647             0.644    42979.699 \nPROX_KINDERGARTEN        0.09772        0.646             0.643    42980.317 \nPROX_TOP_PRIMARY_SCH     0.31070        0.646             0.643    42982.048 \nPROX_HAWKER_MARKET       0.66885        0.646             0.643    42982.901 \nPROX_SUPERMARKET         0.92593        0.646             0.643    42983.077 \n----------------------------------------------------------------------------\n\nStep      =&gt; 12 \nSelected  =&gt; NO_Of_UNITS \nModel     =&gt; SELLING_PRICE ~ AREA_SQM + PROX_CBD + PROX_PARK + FREEHOLD + AGE + PROX_ELDERLYCARE + PROX_SHOPPING_MALL + PROX_URA_GROWTH_AREA + PROX_MRT + PROX_BUS_STOP + FAMILY_FRIENDLY + NO_Of_UNITS \nR2        =&gt; 0.648 \n\n                          Selection Metrics Table                            \n----------------------------------------------------------------------------\nPredictor               Pr(&gt;|t|)    R-Squared    Adj. R-Squared       AIC    \n----------------------------------------------------------------------------\nPROX_CHILDCARE           0.02092        0.649             0.646    42971.858 \nPROX_PRIMARY_SCH         0.05496        0.649             0.645    42973.525 \nPROX_KINDERGARTEN        0.13311        0.648             0.645    42974.967 \nLEASEHOLD_99YR           0.16053        0.648             0.645    42975.257 \nPROX_TOP_PRIMARY_SCH     0.28337        0.648             0.645    42976.084 \nPROX_HAWKER_MARKET       0.62348        0.648             0.644    42977.003 \nPROX_SUPERMARKET         0.65604        0.648             0.644    42977.046 \n----------------------------------------------------------------------------\n\nStep      =&gt; 13 \nSelected  =&gt; PROX_CHILDCARE \nModel     =&gt; SELLING_PRICE ~ AREA_SQM + PROX_CBD + PROX_PARK + FREEHOLD + AGE + PROX_ELDERLYCARE + PROX_SHOPPING_MALL + PROX_URA_GROWTH_AREA + PROX_MRT + PROX_BUS_STOP + FAMILY_FRIENDLY + NO_Of_UNITS + PROX_CHILDCARE \nR2        =&gt; 0.649 \n\n                          Selection Metrics Table                            \n----------------------------------------------------------------------------\nPredictor               Pr(&gt;|t|)    R-Squared    Adj. R-Squared       AIC    \n----------------------------------------------------------------------------\nPROX_PRIMARY_SCH         0.00805        0.651             0.647    42966.758 \nPROX_KINDERGARTEN        0.08599        0.650             0.646    42970.878 \nPROX_TOP_PRIMARY_SCH     0.23060        0.649             0.646    42972.405 \nLEASEHOLD_99YR           0.32104        0.649             0.646    42972.863 \nPROX_HAWKER_MARKET       0.49652        0.649             0.646    42973.391 \nPROX_SUPERMARKET         0.59607        0.649             0.646    42973.574 \n----------------------------------------------------------------------------\n\nStep      =&gt; 14 \nSelected  =&gt; PROX_PRIMARY_SCH \nModel     =&gt; SELLING_PRICE ~ AREA_SQM + PROX_CBD + PROX_PARK + FREEHOLD + AGE + PROX_ELDERLYCARE + PROX_SHOPPING_MALL + PROX_URA_GROWTH_AREA + PROX_MRT + PROX_BUS_STOP + FAMILY_FRIENDLY + NO_Of_UNITS + PROX_CHILDCARE + PROX_PRIMARY_SCH \nR2        =&gt; 0.651 \n\n                          Selection Metrics Table                            \n----------------------------------------------------------------------------\nPredictor               Pr(&gt;|t|)    R-Squared    Adj. R-Squared       AIC    \n----------------------------------------------------------------------------\nPROX_KINDERGARTEN        0.07528        0.651             0.648    42965.558 \nLEASEHOLD_99YR           0.24093        0.651             0.647    42967.367 \nPROX_HAWKER_MARKET       0.29790        0.651             0.647    42967.662 \nPROX_TOP_PRIMARY_SCH     0.38435        0.651             0.647    42967.993 \nPROX_SUPERMARKET         0.76578        0.651             0.647    42968.669 \n----------------------------------------------------------------------------\n\n\nNo more variables to be added.\n\nVariables Selected: \n\n=&gt; AREA_SQM \n=&gt; PROX_CBD \n=&gt; PROX_PARK \n=&gt; FREEHOLD \n=&gt; AGE \n=&gt; PROX_ELDERLYCARE \n=&gt; PROX_SHOPPING_MALL \n=&gt; PROX_URA_GROWTH_AREA \n=&gt; PROX_MRT \n=&gt; PROX_BUS_STOP \n=&gt; FAMILY_FRIENDLY \n=&gt; NO_Of_UNITS \n=&gt; PROX_CHILDCARE \n=&gt; PROX_PRIMARY_SCH \n\n\nUsing the p-value the statistically significant factors are kept.\nUnder the list created - there is a list of 3 included metrics, model, others in the condo_fw_mlr list\n\nplot(condo_fw_mlr)\n\n\n\n\n\n\n\n\n\n\n8.4 Visualising model parameters\n\nggcoefstats(condo_mlr,\n            sort = \"ascending\")\n\nNumber of labels is greater than default palette color count.\n• Select another color `palette` (and/or `package`).\n\n\n\n\n\n\n\n\n\n\n\n8.5 Test for Non-Linearity\nIn multiple linear regression, it is important for us to test the assumption that linearity and additivity of the relationship between dependent and independent variables.\nIn the code chunk below, the ols_plot_resid_fit() of olsrr package is used to perform linearity assumption test.\n\nols_plot_resid_fit(condo_fw_mlr$model)\n\n\n\n\n\n\n\n\nThe figure above reveals that most of the data points are scattered around the 0 line, hence we can safely conclude that the relationships between the dependent and independent variables are linear.\n\n\n8.6 Tests for Normality Assumption\nIn the code chunk below, ols_plot_resid_hist() of olsrr package is used to perform normality assumption test.\n\nols_plot_resid_hist(condo_fw_mlr$model)\n\n\n\n\n\n\n\n\nThe figure above reveals that the residual of the multiple linear regression model (i.e. condo.mlr1) resembles a normal distribution.\nFor formal statistical test methods, the ols_test_normality() of olsrr package can be used as shown in the code chunk below.\n\nols_test_normality(condo_fw_mlr$model)\n\nWarning in ks.test.default(y, \"pnorm\", mean(y), sd(y)): ties should not be\npresent for the one-sample Kolmogorov-Smirnov test\n\n\n-----------------------------------------------\n       Test             Statistic       pvalue  \n-----------------------------------------------\nShapiro-Wilk              0.6856         0.0000 \nKolmogorov-Smirnov        0.1366         0.0000 \nCramer-von Mises         121.0768        0.0000 \nAnderson-Darling         67.9551         0.0000 \n-----------------------------------------------\n\n\nThe summary table reveals that the p-values of the four tests are way smaller than the alpha value of 0.05. Hence we will reject the null hypothesis and infer that there is statistical evidence that the residuals are not normally distributed.\n\n\n8.7 Testing for spatial autocorrelation\nThe hedonic model to be built will utilise geographically referenced attributes, hence it is also important for us to visualise the residual of the hedonic pricing model.\nFirst, we will export the residual of the hedonic pricing model and save it as a data frame.\n\nmlr_output &lt;- as.data.frame(condo_fw_mlr$model$residuals) %&gt;%\n  rename(`FW_MLR_RES` = `condo_fw_mlr$model$residuals`) # renamed to shorten the field name\n\nNext, we will join the newly created data frame with condo_resale_sf object.\n\ncondo_resale_sf &lt;- cbind(condo_resale_sf, # cbind to combine the newly created table condo_resale_sf - is a point data hence using cbind function to  append since there is no common identifier\n                         mlr_output$FW_MLR_RES) %&gt;%\n  rename(`MLR_RES` = `mlr_output.FW_MLR_RES`)\n\nNext, we will use tmap package to display the distribution of the residuals on an interactive map.\nThe code chunk below turns on the interactive mode of tmap.\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\ntm_shape(mpsz) +\n  tmap_options(check.and.fix = TRUE) + # line is used to resolve the issue: polygon issue and geometric error - line written here since the `mpsz` layer is giving the issues. Otherwise it can be done at the start to eliminate all problems.\n  tm_polygons(alpha = 0.4) + # error due to a HDB flat polygon left in the dataset\ntm_shape(condo_resale_sf) +\n  tm_dots(col = \"MLR_RES\",\n          alpha = 0.6,\n          style = \"quantile\",\n          midpoint = NA)\n\n\n\n\ntmap_mode(\"plot\") # used to switch the mode back to plot\n\ntmap mode set to plotting\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe plot above reveals that there is signs of spatial autocorrelation.\n\n\n\n\n8.8 Spatial stationary test\nTo validate our observation, we will conduct the Moran’s I test.\n\nNull hypothesis (Ho): The residuals are randomly distributed (i.e., spatially stationary).\nAlternative hypothesis (H1): The residuals are not randomly distributed and are spatially non-stationary.\n\nAs a first step, we will create a distance-based weight matrix using the dnearneigh() function from the spdep package.\n\n\n\n\n\n\nNote\n\n\n\nactual price vs estimated transacted price is the residual. Darker green shade represents that - estimated price is higher than the actual transacted price.\nOn the other hand, the lighter colour represents actual transactions that are much lower than the estimated price\n\n\nMoran’s I test will be performed with the code chunk below.\nThe latest version of GW model also facilitates the use of sfdep\n\ncondo_resale_sf &lt;- condo_resale_sf %&gt;%\n  mutate(nb = st_knn(geometry, k = 6, # k nearest neighbour\n                     longlat = FALSE), # so that it will not use the grid circle since all the data is already projected - not a longitude,latitude and just use the data as it is. \n         wt = st_weights(nb,\n                         style = \"W\"),\n         .before = 1)\n\nNext, global_moran_perm() of sfdep is used to perform global Moran permutation test.\n\nglobal_moran_perm(condo_resale_sf$MLR_RES, # data from condo_resale_sf and MLR_RES is the column that will be used\n                  condo_resale_sf$nb,\n                  condo_resale_sf$wt,\n                  alternative = \"two.sided\",\n                  nsim = 99) # 100 permutations\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.32254, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\nThe Global Moran’s test I for residual spatial autocorrelation shows that it’s p-value is less than 0.00000000000000022 which is less than the alpha value of 0.05. Hence, we will reject the null hypothesis that the residuals are randomly distributed.\nSince the Observed Global Moran I = 0.25586 (statistic = 0.32254) which is greater than 0, we can infer that the residuals resemble cluster distribution."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#building-hedonic-pricing-models-using-gwmodel",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#building-hedonic-pricing-models-using-gwmodel",
    "title": "In-class Exercise 7: Geographically Weighted Regression (GWR)",
    "section": "9 Building Hedonic Pricing Models using GWmodel",
    "text": "9 Building Hedonic Pricing Models using GWmodel\nThis section will illustrate how to model hedonic pricing by using a geographically weighted regression model. Two spatial weights are used: - fixed bandwidth scheme - adaptive bandwidth scheme\n\n9.1 Building Fixed bandwidth GWR Model\nIn the code chunk below bw.gwr() of GWModel package is used to determine the optimal fixed bandwidth to use in the model. Notice that the argument adaptive is set to FALSE indicating that we are interested to compute the fixed bandwidth.\nThere are two possible approaches can be used to determine the stopping rule, they are: CV cross-validation approach and AIC corrected (AICc) approach. We define the stopping rule using the approach agreement.\n\nbw.fixed &lt;- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n                     PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + \n                     PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + \n                     PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + \n                     FAMILY_FRIENDLY + FREEHOLD,\n                   data = condo_resale_sf, \n                   approach = \"CV\", # CV\n                   kernel = \"gaussian\", # has to be used in later steps for consistency\n                   adaptive = FALSE, \n                   longlat = FALSE) # so that greater distance is not calculated\n\nFixed bandwidth: 17660.96 CV score: 8.259118e+14 \nFixed bandwidth: 10917.26 CV score: 7.970454e+14 \nFixed bandwidth: 6749.419 CV score: 7.273273e+14 \nFixed bandwidth: 4173.553 CV score: 6.300006e+14 \nFixed bandwidth: 2581.58 CV score: 5.404958e+14 \nFixed bandwidth: 1597.687 CV score: 4.857515e+14 \nFixed bandwidth: 989.6077 CV score: 4.722431e+14 \nFixed bandwidth: 613.7939 CV score: 1.378294e+16 \nFixed bandwidth: 1221.873 CV score: 4.778717e+14 \nFixed bandwidth: 846.0596 CV score: 4.791629e+14 \nFixed bandwidth: 1078.325 CV score: 4.751406e+14 \nFixed bandwidth: 934.7772 CV score: 4.72518e+14 \nFixed bandwidth: 1023.495 CV score: 4.730305e+14 \nFixed bandwidth: 968.6643 CV score: 4.721317e+14 \nFixed bandwidth: 955.7206 CV score: 4.722072e+14 \nFixed bandwidth: 976.6639 CV score: 4.721387e+14 \nFixed bandwidth: 963.7202 CV score: 4.721484e+14 \nFixed bandwidth: 971.7199 CV score: 4.721293e+14 \nFixed bandwidth: 973.6083 CV score: 4.721309e+14 \nFixed bandwidth: 970.5527 CV score: 4.721295e+14 \nFixed bandwidth: 972.4412 CV score: 4.721296e+14 \nFixed bandwidth: 971.2741 CV score: 4.721292e+14 \nFixed bandwidth: 970.9985 CV score: 4.721293e+14 \nFixed bandwidth: 971.4443 CV score: 4.721292e+14 \nFixed bandwidth: 971.5496 CV score: 4.721293e+14 \nFixed bandwidth: 971.3793 CV score: 4.721292e+14 \nFixed bandwidth: 971.3391 CV score: 4.721292e+14 \nFixed bandwidth: 971.3143 CV score: 4.721292e+14 \nFixed bandwidth: 971.3545 CV score: 4.721292e+14 \nFixed bandwidth: 971.3296 CV score: 4.721292e+14 \nFixed bandwidth: 971.345 CV score: 4.721292e+14 \nFixed bandwidth: 971.3355 CV score: 4.721292e+14 \nFixed bandwidth: 971.3413 CV score: 4.721292e+14 \nFixed bandwidth: 971.3377 CV score: 4.721292e+14 \nFixed bandwidth: 971.34 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3408 CV score: 4.721292e+14 \nFixed bandwidth: 971.3403 CV score: 4.721292e+14 \nFixed bandwidth: 971.3406 CV score: 4.721292e+14 \nFixed bandwidth: 971.3404 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \n\n\n\nThe bandwidth distances are becoming shorter (in metres)\n\nSome of the results are as shown:\n\nFixed bandwidth: 613.7939 CV score: 1.378294e+16\nFixed bandwidth: 1221.873 CV score: 4.778717e+14\n\nThe bandwidth increases at time which is due to the iterations ran\nFor the values below:\n\nFixed bandwidth: 971.3405 CV score: 4.721292e+14\nFixed bandwidth: 971.3408 CV score: 4.721292e+14\nFixed bandwidth: 971.3403 CV score: 4.721292e+14\nFixed bandwidth: 971.3406 CV score: 4.721292e+14\nFixed bandwidth: 971.3404 CV score: 4.721292e+14\nFixed bandwidth: 971.3405 CV score: 4.721292e+14\nFixed bandwidth: 971.3405 CV score: 4.721292e+14\n\nThe distances are refined while looking for the best CV score. once the rate of change is to minimal then it will stop running the iterations.\n\n9.1.1 GWModel Method - Fixed Bandwidth\nNow to utilise the code chunk below to calibrate the GWR Model using fixed bandwidth and the Gaussian Kernel.\n\ngwr_fixed &lt;- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n                     PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + \n                     PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + \n                     PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + \n                     FAMILY_FRIENDLY + FREEHOLD,\n                   data = condo_resale_sf, \n                   bw = bw.fixed,\n                   kernel = \"gaussian\", # has to be used in later steps for consistency\n                   longlat = FALSE) # so that greater distance is not calculated\n\nThe output is saved in a list of class “gwrm”. The code below can be used to display the model output.\nThe variables are not changed but the spatial components are accounted for in the calculation for this GWR Model.\n\ngwr_fixed\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2024-10-17 03:35:35.221369 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale_sf, bw = bw.fixed, kernel = \"gaussian\", \n    longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  &lt; 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  &lt; 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  &lt; 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  &lt; 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Fixed bandwidth: 971.3405 \n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -3.5988e+07 -5.1998e+05  7.6780e+05  1.7412e+06\n   AREA_SQM              1.0003e+03  5.2758e+03  7.4740e+03  1.2301e+04\n   AGE                  -1.3475e+05 -2.0813e+04 -8.6260e+03 -3.7784e+03\n   PROX_CBD             -7.7047e+07 -2.3608e+05 -8.3600e+04  3.4646e+04\n   PROX_CHILDCARE       -6.0097e+06 -3.3667e+05 -9.7425e+04  2.9007e+05\n   PROX_ELDERLYCARE     -3.5000e+06 -1.5970e+05  3.1971e+04  1.9577e+05\n   PROX_URA_GROWTH_AREA -3.0170e+06 -8.2013e+04  7.0749e+04  2.2612e+05\n   PROX_MRT             -3.5282e+06 -6.5836e+05 -1.8833e+05  3.6922e+04\n   PROX_PARK            -1.2062e+06 -2.1732e+05  3.5383e+04  4.1335e+05\n   PROX_PRIMARY_SCH     -2.2695e+07 -1.7066e+05  4.8472e+04  5.1555e+05\n   PROX_SHOPPING_MALL   -7.2585e+06 -1.6684e+05 -1.0517e+04  1.5923e+05\n   PROX_BUS_STOP        -1.4676e+06 -4.5207e+04  3.7601e+05  1.1664e+06\n   NO_Of_UNITS          -1.3170e+03 -2.4822e+02 -3.0846e+01  2.5496e+02\n   FAMILY_FRIENDLY      -2.2749e+06 -1.1140e+05  7.6214e+03  1.6107e+05\n   FREEHOLD             -9.2067e+06  3.8073e+04  1.5169e+05  3.7528e+05\n                             Max.\n   Intercept            112793548\n   AREA_SQM                 21575\n   AGE                     434201\n   PROX_CBD               2704596\n   PROX_CHILDCARE         1654087\n   PROX_ELDERLYCARE      38867814\n   PROX_URA_GROWTH_AREA  78515730\n   PROX_MRT               3124316\n   PROX_PARK             18122425\n   PROX_PRIMARY_SCH       4637503\n   PROX_SHOPPING_MALL     1529952\n   PROX_BUS_STOP         11342182\n   NO_Of_UNITS              12907\n   FAMILY_FRIENDLY        1720744\n   FREEHOLD               6073636\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 438.3804 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 997.6196 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 42263.61 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41632.36 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 42515.71 \n   Residual sum of squares: 2.53407e+14 \n   R-square value:  0.8909912 \n   Adjusted R-square value:  0.8430417 \n\n   ***********************************************************************\n   Program stops at: 2024-10-17 03:35:35.910841 \n\n\nThe report shows that the AICc of the gwr is 42263.61 under the Diagnostic Information section which is significantly smaller than the global multiple linear regression model of 42967.1.\n\n\n\n9.2 Building Adaptive Bandwidth GWR Model\nGWR based hedonic pricing model will be calibrated by using adaptive bandwidth approach.\nSimilar to the earlier section, we will first use bw.gwr() to determine the recommended data points for usage.\nThe code chunk used will look very similar to the one used to compute the fixed bandwidth except the adaptive argument has changed to TRUE.\n\nbw.adaptive &lt;- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE  + \n                        PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE    + \n                        PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                        PROX_PRIMARY_SCH + PROX_SHOPPING_MALL   + PROX_BUS_STOP + \n                        NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                      data = condo_resale_sf, \n                      approach = \"CV\", \n                      kernel = \"gaussian\", \n                      adaptive = TRUE, \n                      longlat = FALSE)\n\nAdaptive bandwidth: 895 CV score: 7.952401e+14 \nAdaptive bandwidth: 561 CV score: 7.667364e+14 \nAdaptive bandwidth: 354 CV score: 6.953454e+14 \nAdaptive bandwidth: 226 CV score: 6.15223e+14 \nAdaptive bandwidth: 147 CV score: 5.674373e+14 \nAdaptive bandwidth: 98 CV score: 5.426745e+14 \nAdaptive bandwidth: 68 CV score: 5.168117e+14 \nAdaptive bandwidth: 49 CV score: 4.859631e+14 \nAdaptive bandwidth: 37 CV score: 4.646518e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \nAdaptive bandwidth: 25 CV score: 4.430816e+14 \nAdaptive bandwidth: 32 CV score: 4.505602e+14 \nAdaptive bandwidth: 27 CV score: 4.462172e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \n\n\n30 nearest neighbour is the recommended bandwidth - meaning to use 30 data points to calculate the regression model\nNow to calibrate the gwr-based hedonic pricing model by using adaptive bandwidth and gaussian kernel as shown in the code chunk below.\n\ngwr_adaptive &lt;- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                            PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE + \n                            PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                            PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP + \n                            NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                          data = condo_resale_sf, bw = bw.adaptive, \n                          kernel = 'gaussian', \n                          adaptive=TRUE, \n                          longlat = FALSE)\n\nThe code below can be used to display the model output.\n\ngwr_adaptive\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2024-10-17 03:35:41.620301 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale_sf, bw = bw.adaptive, kernel = \"gaussian\", \n    adaptive = TRUE, longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  &lt; 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  &lt; 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  &lt; 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  &lt; 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Adaptive bandwidth: 30 (number of nearest neighbours)\n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -1.3487e+08 -2.4669e+05  7.7928e+05  1.6194e+06\n   AREA_SQM              3.3188e+03  5.6285e+03  7.7825e+03  1.2738e+04\n   AGE                  -9.6746e+04 -2.9288e+04 -1.4043e+04 -5.6119e+03\n   PROX_CBD             -2.5330e+06 -1.6256e+05 -7.7242e+04  2.6624e+03\n   PROX_CHILDCARE       -1.2790e+06 -2.0175e+05  8.7158e+03  3.7778e+05\n   PROX_ELDERLYCARE     -1.6212e+06 -9.2050e+04  6.1029e+04  2.8184e+05\n   PROX_URA_GROWTH_AREA -7.2686e+06 -3.0350e+04  4.5869e+04  2.4613e+05\n   PROX_MRT             -4.3781e+07 -6.7282e+05 -2.2115e+05 -7.4593e+04\n   PROX_PARK            -2.9020e+06 -1.6782e+05  1.1601e+05  4.6572e+05\n   PROX_PRIMARY_SCH     -8.6418e+05 -1.6627e+05 -7.7853e+03  4.3222e+05\n   PROX_SHOPPING_MALL   -1.8272e+06 -1.3175e+05 -1.4049e+04  1.3799e+05\n   PROX_BUS_STOP        -2.0579e+06 -7.1461e+04  4.1104e+05  1.2071e+06\n   NO_Of_UNITS          -2.1993e+03 -2.3685e+02 -3.4699e+01  1.1657e+02\n   FAMILY_FRIENDLY      -5.9879e+05 -5.0927e+04  2.6173e+04  2.2481e+05\n   FREEHOLD             -1.6340e+05  4.0765e+04  1.9023e+05  3.7960e+05\n                            Max.\n   Intercept            18758355\n   AREA_SQM                23064\n   AGE                     13303\n   PROX_CBD             11346650\n   PROX_CHILDCARE        2892127\n   PROX_ELDERLYCARE      2465671\n   PROX_URA_GROWTH_AREA  7384059\n   PROX_MRT              1186242\n   PROX_PARK             2588497\n   PROX_PRIMARY_SCH      3381462\n   PROX_SHOPPING_MALL   38038564\n   PROX_BUS_STOP        12081592\n   NO_Of_UNITS              1010\n   FAMILY_FRIENDLY       2072414\n   FREEHOLD              1813995\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 350.3088 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 1085.691 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 41982.22 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41546.74 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 41914.08 \n   Residual sum of squares: 2.528227e+14 \n   R-square value:  0.8912425 \n   Adjusted R-square value:  0.8561185 \n\n   ***********************************************************************\n   Program stops at: 2024-10-17 03:35:42.503643 \n\n\nThe report shows that the AICc of the adaptive distance gwr is 41982.22 (AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 41982.22) which is even smaller than the AICc of the fixed distance gwr of 42263.61.\n\n9.2.1 Visualisign GWR Output\nIn addition to regression residuals, the output feature class table includes fields for observed and predicted y values, condition number (cond), Local R2, residuals, and explanatory variable coefficients and standard errors:\n\nCondition Number: This diagnostic assesses local collinearity in the model. When local collinearity is high, the results may become unstable. A condition number greater than 30 suggests that the results may be unreliable.\nLocal R²: This metric ranges from 0.0 to 1.0 and indicates how well the local regression model fits the observed y values. Low values suggest poor model performance in certain areas. Mapping Local R² can highlight where the Geographically Weighted Regression (GWR) performs well or poorly, offering insights into potentially missing variables.\nPredicted Values: These are the estimated y values generated by the GWR model, representing the fitted values.\nResiduals: Residuals are calculated by subtracting the predicted y values from the observed y values. Standardized residuals, which have a mean of zero and a standard deviation of 1, can be visualized on a cold-to-hot color scale, indicating areas of under- or over-prediction.\nCoefficient Standard Error: This measures the reliability of each coefficient estimate. Smaller standard errors relative to the coefficient values suggest greater confidence in the estimates, while large standard errors may indicate issues with local collinearity.\n\nThey are all stored in a SpatialPointsDataFrame or SpatialPolygonsDataFrame object integrated with fit.points, GWR coefficient estimates, y value, predicted values, coefficient standard errors and t-values in its “data” slot in an object called SDF of the output list.\n\n\n9.2.2 Converting SDF into sf data.frame\nTo visualise the fields in SDF, we need to first convert it into sf data.frame by using the code chunk below:\n\ngwr_adaptive_output &lt;- as.data.frame(\n  gwr_adaptive$SDF) %&gt;%\n  select(-c(2:12)) # exclude column 2 & 15\n\n\ngwr_sf_adaptive &lt;- cbind(condo_resale_sf,\n                         gwr_adaptive_output)\n\nNext, glimpse() is used to display the content of condo_resale_sf.adpative sf data frame.\n\nglimpse(gwr_sf_adaptive)\n\nRows: 1,436\nColumns: 66\n$ nb                      &lt;nb&gt; &lt;66, 77, 123, 238, 239, 343&gt;, &lt;21, 162, 163, 19…\n$ wt                      &lt;list&gt; &lt;0.1666667, 0.1666667, 0.1666667, 0.1666667, …\n$ POSTCODE                &lt;dbl&gt; 118635, 288420, 267833, 258380, 467169, 466472…\n$ SELLING_PRICE           &lt;dbl&gt; 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ AREA_SQM                &lt;dbl&gt; 309, 290, 248, 127, 145, 139, 218, 141, 165, 1…\n$ AGE                     &lt;dbl&gt; 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22,…\n$ PROX_CBD                &lt;dbl&gt; 7.941259, 6.609797, 6.898000, 4.038861, 11.783…\n$ PROX_CHILDCARE          &lt;dbl&gt; 0.16597932, 0.28027246, 0.42922669, 0.39473543…\n$ PROX_ELDERLYCARE        &lt;dbl&gt; 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.…\n$ PROX_URA_GROWTH_AREA    &lt;dbl&gt; 6.618741, 7.505109, 6.463887, 4.906512, 6.4106…\n$ PROX_HAWKER_MARKET      &lt;dbl&gt; 1.76542207, 0.54507614, 0.37789301, 1.68259969…\n$ PROX_KINDERGARTEN       &lt;dbl&gt; 0.05835552, 0.61592412, 0.14120309, 0.38200076…\n$ PROX_MRT                &lt;dbl&gt; 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.…\n$ PROX_PARK               &lt;dbl&gt; 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.…\n$ PROX_PRIMARY_SCH        &lt;dbl&gt; 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.…\n$ PROX_TOP_PRIMARY_SCH    &lt;dbl&gt; 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.…\n$ PROX_SHOPPING_MALL      &lt;dbl&gt; 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.…\n$ PROX_SUPERMARKET        &lt;dbl&gt; 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.…\n$ PROX_BUS_STOP           &lt;dbl&gt; 0.10336166, 0.28673408, 0.28504777, 0.29872340…\n$ NO_Of_UNITS             &lt;dbl&gt; 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34…\n$ FAMILY_FRIENDLY         &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD                &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR          &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ MLR_RES                 &lt;dbl&gt; -1489099.55, 415494.57, 194129.69, 1088992.71,…\n$ Intercept               &lt;dbl&gt; 2050011.67, 1633128.24, 3433608.17, 234358.91,…\n$ NO_Of_UNITS.1           &lt;dbl&gt; 104.8290640, -288.3441183, -9.5532945, -161.35…\n$ FAMILY_FRIENDLY.1       &lt;dbl&gt; -9075.370, 310074.664, 5949.746, 1556178.531, …\n$ FREEHOLD.1              &lt;dbl&gt; 303955.61, 396221.27, 168821.75, 1212515.58, 3…\n$ y                       &lt;dbl&gt; 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ yhat                    &lt;dbl&gt; 2886531.8, 3466801.5, 3616527.2, 5435481.6, 13…\n$ residual                &lt;dbl&gt; 113468.16, 413198.52, -291527.20, -1185481.63,…\n$ CV_Score                &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Stud_residual           &lt;dbl&gt; 0.38207013, 1.01433140, -0.83780678, -2.846146…\n$ Intercept_SE            &lt;dbl&gt; 516105.5, 488083.5, 963711.4, 444185.5, 211962…\n$ AREA_SQM_SE             &lt;dbl&gt; 823.2860, 825.2380, 988.2240, 617.4007, 1376.2…\n$ AGE_SE                  &lt;dbl&gt; 5889.782, 6226.916, 6510.236, 6010.511, 8180.3…\n$ PROX_CBD_SE             &lt;dbl&gt; 37411.22, 23615.06, 56103.77, 469337.41, 41064…\n$ PROX_CHILDCARE_SE       &lt;dbl&gt; 319111.1, 299705.3, 349128.5, 304965.2, 698720…\n$ PROX_ELDERLYCARE_SE     &lt;dbl&gt; 120633.34, 84546.69, 129687.07, 127150.69, 327…\n$ PROX_URA_GROWTH_AREA_SE &lt;dbl&gt; 56207.39, 76956.50, 95774.60, 470762.12, 47433…\n$ PROX_MRT_SE             &lt;dbl&gt; 185181.3, 281133.9, 275483.7, 279877.1, 363830…\n$ PROX_PARK_SE            &lt;dbl&gt; 205499.6, 229358.7, 314124.3, 227249.4, 364580…\n$ PROX_PRIMARY_SCH_SE     &lt;dbl&gt; 152400.7, 165150.7, 196662.6, 240878.9, 249087…\n$ PROX_SHOPPING_MALL_SE   &lt;dbl&gt; 109268.8, 98906.8, 119913.3, 177104.1, 301032.…\n$ PROX_BUS_STOP_SE        &lt;dbl&gt; 600668.6, 410222.1, 464156.7, 562810.8, 740922…\n$ NO_Of_UNITS_SE          &lt;dbl&gt; 218.1258, 208.9410, 210.9828, 361.7767, 299.50…\n$ FAMILY_FRIENDLY_SE      &lt;dbl&gt; 131474.73, 114989.07, 146607.22, 108726.62, 16…\n$ FREEHOLD_SE             &lt;dbl&gt; 115954.0, 130110.0, 141031.5, 138239.1, 210641…\n$ Intercept_TV            &lt;dbl&gt; 3.9720784, 3.3460017, 3.5629010, 0.5276150, 1.…\n$ AREA_SQM_TV             &lt;dbl&gt; 11.614302, 20.087361, 13.247868, 33.577223, 4.…\n$ AGE_TV                  &lt;dbl&gt; -1.6154474, -9.3441881, -4.1023685, -15.524301…\n$ PROX_CBD_TV             &lt;dbl&gt; -3.22582173, -6.32792021, -4.62353528, 5.17080…\n$ PROX_CHILDCARE_TV       &lt;dbl&gt; 1.000488185, 1.471786337, -0.344047555, 1.5766…\n$ PROX_ELDERLYCARE_TV     &lt;dbl&gt; -3.26126929, 3.84626245, 4.13191383, 2.4756745…\n$ PROX_URA_GROWTH_AREA_TV &lt;dbl&gt; -2.846248368, -1.848971738, -2.648105057, -5.6…\n$ PROX_MRT_TV             &lt;dbl&gt; -1.61864578, -8.92998600, -3.40075727, -7.2870…\n$ PROX_PARK_TV            &lt;dbl&gt; -0.83749312, 2.28192684, 0.66565951, -3.340617…\n$ PROX_PRIMARY_SCH_TV     &lt;dbl&gt; 1.59230221, 6.70194543, 2.90580089, 12.9836104…\n$ PROX_SHOPPING_MALL_TV   &lt;dbl&gt; 2.753588422, -0.886626400, -1.056869486, -0.16…\n$ PROX_BUS_STOP_TV        &lt;dbl&gt; 2.0154464, 4.4941192, 3.0419145, 12.8383775, 0…\n$ NO_Of_UNITS_TV          &lt;dbl&gt; 0.480589953, -1.380026395, -0.045279967, -0.44…\n$ FAMILY_FRIENDLY_TV      &lt;dbl&gt; -0.06902748, 2.69655779, 0.04058290, 14.312764…\n$ FREEHOLD_TV             &lt;dbl&gt; 2.6213469, 3.0452799, 1.1970499, 8.7711485, 1.…\n$ Local_R2                &lt;dbl&gt; 0.8846744, 0.8899773, 0.8947007, 0.9073605, 0.…\n$ geometry                &lt;POINT [m]&gt; POINT (22085.12 29951.54), POINT (25656.…\n$ geometry.1              &lt;POINT [m]&gt; POINT (22085.12 29951.54), POINT (25656.…\n\n\nSummary() function is used in the code chunk below.\n\nsummary(gwr_adaptive$SDF$yhat)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n  171347  1102001  1385528  1751842  1982307 13887901 \n\n\n\n\n9.2.3 Visualising local R2\nThe code chunk below is used to create an interactive point symbol map.\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\ntmap_options(check.and.fix = TRUE)\ntm_shape(mpsz)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(gwr_sf_adaptive) +  \n  tm_dots(col = \"Local_R2\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\n\n\n\n\nSwitching the mode back to plot\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\n\n\n\n9.2.4 Visualising Coefficient Estimates\nThe code chunk below is used to create an interactive point symbol map from the coefficient estimates\n\ntmap_options(check.and.fix = TRUE)\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\nAREA_SQM_SE &lt;- tm_shape(mpsz)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(gwr_sf_adaptive) +  \n  tm_dots(col = \"AREA_SQM_SE\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\nAREA_SQM_TV &lt;- tm_shape(mpsz)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(gwr_sf_adaptive) +  \n  tm_dots(col = \"AREA_SQM_TV\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\ntmap_arrange(AREA_SQM_SE, AREA_SQM_TV, \n             asp=1, ncol=2,\n             sync = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\nSwitching the mode back to plot\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\n\n\n\n9.2.5 Visualising by URA Plannign Region\n\ntm_shape(mpsz[mpsz$REGION_N==\"CENTRAL REGION\", ])+\n  tm_polygons()+\ntm_shape(gwr_sf_adaptive) + \n  tm_bubbles(col = \"Local_R2\",\n           size = 0.15,\n           border.col = \"gray60\",\n           border.lwd = 1)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#conclusion",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#conclusion",
    "title": "In-class Exercise 7: Geographically Weighted Regression (GWR)",
    "section": "10 Conclusion",
    "text": "10 Conclusion\nFor this in class exercise, it primarily uses the sfdep package instead of the spdep package as done in the hands-on exercise.\nEND"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "title": "Take-home Exercise 3b: Geospatial Analytics",
    "section": "",
    "text": "For take-home exercise 3, it consists of 2 options: Take-home Exercise 3a: Modelling Geography of Financial Inclusion with Geographically Weighted Methods & Take-home Exercise 3b: Predicting HDB Resale Prices with Geographically Weighted Machine Learning Methods. The selected option for this take-home exercise will be 3b.\nHousing plays a crucial role in household wealth across the globe, with purchasing a home representing a significant investment for most individuals. Housing prices are influenced by a variety of factors. Some of these factors are global, such as the overall economic conditions of a country or the inflation rate, while others are specific to individual properties. These factors can be categorised into structural and locational components.\nStructural factors relate directly to the characteristics of the property, such as its size, amenities, and tenure.\nLocational factors pertain to the surrounding environment, including proximity to childcare centres, public transportation, and shopping facilities.\nTraditionally, predictive models for housing resale prices have been developed using the Ordinary Least Squares (OLS) method. However, this approach does not account for spatial autocorrelation and spatial heterogeneity present in geographic datasets, such as those related to housing transactions. When spatial autocorrelation is present, OLS estimates can produce biased, inconsistent, or inefficient results (Anselin 1998). To address this limitation, Geographically Weighted Models (GWMs) have been introduced, offering a more accurate approach to modelling and predicting housing resale prices. The steps involved will ultimately build a hedonic pricing models using this methods.\n\n\nFor this take-home exercise, the primary dataset should be the HDB Resale Flat Prices available on data.gov.sg The analysis should concentrate on one specific flat type: three-room, four-room, or five-room flats.\nThe following is a list of suggested predictors to consider, though students are encouraged to include any other relevant independent variables that may enhance the analysis.\n\nStructural factors\n\nArea of the unit\nFloor level\nRemaining lease\nAge of the unit\nMain Upgrading Program (MUP) completed (optional)\n\nLocational factors\n\nProximity to CBD\nProximity to eldercare\nProximity to foodcourt/hawker centres\nProximity to MRT\nProximity to park\nProximity to good primary school\nProximity to shopping mall\nProximity to supermarket\nNumbers of kindergartens within 350m\nNumbers of childcare centres within 350m\nNumbers of bus stop within 350m\nNumbers of primary school within 1km\n\n\nThe four-room flats will be the chosen flat type for analysis as it is one of the most common HDB BTO flat types, which offers a comfortable living space for young couples and families.\nAdditionally, in this take-home exercise, we are tasked with calibrating a predictive model to forecast HDB resale prices for the period of July to September 2024, using resale transaction data from 2023 as the basis for analysis."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Modelling",
    "section": "",
    "text": "Predictive modelling employs statistical learning or machine learning techniques to forecast outcomes, often targeting future events. These models are calibrated using a set of known outcomes and predictors (or variables).\nGeospatial predictive modelling is based on the idea that the events being predicted are spatially constrained, meaning their distribution is not random or uniform across space. When working with geographically referenced data, factors such as infrastructure, sociocultural elements, and topography influence where events occur. Geospatial predictive modelling aims to explain these spatial constraints and influences by correlating past event locations with environmental factors that shape their distribution.\n\n\nIn this hands-on exercise, the goal is to learn how to build predictive models using geographical random forest method. By the end of this hands-on exercise, it would have helped to acquire the skills of:\n\npreparing training and test data sets by using appropriate data sampling methods,\ncalibrating predictive models by using both geospatial statistical learning and machine learning methods,\ncomparing and selecting the best model for predicting the future outcome,\npredicting the future outcomes by using the best model calibrated."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#overview-geographically-weighted-predictive-models",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#overview-geographically-weighted-predictive-models",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Modelling",
    "section": "",
    "text": "Predictive modelling employs statistical learning or machine learning techniques to forecast outcomes, often targeting future events. These models are calibrated using a set of known outcomes and predictors (or variables).\nGeospatial predictive modelling is based on the idea that the events being predicted are spatially constrained, meaning their distribution is not random or uniform across space. When working with geographically referenced data, factors such as infrastructure, sociocultural elements, and topography influence where events occur. Geospatial predictive modelling aims to explain these spatial constraints and influences by correlating past event locations with environmental factors that shape their distribution.\n\n\nIn this hands-on exercise, the goal is to learn how to build predictive models using geographical random forest method. By the end of this hands-on exercise, it would have helped to acquire the skills of:\n\npreparing training and test data sets by using appropriate data sampling methods,\ncalibrating predictive models by using both geospatial statistical learning and machine learning methods,\ncomparing and selecting the best model for predicting the future outcome,\npredicting the future outcomes by using the best model calibrated."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#the-data",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Modelling",
    "section": "2 The Data",
    "text": "2 The Data\n\nAspatial dataset:\n\nHDB Resale data: a list of HDB resale transacted prices in Singapore from Jan 2017 onwards. It is in csv format which can be downloaded from Data.gov.sg.\n\nGeospatial dataset:\n\nMP14_SUBZONE_WEB_PL: a polygon feature data providing information of URA 2014 Master Plan Planning Subzone boundary data. It is in ESRI shapefile format. This data set was also downloaded from Data.gov.sg\n\nLocational factors with geographic coordinates:\n\nDownloaded from Data.gov.sg.\n\nEldercare data is a list of eldercares in Singapore. It is in shapefile format.\nHawker Centre data is a list of hawker centres in Singapore. It is in geojson format.\nParks data is a list of parks in Singapore. It is in geojson format.\nSupermarket data is a list of supermarkets in Singapore. It is in geojson format.\nCHAS clinics data is a list of CHAS clinics in Singapore. It is in geojson format.\nChildcare service data is a list of childcare services in Singapore. It is in geojson format.\nKindergartens data is a list of kindergartens in Singapore. It is in geojson format.\n\nDownloaded from Datamall.lta.gov.sg.\n\nMRT data is a list of MRT/LRT stations in Singapore with the station names and codes. It is in shapefile format.\nBus stops data is a list of bus stops in Singapore. It is in shapefile format.\n\n\nLocational factors without geographic coordinates:\n\nDownloaded from Data.gov.sg.\n\nPrimary school data is extracted from the list on General information of schools from data.gov portal. It is in csv format.\n\nRetrieved/Scraped from other sources\n\nCBD coordinates obtained from Google.\nShopping malls data is a list of Shopping malls in Singapore obtained from Wikipedia.\nGood primary schools is a list of primary schools that are ordered in ranking in terms of popularity and this can be found at Local Salary Forum."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#installing-and-loading-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#installing-and-loading-r-packages",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Modelling",
    "section": "3 Installing and Loading R Packages",
    "text": "3 Installing and Loading R Packages\nThe code chunk below performs 3 tasks:\n\nA list of all the R packages required to accomplish this exercise will be called.\nCheck if R packages or package have been installed in R, otherwise they will be installed.\nAfter all the R packages have been installed, they will be loaded into the R environment.\n\n\npacman::p_load(sf, spdep, GWmodel, SpatialML,\n               tmap, rsample, Metrics, tidyverse)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#the-data",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#the-data",
    "title": "Take-home Exercise 3b: Geospatial Analytics",
    "section": "3 The Data",
    "text": "3 The Data\nThe following sections will consist of steps which import, process and wrangling of data.\n\n3.1 HDB resale Data\nData used for this exercise is HDB Resale data: a list of HDB resale transacted prices in Singapore from Jan 2017 onwards. It is in csv format which can be downloaded from data.gov.sg.\n\nWhen first downloaded, the data was labelled as ResaleflatpricesbasedonregistrationdatefromJan2017onwards. Hence, it was subsequently renamed to resale for ease of referencing and to avoid unnecessary mistakes. Similar to what is required in the task of using HDB resale transaction records in 2023 to predict HDB resale prices between July-September 2024 the code chunk below filters for transaction records for the entirety of 2023 and July till September 2024.\n\nresale &lt;- read_csv(\"data/HDB/rawdata/resale.csv\") %&gt;%\n  filter(month &gt;= \"2023-01\" & month &lt;= \"2024-09\")\n\n\n\n\nresale data snipshot\n\n\nBased on the requirements of this exercise, I have decided to focus my study on four-room flats.\n\n\nroomtype = c('4 ROOM') # '3 ROOM', '4 ROOM', '5 ROOM'\nresale = resale%&gt;%\n  filter(flat_type %in% roomtype)\n\nThe observations have been reduced to 20663.\nThe code chunk below serves the functions of combining block and street_name variables to create a new variable address (excluding unit number) alongside remaining_lease_yr and remaining_lease_mth extracted from remaining_lease. This function will supplement our steps later on in creating the model.\n\nresale_tidy &lt;- resale %&gt;%\n  mutate(address = paste(block,street_name)) %&gt;%\n  mutate(remaining_lease_yr = as.integer(\n    str_sub(remaining_lease, 0, 2)))%&gt;%\n  mutate(remaining_lease_mth = as.integer(\n    str_sub(remaining_lease, 9, 11)))\n\nCode chunk below sorts a list of unique addresses to avoid the issue of repeated geocoding.\n\nadd_list &lt;- sort(unique(resale_tidy$address))\n\nThe following code chunks are used to obtain the postal code of the addresses using geocoding.\n\nget_coords &lt;- function(add_list){\n  \n  # Create a data frame to store all retrieved coordinates\n  postal_coords &lt;- data.frame()\n    \n  for (i in add_list){\n    #print(i)\n\n    r &lt;- GET('https://www.onemap.gov.sg/api/common/elastic/search?',\n           query=list(searchVal=i,\n                     returnGeom='Y',\n                     getAddrDetails='Y'))\n    data &lt;- fromJSON(rawToChar(r$content))\n    found &lt;- data$found\n    res &lt;- data$results\n    \n    # Create a new data frame for each address\n    new_row &lt;- data.frame()\n    \n    # If single result, append \n    if (found == 1){\n      postal &lt;- res$POSTAL \n      lat &lt;- res$LATITUDE\n      lng &lt;- res$LONGITUDE\n      new_row &lt;- data.frame(address= i, \n                            postal = postal, \n                            latitude = lat, \n                            longitude = lng)\n    }\n    \n    # If multiple results, drop NIL and append top 1\n    else if (found &gt; 1){\n      # Remove those with NIL as postal\n      res_sub &lt;- res[res$POSTAL != \"NIL\", ]\n      \n      # Set as NA first if no Postal\n      if (nrow(res_sub) == 0) {\n          new_row &lt;- data.frame(address= i, \n                                postal = NA, \n                                latitude = NA, \n                                longitude = NA)\n      }\n      \n      else{\n        top1 &lt;- head(res_sub, n = 1)\n        postal &lt;- top1$POSTAL \n        lat &lt;- top1$LATITUDE\n        lng &lt;- top1$LONGITUDE\n        new_row &lt;- data.frame(address= i, \n                              postal = postal, \n                              latitude = lat, \n                              longitude = lng)\n      }\n    }\n\n    else {\n      new_row &lt;- data.frame(address= i, \n                            postal = NA, \n                            latitude = NA, \n                            longitude = NA)\n    }\n    \n    # Add the row\n    postal_coords &lt;- rbind(postal_coords, new_row)\n  }\n  return(postal_coords)\n}\n\n\ncoords &lt;- get_coords(add_list)\n\n\nSaving RDS fileReading RDS File\n\n\nThe following code chunk will be used to save the results to avoid having to re-run the code chunks above which will take up additional time and resources.\n\nwrite_rds(coords, \"data/HDB/rds/coords.rds\")\n\n\n\n\ncoords &lt;- read_rds('data/HDB/rds/coords.rds')\n\n\n\n\n\n\n3.2 Structural factors\n\nStructural factors\n\nArea of the unit\nFloor level\nRemaining lease\nAge of the unit\nMain Upgrading Program (MUP) completed (optional)\n\n\n\n\n3.3 Setting CRS\nThe code chunk below first creates an sf object before the EPSG code is set for Singapore which is 4326\n\nresale_tidy &lt;- resale_tidy %&gt;%\n  left_join(coords, by = c(\"address\" = \"address\")) %&gt;%\n  st_as_sf(coords = c(\"longitude\", \"latitude\"), crs = 4326) %&gt;%\n  st_transform(crs = 3414)\nwrite_rds(resale_tidy, \"data/HDB/rds/resale.rds\")\n\n\nresale_tidy &lt;- read_rds(\"data/HDB/rds/resale.rds\")\n\n\n3.3.1 Floor Level\nAs one of the structural factors the code chunk below is used to view the floor levels in resale_tidy\n\nunique(resale_tidy$storey_range)\n\n [1] \"07 TO 09\" \"10 TO 12\" \"01 TO 03\" \"04 TO 06\" \"16 TO 18\" \"25 TO 27\"\n [7] \"13 TO 15\" \"22 TO 24\" \"19 TO 21\" \"28 TO 30\" \"34 TO 36\" \"43 TO 45\"\n[13] \"31 TO 33\" \"46 TO 48\" \"40 TO 42\" \"37 TO 39\" \"49 TO 51\"\n\n\nAs the variable for storey_range is in string, we will generate it as numeric. However, the storey_range as stated follows a range which will make it hard for analysis. Hence, this numeric attribute will be transformed based on the median value ensuring that we have values to work with instead of a range.\n\nresale_tidy &lt;- resale_tidy %&gt;%\n  mutate(\n    level = (as.numeric(str_extract(storey_range, \"^[0-9]+\")) +\n                  as.numeric(str_extract(storey_range, \"[0-9]+$\"))) / 2\n  )\n\n\n\n3.3.2 Remaining Lease & Age of Unit\nWe will also do some data wrangling for remaining_lease_yr & remaining_lease_mth\n\nresale_tidy &lt;- resale_tidy %&gt;%\n  mutate(\n\n# Replace NA in months with 0 as observed in resale_tidy\n\nremaining_lease_mth = if_else(is.na(remaining_lease_mth), 0, remaining_lease_mth),\n    \n# Calculate remaining lease in decimal years\n  remaining_lease = remaining_lease_yr + (remaining_lease_mth / 12),\n    \n# Age of unit calculation based on a HDB 99-year lease\n    unit_age = 99 - remaining_lease\n  ) %&gt;%\n  select(-remaining_lease_yr, -remaining_lease_mth)\n\n\n\n\n3.4 Locational factors\nThe following locational factors will be derived from their respective data sources such as from data.gov.sg for this exercise.\n\nLocational factors\n\nProximity to CBD\nProximity to elder care\nProximity to hawker centres\nProximity to MRT\nProximity to park\nProximity to CHAS Clinics\nProximity to good primary school\nProximity to shopping mall\nProximity to supermarket\nNumbers of kindergartens within 350m\nNumbers of childcare centres within 350m\nNumbers of bus stop within 350m\nNumbers of primary school within 1km\n\n\n\n\n3.5 Geospatial Data\nBased on the locational factors above, we will import these geospatial data into the R environment.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\") %&gt;%\n  st_transform(3414)\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Take-home_Ex\\Take-home_Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\nThe extent of mpsz is shown by using st_bbox() of sf package.\n\nst_bbox(mpsz) #view extent\n\n     xmin      ymin      xmax      ymax \n 2667.538 15748.721 56396.440 50256.334 \n\n\n\neldercare &lt;- st_read(dsn = \"data/geospatial\", layer = \"ELDERCARE\") %&gt;%\n  st_transform(3414)\n\nReading layer `ELDERCARE' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Take-home_Ex\\Take-home_Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 133 features and 18 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 14481.92 ymin: 28218.43 xmax: 41665.14 ymax: 46804.9\nProjected CRS: SVY21\n\n\n\nchas &lt;- st_read(\"data/geospatial/CHASClinics.kml\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MOH_CHAS_CLINICS' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Take-home_Ex\\Take-home_Ex03\\data\\geospatial\\CHASClinics.kml' \n  using driver `KML'\nSimple feature collection with 1193 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.5818 ymin: 1.016264 xmax: 103.9903 ymax: 1.456037\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nchildcare &lt;- st_read(\"data/geospatial/ChildCareServices.kml\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `CHILDCARE' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Take-home_Ex\\Take-home_Ex03\\data\\geospatial\\ChildCareServices.kml' \n  using driver `KML'\nSimple feature collection with 1925 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nkindergartens &lt;- st_read(\"data/geospatial/Kindergartens.geojson\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `Kindergartens' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Take-home_Ex\\Take-home_Ex03\\data\\geospatial\\Kindergartens.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 448 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6887 ymin: 1.247759 xmax: 103.9717 ymax: 1.455452\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nparks &lt;- st_read(\"data/geospatial/Parks.geojson\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `Parks' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Take-home_Ex\\Take-home_Ex03\\data\\geospatial\\Parks.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 430 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6929 ymin: 1.214491 xmax: 104.0538 ymax: 1.462094\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nhawker_centre &lt;- st_read(\"data/geospatial/HawkerCentresGEOJSON.geojson\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `HawkerCentresGEOJSON' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Take-home_Ex\\Take-home_Ex03\\data\\geospatial\\HawkerCentresGEOJSON.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 125 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6974 ymin: 1.272716 xmax: 103.9882 ymax: 1.449017\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nsupermarkets &lt;- st_read(\"data/geospatial/SupermarketsGEOJSON.geojson\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `SupermarketsGEOJSON' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Take-home_Ex\\Take-home_Ex03\\data\\geospatial\\SupermarketsGEOJSON.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 526 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6258 ymin: 1.24715 xmax: 104.0036 ymax: 1.461526\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nbus_stops &lt;- st_read(dsn = \"data/geospatial\", layer = \"BusStop\") %&gt;%\n  st_transform(crs = 3414) %&gt;%\n  filter(lengths(st_within(., mpsz)) &gt; 0)\n\nReading layer `BusStop' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Take-home_Ex\\Take-home_Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 5166 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48285.52 ymax: 52983.82\nProjected CRS: SVY21\n\n\n\nMRT &lt;- st_read(dsn = \"data/geospatial\", layer = \"RapidTransitSystemStation\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `RapidTransitSystemStation' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Take-home_Ex\\Take-home_Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 230 features and 5 fields (with 1 geometry empty)\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 6068.209 ymin: 27478.44 xmax: 45377.5 ymax: 47913.58\nProjected CRS: SVY21\n\nSys.setenv(OGR_GEOMETRY_ACCEPT_UNCLOSED_RING = \"NO\")\n\nMRT &lt;- MRT[!st_is_empty(MRT), ]\n\n# Convert Polygon to Point\nMRT &lt;- st_centroid(MRT)\n\n\n3.5.1 Pre processing Geospatial Data\nIn the previous section, we have loaded the geospatial data of interest it was also observed that some of this data consisted of the Z dimension. We will proceed to remove them as well as drop and unnecessary columns to reduce computation time and ensure geometries are valid.\n\nchas &lt;- st_zm(chas)\nchildcare &lt;- st_zm(childcare)\nkindergartens &lt;- st_zm(kindergartens)\nparks &lt;- st_zm(parks)\nhawker_centre &lt;- st_zm(hawker_centre)\nsupermarkets &lt;- st_zm(supermarkets)\n\nThe code chunks below are used to remove columns not exactly needed to do analysis as the needed variables are generally the Name for identification and Geometry variables\n\neldercare &lt;- eldercare %&gt;%\n  select(c(1))\n\nchas &lt;- chas %&gt;%\n  select(c(1))\n\nchildcare &lt;- childcare %&gt;%\n  select(c(1))\n\nkindergartens &lt;- kindergartens %&gt;%\n  select(c(1))\n\nparks &lt;- parks %&gt;%\n  select(c(1))\n\nhawker_centre &lt;- hawker_centre %&gt;%\n  select(c(1))\n\nsupermarkets &lt;- supermarkets %&gt;%\n  select(c(1))\n\nbus_stops &lt;- bus_stops %&gt;%\n  select(c(1))\n\nMRT &lt;- MRT %&gt;%\n  select(c(5))\n\n\nlength(which(st_is_valid(mpsz) == FALSE))\n\n[1] 9\n\nlength(which(st_is_valid(eldercare) == FALSE))\n\n[1] 0\n\nlength(which(st_is_valid(chas) == FALSE))\n\n[1] 0\n\nlength(which(st_is_valid(childcare) == FALSE))\n\n[1] 0\n\nlength(which(st_is_valid(kindergartens) == FALSE))\n\n[1] 0\n\nlength(which(st_is_valid(parks) == FALSE))\n\n[1] 0\n\nlength(which(st_is_valid(hawker_centre) == FALSE))\n\n[1] 0\n\nlength(which(st_is_valid(supermarkets) == FALSE))\n\n[1] 0\n\nlength(which(st_is_valid(bus_stops) == FALSE))\n\n[1] 0\n\nlength(which(st_is_valid(MRT) == FALSE))\n\n[1] 0"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#weights-based-on-idw",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#weights-based-on-idw",
    "title": "Hands-on Exercise 4: Spatial Weights and Applications",
    "section": "",
    "text": "This section will show how to derive a spatial weight matrix based on Inverse Distance method. Firstly, to compute the distances between areas by using nbdists() of spdep\n\ndist &lt;- nbdists(wm_q, coords, longlat = TRUE)\nids &lt;- lapply(dist, function(x) 1/(x))\nids\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n[[2]]\n[1] 0.01535405 0.01764308 0.01925924 0.02323898 0.01719350\n\n[[3]]\n[1] 0.03916350 0.02822040 0.03695795 0.01395765\n\n[[4]]\n[1] 0.01820896 0.02822040 0.03414741 0.01539065\n\n[[5]]\n[1] 0.03695795 0.03414741 0.01524598 0.01618354\n\n[[6]]\n[1] 0.015390649 0.015245977 0.021748129 0.011883901 0.009810297\n\n[[7]]\n[1] 0.01708612 0.01473997 0.01150924 0.01872915\n\n[[8]]\n[1] 0.02022144 0.03453056 0.02529256 0.01036340 0.02284457 0.01500600 0.01515314\n\n[[9]]\n[1] 0.02022144 0.01574888 0.02109502 0.01508028 0.02902705 0.01502980\n\n[[10]]\n[1] 0.02281552 0.01387777 0.01538326 0.01346650 0.02100510 0.02631658 0.01874863\n[8] 0.01500046\n\n[[11]]\n[1] 0.01882869 0.02243492 0.02247473\n\n[[12]]\n[1] 0.02779227 0.02419652 0.02333385 0.02986130 0.02335429\n\n[[13]]\n[1] 0.02779227 0.02650020 0.02670323 0.01714243\n\n[[14]]\n[1] 0.01882869 0.01233868 0.02098555\n\n[[15]]\n[1] 0.02650020 0.01233868 0.01096284 0.01562226\n\n[[16]]\n[1] 0.02281552 0.02466962 0.02765018 0.01476814 0.01671430\n\n[[17]]\n[1] 0.01387777 0.02243492 0.02098555 0.01096284 0.02466962 0.01593341 0.01437996\n\n[[18]]\n[1] 0.02039779 0.02032767 0.01481665 0.01473691 0.01459380\n\n[[19]]\n[1] 0.01538326 0.01926323 0.02668415 0.02140253 0.01613589 0.01412874\n\n[[20]]\n[1] 0.01346650 0.02039779 0.01926323 0.01723025 0.02153130 0.01469240 0.02327034\n\n[[21]]\n[1] 0.02668415 0.01723025 0.01766299 0.02644986 0.02163800\n\n[[22]]\n[1] 0.02100510 0.02765018 0.02032767 0.02153130 0.01489296\n\n[[23]]\n[1] 0.01481665 0.01469240 0.01401432 0.02246233 0.01880425 0.01530458 0.01849605\n\n[[24]]\n[1] 0.02354598 0.01837201 0.02607264 0.01220154 0.02514180\n\n[[25]]\n[1] 0.02354598 0.02188032 0.01577283 0.01949232 0.02947957\n\n[[26]]\n[1] 0.02155798 0.01745522 0.02212108 0.02220532\n\n[[27]]\n[1] 0.02155798 0.02490625 0.01562326\n\n[[28]]\n[1] 0.01837201 0.02188032 0.02229549 0.03076171 0.02039506\n\n[[29]]\n[1] 0.02490625 0.01686587 0.01395022\n\n[[30]]\n[1] 0.02090587\n\n[[31]]\n[1] 0.02607264 0.01577283 0.01219005 0.01724850 0.01229012 0.01609781 0.01139438\n[8] 0.01150130\n\n[[32]]\n[1] 0.01220154 0.01219005 0.01712515 0.01340413 0.01280928 0.01198216 0.01053374\n[8] 0.01065655\n\n[[33]]\n[1] 0.01949232 0.01745522 0.02229549 0.02090587 0.01979045\n\n[[34]]\n[1] 0.03113041 0.03589551 0.02882915\n\n[[35]]\n[1] 0.01766299 0.02185795 0.02616766 0.02111721 0.02108253 0.01509020\n\n[[36]]\n[1] 0.01724850 0.03113041 0.01571707 0.01860991 0.02073549 0.01680129\n\n[[37]]\n[1] 0.01686587 0.02234793 0.01510990 0.01550676\n\n[[38]]\n[1] 0.01401432 0.02407426 0.02276151 0.01719415\n\n[[39]]\n[1] 0.01229012 0.02172543 0.01711924 0.02629732 0.01896385\n\n[[40]]\n[1] 0.01609781 0.01571707 0.02172543 0.01506473 0.01987922 0.01894207\n\n[[41]]\n[1] 0.02246233 0.02185795 0.02205991 0.01912542 0.01601083 0.01742892\n\n[[42]]\n[1] 0.02212108 0.01562326 0.01395022 0.02234793 0.01711924 0.01836831 0.01683518\n\n[[43]]\n[1] 0.01510990 0.02629732 0.01506473 0.01836831 0.03112027 0.01530782\n\n[[44]]\n[1] 0.01550676 0.02407426 0.03112027 0.01486508\n\n[[45]]\n[1] 0.03589551 0.01860991 0.01987922 0.02205991 0.02107101 0.01982700\n\n[[46]]\n[1] 0.03453056 0.04033752 0.02689769\n\n[[47]]\n[1] 0.02529256 0.02616766 0.04033752 0.01949145 0.02181458\n\n[[48]]\n[1] 0.02313819 0.03370576 0.02289485 0.01630057 0.01818085\n\n[[49]]\n[1] 0.03076171 0.02138091 0.02394529 0.01990000\n\n[[50]]\n[1] 0.01712515 0.02313819 0.02551427 0.02051530 0.02187179\n\n[[51]]\n[1] 0.03370576 0.02138091 0.02873854\n\n[[52]]\n[1] 0.02289485 0.02394529 0.02551427 0.02873854 0.03516672\n\n[[53]]\n[1] 0.01630057 0.01979945 0.01253977\n\n[[54]]\n[1] 0.02514180 0.02039506 0.01340413 0.01990000 0.02051530 0.03516672\n\n[[55]]\n[1] 0.01280928 0.01818085 0.02187179 0.01979945 0.01882298\n\n[[56]]\n[1] 0.01036340 0.01139438 0.01198216 0.02073549 0.01214479 0.01362855 0.01341697\n\n[[57]]\n[1] 0.028079221 0.017643082 0.031423501 0.029114131 0.013520292 0.009903702\n\n[[58]]\n[1] 0.01925924 0.03142350 0.02722997 0.01434859 0.01567192\n\n[[59]]\n[1] 0.01696711 0.01265572 0.01667105 0.01785036\n\n[[60]]\n[1] 0.02419652 0.02670323 0.01696711 0.02343040\n\n[[61]]\n[1] 0.02333385 0.01265572 0.02343040 0.02514093 0.02790764 0.01219751 0.02362452\n\n[[62]]\n[1] 0.02514093 0.02002219 0.02110260\n\n[[63]]\n[1] 0.02986130 0.02790764 0.01407043 0.01805987\n\n[[64]]\n[1] 0.02911413 0.01689892\n\n[[65]]\n[1] 0.02471705\n\n[[66]]\n[1] 0.01574888 0.01726461 0.03068853 0.01954805 0.01810569\n\n[[67]]\n[1] 0.01708612 0.01726461 0.01349843 0.01361172\n\n[[68]]\n[1] 0.02109502 0.02722997 0.03068853 0.01406357 0.01546511\n\n[[69]]\n[1] 0.02174813 0.01645838 0.01419926\n\n[[70]]\n[1] 0.02631658 0.01963168 0.02278487\n\n[[71]]\n[1] 0.01473997 0.01838483 0.03197403\n\n[[72]]\n[1] 0.01874863 0.02247473 0.01476814 0.01593341 0.01963168\n\n[[73]]\n[1] 0.01500046 0.02140253 0.02278487 0.01838483 0.01652709\n\n[[74]]\n[1] 0.01150924 0.01613589 0.03197403 0.01652709 0.01342099 0.02864567\n\n[[75]]\n[1] 0.011883901 0.010533736 0.012539774 0.018822977 0.016458383 0.008217581\n\n[[76]]\n[1] 0.01352029 0.01434859 0.01689892 0.02471705 0.01954805 0.01349843 0.01406357\n\n[[77]]\n[1] 0.014736909 0.018804247 0.022761507 0.012197506 0.020022195 0.014070428\n[7] 0.008440896\n\n[[78]]\n[1] 0.02323898 0.02284457 0.01508028 0.01214479 0.01567192 0.01546511 0.01140779\n\n[[79]]\n[1] 0.01530458 0.01719415 0.01894207 0.01912542 0.01530782 0.01486508 0.02107101\n\n[[80]]\n[1] 0.01500600 0.02882915 0.02111721 0.01680129 0.01601083 0.01982700 0.01949145\n[8] 0.01362855\n\n[[81]]\n[1] 0.02947957 0.02220532 0.01150130 0.01979045 0.01896385 0.01683518\n\n[[82]]\n[1] 0.02327034 0.02644986 0.01849605 0.02108253 0.01742892\n\n[[83]]\n[1] 0.023354289 0.017142433 0.015622258 0.016714303 0.014379961 0.014593799\n[7] 0.014892965 0.018059871 0.008440896\n\n[[84]]\n[1] 0.01872915 0.02902705 0.01810569 0.01361172 0.01342099 0.01297994\n\n[[85]]\n [1] 0.011451133 0.017193502 0.013957649 0.016183544 0.009810297 0.010656545\n [7] 0.013416965 0.009903702 0.014199260 0.008217581 0.011407794\n\n[[86]]\n[1] 0.01515314 0.01502980 0.01412874 0.02163800 0.01509020 0.02689769 0.02181458\n[8] 0.02864567 0.01297994\n\n[[87]]\n[1] 0.01667105 0.02362452 0.02110260 0.02058034\n\n[[88]]\n[1] 0.01785036 0.02058034"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#row-standardised-weights-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#row-standardised-weights-matrix",
    "title": "Hands-on Exercise 4: Spatial Weights and Applications",
    "section": "",
    "text": "Next, we need to assign weights to each neighbouring polygon. In our case, each neighbouring polygon will be assigned equal weight (style=“W”). This is accomplished by assigning the fraction 1/(#ofneighbours) to each neighbouring county then summing the weighted income values.\nWhile this is the most intuitive way to summaries the neighbours’ values it has one drawback in that polygons along the edges of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data. For this example, we’ll stick with the style=“W” option for simplicity’s sake but note that other more robust options are available, notably style=“B”.\n\nrswm_q &lt;- nb2listw(wm_q, style = \"W\", zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\nThe zero.policy = TRUE option allows for lists of non-neighbours. This should be used with caution since the user may not be aware of missing neighbours in their dataset however, a zero.policy of FALSE would return an error.\nTo see the weight of the first polygon’s eight neighbours type:\n\nrswm_q$weights[10]\n\n[[1]]\n[1] 0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125\n\n\nEach neighbour is assigned a value 0.125 of the total weight. This means that when R computes the average neighbouring income values, each neighbour’s income will be multiplied by 0.125 before being tallied.\nUsing the same method, we can also derive a row standardised distance weight matrix by using the code chunk below.\n\nrswm_ids &lt;- nb2listw(wm_q, glist = ids, style = \"B\", zero.policy = TRUE)\nrswm_ids\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn       S0        S1     S2\nB 88 7744 8.786867 0.3776535 3.8137\n\n\n\nrswm_ids$weights[1]\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n\nResults of previous code chunk shown above.\n\nsummary(unlist(rswm_ids$weights))\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n0.008218 0.015088 0.018739 0.019614 0.022823 0.040338"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#application-of-spatial-weight-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#application-of-spatial-weight-matrix",
    "title": "Hands-on Exercise 4: Spatial Weights and Applications",
    "section": "",
    "text": "In this section, it shows how to create four different spatial lagged variables, they are:\n\nspatial lag with row-standardized weights,\nspatial lag as a sum of neighbouring values,\nspatial window average, and\nspatial window sum.\n\n\n\nFinally, we’ll compute the average neighbour GDPPC value for each polygon. These values are often referred to as spatially lagged values.\n\nGDPPC.lag &lt;- lag.listw(rswm_q, hunan$GDPPC)\nGDPPC.lag\n\n [1] 24847.20 22724.80 24143.25 27737.50 27270.25 21248.80 43747.00 33582.71\n [9] 45651.17 32027.62 32671.00 20810.00 25711.50 30672.33 33457.75 31689.20\n[17] 20269.00 23901.60 25126.17 21903.43 22718.60 25918.80 20307.00 20023.80\n[25] 16576.80 18667.00 14394.67 19848.80 15516.33 20518.00 17572.00 15200.12\n[33] 18413.80 14419.33 24094.50 22019.83 12923.50 14756.00 13869.80 12296.67\n[41] 15775.17 14382.86 11566.33 13199.50 23412.00 39541.00 36186.60 16559.60\n[49] 20772.50 19471.20 19827.33 15466.80 12925.67 18577.17 14943.00 24913.00\n[57] 25093.00 24428.80 17003.00 21143.75 20435.00 17131.33 24569.75 23835.50\n[65] 26360.00 47383.40 55157.75 37058.00 21546.67 23348.67 42323.67 28938.60\n[73] 25880.80 47345.67 18711.33 29087.29 20748.29 35933.71 15439.71 29787.50\n[81] 18145.00 21617.00 29203.89 41363.67 22259.09 44939.56 16902.00 16930.00\n\n\nRecall in the previous section, we retrieved the GDPPC of these five countries by using the code chunk below:\n\nnb1 &lt;- wm_q[[1]]\nnb1 &lt;- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\nWe can append the spatially lag GDPPC values onto hunan sf data frame by using the code chunk below.\n\nlag.list &lt;- list(hunan$NAME_3, lag.listw(rswm_q, hunan$GDPPC))\nlag.res &lt;- as.data.frame(lag.list)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag GDPPC\")\nhunan &lt;- left_join(hunan,lag.res)\n\nJoining with `by = join_by(NAME_3)`\n\n\nThe following table shows the average neighboring income values (stored in the Inc.lag object) for each county.\n\nhead(hunan)\n\nSimple feature collection with 6 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 110.4922 ymin: 28.61762 xmax: 112.3013 ymax: 30.12812\nGeodetic CRS:  WGS 84\n   NAME_2  ID_3  NAME_3   ENGTYPE_3  County GDPPC lag GDPPC\n1 Changde 21098 Anxiang      County Anxiang 23667  24847.20\n2 Changde 21100 Hanshou      County Hanshou 20981  22724.80\n3 Changde 21101  Jinshi County City  Jinshi 34592  24143.25\n4 Changde 21102      Li      County      Li 24473  27737.50\n5 Changde 21103   Linli      County   Linli 25554  27270.25\n6 Changde 21104  Shimen      County  Shimen 27137  21248.80\n                        geometry\n1 POLYGON ((112.0625 29.75523...\n2 POLYGON ((112.2288 29.11684...\n3 POLYGON ((111.8927 29.6013,...\n4 POLYGON ((111.3731 29.94649...\n5 POLYGON ((111.6324 29.76288...\n6 POLYGON ((110.8825 30.11675...\n\n\nNext, to plot both the GDPPC and spatial lag GDPPC for comparison using the code chunk below.\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\nlag_gdppc &lt;- qtm(hunan, \"lag GDPPC\")\ntmap_arrange(gdppc, lag_gdppc, asp = 1, ncol = 2)\n\n\n\n\n\n\n\n\n\n\n\nWe can calculate spatial lag as a sum of neighbouring values by assigning binary weights. This requires us to go back to our neighbours list, then apply a function that will assign binary weights, then we use glist = in the nb2listw function to explicitly assign these weights.\nWe start by applying a function that will assign a value of 1 per each neighbour. This is done with lapply(), which we have been using to manipulate the neighbours structure throughout the past notebooks. Basically it applies a function across each value in the neighbours structure.\n\nb_weights &lt;- lapply(wm_q, function(x) 0*x + 1)\nb_weights2 &lt;- nb2listw(wm_q, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1    S2\nB 88 7744 448 896 10224\n\n\nWith the proper weights assigned, we can use lag.listw() to compute a lag variable from our weight and GDPPC.\n\nlag_sum &lt;- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nlag.res &lt;- as.data.frame(lag_sum)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag_sum GDPPC\")\n\nFirst, to examine the result by using the code chunk below.\n\nlag_sum\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 124236 113624  96573 110950 109081 106244 174988 235079 273907 256221\n[11]  98013 104050 102846  92017 133831 158446 141883 119508 150757 153324\n[21] 113593 129594 142149 100119  82884  74668  43184  99244  46549  20518\n[31] 140576 121601  92069  43258 144567 132119  51694  59024  69349  73780\n[41]  94651 100680  69398  52798 140472 118623 180933  82798  83090  97356\n[51]  59482  77334  38777 111463  74715 174391 150558 122144  68012  84575\n[61] 143045  51394  98279  47671  26360 236917 220631 185290  64640  70046\n[71] 126971 144693 129404 284074 112268 203611 145238 251536 108078 238300\n[81] 108870 108085 262835 248182 244850 404456  67608  33860\n\n\nNext, to append the lag_sum GDPPC field into hunan sf data frame by using the code chunk below.\n\nhunan &lt;- left_join(hunan, lag.res)\n\nJoining with `by = join_by(NAME_3)`\n\n\nFollowing which, to plot both the GDPPC and Spatial Lag Sum GDPPC for comparison using the code chunk below.\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\nlag_sum_gdppc &lt;- qtm(hunan, \"lag_sum GDPPC\")\ntmap_arrange(gdppc, lag_sum_gdppc, asp = 1, ncol = 2)\n\n\n\n\n\n\n\n\n\n\n\nThe spatial window average uses row-standardized weights and includes the diagonal element. To do this in R, we need to go back to the neighbors structure and add the diagonal element before assigning weights.\nTo add the diagonal element to the neighbour list, we just need to use include.self() from spdep.\n\nwm_qs &lt;- include.self(wm_q)\n\nNotice that the Number of non-zero links, Percentage non-zero weights and Average number of links are 536, 6.921488 and 6.090909 respectively as compared to wm_q of 448, 5.785124 and 5.090909\nLet us take a good look at the neighbour list of area [1] by using the code chunk below.\n\nwm_qs[[1]]\n\n[1]  1  2  3  4 57 85\n\n\nNotice that now [1] has six neighbours instead of five.\nNow we obtain weights with nb2listw()\n\nwm_qs &lt;- nb2listw(wm_qs)\nwm_qs\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 30.90265 357.5308\n\n\nAgain, utilising nb2listw() and glist() to explicitly assign weight values.\nLastly, we just need to create the lag variable from our weight structure and GDPPC variable.\n\nlag_w_avg_gpdpc &lt;- lag.listw(wm_qs, \n                             hunan$GDPPC)\nlag_w_avg_gpdpc\n\n [1] 24650.50 22434.17 26233.00 27084.60 26927.00 22230.17 47621.20 37160.12\n [9] 49224.71 29886.89 26627.50 22690.17 25366.40 25825.75 30329.00 32682.83\n[17] 25948.62 23987.67 25463.14 21904.38 23127.50 25949.83 20018.75 19524.17\n[25] 18955.00 17800.40 15883.00 18831.33 14832.50 17965.00 17159.89 16199.44\n[33] 18764.50 26878.75 23188.86 20788.14 12365.20 15985.00 13764.83 11907.43\n[41] 17128.14 14593.62 11644.29 12706.00 21712.29 43548.25 35049.00 16226.83\n[49] 19294.40 18156.00 19954.75 18145.17 12132.75 18419.29 14050.83 23619.75\n[57] 24552.71 24733.67 16762.60 20932.60 19467.75 18334.00 22541.00 26028.00\n[65] 29128.50 46569.00 47576.60 36545.50 20838.50 22531.00 42115.50 27619.00\n[73] 27611.33 44523.29 18127.43 28746.38 20734.50 33880.62 14716.38 28516.22\n[81] 18086.14 21244.50 29568.80 48119.71 22310.75 43151.60 17133.40 17009.33\n\n\nNext, to convert the lag variable listw object into a data.frame by using as.data.frame().\n\nlag.list.wm_qs &lt;- list(hunan$NAME_3, lag.listw(wm_qs, hunan$GDPPC))\nlag_wm_qs.res &lt;- as.data.frame(lag.list.wm_qs)\ncolnames(lag_wm_qs.res) &lt;- c(\"NAME_3\", \"lag_window_avg GDPPC\")\n\n\n\n\n\n\n\nNote\n\n\n\nThe third command line on the code chunk above renames the field names of lag_wm_q1.res object into NAME_3 and lag_window_avg GDPPC respectively.\n\n\nNext, the code chunk below will be used to append lag_window_avg GDPPC values onto hunan sf data.frame by using left_join() of dplyr package.\n\nhunan &lt;- left_join(hunan, lag_wm_qs.res)\n\nJoining with `by = join_by(NAME_3)`\n\n\nTo compare the values of lag GDPPC and Spatial window average, kable() of Knitr package is used to prepare a table using the code chunk below.\n\nhunan %&gt;%\n  select(\"County\", \n         \"lag GDPPC\", \n         \"lag_window_avg GDPPC\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag GDPPC\nlag_window_avg GDPPC\ngeometry\n\n\n\n\nAnxiang\n24847.20\n24650.50\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n22724.80\n22434.17\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n24143.25\n26233.00\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n27737.50\n27084.60\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n27270.25\n26927.00\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n21248.80\n22230.17\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n43747.00\n47621.20\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n33582.71\n37160.12\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n45651.17\n49224.71\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n32027.62\n29886.89\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n32671.00\n26627.50\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n20810.00\n22690.17\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n25711.50\n25366.40\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n30672.33\n25825.75\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n33457.75\n30329.00\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n31689.20\n32682.83\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n20269.00\n25948.62\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n23901.60\n23987.67\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n25126.17\n25463.14\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n21903.43\n21904.38\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n22718.60\n23127.50\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n25918.80\n25949.83\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n20307.00\n20018.75\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n20023.80\n19524.17\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n16576.80\n18955.00\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n18667.00\n17800.40\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n14394.67\n15883.00\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n19848.80\n18831.33\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n15516.33\n14832.50\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518.00\n17965.00\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n17572.00\n17159.89\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n15200.12\n16199.44\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n18413.80\n18764.50\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n14419.33\n26878.75\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n24094.50\n23188.86\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n22019.83\n20788.14\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n12923.50\n12365.20\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n14756.00\n15985.00\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n13869.80\n13764.83\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n12296.67\n11907.43\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n15775.17\n17128.14\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n14382.86\n14593.62\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n11566.33\n11644.29\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n13199.50\n12706.00\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n23412.00\n21712.29\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n39541.00\n43548.25\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n36186.60\n35049.00\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n16559.60\n16226.83\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n20772.50\n19294.40\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n19471.20\n18156.00\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n19827.33\n19954.75\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n15466.80\n18145.17\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n12925.67\n12132.75\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n18577.17\n18419.29\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n14943.00\n14050.83\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n24913.00\n23619.75\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n25093.00\n24552.71\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n24428.80\n24733.67\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n17003.00\n16762.60\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n21143.75\n20932.60\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n20435.00\n19467.75\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n17131.33\n18334.00\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n24569.75\n22541.00\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n23835.50\n26028.00\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360.00\n29128.50\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n47383.40\n46569.00\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n55157.75\n47576.60\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n37058.00\n36545.50\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n21546.67\n20838.50\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n23348.67\n22531.00\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n42323.67\n42115.50\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n28938.60\n27619.00\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n25880.80\n27611.33\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n47345.67\n44523.29\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n18711.33\n18127.43\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n29087.29\n28746.38\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n20748.29\n20734.50\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n35933.71\n33880.62\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n15439.71\n14716.38\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n29787.50\n28516.22\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n18145.00\n18086.14\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n21617.00\n21244.50\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n29203.89\n29568.80\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n41363.67\n48119.71\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n22259.09\n22310.75\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n44939.56\n43151.60\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n16902.00\n17133.40\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n16930.00\n17009.33\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\nLastly, qtm() of tmap package is used to plot the lag_gdppc and w_ave_gdppc maps next to each other for quick comparison.\n\nw_avg_gdppc &lt;- qtm(hunan, \"lag_window_avg GDPPC\")\ntmap_arrange(lag_gdppc, w_avg_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nFor more effective comparison, it is advisable to use the core tmap mapping functions.\n\n\n\n\n\nThe spatial window sum is the counter part of the window average, but without using row-standardized weights.\nTo add the diagonal element to the neighbour list, we just need to use include.self() from spdep.\n\nwm_qs &lt;- include.self(wm_q)\nwm_qs\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\nAssigning binary weights to the neighbour structure that includes the diagonal element.\n\nb_weights &lt;- lapply(wm_qs, function(x) 0*x + 1)\nb_weights[1]\n\n[[1]]\n[1] 1 1 1 1 1 1\n\n\n\nNotice that now [1] has six neighbours instead of five.\n\nAgain, we use nb2listw() and glist() to explicitly assign weight values.\n\nb_weights2 &lt;- nb2listw(wm_qs, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 536 1072 14160\n\n\nWith our new weight structure, we can compute the lag variable with lag.listw().\n\nw_sum_gdppc &lt;- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nw_sum_gdppc\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 147903 134605 131165 135423 134635 133381 238106 297281 344573 268982\n[11] 106510 136141 126832 103303 151645 196097 207589 143926 178242 175235\n[21] 138765 155699 160150 117145 113730  89002  63532 112988  59330  35930\n[31] 154439 145795 112587 107515 162322 145517  61826  79925  82589  83352\n[41] 119897 116749  81510  63530 151986 174193 210294  97361  96472 108936\n[51]  79819 108871  48531 128935  84305 188958 171869 148402  83813 104663\n[61] 155742  73336 112705  78084  58257 279414 237883 219273  83354  90124\n[71] 168462 165714 165668 311663 126892 229971 165876 271045 117731 256646\n[81] 126603 127467 295688 336838 267729 431516  85667  51028\n\n\nNext, we will convert the lag variable listw object into a data.frame by using as.data.frame().\n\nw_sum_gdppc.res &lt;- as.data.frame(w_sum_gdppc)\ncolnames(w_sum_gdppc.res) &lt;- c(\"NAME_3\", \"w_sum GDPPC\")\n\nNote: The second command line on the code chunk above renames the field names of w_sum_gdppc.res object into NAME_3 and w_sum GDPPC respectively.\nNext, the code chunk below will be used to append w_sum GDPPC values onto hunan sf data.frame by using left_join() of dplyr package.\n\nhunan &lt;- left_join(hunan, w_sum_gdppc.res)\n\nJoining with `by = join_by(NAME_3)`\n\n\nOnce again, qtm() of tmap package is used to plot the lag_sum GDPPC and w_sum_gdppc maps next to each other for quick comparison.\n\nw_sum_gdppc &lt;- qtm(hunan, \"w_sum GDPPC\")\ntmap_arrange(lag_sum_gdppc, w_sum_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIt is advisable to use the core tmap mapping functions for a more effective comparison."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#references",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#references",
    "title": "Hands-on Exercise 4: Spatial Weights and Applications",
    "section": "",
    "text": "Creating Neighbours using sf objects"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html",
    "title": "Hands-on Exercise 5b: Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "In this hands-on exercise, it will run through the process of computing spatial weights using R. By the end to this hands-on exercise, one should be able to:\n\nimport geospatial data using appropriate function(s) of sf package,\nimport csv file using appropriate function of readr package,\nperform relational join using appropriate join function of dplyr package,\ncompute spatial weights using appropriate functions of spdep package, and\ncalculate spatially lagged variables using appropriate functions of spdep package.\n\n\n\n\nTwo data sets will be used in this hands-on exercise, they are:\n\nHunan county boundary layer. This is a geospatial data set in ESRI shapefile format.\nHunan_2012.csv; This csv file contains selected Hunan’s local development indicators in 2012.\n\n\n\nBefore getting started, ensure that spdep, sf, tmap, tidyverse and knitrpackages of R are currently installed in R.\n\npacman::p_load(spdep, sf, tmap, tidyverse, knitr)\n\n\n\n\n\nIn this section, the geospatial data and its associated attribute table will be brought in R environment. The geospatial data is in ESRI shapefile format and the attribute table is in csv format.\n\n\nThe code chunk below uses st_read() of sf package to import Hunan shapefile into R. The imported shapefile will be a simple feature Object of sf.\n\nhunan &lt;- st_read(dsn = \"data/geospatial\",\n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex05\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n\nNext, Hunan_2012.csv will be imported into R by using read_csv() of readr package. The output is a R dataframe class.\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nThe code chunk below will be used to update the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 dataframe. This is performed by using left_join() of dplyr package.\nThe select() function is used to select variables that are objectively used for the spatial analysis.\n\nhunan &lt;- left_join(hunan, hunan2012) %&gt;%\n  select(1:4, 7, 15)\n\nJoining with `by = join_by(County)`\n\n\n\n\n\n\nNow, a basemap and a choropleth map will be prepared showing the distribution of GDPPC 2012 by using qtm() of tmap package.\n\nbasemap &lt;- tm_shape(hunan) +\n  tm_polygons() +\n  tm_text(\"NAME_3\", size = 0.5)\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\ntmap_arrange(basemap, gdppc, asp = 1, ncol = 2)\n\n\n\n\n\n\n\n\n\nNote: Gross Domestic Product per Capita (GDPPC)\n\n\n\n\nIn this section, we will learn how to use poly2nb() of spdep package to compute contiguity weight matrices for the study area.\nThis function builds a neighbours list based on regions with contiguous boundaries. From the documentation, we learn that we can pass a “queen” argument that takes TRUE or FALSE as options. If this argument is not specified the argument’s default is set to TRUE, that is, if we don’t specify queen = FALSE this function will return a list of first order neighbours using the Queen criteria.\n\n\nThe code chunk below is used to compute Queen contiguity weight matrix.\n\nwm_q &lt;- poly2nb(hunan, queen = TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report above shows that there are 88 area units (regions) in Hunan. The most connected area unit has 11 neighbours. There are two area units with only one neighbour.\nFor each polygon in the polygon object, wm_q lists all neighbouring polygons. For example, to see the neighbours for the first polygon in the object, type:\n\nwm_q[[1]]\n\n[1]  2  3  4 57 85\n\n\nPolygon 1 has 5 neighbours. The numbers represent the polygon IDs as stored in hunan SpatialPolygonsDataFrame class.\nWe can retrieve the county name of Polygon ID=1 by using the code chunk below:\n\nhunan$County[1]\n\n[1] \"Anxiang\"\n\n\nThe output reveals that Polygon ID=1 is Anxiang county.\nTo reveal the county names of the five neighbouring polygons, the code chunk will be used:\n\nhunan$NAME_3[c(2,3,4,57,85)]\n\n[1] \"Hanshou\" \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\"\n\n\nWe can retrieve the GDPPC of these five counties by using the code chunk below.\n\nnb1 &lt;- wm_q[[1]]\nnb1 &lt;- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\nThe printed output above shows that the GDPPC of the five nearest neighbours based on Queen’s method are 20981, 34592, 24473, 21311 and 22879 respectively.\nWe can display the complete weight matrix by using str().\n\nstr(wm_q)\n\nList of 88\n $ : int [1:5] 2 3 4 57 85\n $ : int [1:5] 1 57 58 78 85\n $ : int [1:4] 1 4 5 85\n $ : int [1:4] 1 3 5 6\n $ : int [1:4] 3 4 6 85\n $ : int [1:5] 4 5 69 75 85\n $ : int [1:4] 67 71 74 84\n $ : int [1:7] 9 46 47 56 78 80 86\n $ : int [1:6] 8 66 68 78 84 86\n $ : int [1:8] 16 17 19 20 22 70 72 73\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:3] 11 15 17\n $ : int [1:4] 13 14 17 83\n $ : int [1:5] 10 17 22 72 83\n $ : int [1:7] 10 11 14 15 16 72 83\n $ : int [1:5] 20 22 23 77 83\n $ : int [1:6] 10 20 21 73 74 86\n $ : int [1:7] 10 18 19 21 22 23 82\n $ : int [1:5] 19 20 35 82 86\n $ : int [1:5] 10 16 18 20 83\n $ : int [1:7] 18 20 38 41 77 79 82\n $ : int [1:5] 25 28 31 32 54\n $ : int [1:5] 24 28 31 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:3] 26 29 42\n $ : int [1:5] 24 25 33 49 54\n $ : int [1:3] 27 37 42\n $ : int 33\n $ : int [1:8] 24 25 32 36 39 40 56 81\n $ : int [1:8] 24 31 50 54 55 56 75 85\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 47 80 82 86\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:4] 29 42 43 44\n $ : int [1:4] 23 44 77 79\n $ : int [1:5] 31 40 42 43 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:7] 26 27 29 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:4] 37 38 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:3] 8 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:5] 32 48 52 54 55\n $ : int [1:3] 48 49 52\n $ : int [1:5] 48 49 50 51 54\n $ : int [1:3] 48 55 75\n $ : int [1:6] 24 28 32 49 50 52\n $ : int [1:5] 32 48 50 53 75\n $ : int [1:7] 8 31 32 36 78 80 85\n $ : int [1:6] 1 2 58 64 76 85\n $ : int [1:5] 2 57 68 76 78\n $ : int [1:4] 60 61 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:7] 12 59 60 62 63 77 87\n $ : int [1:3] 61 77 87\n $ : int [1:4] 12 61 77 83\n $ : int [1:2] 57 76\n $ : int 76\n $ : int [1:5] 9 67 68 76 84\n $ : int [1:4] 7 66 76 84\n $ : int [1:5] 9 58 66 76 78\n $ : int [1:3] 6 75 85\n $ : int [1:3] 10 72 73\n $ : int [1:3] 7 73 74\n $ : int [1:5] 10 11 16 17 70\n $ : int [1:5] 10 19 70 71 74\n $ : int [1:6] 7 19 71 73 84 86\n $ : int [1:6] 6 32 53 55 69 85\n $ : int [1:7] 57 58 64 65 66 67 68\n $ : int [1:7] 18 23 38 61 62 63 83\n $ : int [1:7] 2 8 9 56 58 68 85\n $ : int [1:7] 23 38 40 41 43 44 45\n $ : int [1:8] 8 34 35 36 41 45 47 56\n $ : int [1:6] 25 26 31 33 39 42\n $ : int [1:5] 20 21 23 35 41\n $ : int [1:9] 12 13 15 16 17 18 22 63 77\n $ : int [1:6] 7 9 66 67 74 86\n $ : int [1:11] 1 2 3 5 6 32 56 57 69 75 ...\n $ : int [1:9] 8 9 19 21 35 46 47 74 84\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language poly2nb(pl = hunan, queen = TRUE)\n - attr(*, \"type\")= chr \"queen\"\n - attr(*, \"sym\")= logi TRUE\n\n\n\n\n\n\n\n\nWarning\n\n\n\nBe warned: The output might cut across several pages. Do consider saving the trees if you are going to print out the report.\n\n\n\n\n\nleast connectedmost connected\n\n\n\nwm_q[[30]]\n\n[1] 33\n\nwm_q[[65]]\n\n[1] 76\n\n\n\n\n\nwm_q[[85]]\n\n [1]  1  2  3  5  6 32 56 57 69 75 78\n\n\n\nhunan$County[85]\n\n[1] \"Taoyuan\"\n\n\nTo reveal the county names of the eleven neighbouring polygons, the code chunk will be used:\n\nhunan$NAME_3[c(1,2,3,5,6,32,56,57,69,75,78)]\n\n [1] \"Anxiang\"  \"Hanshou\"  \"Jinshi\"   \"Linli\"    \"Shimen\"   \"Yuanling\"\n [7] \"Anhua\"    \"Nan\"      \"Cili\"     \"Sangzhi\"  \"Taojiang\"\n\n\nRevealing the GDPPC of there eleven counties by using the code chunk below.\n\nnb1 &lt;- wm_q[[85]]\nnb1 &lt;- hunan$GDPPC[nb1]\nnb1\n\n [1] 23667 20981 34592 25554 27137 24194 14567 21311 18714 14624 19509\n\n\n\n\n\n\n\n\n\nThe code chunk below is used to compute Rook contiguity weight matrix.\n\nwm_r &lt;- poly2nb(hunan, queen = FALSE)\nsummary(wm_r)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connected area unit has 10 neighbours. There are two area units with only one neighbours.\n\n\n\nA connectivity graph takes a point and displays a line to each neighbouring point. We are working with polygons at the moment, so we will need to get points in order to make our connectivity graphs. The most typically used method for this will be polygon centroids. We will calculate these in the sf package before moving onto the graphs. Getting Latitude and Longitude of Polygon Centroids\nWe will need points to associate with each polygon before we can make our connectivity graph. It will be a little more complicated than just running st_centroid on the sf object: us.bound. We need the coordinates in a separate data frame for this to work. To do this we will use a mapping function. The mapping function applies a given function to each element of a vector and returns a vector of the same length. Our input vector will be the geometry column of us.bound. Our function will be st_centroid. We will be using map_dbl variation of map from the purrr package. For more documentation, check out map documentation\nTo get our longitude values we map the st_centroid function over the geometry column of us.bound and access the longitude value through double bracket notation [[]] and 1. This allows us to get only the longitude, which is the first value in each centroid.\n\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\nWe can do the same for latitude with one key difference. We access the second value per each centroid with [[2]].\n\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\nNow that longitude and latitude is obtained, we use cbind to put longitude and latitude into the same object.\n\ncoords &lt;- cbind(longitude, latitude)\n\nUpon running the code chunk, we can check the first few observations to see if things are formatted correctly.\n\nhead(coords)\n\n     longitude latitude\n[1,]  112.1531 29.44362\n[2,]  112.0372 28.86489\n[3,]  111.8917 29.47107\n[4,]  111.7031 29.74499\n[5,]  111.6138 29.49258\n[6,]  111.0341 29.79863\n\n\n\n\n\nplot(hunan$geometry, border = \"lightgrey\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\n\n\n\n\n\n\n\n\n\n\n\n\nplot(hunan$geometry, border = \"lightgrey\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\n\n\n\n\n\n\n\n\n\n\n\n\npar(mfrow = c(1,2))\nplot(hunan$geometry, border = \"lightgrey\", main = \"Queen Contiguity\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\nplot(hunan$geometry, border = \"lightgrey\", main = \"Rook Contiguity\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn this section, we will learn how to derive distance-based weight matrices by using dnearneigh() of spdep package.\nThe function identifies neighbours of region points by Euclidean distance with a distance band with lower d1= and upper d2= bounds controlled by the bounds = argument. If un-projected coordinates are used and either specified in the coordinates object x or with x as a two column matrix and = TRUE, great circle distances in km will be calculated assuming the WGS84 reference ellipsoid.\n\n\nFirstly, we need to determine the upper limit for distance band by using the steps below:\n\nReturn a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using knearneigh() of spdep.\nConvert the knn object returned by knearneigh() into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using knn2nb().\nReturn the length of neighbour relationship edges by using nbdists() of spdep. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise.\nRemove the list structure of the returned object by using unlist().\n\n\n#coords &lt;- coordinates(hunan)\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nThe summary report shows that the largest first nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour.\n\n\n\nNow, we will compute the distance weight matrix by using dnearneigh() as shown in the code chunk below.\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\n\nQuiz: What is the meaning of “Average number of links: 3.681818” shown above?\nInterpretation: An average of 3.681818 means that, on average, each point has about 3.68 neighbours within the specified distance band (0 to 62 km in this case). This gives a sense of the overall connectivity in the spatial network. A higher average number of links suggests that points are more densely connected, while a lower number suggests sparser connections.\n\nNext, we will use str() to display the content of wm_d62 weight matrix.\n\nstr(wm_d62)\n\nList of 88\n $ : int [1:5] 3 4 5 57 64\n $ : int [1:4] 57 58 78 85\n $ : int [1:4] 1 4 5 57\n $ : int [1:3] 1 3 5\n $ : int [1:4] 1 3 4 85\n $ : int 69\n $ : int [1:2] 67 84\n $ : int [1:4] 9 46 47 78\n $ : int [1:4] 8 46 68 84\n $ : int [1:4] 16 22 70 72\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:2] 11 17\n $ : int 13\n $ : int [1:4] 10 17 22 83\n $ : int [1:3] 11 14 16\n $ : int [1:3] 20 22 63\n $ : int [1:5] 20 21 73 74 82\n $ : int [1:5] 18 19 21 22 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:4] 10 16 18 20\n $ : int [1:3] 41 77 82\n $ : int [1:4] 25 28 31 54\n $ : int [1:4] 24 28 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:2] 26 29\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:2] 27 37\n $ : int 33\n $ : int [1:2] 24 36\n $ : int 50\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:5] 31 34 45 56 80\n $ : int [1:2] 29 42\n $ : int [1:3] 44 77 79\n $ : int [1:4] 40 42 43 81\n $ : int [1:3] 39 45 79\n $ : int [1:5] 23 35 45 79 82\n $ : int [1:5] 26 37 39 43 81\n $ : int [1:3] 39 42 44\n $ : int [1:2] 38 43\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:5] 8 9 35 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:4] 48 49 50 52\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:2] 48 55\n $ : int [1:5] 24 28 49 50 52\n $ : int [1:4] 48 50 53 75\n $ : int 36\n $ : int [1:5] 1 2 3 58 64\n $ : int [1:5] 2 57 64 66 68\n $ : int [1:3] 60 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:5] 12 60 62 63 87\n $ : int [1:4] 61 63 77 87\n $ : int [1:5] 12 18 61 62 83\n $ : int [1:4] 1 57 58 76\n $ : int 76\n $ : int [1:5] 58 67 68 76 84\n $ : int [1:2] 7 66\n $ : int [1:4] 9 58 66 84\n $ : int [1:2] 6 75\n $ : int [1:3] 10 72 73\n $ : int [1:2] 73 74\n $ : int [1:3] 10 11 70\n $ : int [1:4] 19 70 71 74\n $ : int [1:5] 19 21 71 73 86\n $ : int [1:2] 55 69\n $ : int [1:3] 64 65 66\n $ : int [1:3] 23 38 62\n $ : int [1:2] 2 8\n $ : int [1:4] 38 40 41 45\n $ : int [1:5] 34 35 36 45 47\n $ : int [1:5] 25 26 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:4] 12 13 16 63\n $ : int [1:4] 7 9 66 68\n $ : int [1:2] 2 5\n $ : int [1:4] 21 46 47 74\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language dnearneigh(x = coords, d1 = 0, d2 = 62, longlat = TRUE)\n - attr(*, \"dnn\")= num [1:2] 0 62\n - attr(*, \"bounds\")= chr [1:2] \"GE\" \"LE\"\n - attr(*, \"nbtype\")= chr \"distance\"\n - attr(*, \"sym\")= logi TRUE\n\n\nAnother way to display the structure of the weight matrix is to combine table() and card() of spdep.\n\ntable(hunan$County, card(wm_d62))\n\n               \n                1 2 3 4 5 6\n  Anhua         1 0 0 0 0 0\n  Anren         0 0 0 1 0 0\n  Anxiang       0 0 0 0 1 0\n  Baojing       0 0 0 0 1 0\n  Chaling       0 0 1 0 0 0\n  Changning     0 0 1 0 0 0\n  Changsha      0 0 0 1 0 0\n  Chengbu       0 1 0 0 0 0\n  Chenxi        0 0 0 1 0 0\n  Cili          0 1 0 0 0 0\n  Dao           0 0 0 1 0 0\n  Dongan        0 0 1 0 0 0\n  Dongkou       0 0 0 1 0 0\n  Fenghuang     0 0 0 1 0 0\n  Guidong       0 0 1 0 0 0\n  Guiyang       0 0 0 1 0 0\n  Guzhang       0 0 0 0 0 1\n  Hanshou       0 0 0 1 0 0\n  Hengdong      0 0 0 0 1 0\n  Hengnan       0 0 0 0 1 0\n  Hengshan      0 0 0 0 0 1\n  Hengyang      0 0 0 0 0 1\n  Hongjiang     0 0 0 0 1 0\n  Huarong       0 0 0 1 0 0\n  Huayuan       0 0 0 1 0 0\n  Huitong       0 0 0 1 0 0\n  Jiahe         0 0 0 0 1 0\n  Jianghua      0 0 1 0 0 0\n  Jiangyong     0 1 0 0 0 0\n  Jingzhou      0 1 0 0 0 0\n  Jinshi        0 0 0 1 0 0\n  Jishou        0 0 0 0 0 1\n  Lanshan       0 0 0 1 0 0\n  Leiyang       0 0 0 1 0 0\n  Lengshuijiang 0 0 1 0 0 0\n  Li            0 0 1 0 0 0\n  Lianyuan      0 0 0 0 1 0\n  Liling        0 1 0 0 0 0\n  Linli         0 0 0 1 0 0\n  Linwu         0 0 0 1 0 0\n  Linxiang      1 0 0 0 0 0\n  Liuyang       0 1 0 0 0 0\n  Longhui       0 0 1 0 0 0\n  Longshan      0 1 0 0 0 0\n  Luxi          0 0 0 0 1 0\n  Mayang        0 0 0 0 0 1\n  Miluo         0 0 0 0 1 0\n  Nan           0 0 0 0 1 0\n  Ningxiang     0 0 0 1 0 0\n  Ningyuan      0 0 0 0 1 0\n  Pingjiang     0 1 0 0 0 0\n  Qidong        0 0 1 0 0 0\n  Qiyang        0 0 1 0 0 0\n  Rucheng       0 1 0 0 0 0\n  Sangzhi       0 1 0 0 0 0\n  Shaodong      0 0 0 0 1 0\n  Shaoshan      0 0 0 0 1 0\n  Shaoyang      0 0 0 1 0 0\n  Shimen        1 0 0 0 0 0\n  Shuangfeng    0 0 0 0 0 1\n  Shuangpai     0 0 0 1 0 0\n  Suining       0 0 0 0 1 0\n  Taojiang      0 1 0 0 0 0\n  Taoyuan       0 1 0 0 0 0\n  Tongdao       0 1 0 0 0 0\n  Wangcheng     0 0 0 1 0 0\n  Wugang        0 0 1 0 0 0\n  Xiangtan      0 0 0 1 0 0\n  Xiangxiang    0 0 0 0 1 0\n  Xiangyin      0 0 0 1 0 0\n  Xinhua        0 0 0 0 1 0\n  Xinhuang      1 0 0 0 0 0\n  Xinning       0 1 0 0 0 0\n  Xinshao       0 0 0 0 0 1\n  Xintian       0 0 0 0 1 0\n  Xupu          0 1 0 0 0 0\n  Yanling       0 0 1 0 0 0\n  Yizhang       1 0 0 0 0 0\n  Yongshun      0 0 0 1 0 0\n  Yongxing      0 0 0 1 0 0\n  You           0 0 0 1 0 0\n  Yuanjiang     0 0 0 0 1 0\n  Yuanling      1 0 0 0 0 0\n  Yueyang       0 0 1 0 0 0\n  Zhijiang      0 0 0 0 1 0\n  Zhongfang     0 0 0 1 0 0\n  Zhuzhou       0 0 0 0 1 0\n  Zixing        0 0 1 0 0 0\n\n\n\nn_comp &lt;- n.comp.nb(wm_d62)\nn_comp$nc\n\n[1] 1\n\n\n\ntable(n_comp$comp.id)\n\n\n 1 \n88 \n\n\n\n\nNext, we will plot the distance weight matrix by using the code chunk below.\n\nplot(hunan$geometry, border = \"lightgrey\")\nplot(wm_d62, coords, add = TRUE)\nplot(k1, coords, add = TRUE, col = \"red\", length = 0.08)\n\n\n\n\n\n\n\n\nThe red lines show the links of 1st nearest neighbours and the black lines show the links of neighbours within the cut-off distance of 62km.\nAlternatively, we can plot both of them next to each other by using the code chunk below.\n\npar(mfrow = c(1,2))\nplot(hunan$geometry, border = \"lightgrey\", main = \"1st nearest neighbours\")\nplot(k1, coords, add = TRUE, col = \"red\", length = 0.88)\nplot(hunan$geometry, border = \"lightgrey\", main = \"Distance link\")\nplot(wm_d62, coords, add = TRUE, pch = 19, cex = 0.6)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#overview",
    "title": "Hands-on Exercise 5b: Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "In this hands-on exercise, it will run through the process of computing spatial weights using R. By the end to this hands-on exercise, one should be able to:\n\nimport geospatial data using appropriate function(s) of sf package,\nimport csv file using appropriate function of readr package,\nperform relational join using appropriate join function of dplyr package,\ncompute spatial weights using appropriate functions of spdep package, and\ncalculate spatially lagged variables using appropriate functions of spdep package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#the-study-area-and-data",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#the-study-area-and-data",
    "title": "Hands-on Exercise 5b: Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "Two data sets will be used in this hands-on exercise, they are:\n\nHunan county boundary layer. This is a geospatial data set in ESRI shapefile format.\nHunan_2012.csv; This csv file contains selected Hunan’s local development indicators in 2012.\n\n\n\nBefore getting started, ensure that spdep, sf, tmap, tidyverse and knitrpackages of R are currently installed in R.\n\npacman::p_load(spdep, sf, tmap, tidyverse, knitr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#getting-the-data-into-the-r-environment",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#getting-the-data-into-the-r-environment",
    "title": "Hands-on Exercise 5b: Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "In this section, the geospatial data and its associated attribute table will be brought in R environment. The geospatial data is in ESRI shapefile format and the attribute table is in csv format.\n\n\nThe code chunk below uses st_read() of sf package to import Hunan shapefile into R. The imported shapefile will be a simple feature Object of sf.\n\nhunan &lt;- st_read(dsn = \"data/geospatial\",\n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex05\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n\nNext, Hunan_2012.csv will be imported into R by using read_csv() of readr package. The output is a R dataframe class.\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nThe code chunk below will be used to update the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 dataframe. This is performed by using left_join() of dplyr package.\nThe select() function is used to select variables that are objectively used for the spatial analysis.\n\nhunan &lt;- left_join(hunan, hunan2012) %&gt;%\n  select(1:4, 7, 15)\n\nJoining with `by = join_by(County)`"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#visualising-regional-development-indicator",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#visualising-regional-development-indicator",
    "title": "Hands-on Exercise 5b: Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "Now, a basemap and a choropleth map will be prepared showing the distribution of GDPPC 2012 by using qtm() of tmap package.\n\nbasemap &lt;- tm_shape(hunan) +\n  tm_polygons() +\n  tm_text(\"NAME_3\", size = 0.5)\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\ntmap_arrange(basemap, gdppc, asp = 1, ncol = 2)\n\n\n\n\n\n\n\n\n\nNote: Gross Domestic Product per Capita (GDPPC)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#computing-contiguity-spatial-weights",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#computing-contiguity-spatial-weights",
    "title": "Hands-on Exercise 5b: Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "In this section, we will learn how to use poly2nb() of spdep package to compute contiguity weight matrices for the study area.\nThis function builds a neighbours list based on regions with contiguous boundaries. From the documentation, we learn that we can pass a “queen” argument that takes TRUE or FALSE as options. If this argument is not specified the argument’s default is set to TRUE, that is, if we don’t specify queen = FALSE this function will return a list of first order neighbours using the Queen criteria.\n\n\nThe code chunk below is used to compute Queen contiguity weight matrix.\n\nwm_q &lt;- poly2nb(hunan, queen = TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report above shows that there are 88 area units (regions) in Hunan. The most connected area unit has 11 neighbours. There are two area units with only one neighbour.\nFor each polygon in the polygon object, wm_q lists all neighbouring polygons. For example, to see the neighbours for the first polygon in the object, type:\n\nwm_q[[1]]\n\n[1]  2  3  4 57 85\n\n\nPolygon 1 has 5 neighbours. The numbers represent the polygon IDs as stored in hunan SpatialPolygonsDataFrame class.\nWe can retrieve the county name of Polygon ID=1 by using the code chunk below:\n\nhunan$County[1]\n\n[1] \"Anxiang\"\n\n\nThe output reveals that Polygon ID=1 is Anxiang county.\nTo reveal the county names of the five neighbouring polygons, the code chunk will be used:\n\nhunan$NAME_3[c(2,3,4,57,85)]\n\n[1] \"Hanshou\" \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\"\n\n\nWe can retrieve the GDPPC of these five counties by using the code chunk below.\n\nnb1 &lt;- wm_q[[1]]\nnb1 &lt;- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\nThe printed output above shows that the GDPPC of the five nearest neighbours based on Queen’s method are 20981, 34592, 24473, 21311 and 22879 respectively.\nWe can display the complete weight matrix by using str().\n\nstr(wm_q)\n\nList of 88\n $ : int [1:5] 2 3 4 57 85\n $ : int [1:5] 1 57 58 78 85\n $ : int [1:4] 1 4 5 85\n $ : int [1:4] 1 3 5 6\n $ : int [1:4] 3 4 6 85\n $ : int [1:5] 4 5 69 75 85\n $ : int [1:4] 67 71 74 84\n $ : int [1:7] 9 46 47 56 78 80 86\n $ : int [1:6] 8 66 68 78 84 86\n $ : int [1:8] 16 17 19 20 22 70 72 73\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:3] 11 15 17\n $ : int [1:4] 13 14 17 83\n $ : int [1:5] 10 17 22 72 83\n $ : int [1:7] 10 11 14 15 16 72 83\n $ : int [1:5] 20 22 23 77 83\n $ : int [1:6] 10 20 21 73 74 86\n $ : int [1:7] 10 18 19 21 22 23 82\n $ : int [1:5] 19 20 35 82 86\n $ : int [1:5] 10 16 18 20 83\n $ : int [1:7] 18 20 38 41 77 79 82\n $ : int [1:5] 25 28 31 32 54\n $ : int [1:5] 24 28 31 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:3] 26 29 42\n $ : int [1:5] 24 25 33 49 54\n $ : int [1:3] 27 37 42\n $ : int 33\n $ : int [1:8] 24 25 32 36 39 40 56 81\n $ : int [1:8] 24 31 50 54 55 56 75 85\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 47 80 82 86\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:4] 29 42 43 44\n $ : int [1:4] 23 44 77 79\n $ : int [1:5] 31 40 42 43 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:7] 26 27 29 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:4] 37 38 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:3] 8 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:5] 32 48 52 54 55\n $ : int [1:3] 48 49 52\n $ : int [1:5] 48 49 50 51 54\n $ : int [1:3] 48 55 75\n $ : int [1:6] 24 28 32 49 50 52\n $ : int [1:5] 32 48 50 53 75\n $ : int [1:7] 8 31 32 36 78 80 85\n $ : int [1:6] 1 2 58 64 76 85\n $ : int [1:5] 2 57 68 76 78\n $ : int [1:4] 60 61 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:7] 12 59 60 62 63 77 87\n $ : int [1:3] 61 77 87\n $ : int [1:4] 12 61 77 83\n $ : int [1:2] 57 76\n $ : int 76\n $ : int [1:5] 9 67 68 76 84\n $ : int [1:4] 7 66 76 84\n $ : int [1:5] 9 58 66 76 78\n $ : int [1:3] 6 75 85\n $ : int [1:3] 10 72 73\n $ : int [1:3] 7 73 74\n $ : int [1:5] 10 11 16 17 70\n $ : int [1:5] 10 19 70 71 74\n $ : int [1:6] 7 19 71 73 84 86\n $ : int [1:6] 6 32 53 55 69 85\n $ : int [1:7] 57 58 64 65 66 67 68\n $ : int [1:7] 18 23 38 61 62 63 83\n $ : int [1:7] 2 8 9 56 58 68 85\n $ : int [1:7] 23 38 40 41 43 44 45\n $ : int [1:8] 8 34 35 36 41 45 47 56\n $ : int [1:6] 25 26 31 33 39 42\n $ : int [1:5] 20 21 23 35 41\n $ : int [1:9] 12 13 15 16 17 18 22 63 77\n $ : int [1:6] 7 9 66 67 74 86\n $ : int [1:11] 1 2 3 5 6 32 56 57 69 75 ...\n $ : int [1:9] 8 9 19 21 35 46 47 74 84\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language poly2nb(pl = hunan, queen = TRUE)\n - attr(*, \"type\")= chr \"queen\"\n - attr(*, \"sym\")= logi TRUE\n\n\n\n\n\n\n\n\nWarning\n\n\n\nBe warned: The output might cut across several pages. Do consider saving the trees if you are going to print out the report.\n\n\n\n\n\nleast connectedmost connected\n\n\n\nwm_q[[30]]\n\n[1] 33\n\nwm_q[[65]]\n\n[1] 76\n\n\n\n\n\nwm_q[[85]]\n\n [1]  1  2  3  5  6 32 56 57 69 75 78\n\n\n\nhunan$County[85]\n\n[1] \"Taoyuan\"\n\n\nTo reveal the county names of the eleven neighbouring polygons, the code chunk will be used:\n\nhunan$NAME_3[c(1,2,3,5,6,32,56,57,69,75,78)]\n\n [1] \"Anxiang\"  \"Hanshou\"  \"Jinshi\"   \"Linli\"    \"Shimen\"   \"Yuanling\"\n [7] \"Anhua\"    \"Nan\"      \"Cili\"     \"Sangzhi\"  \"Taojiang\"\n\n\nRevealing the GDPPC of there eleven counties by using the code chunk below.\n\nnb1 &lt;- wm_q[[85]]\nnb1 &lt;- hunan$GDPPC[nb1]\nnb1\n\n [1] 23667 20981 34592 25554 27137 24194 14567 21311 18714 14624 19509\n\n\n\n\n\n\n\n\n\nThe code chunk below is used to compute Rook contiguity weight matrix.\n\nwm_r &lt;- poly2nb(hunan, queen = FALSE)\nsummary(wm_r)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connected area unit has 10 neighbours. There are two area units with only one neighbours.\n\n\n\nA connectivity graph takes a point and displays a line to each neighbouring point. We are working with polygons at the moment, so we will need to get points in order to make our connectivity graphs. The most typically used method for this will be polygon centroids. We will calculate these in the sf package before moving onto the graphs. Getting Latitude and Longitude of Polygon Centroids\nWe will need points to associate with each polygon before we can make our connectivity graph. It will be a little more complicated than just running st_centroid on the sf object: us.bound. We need the coordinates in a separate data frame for this to work. To do this we will use a mapping function. The mapping function applies a given function to each element of a vector and returns a vector of the same length. Our input vector will be the geometry column of us.bound. Our function will be st_centroid. We will be using map_dbl variation of map from the purrr package. For more documentation, check out map documentation\nTo get our longitude values we map the st_centroid function over the geometry column of us.bound and access the longitude value through double bracket notation [[]] and 1. This allows us to get only the longitude, which is the first value in each centroid.\n\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\nWe can do the same for latitude with one key difference. We access the second value per each centroid with [[2]].\n\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\nNow that longitude and latitude is obtained, we use cbind to put longitude and latitude into the same object.\n\ncoords &lt;- cbind(longitude, latitude)\n\nUpon running the code chunk, we can check the first few observations to see if things are formatted correctly.\n\nhead(coords)\n\n     longitude latitude\n[1,]  112.1531 29.44362\n[2,]  112.0372 28.86489\n[3,]  111.8917 29.47107\n[4,]  111.7031 29.74499\n[5,]  111.6138 29.49258\n[6,]  111.0341 29.79863\n\n\n\n\n\nplot(hunan$geometry, border = \"lightgrey\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\n\n\n\n\n\n\n\n\n\n\n\n\nplot(hunan$geometry, border = \"lightgrey\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\n\n\n\n\n\n\n\n\n\n\n\n\npar(mfrow = c(1,2))\nplot(hunan$geometry, border = \"lightgrey\", main = \"Queen Contiguity\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\nplot(hunan$geometry, border = \"lightgrey\", main = \"Rook Contiguity\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#computing-distance-based-neighbours",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#computing-distance-based-neighbours",
    "title": "Hands-on Exercise 5b: Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "In this section, we will learn how to derive distance-based weight matrices by using dnearneigh() of spdep package.\nThe function identifies neighbours of region points by Euclidean distance with a distance band with lower d1= and upper d2= bounds controlled by the bounds = argument. If un-projected coordinates are used and either specified in the coordinates object x or with x as a two column matrix and = TRUE, great circle distances in km will be calculated assuming the WGS84 reference ellipsoid.\n\n\nFirstly, we need to determine the upper limit for distance band by using the steps below:\n\nReturn a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using knearneigh() of spdep.\nConvert the knn object returned by knearneigh() into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using knn2nb().\nReturn the length of neighbour relationship edges by using nbdists() of spdep. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise.\nRemove the list structure of the returned object by using unlist().\n\n\n#coords &lt;- coordinates(hunan)\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nThe summary report shows that the largest first nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour.\n\n\n\nNow, we will compute the distance weight matrix by using dnearneigh() as shown in the code chunk below.\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\n\nQuiz: What is the meaning of “Average number of links: 3.681818” shown above?\nInterpretation: An average of 3.681818 means that, on average, each point has about 3.68 neighbours within the specified distance band (0 to 62 km in this case). This gives a sense of the overall connectivity in the spatial network. A higher average number of links suggests that points are more densely connected, while a lower number suggests sparser connections.\n\nNext, we will use str() to display the content of wm_d62 weight matrix.\n\nstr(wm_d62)\n\nList of 88\n $ : int [1:5] 3 4 5 57 64\n $ : int [1:4] 57 58 78 85\n $ : int [1:4] 1 4 5 57\n $ : int [1:3] 1 3 5\n $ : int [1:4] 1 3 4 85\n $ : int 69\n $ : int [1:2] 67 84\n $ : int [1:4] 9 46 47 78\n $ : int [1:4] 8 46 68 84\n $ : int [1:4] 16 22 70 72\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:2] 11 17\n $ : int 13\n $ : int [1:4] 10 17 22 83\n $ : int [1:3] 11 14 16\n $ : int [1:3] 20 22 63\n $ : int [1:5] 20 21 73 74 82\n $ : int [1:5] 18 19 21 22 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:4] 10 16 18 20\n $ : int [1:3] 41 77 82\n $ : int [1:4] 25 28 31 54\n $ : int [1:4] 24 28 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:2] 26 29\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:2] 27 37\n $ : int 33\n $ : int [1:2] 24 36\n $ : int 50\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:5] 31 34 45 56 80\n $ : int [1:2] 29 42\n $ : int [1:3] 44 77 79\n $ : int [1:4] 40 42 43 81\n $ : int [1:3] 39 45 79\n $ : int [1:5] 23 35 45 79 82\n $ : int [1:5] 26 37 39 43 81\n $ : int [1:3] 39 42 44\n $ : int [1:2] 38 43\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:5] 8 9 35 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:4] 48 49 50 52\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:2] 48 55\n $ : int [1:5] 24 28 49 50 52\n $ : int [1:4] 48 50 53 75\n $ : int 36\n $ : int [1:5] 1 2 3 58 64\n $ : int [1:5] 2 57 64 66 68\n $ : int [1:3] 60 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:5] 12 60 62 63 87\n $ : int [1:4] 61 63 77 87\n $ : int [1:5] 12 18 61 62 83\n $ : int [1:4] 1 57 58 76\n $ : int 76\n $ : int [1:5] 58 67 68 76 84\n $ : int [1:2] 7 66\n $ : int [1:4] 9 58 66 84\n $ : int [1:2] 6 75\n $ : int [1:3] 10 72 73\n $ : int [1:2] 73 74\n $ : int [1:3] 10 11 70\n $ : int [1:4] 19 70 71 74\n $ : int [1:5] 19 21 71 73 86\n $ : int [1:2] 55 69\n $ : int [1:3] 64 65 66\n $ : int [1:3] 23 38 62\n $ : int [1:2] 2 8\n $ : int [1:4] 38 40 41 45\n $ : int [1:5] 34 35 36 45 47\n $ : int [1:5] 25 26 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:4] 12 13 16 63\n $ : int [1:4] 7 9 66 68\n $ : int [1:2] 2 5\n $ : int [1:4] 21 46 47 74\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language dnearneigh(x = coords, d1 = 0, d2 = 62, longlat = TRUE)\n - attr(*, \"dnn\")= num [1:2] 0 62\n - attr(*, \"bounds\")= chr [1:2] \"GE\" \"LE\"\n - attr(*, \"nbtype\")= chr \"distance\"\n - attr(*, \"sym\")= logi TRUE\n\n\nAnother way to display the structure of the weight matrix is to combine table() and card() of spdep.\n\ntable(hunan$County, card(wm_d62))\n\n               \n                1 2 3 4 5 6\n  Anhua         1 0 0 0 0 0\n  Anren         0 0 0 1 0 0\n  Anxiang       0 0 0 0 1 0\n  Baojing       0 0 0 0 1 0\n  Chaling       0 0 1 0 0 0\n  Changning     0 0 1 0 0 0\n  Changsha      0 0 0 1 0 0\n  Chengbu       0 1 0 0 0 0\n  Chenxi        0 0 0 1 0 0\n  Cili          0 1 0 0 0 0\n  Dao           0 0 0 1 0 0\n  Dongan        0 0 1 0 0 0\n  Dongkou       0 0 0 1 0 0\n  Fenghuang     0 0 0 1 0 0\n  Guidong       0 0 1 0 0 0\n  Guiyang       0 0 0 1 0 0\n  Guzhang       0 0 0 0 0 1\n  Hanshou       0 0 0 1 0 0\n  Hengdong      0 0 0 0 1 0\n  Hengnan       0 0 0 0 1 0\n  Hengshan      0 0 0 0 0 1\n  Hengyang      0 0 0 0 0 1\n  Hongjiang     0 0 0 0 1 0\n  Huarong       0 0 0 1 0 0\n  Huayuan       0 0 0 1 0 0\n  Huitong       0 0 0 1 0 0\n  Jiahe         0 0 0 0 1 0\n  Jianghua      0 0 1 0 0 0\n  Jiangyong     0 1 0 0 0 0\n  Jingzhou      0 1 0 0 0 0\n  Jinshi        0 0 0 1 0 0\n  Jishou        0 0 0 0 0 1\n  Lanshan       0 0 0 1 0 0\n  Leiyang       0 0 0 1 0 0\n  Lengshuijiang 0 0 1 0 0 0\n  Li            0 0 1 0 0 0\n  Lianyuan      0 0 0 0 1 0\n  Liling        0 1 0 0 0 0\n  Linli         0 0 0 1 0 0\n  Linwu         0 0 0 1 0 0\n  Linxiang      1 0 0 0 0 0\n  Liuyang       0 1 0 0 0 0\n  Longhui       0 0 1 0 0 0\n  Longshan      0 1 0 0 0 0\n  Luxi          0 0 0 0 1 0\n  Mayang        0 0 0 0 0 1\n  Miluo         0 0 0 0 1 0\n  Nan           0 0 0 0 1 0\n  Ningxiang     0 0 0 1 0 0\n  Ningyuan      0 0 0 0 1 0\n  Pingjiang     0 1 0 0 0 0\n  Qidong        0 0 1 0 0 0\n  Qiyang        0 0 1 0 0 0\n  Rucheng       0 1 0 0 0 0\n  Sangzhi       0 1 0 0 0 0\n  Shaodong      0 0 0 0 1 0\n  Shaoshan      0 0 0 0 1 0\n  Shaoyang      0 0 0 1 0 0\n  Shimen        1 0 0 0 0 0\n  Shuangfeng    0 0 0 0 0 1\n  Shuangpai     0 0 0 1 0 0\n  Suining       0 0 0 0 1 0\n  Taojiang      0 1 0 0 0 0\n  Taoyuan       0 1 0 0 0 0\n  Tongdao       0 1 0 0 0 0\n  Wangcheng     0 0 0 1 0 0\n  Wugang        0 0 1 0 0 0\n  Xiangtan      0 0 0 1 0 0\n  Xiangxiang    0 0 0 0 1 0\n  Xiangyin      0 0 0 1 0 0\n  Xinhua        0 0 0 0 1 0\n  Xinhuang      1 0 0 0 0 0\n  Xinning       0 1 0 0 0 0\n  Xinshao       0 0 0 0 0 1\n  Xintian       0 0 0 0 1 0\n  Xupu          0 1 0 0 0 0\n  Yanling       0 0 1 0 0 0\n  Yizhang       1 0 0 0 0 0\n  Yongshun      0 0 0 1 0 0\n  Yongxing      0 0 0 1 0 0\n  You           0 0 0 1 0 0\n  Yuanjiang     0 0 0 0 1 0\n  Yuanling      1 0 0 0 0 0\n  Yueyang       0 0 1 0 0 0\n  Zhijiang      0 0 0 0 1 0\n  Zhongfang     0 0 0 1 0 0\n  Zhuzhou       0 0 0 0 1 0\n  Zixing        0 0 1 0 0 0\n\n\n\nn_comp &lt;- n.comp.nb(wm_d62)\nn_comp$nc\n\n[1] 1\n\n\n\ntable(n_comp$comp.id)\n\n\n 1 \n88 \n\n\n\n\nNext, we will plot the distance weight matrix by using the code chunk below.\n\nplot(hunan$geometry, border = \"lightgrey\")\nplot(wm_d62, coords, add = TRUE)\nplot(k1, coords, add = TRUE, col = \"red\", length = 0.08)\n\n\n\n\n\n\n\n\nThe red lines show the links of 1st nearest neighbours and the black lines show the links of neighbours within the cut-off distance of 62km.\nAlternatively, we can plot both of them next to each other by using the code chunk below.\n\npar(mfrow = c(1,2))\nplot(hunan$geometry, border = \"lightgrey\", main = \"1st nearest neighbours\")\nplot(k1, coords, add = TRUE, col = \"red\", length = 0.88)\nplot(hunan$geometry, border = \"lightgrey\", main = \"Distance link\")\nplot(wm_d62, coords, add = TRUE, pch = 19, cex = 0.6)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html",
    "title": "Hands-on Exercise 5a: Spatial Weights and Applications",
    "section": "",
    "text": "In this hands-on exercise, you will learn how to compute Global Measures of Spatial Autocorrelation (GMSA) by using spdep package. By the end to this hands-on exercise, you will be able to:\n\nimport geospatial data using appropriate function(s) of sf package,\nimport csv file using appropriate function of readr package,\nperform relational join using appropriate join function of dplyr package,\ncompute Global Spatial Autocorrelation (GSA) statistics by using appropriate functions of spdep package,\n\nplot Moran scatterplot,\ncompute and plot spatial correlogram using appropriate function of spdep package.\n\nprovide statistically correct interpretation of GSA statistics."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#overview",
    "title": "Hands-on Exercise 5a: Spatial Weights and Applications",
    "section": "",
    "text": "In this hands-on exercise, you will learn how to compute Global Measures of Spatial Autocorrelation (GMSA) by using spdep package. By the end to this hands-on exercise, you will be able to:\n\nimport geospatial data using appropriate function(s) of sf package,\nimport csv file using appropriate function of readr package,\nperform relational join using appropriate join function of dplyr package,\ncompute Global Spatial Autocorrelation (GSA) statistics by using appropriate functions of spdep package,\n\nplot Moran scatterplot,\ncompute and plot spatial correlogram using appropriate function of spdep package.\n\nprovide statistically correct interpretation of GSA statistics."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#preparing-data",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#preparing-data",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Modelling",
    "section": "4 Preparing Data",
    "text": "4 Preparing Data\n\n4.1 Reading data file to rds\nThe code chunk below is used to read the input data sets. It is in simple feature data frame.\n\nmdata &lt;- read_rds(\"data/mdata.rds\")\n\n\n\n4.2 Data Sampling\nThe dataset is divided into training (65%) and testing (35%) subsets using the initial_split() function from the rsample package, part of the tidymodels suite in R. This split supports model training and evaluation while adhering to best practices for data analysis.\n\nset.seed(1234)\nresale_split &lt;- initial_split(mdata,\n                              prop = 6.5/10,)\ntrain_data &lt;- training(resale_split)\ntest_data &lt;- testing(resale_split)\n\nThe code chunk below is used to save the training and test data into rds format for ease of retrieval.\n\nwrite_rds(train_data, \"data/model/train_data.rds\")\nwrite_rds(test_data, \"data/model/test_data.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#computing-correlation-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#computing-correlation-matrix",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Modelling",
    "section": "5 Computing Correlation Matrix",
    "text": "5 Computing Correlation Matrix\nBefore loading predictors into a predictive model, it’s best practice to check for multicollinearity using a correlation matrix. This helps identify highly correlated predictors that could distort model accuracy.\n\nmdata_nogeo &lt;- mdata %&gt;%\n  st_drop_geometry()\ncorrplot::corrplot(cor(mdata_nogeo[, 2:17]),\n                   diag = FALSE,\n                   order = \"AOE\",\n                   tl.pos = \"td\",\n                   tl.cex = 0.5,\n                   method = \"number\",\n                   type = \"upper\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe correlation matrix above shows that all the correlation values are below 0.8. Hence, there is no sign of multicollinearity observed."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#retriving-the-stored-data",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#retriving-the-stored-data",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Modelling",
    "section": "6 Retriving the Stored Data",
    "text": "6 Retriving the Stored Data\nThe training and testing datasets that were stored earlier are now retrieved.\n\ntrain_data &lt;- read_rds(\"data/model/train_data.rds\")\ntest_data &lt;- read_rds(\"data/model/test_data.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#building-a-non-spatial-multiple-linear-regression",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#building-a-non-spatial-multiple-linear-regression",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Modelling",
    "section": "7 Building a non-spatial multiple linear regression",
    "text": "7 Building a non-spatial multiple linear regression\n\nprice_mlr &lt;- lm(resale_price ~ floor_area_sqm +\n                  storey_order + remaining_lease_mths +\n                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n                  PROX_MRT + PROX_PARK + PROX_MALL + \n                  PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                  WITHIN_1KM_PRISCH,\n                data = train_data)\nsummary(price_mlr)\n\n\nCall:\nlm(formula = resale_price ~ floor_area_sqm + storey_order + remaining_lease_mths + \n    PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRT + PROX_PARK + \n    PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN + \n    WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH, \n    data = train_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-205193  -39120   -1930   36545  472355 \n\nCoefficients:\n                           Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)              107601.073  10601.261  10.150  &lt; 2e-16 ***\nfloor_area_sqm             2780.698     90.579  30.699  &lt; 2e-16 ***\nstorey_order              14299.298    339.115  42.167  &lt; 2e-16 ***\nremaining_lease_mths        344.490      4.592  75.027  &lt; 2e-16 ***\nPROX_CBD                 -16930.196    201.254 -84.124  &lt; 2e-16 ***\nPROX_ELDERLYCARE         -14441.025    994.867 -14.516  &lt; 2e-16 ***\nPROX_HAWKER              -19265.648   1273.597 -15.127  &lt; 2e-16 ***\nPROX_MRT                 -32564.272   1744.232 -18.670  &lt; 2e-16 ***\nPROX_PARK                 -5712.625   1483.885  -3.850 0.000119 ***\nPROX_MALL                -14717.388   2007.818  -7.330 2.47e-13 ***\nPROX_SUPERMARKET         -26881.938   4189.624  -6.416 1.46e-10 ***\nWITHIN_350M_KINDERGARTEN   8520.472    632.812  13.464  &lt; 2e-16 ***\nWITHIN_350M_CHILDCARE     -4510.650    354.015 -12.741  &lt; 2e-16 ***\nWITHIN_350M_BUS             813.493    222.574   3.655 0.000259 ***\nWITHIN_1KM_PRISCH         -8010.834    491.512 -16.298  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 61650 on 10320 degrees of freedom\nMultiple R-squared:  0.7373,    Adjusted R-squared:  0.737 \nF-statistic:  2069 on 14 and 10320 DF,  p-value: &lt; 2.2e-16\n\n\nThe non-spatial multiple linear regression is then saved in rds file format for purposes of easy retrival when needed.\n\nwrite_rds(price_mlr, \"data/model/price_mlr.rds\" )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#gwr-predictive-method",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#gwr-predictive-method",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Modelling",
    "section": "8 gwr predictive method",
    "text": "8 gwr predictive method\nIn this section, we will learn how to calibrate a model to predict HDB resale prices by using the geographically weighted regression method of GWmodel package.\n\n8.1 Converting the training data from sf data.frame to SpatialPointDataFrame\n\ntrain_data_sp &lt;- as_Spatial(train_data)\ntrain_data_sp\n\nclass       : SpatialPointsDataFrame \nfeatures    : 10335 \nextent      : 11597.31, 42623.63, 28217.39, 48741.06  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 17\nnames       : resale_price, floor_area_sqm, storey_order, remaining_lease_mths,          PROX_CBD,     PROX_ELDERLYCARE,        PROX_HAWKER,           PROX_MRT,          PROX_PARK,   PROX_GOOD_PRISCH,        PROX_MALL,            PROX_CHAS,     PROX_SUPERMARKET, WITHIN_350M_KINDERGARTEN, WITHIN_350M_CHILDCARE, ... \nmin values  :       218000,             74,            1,                  555, 0.999393538715878, 1.98943787433087e-08, 0.0333358643817954, 0.0220407324774434, 0.0441643212802781, 0.0652540365486641,                0, 6.20621206270077e-09, 1.21715176356525e-07,                        0,                     0, ... \nmax values  :      1186888,            133,           17,                 1164,  19.6500691667807,     3.30163731686804,   2.86763031236184,   2.13060636038504,   2.41313695915468,   10.6223726149914, 2.27100643784442,    0.808332738794272,     1.57131703651196,                        7,                    20, ... \n\n\n\n\n8.2 Computing adaptive bandwidth for the training data\nNext, bw.gwr() of GWmodel package will be used to determine the optimal bandwidth to be used.\n\n\n\n\n\n\nNote\n\n\n\nThe code chunk below is used to determine the adaptive bandwidth. Additionally, CV method is used to determine the optimal bandwidth.\n\n\n\nbw_adaptive &lt;- bw.gwr(resale_price ~ floor_area_sqm +\n                  storey_order + remaining_lease_mths +\n                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n                  PROX_MRT + PROX_PARK + PROX_MALL + \n                  PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                  WITHIN_1KM_PRISCH,\n                  data = train_data_sp,\n                  approach = \"CV\",\n                  kernel = \"gaussian\",\n                  adaptive = TRUE,\n                  longlat = FALSE)\n\nTake a cup of tea and have a break, it will take a few minutes.\n          -----A kind suggestion from GWmodel development group\nAdaptive bandwidth: 6395 CV score: 3.60536e+13 \nAdaptive bandwidth: 3960 CV score: 3.320316e+13 \nAdaptive bandwidth: 2455 CV score: 2.928339e+13 \nAdaptive bandwidth: 1524 CV score: 2.550957e+13 \nAdaptive bandwidth: 950 CV score: 1.95632e+13 \nAdaptive bandwidth: 593 CV score: 1.58347e+13 \nAdaptive bandwidth: 375 CV score: 1.310042e+13 \nAdaptive bandwidth: 237 CV score: 1.113152e+13 \nAdaptive bandwidth: 155 CV score: 9.572037e+12 \nAdaptive bandwidth: 101 CV score: 8.457003e+12 \nAdaptive bandwidth: 71 CV score: 7.605058e+12 \nAdaptive bandwidth: 49 CV score: 6.965752e+12 \nAdaptive bandwidth: 38 CV score: 8.249935e+12 \nAdaptive bandwidth: 58 CV score: 7.275234e+12 \nAdaptive bandwidth: 45 CV score: 6.871439e+12 \nAdaptive bandwidth: 41 CV score: 6.7928e+12 \nAdaptive bandwidth: 40 CV score: 6.780447e+12 \nAdaptive bandwidth: 38 CV score: 8.249935e+12 \nAdaptive bandwidth: 40 CV score: 6.780447e+12 \n\n\nThe result above shows that 40 neighbour points will be the optimal bandwidth to be used if adaptive bandwidth is used for this data set.\nThe result is then saved as rds format as well.\n\nwrite_rds(bw_adaptive, \"data/model/bw_adaptive.rds\")\n\n\n\n8.3 Constructing the adaptive bandwidth gwr model\nThe code chunk below will call the saved bandwidth by using the code chunk below.\n\nbw_adaptive &lt;- read_rds(\"data/model/bw_adaptive.rds\")\n\nThe code chunk below is then used to calibrate the gwr-based hedonic pricing model by using adaptive bandwidth and Gaussian kernel as shown in the code chunk below.\n\n\n\n\n\n\nNote\n\n\n\nThe use of the same kernel and adaptive arguments in both bw.gwr() and gwr.basic() maintains consistency in the model’s weighting and spatial adaptiveness. The gaussian kernel ensures smooth distance-based weighting, while adaptive = TRUE adjusts the bandwidth to account for the varying density of spatial observations. This setup allows for a more accurate fit in geographically weighted regression (GWR), especially in heterogeneous spatial data, as it adapts locally to data point distribution.\n\n\n\ngwr_adaptive &lt;- gwr.basic(formula = resale_price ~\n                            floor_area_sqm + storey_order +\n                            remaining_lease_mths + PROX_CBD + \n                            PROX_ELDERLYCARE + PROX_HAWKER +\n                            PROX_MRT + PROX_PARK + PROX_MALL + \n                            PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                            WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                            WITHIN_1KM_PRISCH,\n                          data = train_data_sp,\n                          bw = bw_adaptive, \n                          kernel = 'gaussian', \n                          adaptive = TRUE,\n                          longlat = FALSE)\n\nThe code chunk below will be used to save the model in rds format for future use similar to the steps above to prevent having to re-run the code chunk above which can be time consuming.\n\nwrite_rds(gwr_adaptive, \"data/model/gwr_adaptive.rds\")\n\n\n\n8.4 Retrieving gwr output object\nThe code chunk below will be used to retrieve the saved gwr model object in the previous section.\n\ngwr_adaptive &lt;- read_rds(\"data/model/gwr_adaptive.rds\")\n\nThe code chunk below is used to display the model output.\n\ngwr_adaptive\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2024-10-31 16:12:22.509546 \n   Call:\n   gwr.basic(formula = resale_price ~ floor_area_sqm + storey_order + \n    remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + \n    PROX_MRT + PROX_PARK + PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN + \n    WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH, \n    data = train_data_sp, bw = bw_adaptive, kernel = \"gaussian\", \n    adaptive = TRUE, longlat = FALSE)\n\n   Dependent (y) variable:  resale_price\n   Independent variables:  floor_area_sqm storey_order remaining_lease_mths PROX_CBD PROX_ELDERLYCARE PROX_HAWKER PROX_MRT PROX_PARK PROX_MALL PROX_SUPERMARKET WITHIN_350M_KINDERGARTEN WITHIN_350M_CHILDCARE WITHIN_350M_BUS WITHIN_1KM_PRISCH\n   Number of data points: 10335\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n    Min      1Q  Median      3Q     Max \n-205193  -39120   -1930   36545  472355 \n\n   Coefficients:\n                              Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)              107601.073  10601.261  10.150  &lt; 2e-16 ***\n   floor_area_sqm             2780.698     90.579  30.699  &lt; 2e-16 ***\n   storey_order              14299.298    339.115  42.167  &lt; 2e-16 ***\n   remaining_lease_mths        344.490      4.592  75.027  &lt; 2e-16 ***\n   PROX_CBD                 -16930.196    201.254 -84.124  &lt; 2e-16 ***\n   PROX_ELDERLYCARE         -14441.025    994.867 -14.516  &lt; 2e-16 ***\n   PROX_HAWKER              -19265.648   1273.597 -15.127  &lt; 2e-16 ***\n   PROX_MRT                 -32564.272   1744.232 -18.670  &lt; 2e-16 ***\n   PROX_PARK                 -5712.625   1483.885  -3.850 0.000119 ***\n   PROX_MALL                -14717.388   2007.818  -7.330 2.47e-13 ***\n   PROX_SUPERMARKET         -26881.938   4189.624  -6.416 1.46e-10 ***\n   WITHIN_350M_KINDERGARTEN   8520.472    632.812  13.464  &lt; 2e-16 ***\n   WITHIN_350M_CHILDCARE     -4510.650    354.015 -12.741  &lt; 2e-16 ***\n   WITHIN_350M_BUS             813.493    222.574   3.655 0.000259 ***\n   WITHIN_1KM_PRISCH         -8010.834    491.512 -16.298  &lt; 2e-16 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 61650 on 10320 degrees of freedom\n   Multiple R-squared: 0.7373\n   Adjusted R-squared: 0.737 \n   F-statistic:  2069 on 14 and 10320 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 3.922202e+13\n   Sigma(hat): 61610.08\n   AIC:  257320.2\n   AICc:  257320.3\n   BIC:  247249\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Adaptive bandwidth: 40 (number of nearest neighbours)\n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                                   Min.     1st Qu.      Median     3rd Qu.\n   Intercept                -3.2478e+08 -4.7727e+05 -8.3004e+03  5.5025e+05\n   floor_area_sqm           -2.8714e+04  1.4475e+03  2.3011e+03  3.3900e+03\n   storey_order              3.3186e+03  8.5899e+03  1.0826e+04  1.3397e+04\n   remaining_lease_mths     -1.4431e+03  2.6063e+02  3.9048e+02  5.2865e+02\n   PROX_CBD                 -1.0837e+07 -5.7697e+04 -1.3787e+04  2.6552e+04\n   PROX_ELDERLYCARE         -3.2195e+07 -4.0643e+04  1.0562e+04  6.1054e+04\n   PROX_HAWKER              -2.3985e+08 -5.1365e+04  3.0026e+03  6.4287e+04\n   PROX_MRT                 -1.1632e+07 -1.0488e+05 -4.9373e+04  5.1037e+03\n   PROX_PARK                -6.5961e+06 -4.8671e+04 -8.8128e+02  5.3498e+04\n   PROX_MALL                -1.8112e+07 -7.4238e+04 -1.3982e+04  4.9779e+04\n   PROX_SUPERMARKET         -4.5761e+06 -6.3461e+04 -1.7429e+04  3.5616e+04\n   WITHIN_350M_KINDERGARTEN -4.1823e+05 -6.0040e+03  9.0209e+01  4.7127e+03\n   WITHIN_350M_CHILDCARE    -1.0273e+05 -2.2375e+03  2.6668e+02  2.6388e+03\n   WITHIN_350M_BUS          -1.1757e+05 -1.4719e+03  1.1626e+02  1.7584e+03\n   WITHIN_1KM_PRISCH        -6.6465e+05 -5.5959e+03  2.6916e+02  5.7500e+03\n                                  Max.\n   Intercept                1.6493e+08\n   floor_area_sqm           5.0907e+04\n   storey_order             2.9537e+04\n   remaining_lease_mths     1.8119e+03\n   PROX_CBD                 2.2411e+07\n   PROX_ELDERLYCARE         8.2444e+07\n   PROX_HAWKER              5.9654e+06\n   PROX_MRT                 2.0189e+08\n   PROX_PARK                1.5188e+07\n   PROX_MALL                1.0443e+07\n   PROX_SUPERMARKET         3.8330e+06\n   WITHIN_350M_KINDERGARTEN 6.6799e+05\n   WITHIN_350M_CHILDCARE    1.0802e+05\n   WITHIN_350M_BUS          3.7313e+04\n   WITHIN_1KM_PRISCH        5.0231e+05\n   ************************Diagnostic information*************************\n   Number of data points: 10335 \n   Effective number of parameters (2trace(S) - trace(S'S)): 1730.101 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 8604.899 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 238871.9 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 237036.9 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 238209.1 \n   Residual sum of squares: 4.829191e+12 \n   R-square value:  0.967657 \n   Adjusted R-square value:  0.9611534 \n\n   ***********************************************************************\n   Program stops at: 2024-10-31 16:13:26.230757 \n\n\n\n\n8.5 Converting the test data from sf data.frame to SpatialPointDataFrame\n\ntest_data_sp &lt;- test_data %&gt;%\n  as_Spatial()\ntest_data_sp\n\nclass       : SpatialPointsDataFrame \nfeatures    : 5566 \nextent      : 11597.31, 42623.63, 28287.8, 48669.59  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 17\nnames       : resale_price, floor_area_sqm, storey_order, remaining_lease_mths,         PROX_CBD,     PROX_ELDERLYCARE,        PROX_HAWKER,           PROX_MRT,          PROX_PARK,   PROX_GOOD_PRISCH,        PROX_MALL,            PROX_CHAS,     PROX_SUPERMARKET, WITHIN_350M_KINDERGARTEN, WITHIN_350M_CHILDCARE, ... \nmin values  :       230888,             74,            1,                  546, 1.00583660772922, 3.34897933104965e-07, 0.0474019664161957, 0.0414043955932523, 0.0502664084494264, 0.0907500295577619,                0, 4.55547870890763e-09, 1.21715176356525e-07,                        0,                     0, ... \nmax values  :      1050000,            138,           14,                 1151,  19.632402730488,     3.30163731686804,   2.83106651960209,   2.13060636038504,   2.41313695915468,   10.6169590126272, 2.26056404492346,     0.79249074802552,     1.53786629004208,                        7,                    16, ... \n\n\n\n\n8.6 Computing adaptive bandwidth for the test data\n\nbw_test_adaptive &lt;- bw.gwr(resale_price ~ floor_area_sqm +\n                  storey_order + remaining_lease_mths +\n                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n                  PROX_MRT + PROX_PARK + PROX_MALL + \n                  PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                  WITHIN_1KM_PRISCH,\n                  data = test_data_sp,\n                  approach = \"CV\",\n                  kernel = \"gaussian\",\n                  adaptive = TRUE,\n                  longlat = FALSE)\n\nTake a cup of tea and have a break, it will take a few minutes.\n          -----A kind suggestion from GWmodel development group\nAdaptive bandwidth: 3447 CV score: 1.902155e+13 \nAdaptive bandwidth: 2138 CV score: 1.752645e+13 \nAdaptive bandwidth: 1328 CV score: 1.556299e+13 \nAdaptive bandwidth: 828 CV score: 1.357498e+13 \nAdaptive bandwidth: 518 CV score: 1.030751e+13 \nAdaptive bandwidth: 327 CV score: 8.348364e+12 \nAdaptive bandwidth: 208 CV score: 6.860544e+12 \nAdaptive bandwidth: 135 CV score: 5.969504e+12 \nAdaptive bandwidth: 89 CV score: 5.242221e+12 \nAdaptive bandwidth: 62 CV score: 4.742767e+12 \nAdaptive bandwidth: 43 CV score: 4.357839e+12 \nAdaptive bandwidth: 34 CV score: 4.125848e+12 \nAdaptive bandwidth: 25 CV score: 4.04299e+12 \nAdaptive bandwidth: 23 CV score: 1.549626e+13 \nAdaptive bandwidth: 30 CV score: 4.074906e+12 \nAdaptive bandwidth: 25 CV score: 4.04299e+12 \n\n\nThe results above indicates that an adaptive bandwidth of 25 nearest neighbors yields the lowest cross-validation (CV) score of (4.04299e+12), making it the optimal bandwidth for this test dataset when using adaptive bandwidth selection. This value suggests that 25 nearby data points provide the best balance between model fit and generalization for the geographic weighting applied in this test data’s GWR model.\nThe result is then saved as rds format as well.\n\nwrite_rds(bw_test_adaptive, \"data/model/bw_test_adaptive.rds\")\n\nThe code chunk below will call the saved bandwidth by using the code chunk below.\n\nbw_test_adaptive &lt;- read_rds(\"data/model/bw_test_adaptive.rds\")\n\n\n\n8.7 Computing predicted values of the test data\n\ngwr_pred &lt;- gwr.predict(formula = resale_price ~\n                          floor_area_sqm + storey_order +\n                          remaining_lease_mths + PROX_CBD + \n                          PROX_ELDERLYCARE + PROX_HAWKER + \n                          PROX_MRT + PROX_PARK + PROX_MALL + \n                          PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                          WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + \n                          WITHIN_1KM_PRISCH, \n                        data = train_data_sp, \n                        predictdata = test_data_sp, \n                        bw = 40, \n                        kernel = 'gaussian', \n                        adaptive = TRUE, \n                        longlat = FALSE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#preparing-coordinates-data",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#preparing-coordinates-data",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Modelling",
    "section": "9 Preparing coordinates data",
    "text": "9 Preparing coordinates data\n\n9.1 Extracting coordinates data\nThe code chunk below extracts the x,y coordinates from the full, training and test data sets respectively.\n\ncoords &lt;- st_coordinates(mdata)\ncoords_train &lt;- st_coordinates(train_data)\ncoords_test &lt;- st_coordinates(test_data)\n\nBefore moving on, we will write all the output into rds for future usage.\n\ncoords_train &lt;- write_rds(coords_train, \"data/model/coords_train.rds\" )\ncoords_test &lt;- write_rds(coords_test, \"data/model/coords_test.rds\" )\n\n\n\n9.2 Dropping geometry field\nWe will drop the geometry column of the sf data.frame by using st_drop_geometry() of sf package.\n\ntrain_data &lt;- train_data %&gt;% \n  st_drop_geometry()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#calibrating-random-forest-model",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#calibrating-random-forest-model",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Modelling",
    "section": "10 Calibrating Random Forest Model",
    "text": "10 Calibrating Random Forest Model\nIn this section, it will calibrate a model to predict HDB resale price by using random forest function of ranger package.\n\nset.seed(1234)\n\nrf &lt;- ranger(resale_price ~ floor_area_sqm + storey_order + \n               remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE + \n               PROX_HAWKER + PROX_MRT + PROX_PARK + PROX_MALL + \n               PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n               WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + \n               WITHIN_1KM_PRISCH,\n             data = train_data)\nrf\n\nRanger result\n\nCall:\n ranger(resale_price ~ floor_area_sqm + storey_order + remaining_lease_mths +      PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRT + PROX_PARK +      PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +      WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH,      data = train_data) \n\nType:                             Regression \nNumber of trees:                  500 \nSample size:                      10335 \nNumber of independent variables:  14 \nMtry:                             3 \nTarget node size:                 5 \nVariable importance mode:         none \nSplitrule:                        variance \nOOB prediction error (MSE):       728602496 \nR squared (OOB):                  0.9495728 \n\n\nThe output is saved into rds for future usage.\n\nwrite_rds(rf, \"data/model/rf.rds\")\n\n\nrf &lt;- read_rds(\"data/model/rf.rds\")\nrf\n\nRanger result\n\nCall:\n ranger(resale_price ~ floor_area_sqm + storey_order + remaining_lease_mths +      PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRT + PROX_PARK +      PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +      WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH,      data = train_data) \n\nType:                             Regression \nNumber of trees:                  500 \nSample size:                      10335 \nNumber of independent variables:  14 \nMtry:                             3 \nTarget node size:                 5 \nVariable importance mode:         none \nSplitrule:                        variance \nOOB prediction error (MSE):       728602496 \nR squared (OOB):                  0.9495728"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#calibrating-geographical-random-forest-model",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#calibrating-geographical-random-forest-model",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Modelling",
    "section": "11 Calibrating Geographical Random Forest Model",
    "text": "11 Calibrating Geographical Random Forest Model\nIn this section, the steps involved illustrate how to calibrate a model to predict HDB resale price by using grf() of SpatialML package.\n\n11.1 Calibrating using training data\nThe code chunk below calibrates a geographic random forest model by using grf() of SpatialML package.\n\nset.seed(1234)\n\ngwRF_adaptive &lt;- grf(formula = resale_price ~ floor_area_sqm + storey_order +\n                       remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE +\n                       PROX_HAWKER + PROX_MRT + PROX_PARK + PROX_MALL +\n                       PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                       WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                       WITHIN_1KM_PRISCH,\n                     dframe = train_data, \n                     bw = 55,\n                     kernel = \"adaptive\",\n                     coords = coords_train)\n\n\nNumber of Observations: 10335\n\n\nNumber of Independent Variables: 14\n\n\nKernel: Adaptive\nNeightbours: 55\n\n\n\n--------------- Global ML Model Summary ---------------\n\n\nRanger result\n\nCall:\n ranger(resale_price ~ floor_area_sqm + storey_order + remaining_lease_mths +      PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRT + PROX_PARK +      PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +      WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH,      data = train_data, num.trees = 500, mtry = 4, importance = \"impurity\",      num.threads = NULL) \n\nType:                             Regression \nNumber of trees:                  500 \nSample size:                      10335 \nNumber of independent variables:  14 \nMtry:                             4 \nTarget node size:                 5 \nVariable importance mode:         impurity \nSplitrule:                        variance \nOOB prediction error (MSE):       700081018 \nR squared (OOB):                  0.9515468 \n\n\n\nImportance:\n\n\n          floor_area_sqm             storey_order     remaining_lease_mths \n            7.376510e+12             1.413229e+13             2.991844e+13 \n                PROX_CBD         PROX_ELDERLYCARE              PROX_HAWKER \n            5.312697e+13             7.017513e+12             5.506719e+12 \n                PROX_MRT                PROX_PARK                PROX_MALL \n            7.446857e+12             4.825986e+12             4.173165e+12 \n        PROX_SUPERMARKET WITHIN_350M_KINDERGARTEN    WITHIN_350M_CHILDCARE \n            2.879598e+12             1.028775e+12             1.701318e+12 \n         WITHIN_350M_BUS        WITHIN_1KM_PRISCH \n            1.564038e+12             7.214027e+12 \n\n\n\nMean Square Error (Not OOB): 173279991.32\n\n\nR-squared (Not OOB) %: 98.801\n\n\nAIC (Not OOB): 196089.283\n\n\nAICc (Not OOB): 196089.33\n\n\n\n--------------- Local Model Summary ---------------\n\n\n\nResiduals OOB:\n\n\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n-236112.0  -13033.7     444.4     593.8   14831.5  358041.7 \n\n\n\nResiduals Predicted (Not OOB):\n\n\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n-79279.83  -3510.70     54.56     50.98   3909.85  83074.08 \n\n\n\nLocal Variable Importance:\n\n\n                               Min          Max        Mean         StD\nfloor_area_sqm                   0 401562922035 18210850992 41426270899\nstorey_order             302736445 243728744368 16368419468 23620589843\nremaining_lease_mths     696564138 546463600727 34119912443 70328183398\nPROX_CBD                  55173040 382484896335 12154563393 29293290548\nPROX_ELDERLYCARE          45182031 344081962746 10597657883 24546405941\nPROX_HAWKER               43516026 342597797419 10551807020 23408387903\nPROX_MRT                  54234551 299075025906  9873129985 21055852211\nPROX_PARK                 49919822 322633843469  9353956995 19517077658\nPROX_MALL                 43296133 433263607933 11247374493 27537334970\nPROX_SUPERMARKET          52665827 417310417234 10802122271 26572460731\nWITHIN_350M_KINDERGARTEN         0 186468064682  2848177740 12928886968\nWITHIN_350M_CHILDCARE            0 255236737234  5526292324 18109971102\nWITHIN_350M_BUS                  0 193828795378  4747552546 11886064288\nWITHIN_1KM_PRISCH                0 178360608427  1778262602  7163381668\n\n\n\nMean squared error (OOB): 930426169.333\n\n\nR-squared (OOB) %: 93.56\n\n\nAIC (OOB): 213459.669\n\n\nAICc (OOB): 213459.716\n\n\nMean squared error Predicted (Not OOB): 73859413.696\n\n\nR-squared Predicted (Not OOB) %: 99.489\n\n\nAIC Predicted (Not OOB): 187276.161\n\n\nAICc Predicted (Not OOB): 187276.208\n\n\n\nCalculation time (in seconds): 4.5763\n\n\nSaving the model output by using the code chunk below.\n\nwrite_rds(gwRF_adaptive, \"data/model/gwRF_adaptive.rds\")\n\nThe code chunk below can then be used to retrieve the saved model in future.\n\ngwRF_adaptive &lt;- read_rds(\"data/model/gwRF_adaptive.rds\")\n\n\n\n11.2 Predicting by using test data\n\n11.2.1 Preparing the test data\nThe code chunk below is used to combine the test data with its corresponding coordinates data; alongside dropping of the geometry.\n\ntest_data &lt;- cbind(test_data, coords_test) %&gt;%\n  st_drop_geometry()\n\n\n\n11.2.2 Predicting with test data\nNext, predict.grf() of spatialML package will be used to predict the resale value of HDB flats by using the test data and gwRF_adaptive model calibrated earlier.\n\ngwRF_pred &lt;- predict.grf(gwRF_adaptive, \n                           test_data, \n                           x.var.name = \"X\",\n                           y.var.name = \"Y\", \n                           local.w = 1,\n                           global.w = 0)\n\nThe output is saved into rds file for future use.\n\nGRF_pred &lt;- write_rds(gwRF_pred, \"data/model/GRF_pred.rds\")\n\n\n\n11.2.3 Converting the predicting output into a data frame\nThe output of the predict.grf() is a vector of predicted values. It is advisable to convert it into a data frame for further visualisation and analysis.\nThe output is first saved as an rds file before being converted into a data frame from the code chunk below.\n\nGRF_pred &lt;- read_rds(\"data/model/GRF_pred.rds\")\nGRF_pred_df &lt;- as.data.frame(GRF_pred)\n\nIn the code chunk below, cbind() is used to append the predicted values onto the test_data.\n\ntest_data_p &lt;- cbind(test_data, GRF_pred_df)\n\n\nwrite_rds(test_data_p, \"data/model/test_data_p.rds\")\n\n\n\n\n11.3 Calculating Root Mean Square Error\nThe calculation of root mean square error (RMSE) will allow us to measure how far predicted values are from observed values in a regression analysis. In the code chunk below, rmse() of Metrics package is used to compute the RMSE.\n\nrmse(test_data_p$resale_price, \n     test_data_p$GRF_pred)\n\n[1] 27302.9\n\n\n\n\n11.4 Visualising the predicted values\nAlternatively, a scatter plot can be used to visualise the actual resale price and the predicted resale price by using the code chunk below.\n\nggplot(data = test_data_p,\n       aes(x = GRF_pred,\n           y = resale_price)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nA better predictive model should have the scatter point close to the diagonal line. The scatter plot can be also used to detect if any outliers in the model."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10a.html",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10a.html",
    "title": "Hands-on Exercise 10a: Processing and Visualising Flow Data",
    "section": "",
    "text": "Spatial interaction describes the movement of people, materials, or information between geographical locations. It includes a range of flows—from freight and energy distribution to global trade, flight schedules, and pedestrian traffic. Each interaction can be represented as an origin-destination pair in a matrix, where rows and columns represent the centroids of the origin and destination locations, respectively. This type of matrix is typically referred to as an origin-destination or spatial interaction matrix.\nIn this hands-on exercise, we will learn how to build an OD matrix by using Passenger Volume by Origin Destination Bus Stops data set downloaded from LTA DataMall. By the end of this hands-on exercise, we will be able:\n\nto import and extract OD data for a selected time interval,\nto import and save geospatial data (i.e. bus stops and mpsz) into sf tibble data frame objects,\nto populate planning subzone code into bus stops sf tibble data frame,\nto construct desire lines geospatial data from the OD data, and\nto visualise passenger volume by origin and destination bus stops by using the desired lines data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10a.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10a.html#overview",
    "title": "Hands-on Exercise 10a: Processing and Visualising Flow Data",
    "section": "",
    "text": "Spatial interaction describes the movement of people, materials, or information between geographical locations. It includes a range of flows—from freight and energy distribution to global trade, flight schedules, and pedestrian traffic. Each interaction can be represented as an origin-destination pair in a matrix, where rows and columns represent the centroids of the origin and destination locations, respectively. This type of matrix is typically referred to as an origin-destination or spatial interaction matrix.\nIn this hands-on exercise, we will learn how to build an OD matrix by using Passenger Volume by Origin Destination Bus Stops data set downloaded from LTA DataMall. By the end of this hands-on exercise, we will be able:\n\nto import and extract OD data for a selected time interval,\nto import and save geospatial data (i.e. bus stops and mpsz) into sf tibble data frame objects,\nto populate planning subzone code into bus stops sf tibble data frame,\nto construct desire lines geospatial data from the OD data, and\nto visualise passenger volume by origin and destination bus stops by using the desired lines data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10a.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10a.html#getting-started",
    "title": "Hands-on Exercise 10a: Processing and Visualising Flow Data",
    "section": "2 Getting Started",
    "text": "2 Getting Started\nFor the purpose of this exercise, five r packages will be used. They are:\n\nsf for importing, integrating, processing and transforming geospatial data.\ntidyverse for importing, integrating, wrangling and visualising data.\ntmap for creating elegent and cartographic quality thematic maps.\nstplanr provides functions for solving common problems in transport planning and modelling such as downloading and cleaning transport datasets; creating geographic “desire lines” from origin-destination (OD) data; route assignment, locally and interfaces to routing services such as CycleStreets.net; calculation of route segment attributes such as bearing and aggregate flow; and ‘travel watershed’ analysis.\nDT provides an R interface to the JavaScript library DataTables. R data objects (matrices or data frames) can be displayed as tables on HTML pages, and DataTables provides filtering, pagination, sorting, and many other features in the tables.\n\n\npacman::p_load(tmap, sf, DT, stplanr, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10a.html#preparing-the-flow-data",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10a.html#preparing-the-flow-data",
    "title": "Hands-on Exercise 10a: Processing and Visualising Flow Data",
    "section": "3 Preparing the Flow Data",
    "text": "3 Preparing the Flow Data\n\n3.1 Importing the OD data\nFirstly, we will import the Passenger Volume by Origin Destination Bus Stops data set from LTA DataMall by using read_csv() of readr package.\n\nodbus &lt;- read_csv(\"data/aspatial/origin_destination_bus_202210.csv\")\n\nRows: 5122925 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): YEAR_MONTH, DAY_TYPE, PT_TYPE\ndbl (4): TIME_PER_HOUR, ORIGIN_PT_CODE, DESTINATION_PT_CODE, TOTAL_TRIPS\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nodbus tibble data table is displayed by using the code chunk below.\n\nglimpse(odbus)\n\nRows: 5,122,925\nColumns: 7\n$ YEAR_MONTH          &lt;chr&gt; \"2022-10\", \"2022-10\", \"2022-10\", \"2022-10\", \"2022-…\n$ DAY_TYPE            &lt;chr&gt; \"WEEKDAY\", \"WEEKENDS/HOLIDAY\", \"WEEKENDS/HOLIDAY\",…\n$ TIME_PER_HOUR       &lt;dbl&gt; 10, 10, 7, 11, 16, 16, 20, 7, 7, 11, 11, 8, 11, 11…\n$ PT_TYPE             &lt;chr&gt; \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"…\n$ ORIGIN_PT_CODE      &lt;dbl&gt; 65239, 65239, 23519, 52509, 54349, 54349, 43371, 8…\n$ DESTINATION_PT_CODE &lt;dbl&gt; 65159, 65159, 23311, 42041, 53241, 53241, 14139, 9…\n$ TOTAL_TRIPS         &lt;dbl&gt; 2, 1, 2, 1, 1, 4, 1, 3, 1, 5, 2, 5, 15, 40, 1, 1, …\n\n\nA quick inspection of the odbus tibble shows that the values in ORIGIN_PT_CODE and DESTINATION_PT_CODE are stored as numeric data. The following code converts these values to character data type for consistency.\n\nodbus$ORIGIN_PT_CODE &lt;- as.factor(odbus$ORIGIN_PT_CODE)\nodbus$DESTINATION_PT_CODE &lt;- as.factor(odbus$DESTINATION_PT_CODE) \n\n\n\n3.2 Extracting the study data\nFor this hands on exercise, we will extract commuting flows on weekdays for timeslots between 6 and 9 o’clock (AM).\n\nodbus6_9 &lt;- odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 6 &\n           TIME_PER_HOUR &lt;= 9) %&gt;%\n  group_by(ORIGIN_PT_CODE,\n           DESTINATION_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\n`summarise()` has grouped output by 'ORIGIN_PT_CODE'. You can override using\nthe `.groups` argument.\n\n\nTable below shows the content of odbus6_9\n\ndatatable(odbus6_9)\n\nWarning in instance$preRenderHook(instance): It seems your data is too big for\nclient-side DataTables. You may consider server-side processing:\nhttps://rstudio.github.io/DT/server.html\n\n\n\n\n\n\nWe will save the output in rds format for easy retrieval and future usage when needed without the need to repeat the steps above.\n\nwrite_rds(odbus6_9, \"data/rds/odbus6_9.rds\")\n\nThe code chunk below will be used to import the saved odbus6_9.rds from R environment.\n\nodbus6_9 &lt;- read_rds(\"data/rds/odbus6_9.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10a.html#working-with-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10a.html#working-with-geospatial-data",
    "title": "Hands-on Exercise 10a: Processing and Visualising Flow Data",
    "section": "4 Working with Geospatial Data",
    "text": "4 Working with Geospatial Data\nFor the purpose of this exercise, two geospatial datasets will be used. They are:\n\nBusStop: This data provides the location of bus stop as of last quarter of 2022.\nMPSZ-2019: This data provides the sub-zone boundary of URA Master Plan 2019.\n\nBoth data sets are in ESRI shapefile format.\n\n4.1 Importing geospatial data\nThe code chunks below are used to import the datasets and update them with correct ESPG code (i.e. 3414):\n\nbusstop &lt;- st_read(dsn = \"data/geospatial\",\n                   layer = \"BusStop\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `BusStop' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex10\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 5159 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48284.56 ymax: 52983.82\nProjected CRS: SVY21\n\nbusstop\n\nSimple feature collection with 5159 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48284.56 ymax: 52983.82\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n   BUS_STOP_N BUS_ROOF_N             LOC_DESC                  geometry\n1       22069        B06   OPP CEVA LOGISTICS POINT (13576.31 32883.65)\n2       32071        B23         AFT TRACK 13 POINT (13228.59 44206.38)\n3       44331        B01              BLK 239  POINT (21045.1 40242.08)\n4       96081        B05 GRACE INDEPENDENT CH POINT (41603.76 35413.11)\n5       11561        B05              BLK 166 POINT (24568.74 30391.85)\n6       66191        B03         AFT CORFE PL POINT (30951.58 38079.61)\n7       23389       B02A              PEC LTD   POINT (12476.9 32211.6)\n8       54411        B02              BLK 527 POINT (30329.45 39373.92)\n9       28531        B09              BLK 536 POINT (14993.31 36905.61)\n10      96139        B01              BLK 148  POINT (41642.81 36513.9)\n\n\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\",\n                   layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex10\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\nmpsz\n\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n                 SUBZONE_N SUBZONE_C       PLN_AREA_N PLN_AREA_C       REGION_N\n1              MARINA EAST    MESZ01      MARINA EAST         ME CENTRAL REGION\n2         INSTITUTION HILL    RVSZ05     RIVER VALLEY         RV CENTRAL REGION\n3           ROBERTSON QUAY    SRSZ01  SINGAPORE RIVER         SR CENTRAL REGION\n4  JURONG ISLAND AND BUKOM    WISZ01  WESTERN ISLANDS         WI    WEST REGION\n5             FORT CANNING    MUSZ02           MUSEUM         MU CENTRAL REGION\n6         MARINA EAST (MP)    MPSZ05    MARINE PARADE         MP CENTRAL REGION\n7                   SUDONG    WISZ03  WESTERN ISLANDS         WI    WEST REGION\n8                  SEMAKAU    WISZ02  WESTERN ISLANDS         WI    WEST REGION\n9           SOUTHERN GROUP    SISZ02 SOUTHERN ISLANDS         SI CENTRAL REGION\n10                 SENTOSA    SISZ01 SOUTHERN ISLANDS         SI CENTRAL REGION\n   REGION_C                       geometry\n1        CR MULTIPOLYGON (((33222.98 29...\n2        CR MULTIPOLYGON (((28481.45 30...\n3        CR MULTIPOLYGON (((28087.34 30...\n4        WR MULTIPOLYGON (((14557.7 304...\n5        CR MULTIPOLYGON (((29542.53 31...\n6        CR MULTIPOLYGON (((35279.55 30...\n7        WR MULTIPOLYGON (((15772.59 21...\n8        WR MULTIPOLYGON (((19843.41 21...\n9        CR MULTIPOLYGON (((30870.53 22...\n10       CR MULTIPOLYGON (((26879.04 26...\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nst_read() function of sf package is used to import the shapefile into R as a sf data frame.\nst_transform() function of sf package is used to transform the projection to crs 3414.\n\n\n\nSimilar to the section ### Extracting the study data the code chunk below will be used to write mpsz sf tibble data frame into an rds file for future usage.\n\nmpsz &lt;- write_rds(mpsz, \"data/rds/mpsz.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10a.html#geospatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10a.html#geospatial-data-wrangling",
    "title": "Hands-on Exercise 10a: Processing and Visualising Flow Data",
    "section": "5 Geospatial data wrangling",
    "text": "5 Geospatial data wrangling\n\n5.1 Combining Busstop and mpsz\nThe code chunk below transfers the planning subzone code (SUBZONE_C) from the mpsz sf data frame to the busstop sf data frame.\n\nbusstop_mpsz &lt;- st_intersection(busstop, mpsz) %&gt;%\n  select(BUS_STOP_N, SUBZONE_C) %&gt;%\n  st_drop_geometry()\n\nWarning: attribute variables are assumed to be spatially constant throughout\nall geometries\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nst_intersection() is used to perform point and polygon overlay and the output will be in point sf object.\nselect() of dplyr package is then used to retain only BUS_STOP_N and SUBZONE_C in the busstop_mpsz sf data frame.\nfive bus stops are excluded in the resultant data frame because they are outside of the Singapore boundary.\n\n\n\n\ndatatable(busstop_mpsz)\n\n\n\n\n\nBefore moving to the next step, we will save the output into rds format.\n\nwrite_rds(busstop_mpsz, \"data/rds/busstop_mpsz.rds\")  \n\nNext step is to append the planning subzone code from busstop_mpsz data frame onto odbus6_9 data frame.\n\nod_data &lt;- left_join(odbus6_9 , busstop_mpsz,\n            by = c(\"ORIGIN_PT_CODE\" = \"BUS_STOP_N\")) %&gt;%\n  rename(ORIGIN_BS = ORIGIN_PT_CODE,\n         ORIGIN_SZ = SUBZONE_C,\n         DESTIN_BS = DESTINATION_PT_CODE)\n\nWarning in left_join(odbus6_9, busstop_mpsz, by = c(ORIGIN_PT_CODE = \"BUS_STOP_N\")): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 55491 of `x` matches multiple rows in `y`.\nℹ Row 161 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\nBefore continuing a good practice is to check for duplicated records:\n\nduplicate &lt;- od_data %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\n\nIf there are duplicate records, the code chunk below will be used to retain only the unique records.\n\nod_data &lt;- unique(od_data)\n\nIt is also a good practice to confirm if the duplicated records issue has been addressed fully.\n\nanyDuplicated(od_data)\n\n[1] 0\n\n\nNext, we will update od_data data frame with the planning subzone codes.\n\nod_data &lt;- left_join(od_data , busstop_mpsz,\n            by = c(\"DESTIN_BS\" = \"BUS_STOP_N\")) \n\nWarning in left_join(od_data, busstop_mpsz, by = c(DESTIN_BS = \"BUS_STOP_N\")): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 74 of `x` matches multiple rows in `y`.\nℹ Row 1379 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\n\nduplicate &lt;- od_data %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\n\n\nod_data &lt;- unique(od_data)\n\n\nod_data &lt;- od_data %&gt;%\n  rename(DESTIN_SZ = SUBZONE_C) %&gt;%\n  drop_na() %&gt;%\n  group_by(ORIGIN_SZ, DESTIN_SZ) %&gt;%\n  summarise(MORNING_PEAK = sum(TRIPS))\n\n`summarise()` has grouped output by 'ORIGIN_SZ'. You can override using the\n`.groups` argument.\n\n\nCode chunk below to save the output into an rds file format.\n\nwrite_rds(od_data, \"data/rds/od_data_fii.rds\")\n\n\nod_data_fii &lt;- read_rds(\"data/rds/od_data.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10a.html#visualising-spatial-interaction",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10a.html#visualising-spatial-interaction",
    "title": "Hands-on Exercise 10a: Processing and Visualising Flow Data",
    "section": "6 Visualising Spatial Interaction",
    "text": "6 Visualising Spatial Interaction\nIn this section, we will learn how to prepare a desire line by using stplanr package.\n\n6.1 Removing intra-zonal flows\nWe will not plot the intra-zonal flows. The code chunk below will be used to remove intra-zonal flows. Afterwards the output will be saved as rds file format.\n\nod_data_fij &lt;- od_data[od_data$ORIGIN_SZ!=od_data$DESTIN_SZ,]\n\n\nwrite_rds(od_data_fij, \"data/rds/od_data_fij.rds\")\n\n\nod_data_fij &lt;- read_rds(\"data/rds/od_data_fij.rds\")\n\n\n\n6.2 Creating desire lines\nIn this code chunk below, od2line() of stplanr package is used to create the desire lines.\n\nflowLine &lt;- od2line(flow = od_data_fij, \n                    zones = mpsz,\n                    zone_code = \"SUBZONE_C\")\n\nCreating centroids representing desire line start and end points.\n\n\n\nwrite_rds(flowLine, \"data/rds/flowLine.rds\")\n\n\nflowLine &lt;- read_rds(\"data/rds/flowLine.rds\")\n\n\n\n6.3 Visualising the desire lines\nTo visualise the result of the desire lines, the code chunk below is used:\n\ntm_shape(mpsz) +\n  tm_polygons() +\nflowLine %&gt;%  \ntm_shape() +\n  tm_lines(lwd = \"MORNING_PEAK\",\n           style = \"quantile\",\n           scale = c(0.1, 1, 3, 5, 7, 10),\n           n = 6,\n           alpha = 0.3)\n\nWarning in g$scale * (x/maxW): longer object length is not a multiple of\nshorter object length\n\n\nLegend labels were too wide. Therefore, legend.text.size has been set to 0.66. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe rendering process takes more time because of the transparency argument (i.e. alpha)\n\n\nWhen flow data is particularly messy and highly skewed, as seen above, it’s often more effective to focus on selected flows, such as those greater than or equal to 5000, as shown below.\n\ntm_shape(mpsz) +\n  tm_polygons() +\nflowLine %&gt;%  \n  filter(MORNING_PEAK &gt;= 5000) %&gt;%\ntm_shape() +\n  tm_lines(lwd = \"MORNING_PEAK\",\n           style = \"quantile\",\n           scale = c(0.1, 1, 3, 5, 7, 10),\n           n = 6,\n           alpha = 0.5)\n\nWarning in g$scale * (x/maxW): longer object length is not a multiple of\nshorter object length\n\n\nLegend labels were too wide. Therefore, legend.text.size has been set to 0.66. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10b.html",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10b.html",
    "title": "Hands-on Exercise 10b: Calibrating Spatial Interaction Models with R",
    "section": "",
    "text": "Spatial Interaction Models (SIMs), developed by Alan Wilson in the late 1960s and early 1970s, are mathematical models designed to estimate flows between spatial entities. Since their inception, these models have been widely applied and refined, especially for transport modelling (Boyce and Williams, 2015).\nThere are four primary types of traditional SIMs (Wilson, 1971):\n\nUnconstrained\nProduction-constrained\nAttraction-constrained\nDoubly-constrained\n\nOrdinary Least Squares (OLS), log-normal, Poisson, and negative binomial (NB) regression methods are commonly used to calibrate Origin-Destination (OD) flow models by treating flow data as different types of dependent variables. This chapter provides hands-on practice with these methods using relevant R packages to calibrate Spatial Interaction Models (SIMs).\n\n\n\n\n\n\nNote\n\n\n\nCalibration involves adjusting model parameters to align estimated results with observed data as closely as possible. This iterative process, ideal for computers, uses goodness-of-fit statistics to identify an optimal solution. Historically, calibration required researchers to code algorithms that iteratively adjusted each parameter, assessed the fit, and repeated until the best fit was achieved (Adam Dennett, 2018)."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10b.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10b.html#overview",
    "title": "Hands-on Exercise 10b: Calibrating Spatial Interaction Models with R",
    "section": "",
    "text": "Spatial Interaction Models (SIMs), developed by Alan Wilson in the late 1960s and early 1970s, are mathematical models designed to estimate flows between spatial entities. Since their inception, these models have been widely applied and refined, especially for transport modelling (Boyce and Williams, 2015).\nThere are four primary types of traditional SIMs (Wilson, 1971):\n\nUnconstrained\nProduction-constrained\nAttraction-constrained\nDoubly-constrained\n\nOrdinary Least Squares (OLS), log-normal, Poisson, and negative binomial (NB) regression methods are commonly used to calibrate Origin-Destination (OD) flow models by treating flow data as different types of dependent variables. This chapter provides hands-on practice with these methods using relevant R packages to calibrate Spatial Interaction Models (SIMs).\n\n\n\n\n\n\nNote\n\n\n\nCalibration involves adjusting model parameters to align estimated results with observed data as closely as possible. This iterative process, ideal for computers, uses goodness-of-fit statistics to identify an optimal solution. Historically, calibration required researchers to code algorithms that iteratively adjusted each parameter, assessed the fit, and repeated until the best fit was achieved (Adam Dennett, 2018)."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10b.html#the-case-study-and-data",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10b.html#the-case-study-and-data",
    "title": "Hands-on Exercise 10b: Calibrating Spatial Interaction Models with R",
    "section": "2 The Case Study and Data",
    "text": "2 The Case Study and Data\nIn this exercise, we will calibrate a Spatial Interaction Model (SIM) to identify key factors influencing public bus passenger flows during the morning peak hours in Singapore."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10b.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10b.html#getting-started",
    "title": "Hands-on Exercise 10b: Calibrating Spatial Interaction Models with R",
    "section": "3 Getting Started",
    "text": "3 Getting Started\nFor the purpose of this exercise, four r packages will be used. They are:\n\nsf for importing, integrating, processing and transforming geospatial data.\ntidyverse for importing, integrating, wrangling and visualising data.\ntmap for creating thematic maps.\n\n\npacman::p_load(tmap, sf, sp,\n               performance, reshape2,\n               ggpubr, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10b.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10b.html#the-data",
    "title": "Hands-on Exercise 10b: Calibrating Spatial Interaction Models with R",
    "section": "4 The Data",
    "text": "4 The Data\nThis exercise is a continuation of Hands-on Ex10a: Processing and Visualising Flow Data and the following data will be used:\n\nod_data.rds, weekday morning peak passenger flows at planning subzone level.\nmpsz.rds, URA Master Plan 2019 Planning Subzone boundary in simple feature tibble data frame format.\n\nBeside these two data sets, an additional attribute data file called pop.csv will be provided. It"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10b.html#computing-distance-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10b.html#computing-distance-matrix",
    "title": "Hands-on Exercise 10b: Calibrating Spatial Interaction Models with R",
    "section": "5 Computing Distance Matrix",
    "text": "5 Computing Distance Matrix\nIn spatial interaction, a distance matrix is a table that shows the distance between pairs of locations. For example, in the table below we can see an Euclidean distance of 3926.0025 between MESZ01 and RVSZ05, of 3939.1079 between MESZ01 and SRSZ01, and so on. By definition, an location’s distance from itself, which is shown in the main diagonal of the table, is 0.\n\nIn this section, we’ll learn how to compute a distance matrix using the URA Master Plan 2019 Planning Subzone boundaries, saved as an RDS file named mpsz.\nTo begin, import mpsz.rds into the R environment with the code chunk below.\n\nmpsz &lt;- read_rds(\"data/rds/mpsz.rds\")\nmpsz\n\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n                 SUBZONE_N SUBZONE_C       PLN_AREA_N PLN_AREA_C       REGION_N\n1              MARINA EAST    MESZ01      MARINA EAST         ME CENTRAL REGION\n2         INSTITUTION HILL    RVSZ05     RIVER VALLEY         RV CENTRAL REGION\n3           ROBERTSON QUAY    SRSZ01  SINGAPORE RIVER         SR CENTRAL REGION\n4  JURONG ISLAND AND BUKOM    WISZ01  WESTERN ISLANDS         WI    WEST REGION\n5             FORT CANNING    MUSZ02           MUSEUM         MU CENTRAL REGION\n6         MARINA EAST (MP)    MPSZ05    MARINE PARADE         MP CENTRAL REGION\n7                   SUDONG    WISZ03  WESTERN ISLANDS         WI    WEST REGION\n8                  SEMAKAU    WISZ02  WESTERN ISLANDS         WI    WEST REGION\n9           SOUTHERN GROUP    SISZ02 SOUTHERN ISLANDS         SI CENTRAL REGION\n10                 SENTOSA    SISZ01 SOUTHERN ISLANDS         SI CENTRAL REGION\n   REGION_C                       geometry\n1        CR MULTIPOLYGON (((33222.98 29...\n2        CR MULTIPOLYGON (((28481.45 30...\n3        CR MULTIPOLYGON (((28087.34 30...\n4        WR MULTIPOLYGON (((14557.7 304...\n5        CR MULTIPOLYGON (((29542.53 31...\n6        CR MULTIPOLYGON (((35279.55 30...\n7        WR MULTIPOLYGON (((15772.59 21...\n8        WR MULTIPOLYGON (((19843.41 21...\n9        CR MULTIPOLYGON (((30870.53 22...\n10       CR MULTIPOLYGON (((26879.04 26...\n\n\nNotice that it is a sf tibble dataframe object class.\n\n5.1 Converting from sf data.table to SpatialPolygonsDataFrame\nThere are two main methods for computing the distance matrix: one using sf and the other using sp. Based on past experience, the sf method tends to be slower, especially for large datasets. Therefore, the sp method is used in the code chunks below for greater efficiency.\nFirst as.Spatial() will be used to convert mpsz from sf tibble data frame to SpatialPolygonsDataFrame of sp object as shown in the code chunk below.\n\nmpsz_sp &lt;- as(mpsz, \"Spatial\")\nmpsz_sp\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 332 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 6\nnames       : SUBZONE_N, SUBZONE_C, PLN_AREA_N, PLN_AREA_C,       REGION_N, REGION_C \nmin values  : ADMIRALTY,    AMSZ01, ANG MO KIO,         AM, CENTRAL REGION,       CR \nmax values  :    YUNNAN,    YSSZ09,     YISHUN,         YS,    WEST REGION,       WR \n\n\n\n\n5.2 Computing the distance matrix\nNext, spDists() of sp package will be used to compute the Euclidean distance between the centroids of the planning subzones.\n\n\n\n\n\n\nQ&A\n\n\n\nDo you know why the distance is calculated between two centroids of a pair of spatial polygons?\n\n5.3 Ans\nThe distance between centroids of spatial polygons is often calculated to represent the average distance between two areas in a simplified, computationally efficient way. Centroids provide a single reference point per polygon, allowing for straightforward distance comparisons without the complexity of measuring every possible point-to-point distance within the polygons. This approach is particularly useful in models and analyses where approximate distances are sufficient, such as in origin-destination or spatial interaction matrices.\n\n\n\n\ndist &lt;- spDists(mpsz_sp, \n                longlat = FALSE)\n\n\nhead(dist, n = c(10, 10))\n\n           [,1]       [,2]      [,3]      [,4]       [,5]      [,6]      [,7]\n [1,]     0.000  3926.0025  3939.108 20252.964  2989.9839  1431.330 19211.836\n [2,]  3926.003     0.0000   305.737 16513.865   951.8314  5254.066 16242.523\n [3,]  3939.108   305.7370     0.000 16412.062  1045.9088  5299.849 16026.146\n [4,] 20252.964 16513.8648 16412.062     0.000 17450.3044 21665.795  7229.017\n [5,]  2989.984   951.8314  1045.909 17450.304     0.0000  4303.232 17020.916\n [6,]  1431.330  5254.0664  5299.849 21665.795  4303.2323     0.000 20617.082\n [7,] 19211.836 16242.5230 16026.146  7229.017 17020.9161 20617.082     0.000\n [8,] 14960.942 12749.4101 12477.871 11284.279 13336.0421 16281.453  5606.082\n [9,]  7515.256  7934.8082  7649.776 18427.503  7801.6163  8403.896 14810.930\n[10,]  6391.342  4975.0021  4669.295 15469.566  5226.8731  7707.091 13111.391\n           [,8]      [,9]     [,10]\n [1,] 14960.942  7515.256  6391.342\n [2,] 12749.410  7934.808  4975.002\n [3,] 12477.871  7649.776  4669.295\n [4,] 11284.279 18427.503 15469.566\n [5,] 13336.042  7801.616  5226.873\n [6,] 16281.453  8403.896  7707.091\n [7,]  5606.082 14810.930 13111.391\n [8,]     0.000  9472.024  8575.490\n [9,]  9472.024     0.000  3780.800\n[10,]  8575.490  3780.800     0.000\n\n\nNotice from the output dist is a matrix object class of R. The column headers and row headers are not labelled with the planning subzone codes as well.\n\n\n5.4 Labelling column and row heanders of a distance matrix\nFirst, to create a list sorted according to the the distance matrix by planning sub-zone code.\n\nsz_names &lt;- mpsz$SUBZONE_C\n\nNext to attach SUBZONE_C to row and column for distance matrix matching ahead with the code chunk below:\n\ncolnames(dist) &lt;- paste0(sz_names)\nrownames(dist) &lt;- paste0(sz_names)\n\n\n\n5.5 Pivoting distance value by SUBZONE_C\nThe next step is to pivot the distance matrix into a long table format, using the subzone codes from the rows and columns as identifiers, as demonstrated in the code chunk below.\n\ndistPair &lt;- melt(dist) %&gt;%\n  rename(dist = value)\nhead(distPair, 10)\n\n     Var1   Var2      dist\n1  MESZ01 MESZ01     0.000\n2  RVSZ05 MESZ01  3926.003\n3  SRSZ01 MESZ01  3939.108\n4  WISZ01 MESZ01 20252.964\n5  MUSZ02 MESZ01  2989.984\n6  MPSZ05 MESZ01  1431.330\n7  WISZ03 MESZ01 19211.836\n8  WISZ02 MESZ01 14960.942\n9  SISZ02 MESZ01  7515.256\n10 SISZ01 MESZ01  6391.342\n\n\nNotice that the within zone distance is 0.\n\n\n5.6 Updating intra-zonal distances\nIn this section, a constant value will be added to replace intra-zonal distances of 0. First, the minimum distance value will be identified using the summary() function.\n\ndistPair %&gt;%\n  filter(dist &gt; 0) %&gt;%\n  summary()\n\n      Var1             Var2             dist        \n MESZ01 :   331   MESZ01 :   331   Min.   :  173.8  \n RVSZ05 :   331   RVSZ05 :   331   1st Qu.: 7149.5  \n SRSZ01 :   331   SRSZ01 :   331   Median :11890.0  \n WISZ01 :   331   WISZ01 :   331   Mean   :12229.4  \n MUSZ02 :   331   MUSZ02 :   331   3rd Qu.:16401.7  \n MPSZ05 :   331   MPSZ05 :   331   Max.   :49894.4  \n (Other):107906   (Other):107906                    \n\n\nNext, a constant distance value of 50metres is added into intra-zones distance.\n\ndistPair$dist &lt;- ifelse(distPair$dist == 0,\n                        50, distPair$dist)\n\nThe code chunk below will be used to check the result of the data.frame.\n\ndistPair %&gt;%\n  summary()\n\n      Var1             Var2             dist      \n MESZ01 :   332   MESZ01 :   332   Min.   :   50  \n RVSZ05 :   332   RVSZ05 :   332   1st Qu.: 7097  \n SRSZ01 :   332   SRSZ01 :   332   Median :11864  \n WISZ01 :   332   WISZ01 :   332   Mean   :12193  \n MUSZ02 :   332   MUSZ02 :   332   3rd Qu.:16388  \n MPSZ05 :   332   MPSZ05 :   332   Max.   :49894  \n (Other):108232   (Other):108232                  \n\n\nThe code chunk below is used to rename the origin and destination fields.\n\ndistPair &lt;- distPair %&gt;%\n  rename(orig = Var1,\n         dest = Var2)\n\nLastly, the code chunk below is used to save the dataframe for future use.\n\nwrite_rds(distPair, \"data/rds/distPair.rds\") \n\n\ndistPair &lt;- read_rds(\"data/rds/distPair.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10b.html#preparing-flow-data",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10b.html#preparing-flow-data",
    "title": "Hands-on Exercise 10b: Calibrating Spatial Interaction Models with R",
    "section": "6 Preparing flow data",
    "text": "6 Preparing flow data\nThe code chunk below is used to import od_data which was saved in hands-on exercise 10a into R environment.\n\nod_data_fii &lt;- read_rds(\"data/rds/od_data_fii.rds\")\n\nNext, the total passenger trips between and within planning subzones will be calculated using the code chunk below, producing the output dataset flow_data.\n\nflow_data &lt;- od_data_fii %&gt;%\n  group_by(ORIGIN_SZ, DESTIN_SZ) %&gt;% \n  summarize(TRIPS = sum(MORNING_PEAK)) \n\n`summarise()` has grouped output by 'ORIGIN_SZ'. You can override using the\n`.groups` argument.\n\n\nUsing the code chunk below to display flow_data dataframe.\n\nhead(flow_data, 10)\n\n# A tibble: 10 × 3\n# Groups:   ORIGIN_SZ [1]\n   ORIGIN_SZ DESTIN_SZ TRIPS\n   &lt;chr&gt;     &lt;chr&gt;     &lt;dbl&gt;\n 1 AMSZ01    AMSZ01     1998\n 2 AMSZ01    AMSZ02     8289\n 3 AMSZ01    AMSZ03     8971\n 4 AMSZ01    AMSZ04     2252\n 5 AMSZ01    AMSZ05     6136\n 6 AMSZ01    AMSZ06     2148\n 7 AMSZ01    AMSZ07     1620\n 8 AMSZ01    AMSZ08     1925\n 9 AMSZ01    AMSZ09     1773\n10 AMSZ01    AMSZ10       63\n\n\n\n6.1 Separating intra-flow from passenger volume df\nCode chunk below is used to add three new fields in flow_data dataframe.\n\nflow_data$FlowNoIntra &lt;- ifelse(\n  flow_data$ORIGIN_SZ == flow_data$DESTIN_SZ, \n  0, flow_data$TRIPS)\nflow_data$offset &lt;- ifelse(\n  flow_data$ORIGIN_SZ == flow_data$DESTIN_SZ, \n  0.000001, 1)\n\n\n\n6.2 Combining passenger volume data with distance value\nBefore joining flow_data and distPair, the data types of the ORIGIN_SZ and DESTIN_SZ fields in the flow_data dataframe must be converted to factors.\n\nflow_data$ORIGIN_SZ &lt;- as.factor(flow_data$ORIGIN_SZ)\nflow_data$DESTIN_SZ &lt;- as.factor(flow_data$DESTIN_SZ)\n\nThe left_join() function from dplyr will be applied to merge the flow_data dataframe with the distPair dataframe, creating the output dataframe flow_data1.\n\nflow_data1 &lt;- flow_data %&gt;%\n  left_join (distPair,\n             by = c(\"ORIGIN_SZ\" = \"orig\",\n                    \"DESTIN_SZ\" = \"dest\"))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10b.html#preparing-origin-and-destination-attributes",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10b.html#preparing-origin-and-destination-attributes",
    "title": "Hands-on Exercise 10b: Calibrating Spatial Interaction Models with R",
    "section": "7 Preparing Origin and Destination Attributes",
    "text": "7 Preparing Origin and Destination Attributes\n\n7.1 Importing population data\n\npop &lt;- read_csv(\"data/aspatial/pop.csv\")\n\nRows: 332 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): PA, SZ\ndbl (3): AGE7_12, AGE13_24, AGE25_64\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n7.2 Geospatial data wrangling\n\npop &lt;- pop %&gt;%\n  left_join(mpsz,\n            by = c(\"PA\" = \"PLN_AREA_N\",\n                   \"SZ\" = \"SUBZONE_N\")) %&gt;%\n  select(1:6) %&gt;%\n  rename(SZ_NAME = SZ,\n         SZ = SUBZONE_C)\n\n\n\n7.3 Preparing origin attribute\n\nflow_data1 &lt;- flow_data1 %&gt;%\n  left_join(pop,\n            by = c(ORIGIN_SZ = \"SZ\")) %&gt;%\n  rename(ORIGIN_AGE7_12 = AGE7_12,\n         ORIGIN_AGE13_24 = AGE13_24,\n         ORIGIN_AGE25_64 = AGE25_64) %&gt;%\n  select(-c(PA, SZ_NAME))\n\n\n\n7.4 Preparing destination attribute\n\nflow_data1 &lt;- flow_data1 %&gt;%\n  left_join(pop,\n            by = c(DESTIN_SZ = \"SZ\")) %&gt;%\n  rename(DESTIN_AGE7_12 = AGE7_12,\n         DESTIN_AGE13_24 = AGE13_24,\n         DESTIN_AGE25_64 = AGE25_64) %&gt;%\n  select(-c(PA, SZ_NAME))\n\nWe will call the output data file as SIM_data. it is in rds data file format.\n\nwrite_rds(flow_data1, \"data/rds/SIM_data.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10b.html#calibrating-spatial-interaction-models",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10b.html#calibrating-spatial-interaction-models",
    "title": "Hands-on Exercise 10b: Calibrating Spatial Interaction Models with R",
    "section": "8 Calibrating Spatial Interaction Models",
    "text": "8 Calibrating Spatial Interaction Models\nThis section covers the calibration of Spatial Interaction Models using the Poisson Regression method.\n\n8.1 Importing the modelling data\nFirstly, let us import the modelling data by using the code chunk below.\n\nSIM_data &lt;- read_rds(\"data/rds/SIM_data.rds\")\n\n\n\n8.2 Visualising the dependent variable\nFirst, the distribution of the dependent variable (i.e., TRIPS) will be visualized using a histogram, as shown in the code chunk below.\n\nggplot(data = SIM_data,\n       aes(x = TRIPS)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nThe distribution of the dependent variable, TRIPS, is highly skewed and does not follow a normal (bell-shaped) distribution. Next, the relationship between the dependent variable and a key independent variable in Spatial Interaction Models—distance—will be visualized.\n\nggplot(data = SIM_data,\n       aes(x = dist,\n           y = TRIPS)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nThe relationship between the two variables does not appear linear in the original scatter plot. However, when both variables are log-transformed, their relationship more closely resembles a linear pattern.\n\nggplot(data = SIM_data,\n       aes(x = log(dist),\n           y = log(TRIPS))) +\n  geom_point() +\n  geom_smooth(method = lm)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n8.3 Checking for variables with zero values\nSince Poisson Regression operates on log-transformed values and log(0) is undefined, it is essential to ensure no 0 values are present in the explanatory variables. In the code chunk below, the summary() function from Base R is used to compute summary statistics for all variables in the SIM_data dataframe.\n\nsummary(SIM_data)\n\n  ORIGIN_SZ          DESTIN_SZ             TRIPS         FlowNoIntra      \n Length:14734       Length:14734       Min.   :     1   Min.   :     0.0  \n Class :character   Class :character   1st Qu.:    14   1st Qu.:    13.0  \n Mode  :character   Mode  :character   Median :    76   Median :    70.0  \n                                       Mean   :  1021   Mean   :   839.9  \n                                       3rd Qu.:   426   3rd Qu.:   379.0  \n                                       Max.   :232187   Max.   :148274.0  \n     offset              dist       ORIGIN_AGE7_12 ORIGIN_AGE13_24\n Min.   :0.000001   Min.   :   50   Min.   :   0   Min.   :    0  \n 1st Qu.:1.000000   1st Qu.: 3346   1st Qu.: 240   1st Qu.:  440  \n Median :1.000000   Median : 6067   Median : 700   Median : 1350  \n Mean   :0.982150   Mean   : 6880   Mean   :1032   Mean   : 2269  \n 3rd Qu.:1.000000   3rd Qu.: 9729   3rd Qu.:1480   3rd Qu.: 3260  \n Max.   :1.000000   Max.   :26136   Max.   :6340   Max.   :16380  \n ORIGIN_AGE25_64 DESTIN_AGE7_12 DESTIN_AGE13_24 DESTIN_AGE25_64\n Min.   :    0   Min.   :   0   Min.   :    0   Min.   :    0  \n 1st Qu.: 2200   1st Qu.: 240   1st Qu.:  460   1st Qu.: 2200  \n Median : 6810   Median : 720   Median : 1420   Median : 7030  \n Mean   :10487   Mean   :1033   Mean   : 2290   Mean   :10574  \n 3rd Qu.:15770   3rd Qu.:1500   3rd Qu.: 3260   3rd Qu.:15830  \n Max.   :74610   Max.   :6340   Max.   :16380   Max.   :74610  \n\n\nThe print report above reveals that variables ORIGIN_AGE7_12, ORIGIN_AGE13_24, ORIGIN_AGE25_64,DESTIN_AGE7_12, DESTIN_AGE13_24, DESTIN_AGE25_64 consist of 0 values.\nIn view of this, code chunk below will be used to replace zero values to 0.99.\n\nSIM_data$DESTIN_AGE7_12 &lt;- ifelse(\n  SIM_data$DESTIN_AGE7_12 == 0,\n  0.99, SIM_data$DESTIN_AGE7_12)\nSIM_data$DESTIN_AGE13_24 &lt;- ifelse(\n  SIM_data$DESTIN_AGE13_24 == 0,\n  0.99, SIM_data$DESTIN_AGE13_24)\nSIM_data$DESTIN_AGE25_64 &lt;- ifelse(\n  SIM_data$DESTIN_AGE25_64 == 0,\n  0.99, SIM_data$DESTIN_AGE25_64)\nSIM_data$ORIGIN_AGE7_12 &lt;- ifelse(\n  SIM_data$ORIGIN_AGE7_12 == 0,\n  0.99, SIM_data$ORIGIN_AGE7_12)\nSIM_data$ORIGIN_AGE13_24 &lt;- ifelse(\n  SIM_data$ORIGIN_AGE13_24 == 0,\n  0.99, SIM_data$ORIGIN_AGE13_24)\nSIM_data$ORIGIN_AGE25_64 &lt;- ifelse(\n  SIM_data$ORIGIN_AGE25_64 == 0,\n  0.99, SIM_data$ORIGIN_AGE25_64)\n\nRe-run the summary() again.\n\nsummary(SIM_data)\n\n  ORIGIN_SZ          DESTIN_SZ             TRIPS         FlowNoIntra      \n Length:14734       Length:14734       Min.   :     1   Min.   :     0.0  \n Class :character   Class :character   1st Qu.:    14   1st Qu.:    13.0  \n Mode  :character   Mode  :character   Median :    76   Median :    70.0  \n                                       Mean   :  1021   Mean   :   839.9  \n                                       3rd Qu.:   426   3rd Qu.:   379.0  \n                                       Max.   :232187   Max.   :148274.0  \n     offset              dist       ORIGIN_AGE7_12    ORIGIN_AGE13_24   \n Min.   :0.000001   Min.   :   50   Min.   :   0.99   Min.   :    0.99  \n 1st Qu.:1.000000   1st Qu.: 3346   1st Qu.: 240.00   1st Qu.:  440.00  \n Median :1.000000   Median : 6067   Median : 700.00   Median : 1350.00  \n Mean   :0.982150   Mean   : 6880   Mean   :1031.86   Mean   : 2268.84  \n 3rd Qu.:1.000000   3rd Qu.: 9729   3rd Qu.:1480.00   3rd Qu.: 3260.00  \n Max.   :1.000000   Max.   :26136   Max.   :6340.00   Max.   :16380.00  \n ORIGIN_AGE25_64    DESTIN_AGE7_12    DESTIN_AGE13_24    DESTIN_AGE25_64   \n Min.   :    0.99   Min.   :   0.99   Min.   :    0.99   Min.   :    0.99  \n 1st Qu.: 2200.00   1st Qu.: 240.00   1st Qu.:  460.00   1st Qu.: 2200.00  \n Median : 6810.00   Median : 720.00   Median : 1420.00   Median : 7030.00  \n Mean   :10487.62   Mean   :1033.40   Mean   : 2290.35   Mean   :10574.46  \n 3rd Qu.:15770.00   3rd Qu.:1500.00   3rd Qu.: 3260.00   3rd Qu.:15830.00  \n Max.   :74610.00   Max.   :6340.00   Max.   :16380.00   Max.   :74610.00  \n\n\nNotice that all the 0 values have been replaced by 0.99.\n\n\n8.4 Unconstrained Spatial Interaction Model\nIn this section, the process of calibrating an unconstrained spatial interaction model using glm() from Base R’s Stats package is demonstrated. The explanatory variables include the origin population by age cohort, the destination population by age cohort (e.g., ORIGIN_AGE25_64), and the distance between origin and destination in kilometers (e.g., dist).\nThe general formula for an Unconstrained Spatial Interaction Model is outlined below.\n\nThe code chunk used to calibrate to model is shown below:\n\nuncSIM &lt;- glm(formula = TRIPS ~ \n                log(ORIGIN_AGE25_64) + \n                log(DESTIN_AGE25_64) +\n                log(dist),\n              family = poisson(link = \"log\"),\n              data = SIM_data,\n              na.action = na.exclude)\nuncSIM\n\n\nCall:  glm(formula = TRIPS ~ log(ORIGIN_AGE25_64) + log(DESTIN_AGE25_64) + \n    log(dist), family = poisson(link = \"log\"), data = SIM_data, \n    na.action = na.exclude)\n\nCoefficients:\n         (Intercept)  log(ORIGIN_AGE25_64)  log(DESTIN_AGE25_64)  \n           10.407308              0.244859              0.009562  \n           log(dist)  \n           -0.705896  \n\nDegrees of Freedom: 14733 Total (i.e. Null);  14730 Residual\nNull Deviance:      60800000 \nResidual Deviance: 36430000     AIC: 36520000\n\n\n\n\n8.5 R-squared function\nIn order to measure how much variation of the trips can be accounted by the model we will write a function to calculate R-Squared value as shown below.\n\nCalcRSquared &lt;- function(observed,estimated){\n  r &lt;- cor(observed,estimated)\n  R2 &lt;- r^2\n  R2\n}\n\nNext, the R-squared of the unconstrained SIM is used by using the code chunk below.\n\nCalcRSquared(uncSIM$data$TRIPS, uncSIM$fitted.values)\n\n[1] 0.1892576\n\n\n\nr2_mcfadden(uncSIM)\n\n# R2 for Generalized Linear Regression\n       R2: 0.400\n  adj. R2: 0.400\n\n\n\n\n8.6 Origin (Production) constrained SIM\nThis section demonstrates fitting an origin-constrained Spatial Interaction Model (SIM) using the code chunk provided below.\nThe general formula for an Origin-Constrained Spatial Interaction Model is outlined below.\n\n\norcSIM &lt;- glm(formula = TRIPS ~ \n                 ORIGIN_SZ +\n                 log(DESTIN_AGE25_64) +\n                 log(dist),\n              family = poisson(link = \"log\"),\n              data = SIM_data,\n              na.action = na.exclude)\nsummary(orcSIM)\n\n\nCall:\nglm(formula = TRIPS ~ ORIGIN_SZ + log(DESTIN_AGE25_64) + log(dist), \n    family = poisson(link = \"log\"), data = SIM_data, na.action = na.exclude)\n\nCoefficients:\n                       Estimate Std. Error   z value Pr(&gt;|z|)    \n(Intercept)           1.211e+01  3.785e-03  3199.012  &lt; 2e-16 ***\nORIGIN_SZAMSZ02       1.008e+00  4.450e-03   226.401  &lt; 2e-16 ***\nORIGIN_SZAMSZ03       5.474e-01  4.563e-03   119.959  &lt; 2e-16 ***\nORIGIN_SZAMSZ04      -7.494e-02  5.187e-03   -14.448  &lt; 2e-16 ***\nORIGIN_SZAMSZ05      -2.006e-01  5.790e-03   -34.650  &lt; 2e-16 ***\nORIGIN_SZAMSZ06       4.193e-01  5.130e-03    81.736  &lt; 2e-16 ***\nORIGIN_SZAMSZ07      -1.372e+00  9.683e-03  -141.686  &lt; 2e-16 ***\nORIGIN_SZAMSZ08      -1.022e+00  8.956e-03  -114.087  &lt; 2e-16 ***\nORIGIN_SZAMSZ09       2.239e-01  5.408e-03    41.396  &lt; 2e-16 ***\nORIGIN_SZAMSZ10       5.061e-01  4.716e-03   107.311  &lt; 2e-16 ***\nORIGIN_SZAMSZ11      -1.856e+00  1.285e-02  -144.414  &lt; 2e-16 ***\nORIGIN_SZAMSZ12      -1.580e+00  1.076e-02  -146.883  &lt; 2e-16 ***\nORIGIN_SZBDSZ01       1.072e+00  4.345e-03   246.734  &lt; 2e-16 ***\nORIGIN_SZBDSZ02       5.198e-01  5.079e-03   102.340  &lt; 2e-16 ***\nORIGIN_SZBDSZ03       9.865e-01  4.490e-03   219.724  &lt; 2e-16 ***\nORIGIN_SZBDSZ04       1.767e+00  3.894e-03   453.646  &lt; 2e-16 ***\nORIGIN_SZBDSZ05       6.395e-01  4.546e-03   140.691  &lt; 2e-16 ***\nORIGIN_SZBDSZ06       9.363e-01  4.543e-03   206.094  &lt; 2e-16 ***\nORIGIN_SZBDSZ07      -1.281e+00  9.558e-03  -133.991  &lt; 2e-16 ***\nORIGIN_SZBDSZ08      -1.167e+00  9.032e-03  -129.194  &lt; 2e-16 ***\nORIGIN_SZBKSZ01      -4.540e-01  6.538e-03   -69.437  &lt; 2e-16 ***\nORIGIN_SZBKSZ02       3.736e-01  5.115e-03    73.050  &lt; 2e-16 ***\nORIGIN_SZBKSZ03       5.841e-01  4.934e-03   118.375  &lt; 2e-16 ***\nORIGIN_SZBKSZ04      -1.177e-01  5.914e-03   -19.895  &lt; 2e-16 ***\nORIGIN_SZBKSZ05      -2.164e-01  5.832e-03   -37.115  &lt; 2e-16 ***\nORIGIN_SZBKSZ06       3.684e-03  5.873e-03     0.627  0.53048    \nORIGIN_SZBKSZ07       7.456e-01  4.426e-03   168.439  &lt; 2e-16 ***\nORIGIN_SZBKSZ08      -2.279e-02  5.348e-03    -4.261 2.04e-05 ***\nORIGIN_SZBKSZ09      -9.572e-02  5.721e-03   -16.733  &lt; 2e-16 ***\nORIGIN_SZBLSZ01      -1.688e+00  1.482e-02  -113.887  &lt; 2e-16 ***\nORIGIN_SZBLSZ02      -2.154e+00  1.924e-02  -111.980  &lt; 2e-16 ***\nORIGIN_SZBLSZ03      -3.249e+00  3.930e-02   -82.662  &lt; 2e-16 ***\nORIGIN_SZBLSZ04      -2.203e+00  2.306e-02   -95.557  &lt; 2e-16 ***\nORIGIN_SZBMSZ01      -1.267e-01  5.222e-03   -24.266  &lt; 2e-16 ***\nORIGIN_SZBMSZ02      -1.075e+00  6.742e-03  -159.386  &lt; 2e-16 ***\nORIGIN_SZBMSZ03      -4.386e-01  5.794e-03   -75.707  &lt; 2e-16 ***\nORIGIN_SZBMSZ04      -6.333e-02  5.157e-03   -12.280  &lt; 2e-16 ***\nORIGIN_SZBMSZ05      -2.256e+00  1.247e-02  -180.957  &lt; 2e-16 ***\nORIGIN_SZBMSZ06      -2.378e+00  1.618e-02  -147.029  &lt; 2e-16 ***\nORIGIN_SZBMSZ07      -4.769e-01  5.653e-03   -84.362  &lt; 2e-16 ***\nORIGIN_SZBMSZ08      -5.652e-01  5.811e-03   -97.259  &lt; 2e-16 ***\nORIGIN_SZBMSZ09      -1.232e+00  8.688e-03  -141.760  &lt; 2e-16 ***\nORIGIN_SZBMSZ10      -1.471e+00  9.130e-03  -161.131  &lt; 2e-16 ***\nORIGIN_SZBMSZ11      -7.866e-01  6.595e-03  -119.263  &lt; 2e-16 ***\nORIGIN_SZBMSZ12      -1.072e+00  9.149e-03  -117.206  &lt; 2e-16 ***\nORIGIN_SZBMSZ13      -1.207e-01  5.691e-03   -21.218  &lt; 2e-16 ***\nORIGIN_SZBMSZ14      -5.376e-01  6.629e-03   -81.098  &lt; 2e-16 ***\nORIGIN_SZBMSZ15      -3.253e-01  6.054e-03   -53.740  &lt; 2e-16 ***\nORIGIN_SZBMSZ16      -1.548e+00  9.144e-03  -169.303  &lt; 2e-16 ***\nORIGIN_SZBMSZ17      -2.169e+00  1.576e-02  -137.622  &lt; 2e-16 ***\nORIGIN_SZBPSZ01       1.369e-01  5.553e-03    24.660  &lt; 2e-16 ***\nORIGIN_SZBPSZ02      -3.292e-02  6.462e-03    -5.094 3.50e-07 ***\nORIGIN_SZBPSZ03       1.491e-01  6.149e-03    24.241  &lt; 2e-16 ***\nORIGIN_SZBPSZ04       3.544e-01  5.084e-03    69.711  &lt; 2e-16 ***\nORIGIN_SZBPSZ05       5.454e-01  4.554e-03   119.764  &lt; 2e-16 ***\nORIGIN_SZBPSZ06      -1.406e+00  9.311e-03  -151.045  &lt; 2e-16 ***\nORIGIN_SZBPSZ07      -1.004e+00  8.575e-03  -117.068  &lt; 2e-16 ***\nORIGIN_SZBSSZ01      -1.625e-02  5.276e-03    -3.080  0.00207 ** \nORIGIN_SZBSSZ02       3.088e-01  4.787e-03    64.495  &lt; 2e-16 ***\nORIGIN_SZBSSZ03       2.555e-01  4.689e-03    54.487  &lt; 2e-16 ***\nORIGIN_SZBTSZ01      -6.646e-02  5.385e-03   -12.340  &lt; 2e-16 ***\nORIGIN_SZBTSZ02      -1.078e+00  7.797e-03  -138.225  &lt; 2e-16 ***\nORIGIN_SZBTSZ03      -2.284e-01  5.727e-03   -39.876  &lt; 2e-16 ***\nORIGIN_SZBTSZ04      -1.053e+00  1.019e-02  -103.339  &lt; 2e-16 ***\nORIGIN_SZBTSZ05      -1.647e+00  1.100e-02  -149.690  &lt; 2e-16 ***\nORIGIN_SZBTSZ06      -7.804e-01  7.181e-03  -108.682  &lt; 2e-16 ***\nORIGIN_SZBTSZ07      -2.298e+00  1.321e-02  -173.921  &lt; 2e-16 ***\nORIGIN_SZBTSZ08      -1.283e+00  9.394e-03  -136.560  &lt; 2e-16 ***\nORIGIN_SZCBSZ01      -1.911e+00  5.483e-02   -34.844  &lt; 2e-16 ***\nORIGIN_SZCCSZ01      -1.758e+00  1.331e-02  -132.099  &lt; 2e-16 ***\nORIGIN_SZCHSZ01      -1.236e+00  1.178e-02  -104.954  &lt; 2e-16 ***\nORIGIN_SZCHSZ02      -5.424e-01  7.940e-03   -68.307  &lt; 2e-16 ***\nORIGIN_SZCHSZ03       4.332e-01  5.841e-03    74.153  &lt; 2e-16 ***\nORIGIN_SZCKSZ01       1.843e-01  5.117e-03    36.007  &lt; 2e-16 ***\nORIGIN_SZCKSZ02       6.800e-01  5.087e-03   133.672  &lt; 2e-16 ***\nORIGIN_SZCKSZ03       8.030e-01  4.522e-03   177.574  &lt; 2e-16 ***\nORIGIN_SZCKSZ04       1.298e+00  4.562e-03   284.446  &lt; 2e-16 ***\nORIGIN_SZCKSZ05       1.011e+00  5.305e-03   190.602  &lt; 2e-16 ***\nORIGIN_SZCKSZ06       1.262e+00  5.042e-03   250.262  &lt; 2e-16 ***\nORIGIN_SZCLSZ01      -6.805e-01  7.661e-03   -88.836  &lt; 2e-16 ***\nORIGIN_SZCLSZ02      -1.837e+00  1.364e-02  -134.665  &lt; 2e-16 ***\nORIGIN_SZCLSZ03      -1.001e+00  7.949e-03  -125.969  &lt; 2e-16 ***\nORIGIN_SZCLSZ04       6.966e-01  4.460e-03   156.204  &lt; 2e-16 ***\nORIGIN_SZCLSZ05      -1.974e+00  1.474e-02  -133.906  &lt; 2e-16 ***\nORIGIN_SZCLSZ06       8.585e-01  4.204e-03   204.230  &lt; 2e-16 ***\nORIGIN_SZCLSZ07      -2.974e-01  5.575e-03   -53.346  &lt; 2e-16 ***\nORIGIN_SZCLSZ08       3.231e-01  5.802e-03    55.688  &lt; 2e-16 ***\nORIGIN_SZCLSZ09      -1.697e+00  1.555e-02  -109.106  &lt; 2e-16 ***\nORIGIN_SZDTSZ02      -4.061e+00  8.341e-02   -48.693  &lt; 2e-16 ***\nORIGIN_SZDTSZ03      -4.031e+00  7.381e-02   -54.618  &lt; 2e-16 ***\nORIGIN_SZDTSZ13      -3.000e+00  3.129e-02   -95.889  &lt; 2e-16 ***\nORIGIN_SZGLSZ01      -1.405e+00  9.192e-03  -152.876  &lt; 2e-16 ***\nORIGIN_SZGLSZ02       2.536e-01  4.889e-03    51.880  &lt; 2e-16 ***\nORIGIN_SZGLSZ03       2.411e-01  4.855e-03    49.649  &lt; 2e-16 ***\nORIGIN_SZGLSZ04       8.350e-01  4.200e-03   198.826  &lt; 2e-16 ***\nORIGIN_SZGLSZ05       6.207e-01  4.375e-03   141.857  &lt; 2e-16 ***\nORIGIN_SZHGSZ01       2.806e-01  4.746e-03    59.121  &lt; 2e-16 ***\nORIGIN_SZHGSZ02       4.917e-01  4.712e-03   104.351  &lt; 2e-16 ***\nORIGIN_SZHGSZ03       2.452e-01  5.113e-03    47.952  &lt; 2e-16 ***\nORIGIN_SZHGSZ04       9.052e-01  4.303e-03   210.358  &lt; 2e-16 ***\nORIGIN_SZHGSZ05       1.170e+00  4.253e-03   275.033  &lt; 2e-16 ***\nORIGIN_SZHGSZ06      -1.016e-01  5.413e-03   -18.773  &lt; 2e-16 ***\nORIGIN_SZHGSZ07       6.984e-01  4.455e-03   156.757  &lt; 2e-16 ***\nORIGIN_SZHGSZ08       1.005e-01  5.354e-03    18.781  &lt; 2e-16 ***\nORIGIN_SZHGSZ09      -5.390e-01  6.962e-03   -77.417  &lt; 2e-16 ***\nORIGIN_SZHGSZ10      -3.512e+00  4.211e-02   -83.388  &lt; 2e-16 ***\nORIGIN_SZJESZ01       4.022e-01  4.869e-03    82.601  &lt; 2e-16 ***\nORIGIN_SZJESZ02       2.273e-01  4.924e-03    46.158  &lt; 2e-16 ***\nORIGIN_SZJESZ03       1.829e-01  5.286e-03    34.598  &lt; 2e-16 ***\nORIGIN_SZJESZ04      -1.177e+00  9.142e-03  -128.767  &lt; 2e-16 ***\nORIGIN_SZJESZ05      -2.065e+00  1.382e-02  -149.494  &lt; 2e-16 ***\nORIGIN_SZJESZ06       2.301e-01  4.853e-03    47.410  &lt; 2e-16 ***\nORIGIN_SZJESZ07      -1.889e+00  1.183e-02  -159.599  &lt; 2e-16 ***\nORIGIN_SZJESZ08      -1.062e+00  1.147e-02   -92.551  &lt; 2e-16 ***\nORIGIN_SZJESZ09       5.237e-01  4.959e-03   105.612  &lt; 2e-16 ***\nORIGIN_SZJESZ10      -1.829e+00  1.800e-02  -101.616  &lt; 2e-16 ***\nORIGIN_SZJESZ11      -2.023e+00  1.931e-02  -104.738  &lt; 2e-16 ***\nORIGIN_SZJWSZ01       2.125e-01  6.405e-03    33.183  &lt; 2e-16 ***\nORIGIN_SZJWSZ02       8.858e-01  4.521e-03   195.929  &lt; 2e-16 ***\nORIGIN_SZJWSZ03       1.269e+00  4.188e-03   302.922  &lt; 2e-16 ***\nORIGIN_SZJWSZ04       1.284e+00  4.280e-03   300.017  &lt; 2e-16 ***\nORIGIN_SZJWSZ05      -1.393e+00  1.252e-02  -111.339  &lt; 2e-16 ***\nORIGIN_SZJWSZ06      -1.015e+00  1.067e-02   -95.109  &lt; 2e-16 ***\nORIGIN_SZJWSZ07      -2.694e+00  2.751e-02   -97.911  &lt; 2e-16 ***\nORIGIN_SZJWSZ08       1.950e+00  4.110e-03   474.430  &lt; 2e-16 ***\nORIGIN_SZJWSZ09       1.831e+00  3.899e-03   469.595  &lt; 2e-16 ***\nORIGIN_SZKLSZ01       1.636e-01  4.902e-03    33.374  &lt; 2e-16 ***\nORIGIN_SZKLSZ02      -5.156e-01  6.321e-03   -81.570  &lt; 2e-16 ***\nORIGIN_SZKLSZ03      -4.145e-01  5.949e-03   -69.666  &lt; 2e-16 ***\nORIGIN_SZKLSZ04      -2.283e+00  1.187e-02  -192.327  &lt; 2e-16 ***\nORIGIN_SZKLSZ05      -8.593e-01  8.272e-03  -103.882  &lt; 2e-16 ***\nORIGIN_SZKLSZ06      -4.709e+00  1.857e-01   -25.352  &lt; 2e-16 ***\nORIGIN_SZKLSZ07      -1.123e+00  8.408e-03  -133.615  &lt; 2e-16 ***\nORIGIN_SZKLSZ08      -1.476e+00  9.152e-03  -161.321  &lt; 2e-16 ***\nORIGIN_SZLKSZ01      -3.273e+00  3.875e-02   -84.465  &lt; 2e-16 ***\nORIGIN_SZMDSZ01      -2.615e+00  2.802e-02   -93.303  &lt; 2e-16 ***\nORIGIN_SZMDSZ02      -8.945e-01  1.035e-02   -86.389  &lt; 2e-16 ***\nORIGIN_SZMDSZ03      -1.998e+00  1.703e-02  -117.297  &lt; 2e-16 ***\nORIGIN_SZMPSZ01      -1.093e+00  8.367e-03  -130.656  &lt; 2e-16 ***\nORIGIN_SZMPSZ02      -5.975e-01  6.898e-03   -86.616  &lt; 2e-16 ***\nORIGIN_SZMPSZ03      -9.706e-03  5.319e-03    -1.825  0.06804 .  \nORIGIN_SZMUSZ02      -3.923e+00  1.038e-01   -37.806  &lt; 2e-16 ***\nORIGIN_SZNTSZ01      -2.829e+00  3.529e-02   -80.157  &lt; 2e-16 ***\nORIGIN_SZNTSZ02      -3.256e+00  2.323e-02  -140.180  &lt; 2e-16 ***\nORIGIN_SZNTSZ03      -9.865e-01  7.777e-03  -126.848  &lt; 2e-16 ***\nORIGIN_SZNTSZ05      -3.353e+00  4.964e-02   -67.546  &lt; 2e-16 ***\nORIGIN_SZNTSZ06      -3.818e+00  5.576e-02   -68.483  &lt; 2e-16 ***\nORIGIN_SZNVSZ01       4.449e-01  4.482e-03    99.269  &lt; 2e-16 ***\nORIGIN_SZNVSZ02      -6.279e-01  6.470e-03   -97.044  &lt; 2e-16 ***\nORIGIN_SZNVSZ03      -1.212e+00  7.788e-03  -155.644  &lt; 2e-16 ***\nORIGIN_SZNVSZ04      -1.469e+00  9.091e-03  -161.543  &lt; 2e-16 ***\nORIGIN_SZNVSZ05      -2.628e+00  1.579e-02  -166.466  &lt; 2e-16 ***\nORIGIN_SZPGSZ01      -9.541e-01  1.223e-02   -78.035  &lt; 2e-16 ***\nORIGIN_SZPGSZ02      -5.353e-01  7.233e-03   -74.009  &lt; 2e-16 ***\nORIGIN_SZPGSZ03       9.574e-01  4.437e-03   215.779  &lt; 2e-16 ***\nORIGIN_SZPGSZ04       1.110e+00  4.417e-03   251.169  &lt; 2e-16 ***\nORIGIN_SZPGSZ05       2.658e-01  5.758e-03    46.156  &lt; 2e-16 ***\nORIGIN_SZPLSZ01      -8.153e-01  1.044e-02   -78.119  &lt; 2e-16 ***\nORIGIN_SZPLSZ02      -1.675e+00  1.478e-02  -113.340  &lt; 2e-16 ***\nORIGIN_SZPLSZ03      -2.963e+00  3.672e-02   -80.686  &lt; 2e-16 ***\nORIGIN_SZPLSZ04      -3.279e+00  3.684e-02   -89.012  &lt; 2e-16 ***\nORIGIN_SZPLSZ05      -2.466e+00  2.245e-02  -109.864  &lt; 2e-16 ***\nORIGIN_SZPNSZ01       1.411e+00  4.584e-03   307.690  &lt; 2e-16 ***\nORIGIN_SZPNSZ02      -5.043e-01  1.108e-02   -45.503  &lt; 2e-16 ***\nORIGIN_SZPNSZ03      -1.878e+00  1.940e-02   -96.796  &lt; 2e-16 ***\nORIGIN_SZPNSZ04      -2.761e+00  3.112e-02   -88.706  &lt; 2e-16 ***\nORIGIN_SZPNSZ05      -2.277e+00  2.628e-02   -86.662  &lt; 2e-16 ***\nORIGIN_SZPRSZ01      -7.934e-01  1.142e-02   -69.499  &lt; 2e-16 ***\nORIGIN_SZPRSZ02       9.414e-01  4.615e-03   203.981  &lt; 2e-16 ***\nORIGIN_SZPRSZ03       7.674e-01  4.626e-03   165.881  &lt; 2e-16 ***\nORIGIN_SZPRSZ04      -3.771e-01  7.516e-03   -50.168  &lt; 2e-16 ***\nORIGIN_SZPRSZ05       1.327e+00  4.325e-03   306.737  &lt; 2e-16 ***\nORIGIN_SZPRSZ06      -4.081e-01  8.651e-03   -47.172  &lt; 2e-16 ***\nORIGIN_SZPRSZ07      -2.151e+00  1.610e-02  -133.558  &lt; 2e-16 ***\nORIGIN_SZPRSZ08       5.293e-04  6.383e-03     0.083  0.93391    \nORIGIN_SZQTSZ01      -4.144e-01  6.846e-03   -60.539  &lt; 2e-16 ***\nORIGIN_SZQTSZ02      -7.967e-01  6.327e-03  -125.933  &lt; 2e-16 ***\nORIGIN_SZQTSZ03      -2.415e-01  5.681e-03   -42.509  &lt; 2e-16 ***\nORIGIN_SZQTSZ04      -1.013e+00  7.129e-03  -142.123  &lt; 2e-16 ***\nORIGIN_SZQTSZ05      -3.923e-01  5.994e-03   -65.446  &lt; 2e-16 ***\nORIGIN_SZQTSZ06      -5.662e-01  6.481e-03   -87.359  &lt; 2e-16 ***\nORIGIN_SZQTSZ07      -1.558e+00  9.635e-03  -161.662  &lt; 2e-16 ***\nORIGIN_SZQTSZ08      -1.577e-01  5.699e-03   -27.665  &lt; 2e-16 ***\nORIGIN_SZQTSZ09      -6.189e-01  6.633e-03   -93.312  &lt; 2e-16 ***\nORIGIN_SZQTSZ10      -4.511e-01  6.512e-03   -69.271  &lt; 2e-16 ***\nORIGIN_SZQTSZ11      -1.455e+00  9.800e-03  -148.421  &lt; 2e-16 ***\nORIGIN_SZQTSZ12      -1.475e+00  1.044e-02  -141.309  &lt; 2e-16 ***\nORIGIN_SZQTSZ13      -3.529e-01  6.413e-03   -55.038  &lt; 2e-16 ***\nORIGIN_SZQTSZ14      -1.591e+00  9.847e-03  -161.565  &lt; 2e-16 ***\nORIGIN_SZQTSZ15      -8.955e-01  1.027e-02   -87.184  &lt; 2e-16 ***\nORIGIN_SZRCSZ01      -1.375e+00  1.265e-02  -108.704  &lt; 2e-16 ***\nORIGIN_SZRCSZ06      -6.196e-01  8.475e-03   -73.116  &lt; 2e-16 ***\nORIGIN_SZRVSZ01      -3.523e+00  3.237e-02  -108.818  &lt; 2e-16 ***\nORIGIN_SZRVSZ02      -2.912e+00  2.776e-02  -104.868  &lt; 2e-16 ***\nORIGIN_SZRVSZ03      -3.145e+00  2.379e-02  -132.232  &lt; 2e-16 ***\nORIGIN_SZRVSZ04      -3.357e+00  5.567e-02   -60.309  &lt; 2e-16 ***\nORIGIN_SZRVSZ05      -2.438e+00  1.644e-02  -148.272  &lt; 2e-16 ***\nORIGIN_SZSBSZ01       5.890e-01  5.529e-03   106.520  &lt; 2e-16 ***\nORIGIN_SZSBSZ02      -7.098e-01  8.213e-03   -86.432  &lt; 2e-16 ***\nORIGIN_SZSBSZ03       9.634e-01  4.611e-03   208.943  &lt; 2e-16 ***\nORIGIN_SZSBSZ04       7.729e-01  5.289e-03   146.136  &lt; 2e-16 ***\nORIGIN_SZSBSZ05      -9.966e-02  6.543e-03   -15.231  &lt; 2e-16 ***\nORIGIN_SZSBSZ06      -1.778e+00  1.719e-02  -103.427  &lt; 2e-16 ***\nORIGIN_SZSBSZ07      -1.161e+00  1.256e-02   -92.436  &lt; 2e-16 ***\nORIGIN_SZSBSZ08      -1.212e+00  1.222e-02   -99.227  &lt; 2e-16 ***\nORIGIN_SZSBSZ09      -5.783e-01  8.579e-03   -67.412  &lt; 2e-16 ***\nORIGIN_SZSESZ02       9.999e-01  4.409e-03   226.798  &lt; 2e-16 ***\nORIGIN_SZSESZ03       1.214e+00  4.164e-03   291.675  &lt; 2e-16 ***\nORIGIN_SZSESZ04       8.141e-01  4.868e-03   167.238  &lt; 2e-16 ***\nORIGIN_SZSESZ05      -2.186e-01  5.915e-03   -36.961  &lt; 2e-16 ***\nORIGIN_SZSESZ06       7.298e-01  4.689e-03   155.641  &lt; 2e-16 ***\nORIGIN_SZSESZ07      -2.543e+00  1.961e-02  -129.689  &lt; 2e-16 ***\nORIGIN_SZSGSZ01      -1.016e+00  8.550e-03  -118.869  &lt; 2e-16 ***\nORIGIN_SZSGSZ02      -1.120e+00  9.589e-03  -116.799  &lt; 2e-16 ***\nORIGIN_SZSGSZ03       2.169e-01  5.167e-03    41.970  &lt; 2e-16 ***\nORIGIN_SZSGSZ04       2.672e-01  4.792e-03    55.757  &lt; 2e-16 ***\nORIGIN_SZSGSZ05      -1.785e+00  1.060e-02  -168.456  &lt; 2e-16 ***\nORIGIN_SZSGSZ06       4.017e-01  4.541e-03    88.470  &lt; 2e-16 ***\nORIGIN_SZSGSZ07      -6.303e-01  6.235e-03  -101.098  &lt; 2e-16 ***\nORIGIN_SZSKSZ01      -1.928e-01  7.765e-03   -24.826  &lt; 2e-16 ***\nORIGIN_SZSKSZ02       3.870e-01  5.689e-03    68.026  &lt; 2e-16 ***\nORIGIN_SZSKSZ03      -6.815e-01  7.983e-03   -85.369  &lt; 2e-16 ***\nORIGIN_SZSKSZ04      -2.528e+00  2.702e-02   -93.548  &lt; 2e-16 ***\nORIGIN_SZSKSZ05      -1.370e+00  1.552e-02   -88.311  &lt; 2e-16 ***\nORIGIN_SZSLSZ01      -3.218e+00  3.058e-02  -105.238  &lt; 2e-16 ***\nORIGIN_SZSLSZ04      -6.800e-01  7.683e-03   -88.497  &lt; 2e-16 ***\nORIGIN_SZSRSZ01      -2.389e+00  1.583e-02  -150.989  &lt; 2e-16 ***\nORIGIN_SZTHSZ01      -2.183e+00  4.887e-02   -44.666  &lt; 2e-16 ***\nORIGIN_SZTHSZ03      -2.243e+00  2.243e-02  -100.025  &lt; 2e-16 ***\nORIGIN_SZTHSZ04      -2.005e+00  2.869e-02   -69.879  &lt; 2e-16 ***\nORIGIN_SZTHSZ06      -2.276e+00  1.784e-02  -127.557  &lt; 2e-16 ***\nORIGIN_SZTMSZ01       4.015e-01  5.814e-03    69.048  &lt; 2e-16 ***\nORIGIN_SZTMSZ02       2.222e+00  3.795e-03   585.568  &lt; 2e-16 ***\nORIGIN_SZTMSZ03       1.412e+00  4.108e-03   343.608  &lt; 2e-16 ***\nORIGIN_SZTMSZ04       9.106e-01  4.742e-03   192.036  &lt; 2e-16 ***\nORIGIN_SZTMSZ05      -3.259e-01  7.534e-03   -43.253  &lt; 2e-16 ***\nORIGIN_SZTNSZ01      -1.806e+00  1.038e-02  -174.076  &lt; 2e-16 ***\nORIGIN_SZTNSZ02      -1.741e+00  9.778e-03  -178.108  &lt; 2e-16 ***\nORIGIN_SZTNSZ03      -2.277e+00  1.338e-02  -170.199  &lt; 2e-16 ***\nORIGIN_SZTNSZ04      -7.703e-01  7.197e-03  -107.032  &lt; 2e-16 ***\nORIGIN_SZTPSZ01      -6.466e-01  6.287e-03  -102.841  &lt; 2e-16 ***\nORIGIN_SZTPSZ02       4.633e-01  4.347e-03   106.578  &lt; 2e-16 ***\nORIGIN_SZTPSZ03      -5.186e-01  6.085e-03   -85.234  &lt; 2e-16 ***\nORIGIN_SZTPSZ04      -2.900e-01  5.779e-03   -50.190  &lt; 2e-16 ***\nORIGIN_SZTPSZ05      -2.169e-01  6.072e-03   -35.720  &lt; 2e-16 ***\nORIGIN_SZTPSZ06       3.357e-01  5.942e-03    56.486  &lt; 2e-16 ***\nORIGIN_SZTPSZ07      -2.517e-01  6.317e-03   -39.846  &lt; 2e-16 ***\nORIGIN_SZTPSZ08      -1.075e+00  9.109e-03  -118.034  &lt; 2e-16 ***\nORIGIN_SZTPSZ09      -3.708e-01  6.189e-03   -59.903  &lt; 2e-16 ***\nORIGIN_SZTPSZ10      -6.889e-01  7.634e-03   -90.229  &lt; 2e-16 ***\nORIGIN_SZTPSZ11       7.661e-02  5.459e-03    14.033  &lt; 2e-16 ***\nORIGIN_SZTPSZ12      -5.971e-01  6.522e-03   -91.552  &lt; 2e-16 ***\nORIGIN_SZTSSZ01      -3.517e+00  4.739e-02   -74.210  &lt; 2e-16 ***\nORIGIN_SZTSSZ02       3.022e-01  7.334e-03    41.203  &lt; 2e-16 ***\nORIGIN_SZTSSZ03       3.730e-01  7.073e-03    52.733  &lt; 2e-16 ***\nORIGIN_SZTSSZ04       3.610e-01  7.463e-03    48.372  &lt; 2e-16 ***\nORIGIN_SZTSSZ05      -1.103e+00  1.404e-02   -78.566  &lt; 2e-16 ***\nORIGIN_SZTSSZ06      -1.310e+00  1.718e-02   -76.286  &lt; 2e-16 ***\nORIGIN_SZWCSZ01      -1.233e-01  7.861e-03   -15.690  &lt; 2e-16 ***\nORIGIN_SZWCSZ02      -2.872e+00  3.159e-02   -90.911  &lt; 2e-16 ***\nORIGIN_SZWCSZ03      -4.138e+00  1.241e-01   -33.349  &lt; 2e-16 ***\nORIGIN_SZWDSZ01       1.370e+00  4.146e-03   330.448  &lt; 2e-16 ***\nORIGIN_SZWDSZ02       1.041e+00  4.747e-03   219.219  &lt; 2e-16 ***\nORIGIN_SZWDSZ03       2.189e+00  4.035e-03   542.344  &lt; 2e-16 ***\nORIGIN_SZWDSZ04       1.142e+00  4.963e-03   230.074  &lt; 2e-16 ***\nORIGIN_SZWDSZ05       5.160e-01  4.998e-03   103.230  &lt; 2e-16 ***\nORIGIN_SZWDSZ06       1.208e+00  4.611e-03   262.019  &lt; 2e-16 ***\nORIGIN_SZWDSZ07      -3.805e-01  8.034e-03   -47.365  &lt; 2e-16 ***\nORIGIN_SZWDSZ08      -4.839e-01  7.878e-03   -61.426  &lt; 2e-16 ***\nORIGIN_SZWDSZ09       1.475e+00  4.401e-03   335.097  &lt; 2e-16 ***\nORIGIN_SZYSSZ01      -1.552e-01  5.643e-03   -27.496  &lt; 2e-16 ***\nORIGIN_SZYSSZ02       8.958e-01  4.973e-03   180.144  &lt; 2e-16 ***\nORIGIN_SZYSSZ03       1.757e+00  4.275e-03   411.050  &lt; 2e-16 ***\nORIGIN_SZYSSZ04       8.439e-01  4.538e-03   185.955  &lt; 2e-16 ***\nORIGIN_SZYSSZ05      -9.995e-02  5.920e-03   -16.884  &lt; 2e-16 ***\nORIGIN_SZYSSZ06      -1.175e+00  1.079e-02  -108.835  &lt; 2e-16 ***\nORIGIN_SZYSSZ07      -1.202e+00  1.127e-02  -106.642  &lt; 2e-16 ***\nORIGIN_SZYSSZ08       1.244e-02  6.104e-03     2.039  0.04148 *  \nORIGIN_SZYSSZ09       1.385e+00  4.239e-03   326.757  &lt; 2e-16 ***\nlog(DESTIN_AGE25_64)  2.298e-02  8.832e-05   260.146  &lt; 2e-16 ***\nlog(dist)            -6.947e-01  1.295e-04 -5363.438  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 60796037  on 14733  degrees of freedom\nResidual deviance: 26726668  on 14453  degrees of freedom\nAIC: 26818857\n\nNumber of Fisher Scoring iterations: 7\n\n\nExamining how the constraints hold for destinations this time.\n\nCalcRSquared(orcSIM$data$TRIPS, orcSIM$fitted.values)\n\n[1] 0.4165837\n\n\n\n\n8.7 Destination constrained\nThis section demonstrates fitting a destination-constrained Spatial Interaction Model (SIM) using the code chunk provided below.\nThe general formula for a Destination-Constrained Spatial Interaction Model is outlined below.\n\n\ndecSIM &lt;- glm(formula = TRIPS ~ \n                DESTIN_SZ + \n                log(ORIGIN_AGE25_64) + \n                log(dist),\n              family = poisson(link = \"log\"),\n              data = SIM_data,\n              na.action = na.exclude)\nsummary(decSIM)\n\n\nCall:\nglm(formula = TRIPS ~ DESTIN_SZ + log(ORIGIN_AGE25_64) + log(dist), \n    family = poisson(link = \"log\"), data = SIM_data, na.action = na.exclude)\n\nCoefficients:\n                       Estimate Std. Error   z value Pr(&gt;|z|)    \n(Intercept)          10.8110189  0.0033476  3229.499  &lt; 2e-16 ***\nDESTIN_SZAMSZ02       0.1775885  0.0041530    42.761  &lt; 2e-16 ***\nDESTIN_SZAMSZ03       0.2064091  0.0040888    50.482  &lt; 2e-16 ***\nDESTIN_SZAMSZ04      -0.9406455  0.0060637  -155.127  &lt; 2e-16 ***\nDESTIN_SZAMSZ05      -1.1578100  0.0061804  -187.337  &lt; 2e-16 ***\nDESTIN_SZAMSZ06      -0.8861493  0.0059241  -149.584  &lt; 2e-16 ***\nDESTIN_SZAMSZ07      -1.7712447  0.0096070  -184.370  &lt; 2e-16 ***\nDESTIN_SZAMSZ08      -1.0707197  0.0067763  -158.009  &lt; 2e-16 ***\nDESTIN_SZAMSZ09      -0.9682250  0.0060435  -160.210  &lt; 2e-16 ***\nDESTIN_SZAMSZ10       0.2612773  0.0043738    59.737  &lt; 2e-16 ***\nDESTIN_SZAMSZ11      -0.3714704  0.0086200   -43.094  &lt; 2e-16 ***\nDESTIN_SZAMSZ12       0.0250455  0.0049850     5.024 5.06e-07 ***\nDESTIN_SZBDSZ01       0.5154763  0.0037827   136.271  &lt; 2e-16 ***\nDESTIN_SZBDSZ02      -0.2843120  0.0049517   -57.417  &lt; 2e-16 ***\nDESTIN_SZBDSZ03      -0.0134646  0.0042692    -3.154  0.00161 ** \nDESTIN_SZBDSZ04       1.0014441  0.0034463   290.582  &lt; 2e-16 ***\nDESTIN_SZBDSZ05       0.3721573  0.0038992    95.445  &lt; 2e-16 ***\nDESTIN_SZBDSZ06       0.2013935  0.0042182    47.744  &lt; 2e-16 ***\nDESTIN_SZBDSZ07      -1.0642612  0.0092942  -114.508  &lt; 2e-16 ***\nDESTIN_SZBDSZ08      -1.7769370  0.0105721  -168.077  &lt; 2e-16 ***\nDESTIN_SZBKSZ01      -1.1944766  0.0065580  -182.141  &lt; 2e-16 ***\nDESTIN_SZBKSZ02      -0.2604946  0.0052044   -50.053  &lt; 2e-16 ***\nDESTIN_SZBKSZ03      -0.5905775  0.0055618  -106.184  &lt; 2e-16 ***\nDESTIN_SZBKSZ04      -0.0521573  0.0048274   -10.804  &lt; 2e-16 ***\nDESTIN_SZBKSZ05      -0.8258599  0.0057094  -144.650  &lt; 2e-16 ***\nDESTIN_SZBKSZ06      -0.8696763  0.0060934  -142.725  &lt; 2e-16 ***\nDESTIN_SZBKSZ07       0.2216292  0.0040334    54.949  &lt; 2e-16 ***\nDESTIN_SZBKSZ08      -1.1179375  0.0068749  -162.612  &lt; 2e-16 ***\nDESTIN_SZBKSZ09      -0.2888733  0.0049056   -58.886  &lt; 2e-16 ***\nDESTIN_SZBLSZ01      -0.4487061  0.0070226   -63.894  &lt; 2e-16 ***\nDESTIN_SZBLSZ02       0.6343096  0.0065174    97.326  &lt; 2e-16 ***\nDESTIN_SZBLSZ03       1.3492337  0.0074135   181.997  &lt; 2e-16 ***\nDESTIN_SZBLSZ04      -0.0339193  0.0131568    -2.578  0.00993 ** \nDESTIN_SZBMSZ01      -0.3497912  0.0046910   -74.567  &lt; 2e-16 ***\nDESTIN_SZBMSZ02      -0.5995634  0.0048828  -122.792  &lt; 2e-16 ***\nDESTIN_SZBMSZ03      -0.8726401  0.0056851  -153.495  &lt; 2e-16 ***\nDESTIN_SZBMSZ04      -0.5350402  0.0048888  -109.442  &lt; 2e-16 ***\nDESTIN_SZBMSZ05      -0.4981814  0.0065971   -75.515  &lt; 2e-16 ***\nDESTIN_SZBMSZ06      -2.0640198  0.0123050  -167.739  &lt; 2e-16 ***\nDESTIN_SZBMSZ07      -0.3100988  0.0045283   -68.480  &lt; 2e-16 ***\nDESTIN_SZBMSZ08      -1.2748152  0.0062622  -203.573  &lt; 2e-16 ***\nDESTIN_SZBMSZ09      -2.8056325  0.0143532  -195.471  &lt; 2e-16 ***\nDESTIN_SZBMSZ10      -1.9166407  0.0089273  -214.693  &lt; 2e-16 ***\nDESTIN_SZBMSZ11      -1.7261160  0.0079281  -217.722  &lt; 2e-16 ***\nDESTIN_SZBMSZ12      -1.1495908  0.0077721  -147.912  &lt; 2e-16 ***\nDESTIN_SZBMSZ13      -0.5428008  0.0050824  -106.799  &lt; 2e-16 ***\nDESTIN_SZBMSZ14      -1.1422302  0.0076325  -149.653  &lt; 2e-16 ***\nDESTIN_SZBMSZ15      -1.2217517  0.0068685  -177.878  &lt; 2e-16 ***\nDESTIN_SZBMSZ16      -2.4074288  0.0107900  -223.116  &lt; 2e-16 ***\nDESTIN_SZBMSZ17      -2.6985491  0.0164771  -163.776  &lt; 2e-16 ***\nDESTIN_SZBPSZ01      -0.6183085  0.0054605  -113.233  &lt; 2e-16 ***\nDESTIN_SZBPSZ02      -1.4579175  0.0083271  -175.080  &lt; 2e-16 ***\nDESTIN_SZBPSZ03      -1.0775392  0.0075109  -143.463  &lt; 2e-16 ***\nDESTIN_SZBPSZ04      -0.6645303  0.0058070  -114.436  &lt; 2e-16 ***\nDESTIN_SZBPSZ05       0.3449386  0.0039504    87.318  &lt; 2e-16 ***\nDESTIN_SZBPSZ06      -0.9360064  0.0077394  -120.941  &lt; 2e-16 ***\nDESTIN_SZBPSZ07      -0.6850065  0.0077761   -88.091  &lt; 2e-16 ***\nDESTIN_SZBSSZ01      -0.3144210  0.0045803   -68.647  &lt; 2e-16 ***\nDESTIN_SZBSSZ02      -0.7531935  0.0051075  -147.469  &lt; 2e-16 ***\nDESTIN_SZBSSZ03       0.1964072  0.0038255    51.342  &lt; 2e-16 ***\nDESTIN_SZBTSZ01       0.0749897  0.0041584    18.033  &lt; 2e-16 ***\nDESTIN_SZBTSZ02      -0.8214254  0.0065659  -125.105  &lt; 2e-16 ***\nDESTIN_SZBTSZ03      -0.1672596  0.0047942   -34.888  &lt; 2e-16 ***\nDESTIN_SZBTSZ04      -1.7727273  0.0103706  -170.938  &lt; 2e-16 ***\nDESTIN_SZBTSZ05      -0.8162630  0.0067401  -121.105  &lt; 2e-16 ***\nDESTIN_SZBTSZ06      -0.8159130  0.0059754  -136.546  &lt; 2e-16 ***\nDESTIN_SZBTSZ07      -2.1139258  0.0105602  -200.178  &lt; 2e-16 ***\nDESTIN_SZBTSZ08      -1.3565179  0.0086828  -156.231  &lt; 2e-16 ***\nDESTIN_SZCBSZ01      -4.6643129  0.3162417   -14.749  &lt; 2e-16 ***\nDESTIN_SZCCSZ01      -1.0088833  0.0080155  -125.866  &lt; 2e-16 ***\nDESTIN_SZCHSZ01      -1.1909317  0.0095262  -125.017  &lt; 2e-16 ***\nDESTIN_SZCHSZ02       0.0890035  0.0052277    17.025  &lt; 2e-16 ***\nDESTIN_SZCHSZ03       1.4883985  0.0039094   380.724  &lt; 2e-16 ***\nDESTIN_SZCKSZ01      -0.1684738  0.0047561   -35.422  &lt; 2e-16 ***\nDESTIN_SZCKSZ02      -0.4314614  0.0051537   -83.720  &lt; 2e-16 ***\nDESTIN_SZCKSZ03       0.6413457  0.0038639   165.983  &lt; 2e-16 ***\nDESTIN_SZCKSZ04      -0.6370791  0.0059869  -106.412  &lt; 2e-16 ***\nDESTIN_SZCKSZ05      -0.4185112  0.0065348   -64.044  &lt; 2e-16 ***\nDESTIN_SZCKSZ06       0.7003888  0.0045139   155.163  &lt; 2e-16 ***\nDESTIN_SZCLSZ01       0.3751343  0.0047400    79.143  &lt; 2e-16 ***\nDESTIN_SZCLSZ02      -2.2913668  0.0133371  -171.804  &lt; 2e-16 ***\nDESTIN_SZCLSZ03      -1.0498490  0.0076548  -137.149  &lt; 2e-16 ***\nDESTIN_SZCLSZ04      -0.1118915  0.0044886   -24.928  &lt; 2e-16 ***\nDESTIN_SZCLSZ05      -1.3113032  0.0084067  -155.983  &lt; 2e-16 ***\nDESTIN_SZCLSZ06       0.1661786  0.0040203    41.334  &lt; 2e-16 ***\nDESTIN_SZCLSZ07      -0.6429895  0.0052617  -122.202  &lt; 2e-16 ***\nDESTIN_SZCLSZ08      -0.4271702  0.0057208   -74.670  &lt; 2e-16 ***\nDESTIN_SZCLSZ09       0.3882136  0.0063758    60.888  &lt; 2e-16 ***\nDESTIN_SZDTSZ02      -3.0106480  0.0348374   -86.420  &lt; 2e-16 ***\nDESTIN_SZDTSZ03      -1.4195712  0.0144110   -98.506  &lt; 2e-16 ***\nDESTIN_SZDTSZ13      -2.2368573  0.0161427  -138.567  &lt; 2e-16 ***\nDESTIN_SZGLSZ01       0.0013721  0.0051224     0.268  0.78881    \nDESTIN_SZGLSZ02      -0.3376674  0.0046195   -73.097  &lt; 2e-16 ***\nDESTIN_SZGLSZ03       0.3659900  0.0038384    95.350  &lt; 2e-16 ***\nDESTIN_SZGLSZ04       0.2969928  0.0038026    78.103  &lt; 2e-16 ***\nDESTIN_SZGLSZ05       0.1786445  0.0038853    45.980  &lt; 2e-16 ***\nDESTIN_SZHGSZ01       0.2979206  0.0038825    76.735  &lt; 2e-16 ***\nDESTIN_SZHGSZ02      -0.5701034  0.0051182  -111.388  &lt; 2e-16 ***\nDESTIN_SZHGSZ03      -1.0387610  0.0061020  -170.233  &lt; 2e-16 ***\nDESTIN_SZHGSZ04      -0.2264881  0.0043617   -51.926  &lt; 2e-16 ***\nDESTIN_SZHGSZ05      -0.2287090  0.0044851   -50.993  &lt; 2e-16 ***\nDESTIN_SZHGSZ06      -0.7896437  0.0054081  -146.010  &lt; 2e-16 ***\nDESTIN_SZHGSZ07       0.2268880  0.0040336    56.249  &lt; 2e-16 ***\nDESTIN_SZHGSZ08      -0.4260784  0.0048967   -87.013  &lt; 2e-16 ***\nDESTIN_SZHGSZ09       0.1027784  0.0051341    20.019  &lt; 2e-16 ***\nDESTIN_SZHGSZ10      -2.8571803  0.0262064  -109.026  &lt; 2e-16 ***\nDESTIN_SZJESZ01      -0.0843635  0.0048222   -17.495  &lt; 2e-16 ***\nDESTIN_SZJESZ02      -0.5197682  0.0051511  -100.904  &lt; 2e-16 ***\nDESTIN_SZJESZ03      -0.6250311  0.0056619  -110.392  &lt; 2e-16 ***\nDESTIN_SZJESZ04      -0.3937360  0.0065536   -60.080  &lt; 2e-16 ***\nDESTIN_SZJESZ05      -0.9748291  0.0097665   -99.814  &lt; 2e-16 ***\nDESTIN_SZJESZ06       0.3642736  0.0040600    89.722  &lt; 2e-16 ***\nDESTIN_SZJESZ07      -1.1571882  0.0081557  -141.887  &lt; 2e-16 ***\nDESTIN_SZJESZ08      -0.5955747  0.0078071   -76.286  &lt; 2e-16 ***\nDESTIN_SZJESZ09      -0.3629500  0.0053966   -67.256  &lt; 2e-16 ***\nDESTIN_SZJESZ10       0.7691552  0.0069348   110.912  &lt; 2e-16 ***\nDESTIN_SZJESZ11       0.9365743  0.0065801   142.335  &lt; 2e-16 ***\nDESTIN_SZJWSZ01      -0.4568805  0.0064536   -70.795  &lt; 2e-16 ***\nDESTIN_SZJWSZ02      -0.2880426  0.0051632   -55.788  &lt; 2e-16 ***\nDESTIN_SZJWSZ03       0.6680404  0.0039264   170.142  &lt; 2e-16 ***\nDESTIN_SZJWSZ04       0.9492158  0.0037186   255.262  &lt; 2e-16 ***\nDESTIN_SZJWSZ05      -0.1938053  0.0060810   -31.871  &lt; 2e-16 ***\nDESTIN_SZJWSZ06       0.3813164  0.0054551    69.900  &lt; 2e-16 ***\nDESTIN_SZJWSZ07      -1.2676010  0.0280038   -45.265  &lt; 2e-16 ***\nDESTIN_SZJWSZ08       0.5013149  0.0044573   112.471  &lt; 2e-16 ***\nDESTIN_SZJWSZ09       1.4161404  0.0033937   417.291  &lt; 2e-16 ***\nDESTIN_SZKLSZ01      -0.6909444  0.0051540  -134.059  &lt; 2e-16 ***\nDESTIN_SZKLSZ02      -0.8146023  0.0057129  -142.589  &lt; 2e-16 ***\nDESTIN_SZKLSZ03      -1.3956114  0.0065167  -214.161  &lt; 2e-16 ***\nDESTIN_SZKLSZ04      -1.9070281  0.0087370  -218.270  &lt; 2e-16 ***\nDESTIN_SZKLSZ05      -0.9293576  0.0071070  -130.766  &lt; 2e-16 ***\nDESTIN_SZKLSZ06      -2.5402234  0.0362062   -70.160  &lt; 2e-16 ***\nDESTIN_SZKLSZ07      -1.2017213  0.0065751  -182.769  &lt; 2e-16 ***\nDESTIN_SZKLSZ08      -0.6083433  0.0050916  -119.480  &lt; 2e-16 ***\nDESTIN_SZLKSZ01      -1.5186810  0.0204155   -74.389  &lt; 2e-16 ***\nDESTIN_SZMDSZ01      -1.4601772  0.0198347   -73.617  &lt; 2e-16 ***\nDESTIN_SZMDSZ02      -1.1554609  0.0111345  -103.773  &lt; 2e-16 ***\nDESTIN_SZMDSZ03      -2.9919337  0.0250838  -119.277  &lt; 2e-16 ***\nDESTIN_SZMPSZ01      -1.1705809  0.0077128  -151.771  &lt; 2e-16 ***\nDESTIN_SZMPSZ02      -0.9380957  0.0060321  -155.517  &lt; 2e-16 ***\nDESTIN_SZMPSZ03      -0.1761013  0.0046389   -37.962  &lt; 2e-16 ***\nDESTIN_SZMUSZ02      -2.4525115  0.0199630  -122.853  &lt; 2e-16 ***\nDESTIN_SZNTSZ01      -3.6605524  0.0447752   -81.754  &lt; 2e-16 ***\nDESTIN_SZNTSZ02      -2.0082021  0.0108736  -184.686  &lt; 2e-16 ***\nDESTIN_SZNTSZ03      -1.2387489  0.0076141  -162.691  &lt; 2e-16 ***\nDESTIN_SZNTSZ05      -1.8054361  0.0249540   -72.351  &lt; 2e-16 ***\nDESTIN_SZNTSZ06      -2.9500517  0.0428601   -68.830  &lt; 2e-16 ***\nDESTIN_SZNVSZ01      -0.4089022  0.0044288   -92.327  &lt; 2e-16 ***\nDESTIN_SZNVSZ02      -0.6865452  0.0052770  -130.102  &lt; 2e-16 ***\nDESTIN_SZNVSZ03      -0.7333670  0.0054243  -135.199  &lt; 2e-16 ***\nDESTIN_SZNVSZ04      -2.2095097  0.0106997  -206.503  &lt; 2e-16 ***\nDESTIN_SZNVSZ05      -1.8721104  0.0089058  -210.212  &lt; 2e-16 ***\nDESTIN_SZPGSZ01      -1.8756618  0.0153008  -122.586  &lt; 2e-16 ***\nDESTIN_SZPGSZ02      -0.9435337  0.0067224  -140.356  &lt; 2e-16 ***\nDESTIN_SZPGSZ03       0.3458476  0.0040152    86.134  &lt; 2e-16 ***\nDESTIN_SZPGSZ04      -0.0271485  0.0044805    -6.059 1.37e-09 ***\nDESTIN_SZPGSZ05      -0.8920273  0.0070730  -126.117  &lt; 2e-16 ***\nDESTIN_SZPLSZ01      -0.2153087  0.0068270   -31.538  &lt; 2e-16 ***\nDESTIN_SZPLSZ02      -1.3646116  0.0131155  -104.046  &lt; 2e-16 ***\nDESTIN_SZPLSZ03      -0.0869245  0.0095838    -9.070  &lt; 2e-16 ***\nDESTIN_SZPLSZ04      -0.2574560  0.0093336   -27.584  &lt; 2e-16 ***\nDESTIN_SZPLSZ05      -0.7186364  0.0116835   -61.509  &lt; 2e-16 ***\nDESTIN_SZPNSZ01       1.1326963  0.0049977   226.643  &lt; 2e-16 ***\nDESTIN_SZPNSZ02       1.6516855  0.0064492   256.106  &lt; 2e-16 ***\nDESTIN_SZPNSZ03       0.8504093  0.0077034   110.394  &lt; 2e-16 ***\nDESTIN_SZPNSZ04       1.6891381  0.0075802   222.836  &lt; 2e-16 ***\nDESTIN_SZPNSZ05       0.7402750  0.0115948    63.845  &lt; 2e-16 ***\nDESTIN_SZPRSZ01      -1.0257636  0.0084652  -121.175  &lt; 2e-16 ***\nDESTIN_SZPRSZ02      -0.2028503  0.0049839   -40.701  &lt; 2e-16 ***\nDESTIN_SZPRSZ03       0.5560483  0.0038496   144.442  &lt; 2e-16 ***\nDESTIN_SZPRSZ04      -0.6824142  0.0079047   -86.330  &lt; 2e-16 ***\nDESTIN_SZPRSZ05       0.0316117  0.0044946     7.033 2.02e-12 ***\nDESTIN_SZPRSZ06       0.3706283  0.0052006    71.267  &lt; 2e-16 ***\nDESTIN_SZPRSZ07      -1.4740460  0.0117304  -125.661  &lt; 2e-16 ***\nDESTIN_SZPRSZ08      -0.7869180  0.0064862  -121.321  &lt; 2e-16 ***\nDESTIN_SZQTSZ01      -1.2790095  0.0085392  -149.781  &lt; 2e-16 ***\nDESTIN_SZQTSZ02      -1.4989188  0.0073423  -204.149  &lt; 2e-16 ***\nDESTIN_SZQTSZ03      -0.9334132  0.0064035  -145.765  &lt; 2e-16 ***\nDESTIN_SZQTSZ04      -1.0506142  0.0065335  -160.805  &lt; 2e-16 ***\nDESTIN_SZQTSZ05      -0.9765013  0.0058471  -167.006  &lt; 2e-16 ***\nDESTIN_SZQTSZ06      -1.2206088  0.0063560  -192.042  &lt; 2e-16 ***\nDESTIN_SZQTSZ07      -1.6794007  0.0108727  -154.460  &lt; 2e-16 ***\nDESTIN_SZQTSZ08      -0.1214413  0.0047980   -25.311  &lt; 2e-16 ***\nDESTIN_SZQTSZ09      -0.5252607  0.0057371   -91.555  &lt; 2e-16 ***\nDESTIN_SZQTSZ10      -0.5981644  0.0054192  -110.378  &lt; 2e-16 ***\nDESTIN_SZQTSZ11      -0.0766021  0.0053446   -14.333  &lt; 2e-16 ***\nDESTIN_SZQTSZ12      -0.6153017  0.0070680   -87.054  &lt; 2e-16 ***\nDESTIN_SZQTSZ13      -0.1690535  0.0051315   -32.944  &lt; 2e-16 ***\nDESTIN_SZQTSZ14      -0.5398362  0.0062233   -86.744  &lt; 2e-16 ***\nDESTIN_SZQTSZ15      -0.1873015  0.0073132   -25.611  &lt; 2e-16 ***\nDESTIN_SZRCSZ01      -0.5875494  0.0071798   -81.833  &lt; 2e-16 ***\nDESTIN_SZRCSZ06      -2.0856090  0.0188789  -110.473  &lt; 2e-16 ***\nDESTIN_SZRVSZ01      -2.6183708  0.0162319  -161.310  &lt; 2e-16 ***\nDESTIN_SZRVSZ02      -3.1882190  0.0326141   -97.756  &lt; 2e-16 ***\nDESTIN_SZRVSZ03      -2.5981974  0.0135074  -192.353  &lt; 2e-16 ***\nDESTIN_SZRVSZ04      -1.9741504  0.0154961  -127.396  &lt; 2e-16 ***\nDESTIN_SZRVSZ05      -3.1547734  0.0256310  -123.084  &lt; 2e-16 ***\nDESTIN_SZSBSZ01      -0.3097949  0.0060601   -51.121  &lt; 2e-16 ***\nDESTIN_SZSBSZ02      -1.1229132  0.0076338  -147.097  &lt; 2e-16 ***\nDESTIN_SZSBSZ03       0.6289715  0.0041400   151.926  &lt; 2e-16 ***\nDESTIN_SZSBSZ04       0.1419430  0.0051357    27.638  &lt; 2e-16 ***\nDESTIN_SZSBSZ05      -0.9256413  0.0071963  -128.628  &lt; 2e-16 ***\nDESTIN_SZSBSZ06      -2.3487368  0.0221611  -105.984  &lt; 2e-16 ***\nDESTIN_SZSBSZ07      -0.7864630  0.0181706   -43.282  &lt; 2e-16 ***\nDESTIN_SZSBSZ08       1.3240051  0.0051598   256.599  &lt; 2e-16 ***\nDESTIN_SZSBSZ09       0.8431156  0.0048330   174.449  &lt; 2e-16 ***\nDESTIN_SZSESZ02      -0.2385874  0.0046618   -51.180  &lt; 2e-16 ***\nDESTIN_SZSESZ03       0.5439188  0.0036932   147.276  &lt; 2e-16 ***\nDESTIN_SZSESZ04      -0.6715716  0.0054222  -123.856  &lt; 2e-16 ***\nDESTIN_SZSESZ05      -0.3601932  0.0047508   -75.818  &lt; 2e-16 ***\nDESTIN_SZSESZ06      -0.6088413  0.0057017  -106.782  &lt; 2e-16 ***\nDESTIN_SZSESZ07      -2.9477507  0.0226797  -129.973  &lt; 2e-16 ***\nDESTIN_SZSGSZ01      -0.5100640  0.0058280   -87.519  &lt; 2e-16 ***\nDESTIN_SZSGSZ02      -0.0439941  0.0051633    -8.520  &lt; 2e-16 ***\nDESTIN_SZSGSZ03      -0.3700648  0.0047152   -78.483  &lt; 2e-16 ***\nDESTIN_SZSGSZ04      -0.3021335  0.0046865   -64.468  &lt; 2e-16 ***\nDESTIN_SZSGSZ05      -2.2253287  0.0097908  -227.288  &lt; 2e-16 ***\nDESTIN_SZSGSZ06       0.2963602  0.0037948    78.097  &lt; 2e-16 ***\nDESTIN_SZSGSZ07      -0.5940373  0.0051371  -115.637  &lt; 2e-16 ***\nDESTIN_SZSISZ01      -1.4528976  0.0257790   -56.360  &lt; 2e-16 ***\nDESTIN_SZSKSZ01      -0.0374952  0.0066885    -5.606 2.07e-08 ***\nDESTIN_SZSKSZ02       0.7271418  0.0050281   144.617  &lt; 2e-16 ***\nDESTIN_SZSKSZ03      -0.0640794  0.0059146   -10.834  &lt; 2e-16 ***\nDESTIN_SZSKSZ04      -0.5610767  0.0139676   -40.170  &lt; 2e-16 ***\nDESTIN_SZSKSZ05       0.1510974  0.0104871    14.408  &lt; 2e-16 ***\nDESTIN_SZSLSZ01      -0.5823031  0.0083356   -69.858  &lt; 2e-16 ***\nDESTIN_SZSLSZ04      -0.8166665  0.0070329  -116.122  &lt; 2e-16 ***\nDESTIN_SZSRSZ01      -2.3241796  0.0127215  -182.696  &lt; 2e-16 ***\nDESTIN_SZTHSZ01      -2.8157635  0.0366840   -76.757  &lt; 2e-16 ***\nDESTIN_SZTHSZ03      -2.1005978  0.0250842   -83.742  &lt; 2e-16 ***\nDESTIN_SZTHSZ04      -2.1246250  0.0213690   -99.425  &lt; 2e-16 ***\nDESTIN_SZTHSZ06      -1.4571092  0.0150031   -97.121  &lt; 2e-16 ***\nDESTIN_SZTMSZ01      -0.1234559  0.0055152   -22.385  &lt; 2e-16 ***\nDESTIN_SZTMSZ02       1.5961628  0.0032599   489.635  &lt; 2e-16 ***\nDESTIN_SZTMSZ03       0.6977233  0.0037138   187.875  &lt; 2e-16 ***\nDESTIN_SZTMSZ04       0.8606606  0.0037592   228.947  &lt; 2e-16 ***\nDESTIN_SZTMSZ05       0.3750655  0.0051281    73.140  &lt; 2e-16 ***\nDESTIN_SZTNSZ01      -1.2624562  0.0066979  -188.485  &lt; 2e-16 ***\nDESTIN_SZTNSZ02      -2.0761581  0.0096538  -215.062  &lt; 2e-16 ***\nDESTIN_SZTNSZ03      -2.1128125  0.0115717  -182.584  &lt; 2e-16 ***\nDESTIN_SZTNSZ04      -1.2417494  0.0068502  -181.271  &lt; 2e-16 ***\nDESTIN_SZTPSZ01      -0.7094356  0.0055768  -127.211  &lt; 2e-16 ***\nDESTIN_SZTPSZ02       0.1491604  0.0037260    40.032  &lt; 2e-16 ***\nDESTIN_SZTPSZ03      -0.4973355  0.0054878   -90.626  &lt; 2e-16 ***\nDESTIN_SZTPSZ04      -1.5160395  0.0071592  -211.761  &lt; 2e-16 ***\nDESTIN_SZTPSZ05      -0.9196565  0.0056750  -162.054  &lt; 2e-16 ***\nDESTIN_SZTPSZ06      -0.2710649  0.0062637   -43.276  &lt; 2e-16 ***\nDESTIN_SZTPSZ07      -2.0198681  0.0116556  -173.296  &lt; 2e-16 ***\nDESTIN_SZTPSZ08      -1.4881412  0.0085532  -173.987  &lt; 2e-16 ***\nDESTIN_SZTPSZ09      -0.5901273  0.0059394   -99.358  &lt; 2e-16 ***\nDESTIN_SZTPSZ10      -1.1215711  0.0084488  -132.749  &lt; 2e-16 ***\nDESTIN_SZTPSZ11      -0.4837089  0.0050905   -95.022  &lt; 2e-16 ***\nDESTIN_SZTPSZ12      -0.8653927  0.0061326  -141.113  &lt; 2e-16 ***\nDESTIN_SZTSSZ01      -0.5515103  0.0208541   -26.446  &lt; 2e-16 ***\nDESTIN_SZTSSZ02       0.8373778  0.0093757    89.314  &lt; 2e-16 ***\nDESTIN_SZTSSZ03       1.7021888  0.0064394   264.340  &lt; 2e-16 ***\nDESTIN_SZTSSZ04       1.5355016  0.0067855   226.292  &lt; 2e-16 ***\nDESTIN_SZTSSZ05       1.6932319  0.0073725   229.668  &lt; 2e-16 ***\nDESTIN_SZTSSZ06       0.4567808  0.0137927    33.118  &lt; 2e-16 ***\nDESTIN_SZWCSZ01       1.3967640  0.0045392   307.711  &lt; 2e-16 ***\nDESTIN_SZWCSZ02      -0.4560229  0.0122949   -37.090  &lt; 2e-16 ***\nDESTIN_SZWCSZ03      -2.0710051  0.0325121   -63.699  &lt; 2e-16 ***\nDESTIN_SZWDSZ01       1.5137342  0.0034774   435.310  &lt; 2e-16 ***\nDESTIN_SZWDSZ02      -0.3005475  0.0055149   -54.497  &lt; 2e-16 ***\nDESTIN_SZWDSZ03       1.2514543  0.0036112   346.550  &lt; 2e-16 ***\nDESTIN_SZWDSZ04      -0.1702528  0.0058295   -29.205  &lt; 2e-16 ***\nDESTIN_SZWDSZ05      -0.0005419  0.0053911    -0.101  0.91994    \nDESTIN_SZWDSZ06       0.5203361  0.0040318   129.058  &lt; 2e-16 ***\nDESTIN_SZWDSZ07       0.6006472  0.0061745    97.279  &lt; 2e-16 ***\nDESTIN_SZWDSZ08       0.6650867  0.0060867   109.268  &lt; 2e-16 ***\nDESTIN_SZWDSZ09       0.6237312  0.0044830   139.132  &lt; 2e-16 ***\nDESTIN_SZYSSZ01       1.0471638  0.0038255   273.732  &lt; 2e-16 ***\nDESTIN_SZYSSZ02       0.2341114  0.0048213    48.558  &lt; 2e-16 ***\nDESTIN_SZYSSZ03      -0.0916446  0.0051335   -17.852  &lt; 2e-16 ***\nDESTIN_SZYSSZ04      -0.0085536  0.0048684    -1.757  0.07892 .  \nDESTIN_SZYSSZ05      -1.5775071  0.0100297  -157.283  &lt; 2e-16 ***\nDESTIN_SZYSSZ06      -1.8130307  0.0098617  -183.846  &lt; 2e-16 ***\nDESTIN_SZYSSZ07      -1.1703963  0.0111525  -104.945  &lt; 2e-16 ***\nDESTIN_SZYSSZ08       0.5253514  0.0039556   132.813  &lt; 2e-16 ***\nDESTIN_SZYSSZ09       0.4353435  0.0038890   111.943  &lt; 2e-16 ***\nlog(ORIGIN_AGE25_64)  0.2249135  0.0001404  1602.353  &lt; 2e-16 ***\nlog(dist)            -0.6989356  0.0001287 -5431.279  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 60796037  on 14733  degrees of freedom\nResidual deviance: 26208384  on 14452  degrees of freedom\nAIC: 26300575\n\nNumber of Fisher Scoring iterations: 7\n\n\nNow to examine how the constraints hold for destinations this time.\n\nCalcRSquared(decSIM$data$TRIPS, decSIM$fitted.values)\n\n[1] 0.4972985\n\n\n\n\n8.8 Doubly constrained\nThis section demonstrates fitting a doubly constrained Spatial Interaction Model (SIM) using the code chunk below.\nThe general formula for a Doubly Constrained Spatial Interaction Model is outlined below.\n\n\ndbcSIM &lt;- glm(formula = TRIPS ~ \n                ORIGIN_SZ + \n                DESTIN_SZ + \n                log(dist),\n              family = poisson(link = \"log\"),\n              data = SIM_data,\n              na.action = na.exclude)\nsummary(dbcSIM)\n\n\nCall:\nglm(formula = TRIPS ~ ORIGIN_SZ + DESTIN_SZ + log(dist), family = poisson(link = \"log\"), \n    data = SIM_data, na.action = na.exclude)\n\nCoefficients:\n                  Estimate Std. Error   z value Pr(&gt;|z|)    \n(Intercept)     12.4165310  0.0043949  2825.242  &lt; 2e-16 ***\nORIGIN_SZAMSZ02  0.9496891  0.0045740   207.630  &lt; 2e-16 ***\nORIGIN_SZAMSZ03  0.5519174  0.0046672   118.253  &lt; 2e-16 ***\nORIGIN_SZAMSZ04  0.1028140  0.0052468    19.596  &lt; 2e-16 ***\nORIGIN_SZAMSZ05  0.0822549  0.0058663    14.022  &lt; 2e-16 ***\nORIGIN_SZAMSZ06  0.6617809  0.0052580   125.861  &lt; 2e-16 ***\nORIGIN_SZAMSZ07 -0.9508298  0.0097681   -97.340  &lt; 2e-16 ***\nORIGIN_SZAMSZ08 -0.7271779  0.0090946   -79.958  &lt; 2e-16 ***\nORIGIN_SZAMSZ09  0.4896781  0.0055203    88.704  &lt; 2e-16 ***\nORIGIN_SZAMSZ10  0.4819428  0.0048175   100.040  &lt; 2e-16 ***\nORIGIN_SZAMSZ11 -1.7719841  0.0130695  -135.582  &lt; 2e-16 ***\nORIGIN_SZAMSZ12 -1.7679107  0.0108777  -162.526  &lt; 2e-16 ***\nORIGIN_SZBDSZ01  0.8314812  0.0045187   184.010  &lt; 2e-16 ***\nORIGIN_SZBDSZ02  0.4305836  0.0052535    81.961  &lt; 2e-16 ***\nORIGIN_SZBDSZ03  0.8009370  0.0046384   172.676  &lt; 2e-16 ***\nORIGIN_SZBDSZ04  1.4562985  0.0040456   359.971  &lt; 2e-16 ***\nORIGIN_SZBDSZ05  0.4501939  0.0046960    95.867  &lt; 2e-16 ***\nORIGIN_SZBDSZ06  0.7745026  0.0047424   163.314  &lt; 2e-16 ***\nORIGIN_SZBDSZ07 -1.1784123  0.0098105  -120.117  &lt; 2e-16 ***\nORIGIN_SZBDSZ08 -0.9830996  0.0091135  -107.873  &lt; 2e-16 ***\nORIGIN_SZBKSZ01 -0.3042966  0.0067086   -45.359  &lt; 2e-16 ***\nORIGIN_SZBKSZ02  0.4801541  0.0054160    88.655  &lt; 2e-16 ***\nORIGIN_SZBKSZ03  0.7823931  0.0052007   150.440  &lt; 2e-16 ***\nORIGIN_SZBKSZ04 -0.1292545  0.0061735   -20.937  &lt; 2e-16 ***\nORIGIN_SZBKSZ05 -0.0258584  0.0060192    -4.296 1.74e-05 ***\nORIGIN_SZBKSZ06  0.1994719  0.0061206    32.590  &lt; 2e-16 ***\nORIGIN_SZBKSZ07  0.7434860  0.0046598   159.553  &lt; 2e-16 ***\nORIGIN_SZBKSZ08  0.1625007  0.0055219    29.428  &lt; 2e-16 ***\nORIGIN_SZBKSZ09 -0.0864293  0.0059533   -14.518  &lt; 2e-16 ***\nORIGIN_SZBLSZ01 -2.1022485  0.0150316  -139.855  &lt; 2e-16 ***\nORIGIN_SZBLSZ02 -2.9460181  0.0195760  -150.491  &lt; 2e-16 ***\nORIGIN_SZBLSZ03 -4.9412872  0.0398540  -123.985  &lt; 2e-16 ***\nORIGIN_SZBLSZ04 -2.8143593  0.0239209  -117.653  &lt; 2e-16 ***\nORIGIN_SZBMSZ01 -0.0264561  0.0053639    -4.932 8.13e-07 ***\nORIGIN_SZBMSZ02 -0.8656513  0.0068511  -126.353  &lt; 2e-16 ***\nORIGIN_SZBMSZ03 -0.1723467  0.0059613   -28.911  &lt; 2e-16 ***\nORIGIN_SZBMSZ04  0.2169844  0.0053578    40.499  &lt; 2e-16 ***\nORIGIN_SZBMSZ05 -2.0252956  0.0126107  -160.602  &lt; 2e-16 ***\nORIGIN_SZBMSZ06 -1.7642018  0.0163931  -107.619  &lt; 2e-16 ***\nORIGIN_SZBMSZ07 -0.3271629  0.0058137   -56.274  &lt; 2e-16 ***\nORIGIN_SZBMSZ08 -0.2533255  0.0059335   -42.694  &lt; 2e-16 ***\nORIGIN_SZBMSZ09 -0.7712635  0.0087939   -87.704  &lt; 2e-16 ***\nORIGIN_SZBMSZ10 -1.0098048  0.0092519  -109.145  &lt; 2e-16 ***\nORIGIN_SZBMSZ11 -0.3816187  0.0067302   -56.702  &lt; 2e-16 ***\nORIGIN_SZBMSZ12 -0.6666616  0.0095680   -69.676  &lt; 2e-16 ***\nORIGIN_SZBMSZ13 -0.0076108  0.0059040    -1.289  0.19737    \nORIGIN_SZBMSZ14 -0.1682476  0.0069391   -24.246  &lt; 2e-16 ***\nORIGIN_SZBMSZ15  0.0904585  0.0062822    14.399  &lt; 2e-16 ***\nORIGIN_SZBMSZ16 -1.1808741  0.0092258  -127.997  &lt; 2e-16 ***\nORIGIN_SZBMSZ17 -1.7189127  0.0158408  -108.512  &lt; 2e-16 ***\nORIGIN_SZBPSZ01  0.4294645  0.0058051    73.980  &lt; 2e-16 ***\nORIGIN_SZBPSZ02  0.5028906  0.0068169    73.771  &lt; 2e-16 ***\nORIGIN_SZBPSZ03  0.6656178  0.0066126   100.658  &lt; 2e-16 ***\nORIGIN_SZBPSZ04  0.5203612  0.0053224    97.769  &lt; 2e-16 ***\nORIGIN_SZBPSZ05  0.5377769  0.0047907   112.256  &lt; 2e-16 ***\nORIGIN_SZBPSZ06 -1.2327809  0.0094950  -129.835  &lt; 2e-16 ***\nORIGIN_SZBPSZ07 -0.9035255  0.0088739  -101.818  &lt; 2e-16 ***\nORIGIN_SZBSSZ01  0.1210027  0.0053990    22.412  &lt; 2e-16 ***\nORIGIN_SZBSSZ02  0.4618449  0.0048641    94.951  &lt; 2e-16 ***\nORIGIN_SZBSSZ03  0.2160739  0.0047835    45.170  &lt; 2e-16 ***\nORIGIN_SZBTSZ01 -0.1108042  0.0055599   -19.929  &lt; 2e-16 ***\nORIGIN_SZBTSZ02 -0.8911221  0.0079213  -112.498  &lt; 2e-16 ***\nORIGIN_SZBTSZ03 -0.2203980  0.0059325   -37.151  &lt; 2e-16 ***\nORIGIN_SZBTSZ04 -0.6427946  0.0105438   -60.964  &lt; 2e-16 ***\nORIGIN_SZBTSZ05 -1.4662312  0.0111784  -131.166  &lt; 2e-16 ***\nORIGIN_SZBTSZ06 -0.6105884  0.0073456   -83.123  &lt; 2e-16 ***\nORIGIN_SZBTSZ07 -1.9041317  0.0132781  -143.404  &lt; 2e-16 ***\nORIGIN_SZBTSZ08 -1.0627939  0.0095982  -110.728  &lt; 2e-16 ***\nORIGIN_SZCBSZ01 -2.9365941  0.0548632   -53.526  &lt; 2e-16 ***\nORIGIN_SZCCSZ01 -1.5313555  0.0134599  -113.772  &lt; 2e-16 ***\nORIGIN_SZCHSZ01 -1.2034494  0.0119468  -100.734  &lt; 2e-16 ***\nORIGIN_SZCHSZ02 -0.8299415  0.0081984  -101.232  &lt; 2e-16 ***\nORIGIN_SZCHSZ03 -0.5143946  0.0061944   -83.042  &lt; 2e-16 ***\nORIGIN_SZCKSZ01  0.2372583  0.0053612    44.255  &lt; 2e-16 ***\nORIGIN_SZCKSZ02  0.9124836  0.0054472   167.515  &lt; 2e-16 ***\nORIGIN_SZCKSZ03  0.7237808  0.0048401   149.539  &lt; 2e-16 ***\nORIGIN_SZCKSZ04  1.6884022  0.0050169   336.540  &lt; 2e-16 ***\nORIGIN_SZCKSZ05  1.3932005  0.0062346   223.464  &lt; 2e-16 ***\nORIGIN_SZCKSZ06  1.0670053  0.0066112   161.394  &lt; 2e-16 ***\nORIGIN_SZCLSZ01 -0.8602837  0.0079240  -108.567  &lt; 2e-16 ***\nORIGIN_SZCLSZ02 -1.3853421  0.0137444  -100.793  &lt; 2e-16 ***\nORIGIN_SZCLSZ03 -0.8582608  0.0081177  -105.727  &lt; 2e-16 ***\nORIGIN_SZCLSZ04  0.7836027  0.0046427   168.782  &lt; 2e-16 ***\nORIGIN_SZCLSZ05 -1.8121756  0.0148960  -121.655  &lt; 2e-16 ***\nORIGIN_SZCLSZ06  0.8296870  0.0043909   188.955  &lt; 2e-16 ***\nORIGIN_SZCLSZ07 -0.2325219  0.0057432   -40.487  &lt; 2e-16 ***\nORIGIN_SZCLSZ08  0.2714336  0.0062625    43.342  &lt; 2e-16 ***\nORIGIN_SZCLSZ09 -2.2223744  0.0160946  -138.082  &lt; 2e-16 ***\nORIGIN_SZDTSZ02 -4.0704970  0.0834192   -48.796  &lt; 2e-16 ***\nORIGIN_SZDTSZ03 -3.4529031  0.0738295   -46.769  &lt; 2e-16 ***\nORIGIN_SZDTSZ13 -2.8301983  0.0313085   -90.397  &lt; 2e-16 ***\nORIGIN_SZGLSZ01 -1.4674986  0.0093137  -157.563  &lt; 2e-16 ***\nORIGIN_SZGLSZ02  0.2749369  0.0050051    54.931  &lt; 2e-16 ***\nORIGIN_SZGLSZ03  0.0781954  0.0049748    15.718  &lt; 2e-16 ***\nORIGIN_SZGLSZ04  0.8167797  0.0043260   188.808  &lt; 2e-16 ***\nORIGIN_SZGLSZ05  0.5277509  0.0044879   117.595  &lt; 2e-16 ***\nORIGIN_SZHGSZ01  0.2323885  0.0048555    47.861  &lt; 2e-16 ***\nORIGIN_SZHGSZ02  0.5707182  0.0048256   118.268  &lt; 2e-16 ***\nORIGIN_SZHGSZ03  0.4231170  0.0052149    81.136  &lt; 2e-16 ***\nORIGIN_SZHGSZ04  0.9341168  0.0044128   211.681  &lt; 2e-16 ***\nORIGIN_SZHGSZ05  1.2192790  0.0043790   278.437  &lt; 2e-16 ***\nORIGIN_SZHGSZ06  0.0490041  0.0054961     8.916  &lt; 2e-16 ***\nORIGIN_SZHGSZ07  0.6337041  0.0045735   138.559  &lt; 2e-16 ***\nORIGIN_SZHGSZ08  0.0312612  0.0054684     5.717 1.09e-08 ***\nORIGIN_SZHGSZ09 -0.6985397  0.0071800   -97.289  &lt; 2e-16 ***\nORIGIN_SZHGSZ10 -2.9958967  0.0422303   -70.942  &lt; 2e-16 ***\nORIGIN_SZJESZ01  0.4363431  0.0051329    85.010  &lt; 2e-16 ***\nORIGIN_SZJESZ02  0.3460900  0.0051372    67.370  &lt; 2e-16 ***\nORIGIN_SZJESZ03  0.2928005  0.0055108    53.132  &lt; 2e-16 ***\nORIGIN_SZJESZ04 -1.1924298  0.0093540  -127.478  &lt; 2e-16 ***\nORIGIN_SZJESZ05 -2.0178136  0.0139479  -144.668  &lt; 2e-16 ***\nORIGIN_SZJESZ06  0.1637633  0.0050685    32.310  &lt; 2e-16 ***\nORIGIN_SZJESZ07 -1.8227460  0.0119383  -152.680  &lt; 2e-16 ***\nORIGIN_SZJESZ08 -1.1556281  0.0117870   -98.043  &lt; 2e-16 ***\nORIGIN_SZJESZ09  0.4766229  0.0052813    90.248  &lt; 2e-16 ***\nORIGIN_SZJESZ10 -2.6868992  0.0186864  -143.789  &lt; 2e-16 ***\nORIGIN_SZJESZ11 -3.0618150  0.0199755  -153.278  &lt; 2e-16 ***\nORIGIN_SZJWSZ01  0.4417418  0.0068611    64.383  &lt; 2e-16 ***\nORIGIN_SZJWSZ02  0.9738087  0.0047905   203.281  &lt; 2e-16 ***\nORIGIN_SZJWSZ03  1.1548028  0.0045180   255.599  &lt; 2e-16 ***\nORIGIN_SZJWSZ04  0.9078417  0.0046668   194.532  &lt; 2e-16 ***\nORIGIN_SZJWSZ05 -1.7092500  0.0127422  -134.141  &lt; 2e-16 ***\nORIGIN_SZJWSZ06 -1.3284287  0.0109785  -121.002  &lt; 2e-16 ***\nORIGIN_SZJWSZ07 -2.3231549  0.0281427   -82.549  &lt; 2e-16 ***\nORIGIN_SZJWSZ08  1.9386127  0.0046041   421.059  &lt; 2e-16 ***\nORIGIN_SZJWSZ09  1.3987549  0.0042610   328.266  &lt; 2e-16 ***\nORIGIN_SZKLSZ01  0.2617735  0.0050089    52.261  &lt; 2e-16 ***\nORIGIN_SZKLSZ02 -0.4325093  0.0064279   -67.286  &lt; 2e-16 ***\nORIGIN_SZKLSZ03 -0.2787173  0.0060380   -46.161  &lt; 2e-16 ***\nORIGIN_SZKLSZ04 -1.9432693  0.0119163  -163.076  &lt; 2e-16 ***\nORIGIN_SZKLSZ05 -0.5420067  0.0085529   -63.371  &lt; 2e-16 ***\nORIGIN_SZKLSZ06 -4.2949009  0.1857686   -23.120  &lt; 2e-16 ***\nORIGIN_SZKLSZ07 -0.8576946  0.0085178  -100.694  &lt; 2e-16 ***\nORIGIN_SZKLSZ08 -1.3840925  0.0092323  -149.918  &lt; 2e-16 ***\nORIGIN_SZLKSZ01 -2.8108510  0.0392356   -71.640  &lt; 2e-16 ***\nORIGIN_SZMDSZ01 -1.6745388  0.0296543   -56.469  &lt; 2e-16 ***\nORIGIN_SZMDSZ02 -0.8193738  0.0106631   -76.842  &lt; 2e-16 ***\nORIGIN_SZMDSZ03 -1.5088267  0.0172032   -87.706  &lt; 2e-16 ***\nORIGIN_SZMPSZ01 -0.9860154  0.0085053  -115.929  &lt; 2e-16 ***\nORIGIN_SZMPSZ02 -0.5958875  0.0070097   -85.008  &lt; 2e-16 ***\nORIGIN_SZMPSZ03 -0.0490122  0.0054582    -8.980  &lt; 2e-16 ***\nORIGIN_SZMUSZ02 -3.5233367  0.1037749   -33.952  &lt; 2e-16 ***\nORIGIN_SZNTSZ01 -2.6451541  0.0353125   -74.907  &lt; 2e-16 ***\nORIGIN_SZNTSZ02 -2.7710546  0.0232841  -119.011  &lt; 2e-16 ***\nORIGIN_SZNTSZ03 -0.6123404  0.0079083   -77.430  &lt; 2e-16 ***\nORIGIN_SZNTSZ05 -2.9257445  0.0496704   -58.903  &lt; 2e-16 ***\nORIGIN_SZNTSZ06 -3.3260031  0.0557966   -59.609  &lt; 2e-16 ***\nORIGIN_SZNVSZ01  0.6421306  0.0046037   139.482  &lt; 2e-16 ***\nORIGIN_SZNVSZ02 -0.4251550  0.0065890   -64.525  &lt; 2e-16 ***\nORIGIN_SZNVSZ03 -1.0765622  0.0078766  -136.679  &lt; 2e-16 ***\nORIGIN_SZNVSZ04 -1.2289504  0.0091468  -134.358  &lt; 2e-16 ***\nORIGIN_SZNVSZ05 -2.3551389  0.0158219  -148.853  &lt; 2e-16 ***\nORIGIN_SZPGSZ01  0.1518212  0.0154825     9.806  &lt; 2e-16 ***\nORIGIN_SZPGSZ02 -0.4062609  0.0073780   -55.064  &lt; 2e-16 ***\nORIGIN_SZPGSZ03  0.8976913  0.0046122   194.636  &lt; 2e-16 ***\nORIGIN_SZPGSZ04  1.1161685  0.0045850   243.437  &lt; 2e-16 ***\nORIGIN_SZPGSZ05  0.4794249  0.0060213    79.621  &lt; 2e-16 ***\nORIGIN_SZPLSZ01 -0.8322377  0.0107898   -77.132  &lt; 2e-16 ***\nORIGIN_SZPLSZ02 -1.2968937  0.0149841   -86.551  &lt; 2e-16 ***\nORIGIN_SZPLSZ03 -3.2744991  0.0374541   -87.427  &lt; 2e-16 ***\nORIGIN_SZPLSZ04 -3.5423615  0.0372570   -95.079  &lt; 2e-16 ***\nORIGIN_SZPLSZ05 -2.4343705  0.0227807  -106.861  &lt; 2e-16 ***\nORIGIN_SZPNSZ01  0.8052461  0.0056124   143.476  &lt; 2e-16 ***\nORIGIN_SZPNSZ02 -1.8042362  0.0128222  -140.712  &lt; 2e-16 ***\nORIGIN_SZPNSZ03 -2.6363996  0.0200058  -131.782  &lt; 2e-16 ***\nORIGIN_SZPNSZ04 -4.8427070  0.0320126  -151.275  &lt; 2e-16 ***\nORIGIN_SZPNSZ05 -3.6613775  0.0285686  -128.161  &lt; 2e-16 ***\nORIGIN_SZPRSZ01 -0.5645384  0.0117126   -48.199  &lt; 2e-16 ***\nORIGIN_SZPRSZ02  0.9145886  0.0048137   189.998  &lt; 2e-16 ***\nORIGIN_SZPRSZ03  0.4478971  0.0048102    93.113  &lt; 2e-16 ***\nORIGIN_SZPRSZ04 -0.5312444  0.0079019   -67.230  &lt; 2e-16 ***\nORIGIN_SZPRSZ05  1.1462662  0.0045250   253.318  &lt; 2e-16 ***\nORIGIN_SZPRSZ06 -0.7392744  0.0090347   -81.826  &lt; 2e-16 ***\nORIGIN_SZPRSZ07 -2.1667862  0.0162528  -133.318  &lt; 2e-16 ***\nORIGIN_SZPRSZ08 -0.1327079  0.0065712   -20.195  &lt; 2e-16 ***\nORIGIN_SZQTSZ01  0.1062151  0.0071538    14.847  &lt; 2e-16 ***\nORIGIN_SZQTSZ02 -0.4993990  0.0064382   -77.568  &lt; 2e-16 ***\nORIGIN_SZQTSZ03  0.1161844  0.0058822    19.752  &lt; 2e-16 ***\nORIGIN_SZQTSZ04 -0.8102612  0.0072742  -111.389  &lt; 2e-16 ***\nORIGIN_SZQTSZ05 -0.0417272  0.0061917    -6.739 1.59e-11 ***\nORIGIN_SZQTSZ06 -0.2521417  0.0066449   -37.945  &lt; 2e-16 ***\nORIGIN_SZQTSZ07 -1.2395975  0.0097496  -127.143  &lt; 2e-16 ***\nORIGIN_SZQTSZ08 -0.1105467  0.0059364   -18.622  &lt; 2e-16 ***\nORIGIN_SZQTSZ09 -0.5078461  0.0067895   -74.798  &lt; 2e-16 ***\nORIGIN_SZQTSZ10 -0.3866593  0.0066995   -57.714  &lt; 2e-16 ***\nORIGIN_SZQTSZ11 -1.5264609  0.0099770  -152.998  &lt; 2e-16 ***\nORIGIN_SZQTSZ12 -1.3866518  0.0106887  -129.730  &lt; 2e-16 ***\nORIGIN_SZQTSZ13 -0.3764286  0.0066707   -56.430  &lt; 2e-16 ***\nORIGIN_SZQTSZ14 -1.4907399  0.0100120  -148.896  &lt; 2e-16 ***\nORIGIN_SZQTSZ15 -1.0552239  0.0108792   -96.994  &lt; 2e-16 ***\nORIGIN_SZRCSZ01 -1.3136074  0.0126986  -103.445  &lt; 2e-16 ***\nORIGIN_SZRCSZ06 -0.2418276  0.0085509   -28.281  &lt; 2e-16 ***\nORIGIN_SZRVSZ01 -2.9263747  0.0324968   -90.051  &lt; 2e-16 ***\nORIGIN_SZRVSZ02 -2.2980940  0.0278202   -82.605  &lt; 2e-16 ***\nORIGIN_SZRVSZ03 -2.4663765  0.0238674  -103.336  &lt; 2e-16 ***\nORIGIN_SZRVSZ04 -3.1853677  0.0556939   -57.194  &lt; 2e-16 ***\nORIGIN_SZRVSZ05 -1.5695490  0.0166684   -94.163  &lt; 2e-16 ***\nORIGIN_SZSBSZ01  0.7674590  0.0061811   124.163  &lt; 2e-16 ***\nORIGIN_SZSBSZ02 -0.7307279  0.0084105   -86.883  &lt; 2e-16 ***\nORIGIN_SZSBSZ03  0.5920074  0.0050167   118.008  &lt; 2e-16 ***\nORIGIN_SZSBSZ04  0.3684857  0.0058575    62.908  &lt; 2e-16 ***\nORIGIN_SZSBSZ05 -0.0036863  0.0068459    -0.538  0.59026    \nORIGIN_SZSBSZ06 -1.1939284  0.0181541   -65.766  &lt; 2e-16 ***\nORIGIN_SZSBSZ07 -0.4896579  0.0135618   -36.106  &lt; 2e-16 ***\nORIGIN_SZSBSZ08 -2.1221691  0.0127258  -166.762  &lt; 2e-16 ***\nORIGIN_SZSBSZ09 -1.2032410  0.0089611  -134.273  &lt; 2e-16 ***\nORIGIN_SZSESZ02  1.0721820  0.0045336   236.498  &lt; 2e-16 ***\nORIGIN_SZSESZ03  1.0808012  0.0042923   251.801  &lt; 2e-16 ***\nORIGIN_SZSESZ04  1.0137448  0.0050668   200.076  &lt; 2e-16 ***\nORIGIN_SZSESZ05 -0.1678679  0.0060206   -27.882  &lt; 2e-16 ***\nORIGIN_SZSESZ06  0.9165834  0.0048323   189.677  &lt; 2e-16 ***\nORIGIN_SZSESZ07 -2.2499789  0.0196327  -114.603  &lt; 2e-16 ***\nORIGIN_SZSGSZ01 -0.9369800  0.0087282  -107.351  &lt; 2e-16 ***\nORIGIN_SZSGSZ02 -1.1690716  0.0097131  -120.360  &lt; 2e-16 ***\nORIGIN_SZSGSZ03  0.2604352  0.0052709    49.410  &lt; 2e-16 ***\nORIGIN_SZSGSZ04  0.3468823  0.0048897    70.942  &lt; 2e-16 ***\nORIGIN_SZSGSZ05 -1.5927797  0.0106308  -149.827  &lt; 2e-16 ***\nORIGIN_SZSGSZ06  0.3605651  0.0046361    77.774  &lt; 2e-16 ***\nORIGIN_SZSGSZ07 -0.5333873  0.0063119   -84.504  &lt; 2e-16 ***\nORIGIN_SZSKSZ01 -0.2706750  0.0082836   -32.676  &lt; 2e-16 ***\nORIGIN_SZSKSZ02  0.0970953  0.0063378    15.320  &lt; 2e-16 ***\nORIGIN_SZSKSZ03 -0.6954342  0.0082538   -84.256  &lt; 2e-16 ***\nORIGIN_SZSKSZ04 -2.3863580  0.0284607   -83.847  &lt; 2e-16 ***\nORIGIN_SZSKSZ05 -1.5443140  0.0179059   -86.246  &lt; 2e-16 ***\nORIGIN_SZSLSZ01 -2.9450656  0.0307283   -95.842  &lt; 2e-16 ***\nORIGIN_SZSLSZ04 -0.5739349  0.0077851   -73.722  &lt; 2e-16 ***\nORIGIN_SZSRSZ01 -1.6136735  0.0160199  -100.729  &lt; 2e-16 ***\nORIGIN_SZTHSZ01 -2.6034976  0.0489378   -53.200  &lt; 2e-16 ***\nORIGIN_SZTHSZ03 -1.2770601  0.0229815   -55.569  &lt; 2e-16 ***\nORIGIN_SZTHSZ04 -2.0110399  0.0287527   -69.943  &lt; 2e-16 ***\nORIGIN_SZTHSZ06 -1.7720116  0.0180394   -98.230  &lt; 2e-16 ***\nORIGIN_SZTMSZ01  0.1254729  0.0060924    20.595  &lt; 2e-16 ***\nORIGIN_SZTMSZ02  1.6667504  0.0039836   418.403  &lt; 2e-16 ***\nORIGIN_SZTMSZ03  1.0941176  0.0042911   254.976  &lt; 2e-16 ***\nORIGIN_SZTMSZ04  0.3209520  0.0050349    63.746  &lt; 2e-16 ***\nORIGIN_SZTMSZ05 -0.8155124  0.0079342  -102.785  &lt; 2e-16 ***\nORIGIN_SZTNSZ01 -1.4237298  0.0104636  -136.064  &lt; 2e-16 ***\nORIGIN_SZTNSZ02 -1.2718890  0.0098660  -128.916  &lt; 2e-16 ***\nORIGIN_SZTNSZ03 -1.7960517  0.0134675  -133.362  &lt; 2e-16 ***\nORIGIN_SZTNSZ04 -0.3508142  0.0073556   -47.694  &lt; 2e-16 ***\nORIGIN_SZTPSZ01 -0.3841699  0.0064137   -59.898  &lt; 2e-16 ***\nORIGIN_SZTPSZ02  0.5315265  0.0044497   119.451  &lt; 2e-16 ***\nORIGIN_SZTPSZ03 -0.4669723  0.0062160   -75.124  &lt; 2e-16 ***\nORIGIN_SZTPSZ04 -0.0617169  0.0058830   -10.491  &lt; 2e-16 ***\nORIGIN_SZTPSZ05  0.0713309  0.0062133    11.480  &lt; 2e-16 ***\nORIGIN_SZTPSZ06  0.6800356  0.0069456    97.909  &lt; 2e-16 ***\nORIGIN_SZTPSZ07 -0.0432782  0.0064382    -6.722 1.79e-11 ***\nORIGIN_SZTPSZ08 -0.6976429  0.0092416   -75.490  &lt; 2e-16 ***\nORIGIN_SZTPSZ09 -0.3708833  0.0063548   -58.363  &lt; 2e-16 ***\nORIGIN_SZTPSZ10 -0.4063575  0.0077803   -52.229  &lt; 2e-16 ***\nORIGIN_SZTPSZ11  0.1040282  0.0056115    18.538  &lt; 2e-16 ***\nORIGIN_SZTPSZ12 -0.5104672  0.0066261   -77.039  &lt; 2e-16 ***\nORIGIN_SZTSSZ01 -3.5036830  0.0487290   -71.901  &lt; 2e-16 ***\nORIGIN_SZTSSZ02 -0.0386819  0.0094886    -4.077 4.57e-05 ***\nORIGIN_SZTSSZ03 -0.3862387  0.0095139   -40.597  &lt; 2e-16 ***\nORIGIN_SZTSSZ04 -0.6380676  0.0099905   -63.867  &lt; 2e-16 ***\nORIGIN_SZTSSZ05 -2.7354613  0.0162414  -168.425  &lt; 2e-16 ***\nORIGIN_SZTSSZ06 -2.6310865  0.0255772  -102.868  &lt; 2e-16 ***\nORIGIN_SZWCSZ01 -1.1561047  0.0087394  -132.286  &lt; 2e-16 ***\nORIGIN_SZWCSZ02 -2.6956217  0.0319117   -84.471  &lt; 2e-16 ***\nORIGIN_SZWCSZ03 -4.3526889  0.1241082   -35.072  &lt; 2e-16 ***\nORIGIN_SZWDSZ01  0.8712417  0.0043720   199.277  &lt; 2e-16 ***\nORIGIN_SZWDSZ02  0.9119539  0.0050326   181.210  &lt; 2e-16 ***\nORIGIN_SZWDSZ03  1.6205678  0.0045250   358.136  &lt; 2e-16 ***\nORIGIN_SZWDSZ04  1.2081941  0.0054272   222.618  &lt; 2e-16 ***\nORIGIN_SZWDSZ05  0.4284783  0.0052752    81.224  &lt; 2e-16 ***\nORIGIN_SZWDSZ06  0.9018716  0.0049820   181.028  &lt; 2e-16 ***\nORIGIN_SZWDSZ07 -0.6444820  0.0084731   -76.062  &lt; 2e-16 ***\nORIGIN_SZWDSZ08 -0.8764983  0.0082622  -106.085  &lt; 2e-16 ***\nORIGIN_SZWDSZ09  1.3292589  0.0048663   273.158  &lt; 2e-16 ***\nORIGIN_SZYSSZ01 -0.4780462  0.0058489   -81.733  &lt; 2e-16 ***\nORIGIN_SZYSSZ02  0.9323419  0.0054402   171.380  &lt; 2e-16 ***\nORIGIN_SZYSSZ03  2.0577240  0.0046737   440.274  &lt; 2e-16 ***\nORIGIN_SZYSSZ04  0.8697472  0.0047269   184.000  &lt; 2e-16 ***\nORIGIN_SZYSSZ05  0.1662764  0.0060376    27.540  &lt; 2e-16 ***\nORIGIN_SZYSSZ06 -0.8115617  0.0109084   -74.398  &lt; 2e-16 ***\nORIGIN_SZYSSZ07 -0.8971248  0.0119220   -75.250  &lt; 2e-16 ***\nORIGIN_SZYSSZ08 -0.2738680  0.0063553   -43.093  &lt; 2e-16 ***\nORIGIN_SZYSSZ09  1.2274518  0.0044951   273.066  &lt; 2e-16 ***\nDESTIN_SZAMSZ02 -0.0516322  0.0042829   -12.055  &lt; 2e-16 ***\nDESTIN_SZAMSZ03  0.0801823  0.0041904    19.135  &lt; 2e-16 ***\nDESTIN_SZAMSZ04 -0.9282211  0.0061322  -151.368  &lt; 2e-16 ***\nDESTIN_SZAMSZ05 -1.0794168  0.0062543  -172.588  &lt; 2e-16 ***\nDESTIN_SZAMSZ06 -0.8839603  0.0060851  -145.267  &lt; 2e-16 ***\nDESTIN_SZAMSZ07 -1.5835093  0.0096846  -163.508  &lt; 2e-16 ***\nDESTIN_SZAMSZ08 -0.9756903  0.0068829  -141.756  &lt; 2e-16 ***\nDESTIN_SZAMSZ09 -1.0362692  0.0061651  -168.087  &lt; 2e-16 ***\nDESTIN_SZAMSZ10 -0.1227646  0.0044788   -27.410  &lt; 2e-16 ***\nDESTIN_SZAMSZ11 -0.4802374  0.0088108   -54.506  &lt; 2e-16 ***\nDESTIN_SZAMSZ12  0.2142621  0.0050653    42.300  &lt; 2e-16 ***\nDESTIN_SZBDSZ01  0.3582789  0.0039578    90.524  &lt; 2e-16 ***\nDESTIN_SZBDSZ02 -0.4368229  0.0051384   -85.012  &lt; 2e-16 ***\nDESTIN_SZBDSZ03 -0.1568727  0.0044329   -35.388  &lt; 2e-16 ***\nDESTIN_SZBDSZ04  0.6731669  0.0036215   185.882  &lt; 2e-16 ***\nDESTIN_SZBDSZ05  0.3647198  0.0040496    90.062  &lt; 2e-16 ***\nDESTIN_SZBDSZ06  0.0589240  0.0044352    13.286  &lt; 2e-16 ***\nDESTIN_SZBDSZ07 -0.6648168  0.0095742   -69.438  &lt; 2e-16 ***\nDESTIN_SZBDSZ08 -1.7214136  0.0106600  -161.483  &lt; 2e-16 ***\nDESTIN_SZBKSZ01 -1.2688264  0.0067263  -188.637  &lt; 2e-16 ***\nDESTIN_SZBKSZ02 -0.3912129  0.0055446   -70.558  &lt; 2e-16 ***\nDESTIN_SZBKSZ03 -0.8663392  0.0058693  -147.605  &lt; 2e-16 ***\nDESTIN_SZBKSZ04 -0.1247273  0.0051254   -24.335  &lt; 2e-16 ***\nDESTIN_SZBKSZ05 -0.7407774  0.0059120  -125.300  &lt; 2e-16 ***\nDESTIN_SZBKSZ06 -0.9934643  0.0063345  -156.834  &lt; 2e-16 ***\nDESTIN_SZBKSZ07  0.0882230  0.0042928    20.551  &lt; 2e-16 ***\nDESTIN_SZBKSZ08 -1.1134447  0.0070752  -157.372  &lt; 2e-16 ***\nDESTIN_SZBKSZ09 -0.1788171  0.0051327   -34.839  &lt; 2e-16 ***\nDESTIN_SZBLSZ01 -0.7696433  0.0071898  -107.047  &lt; 2e-16 ***\nDESTIN_SZBLSZ02  0.4076650  0.0068001    59.950  &lt; 2e-16 ***\nDESTIN_SZBLSZ03  1.5398488  0.0078230   196.836  &lt; 2e-16 ***\nDESTIN_SZBLSZ04 -0.3499486  0.0136985   -25.546  &lt; 2e-16 ***\nDESTIN_SZBMSZ01 -0.2114705  0.0048311   -43.773  &lt; 2e-16 ***\nDESTIN_SZBMSZ02 -0.3316806  0.0049958   -66.391  &lt; 2e-16 ***\nDESTIN_SZBMSZ03 -0.5134774  0.0058534   -87.723  &lt; 2e-16 ***\nDESTIN_SZBMSZ04 -0.2205274  0.0051028   -43.217  &lt; 2e-16 ***\nDESTIN_SZBMSZ05 -0.2101165  0.0067710   -31.032  &lt; 2e-16 ***\nDESTIN_SZBMSZ06 -1.3832385  0.0124821  -110.818  &lt; 2e-16 ***\nDESTIN_SZBMSZ07 -0.0133462  0.0046787    -2.853  0.00434 ** \nDESTIN_SZBMSZ08 -0.9056756  0.0063868  -141.805  &lt; 2e-16 ***\nDESTIN_SZBMSZ09 -2.3175407  0.0144523  -160.358  &lt; 2e-16 ***\nDESTIN_SZBMSZ10 -1.3973725  0.0090463  -154.470  &lt; 2e-16 ***\nDESTIN_SZBMSZ11 -1.3950206  0.0080459  -173.383  &lt; 2e-16 ***\nDESTIN_SZBMSZ12 -0.6882789  0.0081539   -84.411  &lt; 2e-16 ***\nDESTIN_SZBMSZ13 -0.2729120  0.0052969   -51.523  &lt; 2e-16 ***\nDESTIN_SZBMSZ14 -0.7581980  0.0080215   -94.521  &lt; 2e-16 ***\nDESTIN_SZBMSZ15 -0.9323237  0.0071093  -131.142  &lt; 2e-16 ***\nDESTIN_SZBMSZ16 -2.0655530  0.0108490  -190.391  &lt; 2e-16 ***\nDESTIN_SZBMSZ17 -2.5124893  0.0165366  -151.935  &lt; 2e-16 ***\nDESTIN_SZBPSZ01 -0.8203274  0.0057682  -142.216  &lt; 2e-16 ***\nDESTIN_SZBPSZ02 -1.5284265  0.0087447  -174.783  &lt; 2e-16 ***\nDESTIN_SZBPSZ03 -1.2434382  0.0080852  -153.792  &lt; 2e-16 ***\nDESTIN_SZBPSZ04 -0.7778558  0.0060900  -127.727  &lt; 2e-16 ***\nDESTIN_SZBPSZ05  0.1782204  0.0042331    42.101  &lt; 2e-16 ***\nDESTIN_SZBPSZ06 -0.6758807  0.0079728   -84.773  &lt; 2e-16 ***\nDESTIN_SZBPSZ07 -0.5029450  0.0081151   -61.976  &lt; 2e-16 ***\nDESTIN_SZBSSZ01 -0.1269916  0.0046949   -27.049  &lt; 2e-16 ***\nDESTIN_SZBSSZ02 -0.7536917  0.0051895  -145.233  &lt; 2e-16 ***\nDESTIN_SZBSSZ03  0.2747969  0.0039115    70.254  &lt; 2e-16 ***\nDESTIN_SZBTSZ01  0.1708577  0.0043381    39.385  &lt; 2e-16 ***\nDESTIN_SZBTSZ02 -0.6820190  0.0067243  -101.427  &lt; 2e-16 ***\nDESTIN_SZBTSZ03  0.0610599  0.0049825    12.255  &lt; 2e-16 ***\nDESTIN_SZBTSZ04 -1.3199639  0.0107063  -123.288  &lt; 2e-16 ***\nDESTIN_SZBTSZ05 -0.4174991  0.0069221   -60.314  &lt; 2e-16 ***\nDESTIN_SZBTSZ06 -0.5260242  0.0061145   -86.029  &lt; 2e-16 ***\nDESTIN_SZBTSZ07 -1.6678047  0.0106335  -156.844  &lt; 2e-16 ***\nDESTIN_SZBTSZ08 -0.7999935  0.0089175   -89.711  &lt; 2e-16 ***\nDESTIN_SZCBSZ01 -5.6321332  0.3162476   -17.809  &lt; 2e-16 ***\nDESTIN_SZCCSZ01 -0.9342781  0.0081409  -114.763  &lt; 2e-16 ***\nDESTIN_SZCHSZ01 -1.2808546  0.0096774  -132.355  &lt; 2e-16 ***\nDESTIN_SZCHSZ02  0.0067332  0.0054322     1.239  0.21516    \nDESTIN_SZCHSZ03  1.0988838  0.0041378   265.570  &lt; 2e-16 ***\nDESTIN_SZCKSZ01 -0.3192235  0.0050632   -63.048  &lt; 2e-16 ***\nDESTIN_SZCKSZ02 -0.7776453  0.0055279  -140.676  &lt; 2e-16 ***\nDESTIN_SZCKSZ03  0.2772358  0.0042541    65.170  &lt; 2e-16 ***\nDESTIN_SZCKSZ04 -1.3842048  0.0065159  -212.436  &lt; 2e-16 ***\nDESTIN_SZCKSZ05 -1.2051808  0.0076814  -156.897  &lt; 2e-16 ***\nDESTIN_SZCKSZ06  0.1321955  0.0061568    21.472  &lt; 2e-16 ***\nDESTIN_SZCLSZ01  0.1942449  0.0049977    38.867  &lt; 2e-16 ***\nDESTIN_SZCLSZ02 -2.0828648  0.0134597  -154.749  &lt; 2e-16 ***\nDESTIN_SZCLSZ03 -0.8823728  0.0078307  -112.681  &lt; 2e-16 ***\nDESTIN_SZCLSZ04 -0.2311432  0.0047194   -48.977  &lt; 2e-16 ***\nDESTIN_SZCLSZ05 -1.0113430  0.0085536  -118.237  &lt; 2e-16 ***\nDESTIN_SZCLSZ06  0.0694682  0.0042166    16.475  &lt; 2e-16 ***\nDESTIN_SZCLSZ07 -0.4953961  0.0054184   -91.429  &lt; 2e-16 ***\nDESTIN_SZCLSZ08 -0.3849563  0.0061404   -62.693  &lt; 2e-16 ***\nDESTIN_SZCLSZ09  0.4201808  0.0067112    62.609  &lt; 2e-16 ***\nDESTIN_SZDTSZ02 -2.6513032  0.0348725   -76.029  &lt; 2e-16 ***\nDESTIN_SZDTSZ03 -1.5192228  0.0144477  -105.153  &lt; 2e-16 ***\nDESTIN_SZDTSZ13 -2.2041951  0.0161726  -136.292  &lt; 2e-16 ***\nDESTIN_SZGLSZ01 -0.0139744  0.0052464    -2.664  0.00773 ** \nDESTIN_SZGLSZ02 -0.2850816  0.0047467   -60.059  &lt; 2e-16 ***\nDESTIN_SZGLSZ03  0.3511872  0.0039473    88.969  &lt; 2e-16 ***\nDESTIN_SZGLSZ04  0.2909117  0.0039436    73.769  &lt; 2e-16 ***\nDESTIN_SZGLSZ05  0.1845361  0.0040011    46.121  &lt; 2e-16 ***\nDESTIN_SZHGSZ01  0.1418382  0.0039875    35.571  &lt; 2e-16 ***\nDESTIN_SZHGSZ02 -0.7233151  0.0052374  -138.105  &lt; 2e-16 ***\nDESTIN_SZHGSZ03 -1.1918463  0.0062129  -191.834  &lt; 2e-16 ***\nDESTIN_SZHGSZ04 -0.4380360  0.0044839   -97.691  &lt; 2e-16 ***\nDESTIN_SZHGSZ05 -0.5671024  0.0046427  -122.149  &lt; 2e-16 ***\nDESTIN_SZHGSZ06 -0.8271411  0.0054935  -150.566  &lt; 2e-16 ***\nDESTIN_SZHGSZ07  0.0721800  0.0041589    17.356  &lt; 2e-16 ***\nDESTIN_SZHGSZ08 -0.4297429  0.0050021   -85.913  &lt; 2e-16 ***\nDESTIN_SZHGSZ09 -0.2085461  0.0052544   -39.690  &lt; 2e-16 ***\nDESTIN_SZHGSZ10 -2.9169699  0.0262698  -111.039  &lt; 2e-16 ***\nDESTIN_SZJESZ01 -0.2822473  0.0051166   -55.163  &lt; 2e-16 ***\nDESTIN_SZJESZ02 -0.6761389  0.0053635  -126.063  &lt; 2e-16 ***\nDESTIN_SZJESZ03 -0.7371756  0.0058983  -124.980  &lt; 2e-16 ***\nDESTIN_SZJESZ04 -0.4593491  0.0067970   -67.581  &lt; 2e-16 ***\nDESTIN_SZJESZ05 -1.1418012  0.0099049  -115.277  &lt; 2e-16 ***\nDESTIN_SZJESZ06  0.1759680  0.0042791    41.123  &lt; 2e-16 ***\nDESTIN_SZJESZ07 -1.2260587  0.0082714  -148.229  &lt; 2e-16 ***\nDESTIN_SZJESZ08 -0.8547001  0.0080417  -106.283  &lt; 2e-16 ***\nDESTIN_SZJESZ09 -0.4306353  0.0057006   -75.542  &lt; 2e-16 ***\nDESTIN_SZJESZ10  0.6584971  0.0073664    89.392  &lt; 2e-16 ***\nDESTIN_SZJESZ11  0.9661208  0.0070491   137.056  &lt; 2e-16 ***\nDESTIN_SZJWSZ01 -0.9128436  0.0069529  -131.290  &lt; 2e-16 ***\nDESTIN_SZJWSZ02 -0.7285851  0.0054839  -132.859  &lt; 2e-16 ***\nDESTIN_SZJWSZ03  0.2601455  0.0043215    60.198  &lt; 2e-16 ***\nDESTIN_SZJWSZ04  0.6860274  0.0041135   166.775  &lt; 2e-16 ***\nDESTIN_SZJWSZ05 -0.4684576  0.0062875   -74.506  &lt; 2e-16 ***\nDESTIN_SZJWSZ06 -0.2459774  0.0057575   -42.723  &lt; 2e-16 ***\nDESTIN_SZJWSZ07 -1.8854234  0.0287721   -65.529  &lt; 2e-16 ***\nDESTIN_SZJWSZ08 -0.5523308  0.0051054  -108.186  &lt; 2e-16 ***\nDESTIN_SZJWSZ09  0.8818747  0.0037800   233.301  &lt; 2e-16 ***\nDESTIN_SZKLSZ01 -0.5814386  0.0052711  -110.308  &lt; 2e-16 ***\nDESTIN_SZKLSZ02 -0.7090577  0.0058161  -121.914  &lt; 2e-16 ***\nDESTIN_SZKLSZ03 -1.2191910  0.0065984  -184.772  &lt; 2e-16 ***\nDESTIN_SZKLSZ04 -1.6961428  0.0087866  -193.038  &lt; 2e-16 ***\nDESTIN_SZKLSZ05 -0.6927144  0.0073574   -94.153  &lt; 2e-16 ***\nDESTIN_SZKLSZ06 -2.2967464  0.0362605   -63.340  &lt; 2e-16 ***\nDESTIN_SZKLSZ07 -0.9536980  0.0066777  -142.819  &lt; 2e-16 ***\nDESTIN_SZKLSZ08 -0.4565596  0.0051736   -88.249  &lt; 2e-16 ***\nDESTIN_SZLKSZ01 -1.7277135  0.0207336   -83.329  &lt; 2e-16 ***\nDESTIN_SZMDSZ01 -1.7155417  0.0210080   -81.661  &lt; 2e-16 ***\nDESTIN_SZMDSZ02 -1.3694928  0.0114174  -119.948  &lt; 2e-16 ***\nDESTIN_SZMDSZ03 -2.7183729  0.0252678  -107.582  &lt; 2e-16 ***\nDESTIN_SZMPSZ01 -0.8051991  0.0078564  -102.490  &lt; 2e-16 ***\nDESTIN_SZMPSZ02 -0.7627000  0.0061386  -124.246  &lt; 2e-16 ***\nDESTIN_SZMPSZ03 -0.0649484  0.0047787   -13.591  &lt; 2e-16 ***\nDESTIN_SZMUSZ02 -1.9549128  0.0200160   -97.667  &lt; 2e-16 ***\nDESTIN_SZNTSZ01 -3.3048398  0.0448053   -73.760  &lt; 2e-16 ***\nDESTIN_SZNTSZ02 -1.6454847  0.0109337  -150.497  &lt; 2e-16 ***\nDESTIN_SZNTSZ03 -1.1389723  0.0077396  -147.161  &lt; 2e-16 ***\nDESTIN_SZNTSZ05 -2.0264109  0.0250226   -80.983  &lt; 2e-16 ***\nDESTIN_SZNTSZ06 -3.3496282  0.0428989   -78.082  &lt; 2e-16 ***\nDESTIN_SZNVSZ01 -0.3407614  0.0045493   -74.905  &lt; 2e-16 ***\nDESTIN_SZNVSZ02 -0.4987695  0.0053942   -92.465  &lt; 2e-16 ***\nDESTIN_SZNVSZ03 -0.4936107  0.0055158   -89.491  &lt; 2e-16 ***\nDESTIN_SZNVSZ04 -1.9141281  0.0107557  -177.964  &lt; 2e-16 ***\nDESTIN_SZNVSZ05 -1.5378263  0.0089577  -171.677  &lt; 2e-16 ***\nDESTIN_SZPGSZ01 -1.7744485  0.0194346   -91.304  &lt; 2e-16 ***\nDESTIN_SZPGSZ02 -0.9282918  0.0069006  -134.523  &lt; 2e-16 ***\nDESTIN_SZPGSZ03  0.0885025  0.0042145    21.000  &lt; 2e-16 ***\nDESTIN_SZPGSZ04 -0.3879375  0.0046862   -82.784  &lt; 2e-16 ***\nDESTIN_SZPGSZ05 -0.9649873  0.0074625  -129.311  &lt; 2e-16 ***\nDESTIN_SZPLSZ01 -0.6159175  0.0070845   -86.939  &lt; 2e-16 ***\nDESTIN_SZPLSZ02 -1.7551386  0.0133081  -131.885  &lt; 2e-16 ***\nDESTIN_SZPLSZ03 -0.1378379  0.0098704   -13.965  &lt; 2e-16 ***\nDESTIN_SZPLSZ04 -0.1411200  0.0096446   -14.632  &lt; 2e-16 ***\nDESTIN_SZPLSZ05 -0.8483196  0.0119048   -71.259  &lt; 2e-16 ***\nDESTIN_SZPNSZ01 -0.1579087  0.0057330   -27.544  &lt; 2e-16 ***\nDESTIN_SZPNSZ02  1.0243480  0.0076680   133.587  &lt; 2e-16 ***\nDESTIN_SZPNSZ03  0.0451598  0.0081444     5.545 2.94e-08 ***\nDESTIN_SZPNSZ04  1.8941928  0.0087479   216.530  &lt; 2e-16 ***\nDESTIN_SZPNSZ05  1.0341581  0.0130830    79.046  &lt; 2e-16 ***\nDESTIN_SZPRSZ01 -1.4038513  0.0086911  -161.527  &lt; 2e-16 ***\nDESTIN_SZPRSZ02 -0.4942539  0.0052403   -94.319  &lt; 2e-16 ***\nDESTIN_SZPRSZ03  0.4219510  0.0040281   104.751  &lt; 2e-16 ***\nDESTIN_SZPRSZ04 -0.4841099  0.0083498   -57.979  &lt; 2e-16 ***\nDESTIN_SZPRSZ05 -0.2988481  0.0047512   -62.899  &lt; 2e-16 ***\nDESTIN_SZPRSZ06  0.0012333  0.0054530     0.226  0.82108    \nDESTIN_SZPRSZ07 -1.1417482  0.0118845   -96.070  &lt; 2e-16 ***\nDESTIN_SZPRSZ08 -0.8259249  0.0066757  -123.720  &lt; 2e-16 ***\nDESTIN_SZQTSZ01 -1.2134330  0.0089222  -136.002  &lt; 2e-16 ***\nDESTIN_SZQTSZ02 -1.2397956  0.0074512  -166.388  &lt; 2e-16 ***\nDESTIN_SZQTSZ03 -0.7448659  0.0066511  -111.992  &lt; 2e-16 ***\nDESTIN_SZQTSZ04 -0.6243112  0.0066812   -93.443  &lt; 2e-16 ***\nDESTIN_SZQTSZ05 -0.6102589  0.0060458  -100.940  &lt; 2e-16 ***\nDESTIN_SZQTSZ06 -0.9164592  0.0065095  -140.788  &lt; 2e-16 ***\nDESTIN_SZQTSZ07 -1.4600643  0.0109976  -132.762  &lt; 2e-16 ***\nDESTIN_SZQTSZ08  0.0004582  0.0050178     0.091  0.92724    \nDESTIN_SZQTSZ09 -0.5226213  0.0058901   -88.728  &lt; 2e-16 ***\nDESTIN_SZQTSZ10 -0.3867082  0.0055876   -69.208  &lt; 2e-16 ***\nDESTIN_SZQTSZ11  0.0260589  0.0055065     4.732 2.22e-06 ***\nDESTIN_SZQTSZ12 -0.3387634  0.0072779   -46.547  &lt; 2e-16 ***\nDESTIN_SZQTSZ13 -0.0512118  0.0053664    -9.543  &lt; 2e-16 ***\nDESTIN_SZQTSZ14 -0.2555346  0.0063792   -40.057  &lt; 2e-16 ***\nDESTIN_SZQTSZ15 -0.1820651  0.0077537   -23.481  &lt; 2e-16 ***\nDESTIN_SZRCSZ01 -0.4641196  0.0072515   -64.003  &lt; 2e-16 ***\nDESTIN_SZRCSZ06 -2.0929548  0.0189106  -110.676  &lt; 2e-16 ***\nDESTIN_SZRVSZ01 -1.7885682  0.0163492  -109.398  &lt; 2e-16 ***\nDESTIN_SZRVSZ02 -3.1669721  0.0326320   -97.051  &lt; 2e-16 ***\nDESTIN_SZRVSZ03 -2.0306835  0.0135749  -149.591  &lt; 2e-16 ***\nDESTIN_SZRVSZ04 -1.5113470  0.0155637   -97.107  &lt; 2e-16 ***\nDESTIN_SZRVSZ05 -2.3683855  0.0259334   -91.326  &lt; 2e-16 ***\nDESTIN_SZSBSZ01 -0.5841063  0.0068588   -85.162  &lt; 2e-16 ***\nDESTIN_SZSBSZ02 -1.0777704  0.0078288  -137.667  &lt; 2e-16 ***\nDESTIN_SZSBSZ03  0.4734371  0.0045880   103.190  &lt; 2e-16 ***\nDESTIN_SZSBSZ04  0.0546094  0.0057517     9.494  &lt; 2e-16 ***\nDESTIN_SZSBSZ05 -0.9588198  0.0075242  -127.431  &lt; 2e-16 ***\nDESTIN_SZSBSZ06 -1.8528944  0.0234040   -79.170  &lt; 2e-16 ***\nDESTIN_SZSBSZ07 -1.8403768  0.0195878   -93.955  &lt; 2e-16 ***\nDESTIN_SZSBSZ08  0.9205969  0.0055698   165.285  &lt; 2e-16 ***\nDESTIN_SZSBSZ09  0.5166486  0.0051939    99.472  &lt; 2e-16 ***\nDESTIN_SZSESZ02 -0.5728211  0.0048270  -118.669  &lt; 2e-16 ***\nDESTIN_SZSESZ03  0.2554787  0.0038335    66.645  &lt; 2e-16 ***\nDESTIN_SZSESZ04 -0.8982794  0.0056698  -158.432  &lt; 2e-16 ***\nDESTIN_SZSESZ05 -0.4661655  0.0048578   -95.962  &lt; 2e-16 ***\nDESTIN_SZSESZ06 -0.8392849  0.0059198  -141.777  &lt; 2e-16 ***\nDESTIN_SZSESZ07 -3.2182325  0.0227089  -141.717  &lt; 2e-16 ***\nDESTIN_SZSGSZ01 -0.2751206  0.0059581   -46.176  &lt; 2e-16 ***\nDESTIN_SZSGSZ02 -0.2951806  0.0052515   -56.209  &lt; 2e-16 ***\nDESTIN_SZSGSZ03 -0.4469508  0.0048181   -92.766  &lt; 2e-16 ***\nDESTIN_SZSGSZ04 -0.2842809  0.0047961   -59.274  &lt; 2e-16 ***\nDESTIN_SZSGSZ05 -2.0643753  0.0098252  -210.109  &lt; 2e-16 ***\nDESTIN_SZSGSZ06  0.2501247  0.0038873    64.343  &lt; 2e-16 ***\nDESTIN_SZSGSZ07 -0.5743750  0.0052184  -110.067  &lt; 2e-16 ***\nDESTIN_SZSISZ01 -1.1030669  0.0259113   -42.571  &lt; 2e-16 ***\nDESTIN_SZSKSZ01 -0.5462538  0.0071443   -76.460  &lt; 2e-16 ***\nDESTIN_SZSKSZ02  0.2965180  0.0056707    52.290  &lt; 2e-16 ***\nDESTIN_SZSKSZ03 -0.4521490  0.0062177   -72.719  &lt; 2e-16 ***\nDESTIN_SZSKSZ04 -0.6665145  0.0148252   -44.958  &lt; 2e-16 ***\nDESTIN_SZSKSZ05 -0.1474142  0.0121958   -12.087  &lt; 2e-16 ***\nDESTIN_SZSLSZ01 -0.8855715  0.0084587  -104.693  &lt; 2e-16 ***\nDESTIN_SZSLSZ04 -1.1787840  0.0071355  -165.200  &lt; 2e-16 ***\nDESTIN_SZSRSZ01 -1.6435064  0.0128822  -127.580  &lt; 2e-16 ***\nDESTIN_SZTHSZ01 -3.4388625  0.0367651   -93.536  &lt; 2e-16 ***\nDESTIN_SZTHSZ03 -2.5809435  0.0256853  -100.483  &lt; 2e-16 ***\nDESTIN_SZTHSZ04 -2.4887189  0.0214441  -116.056  &lt; 2e-16 ***\nDESTIN_SZTHSZ06 -1.7965101  0.0152160  -118.067  &lt; 2e-16 ***\nDESTIN_SZTMSZ01 -0.3251891  0.0058067   -56.002  &lt; 2e-16 ***\nDESTIN_SZTMSZ02  1.1558743  0.0034703   333.080  &lt; 2e-16 ***\nDESTIN_SZTMSZ03  0.4525619  0.0039244   115.319  &lt; 2e-16 ***\nDESTIN_SZTMSZ04  0.8223271  0.0040060   205.274  &lt; 2e-16 ***\nDESTIN_SZTMSZ05  0.3880619  0.0054308    71.456  &lt; 2e-16 ***\nDESTIN_SZTNSZ01 -0.9533112  0.0067853  -140.496  &lt; 2e-16 ***\nDESTIN_SZTNSZ02 -1.5909451  0.0097396  -163.348  &lt; 2e-16 ***\nDESTIN_SZTNSZ03 -1.6470771  0.0116598  -141.261  &lt; 2e-16 ***\nDESTIN_SZTNSZ04 -1.0686173  0.0069848  -152.993  &lt; 2e-16 ***\nDESTIN_SZTPSZ01 -0.5180183  0.0056886   -91.063  &lt; 2e-16 ***\nDESTIN_SZTPSZ02  0.2160781  0.0038283    56.443  &lt; 2e-16 ***\nDESTIN_SZTPSZ03 -0.2479956  0.0056651   -43.776  &lt; 2e-16 ***\nDESTIN_SZTPSZ04 -1.5015463  0.0072444  -207.271  &lt; 2e-16 ***\nDESTIN_SZTPSZ05 -0.9551144  0.0057981  -164.729  &lt; 2e-16 ***\nDESTIN_SZTPSZ06 -0.4846634  0.0074621   -64.950  &lt; 2e-16 ***\nDESTIN_SZTPSZ07 -1.9753440  0.0118295  -166.984  &lt; 2e-16 ***\nDESTIN_SZTPSZ08 -1.3455063  0.0086909  -154.817  &lt; 2e-16 ***\nDESTIN_SZTPSZ09 -0.3556620  0.0061296   -58.024  &lt; 2e-16 ***\nDESTIN_SZTPSZ10 -1.3213501  0.0085951  -153.733  &lt; 2e-16 ***\nDESTIN_SZTPSZ11 -0.3877006  0.0052409   -73.977  &lt; 2e-16 ***\nDESTIN_SZTPSZ12 -0.7064020  0.0062472  -113.075  &lt; 2e-16 ***\nDESTIN_SZTSSZ01 -0.8827157  0.0218327   -40.431  &lt; 2e-16 ***\nDESTIN_SZTSSZ02 -0.6067055  0.0115514   -52.522  &lt; 2e-16 ***\nDESTIN_SZTSSZ03  0.4380259  0.0086774    50.479  &lt; 2e-16 ***\nDESTIN_SZTSSZ04  0.4902124  0.0089922    54.515  &lt; 2e-16 ***\nDESTIN_SZTSSZ05  1.4336278  0.0093410   153.477  &lt; 2e-16 ***\nDESTIN_SZTSSZ06  0.9223573  0.0209024    44.127  &lt; 2e-16 ***\nDESTIN_SZWCSZ01  1.1559309  0.0051787   223.208  &lt; 2e-16 ***\nDESTIN_SZWCSZ02 -1.2664455  0.0126131  -100.407  &lt; 2e-16 ***\nDESTIN_SZWCSZ03 -2.7360882  0.0325753   -83.993  &lt; 2e-16 ***\nDESTIN_SZWDSZ01  0.8193492  0.0037301   219.657  &lt; 2e-16 ***\nDESTIN_SZWDSZ02 -0.7852474  0.0058655  -133.875  &lt; 2e-16 ***\nDESTIN_SZWDSZ03  0.5742422  0.0041884   137.104  &lt; 2e-16 ***\nDESTIN_SZWDSZ04 -0.8391525  0.0065075  -128.951  &lt; 2e-16 ***\nDESTIN_SZWDSZ05 -0.3510692  0.0057253   -61.319  &lt; 2e-16 ***\nDESTIN_SZWDSZ06  0.1358804  0.0043968    30.905  &lt; 2e-16 ***\nDESTIN_SZWDSZ07 -0.2207379  0.0066369   -33.259  &lt; 2e-16 ***\nDESTIN_SZWDSZ08 -0.0264655  0.0065065    -4.068 4.75e-05 ***\nDESTIN_SZWDSZ09 -0.2065828  0.0050524   -40.888  &lt; 2e-16 ***\nDESTIN_SZYSSZ01  0.7467996  0.0040979   182.238  &lt; 2e-16 ***\nDESTIN_SZYSSZ02 -0.3002718  0.0053434   -56.195  &lt; 2e-16 ***\nDESTIN_SZYSSZ03 -1.1087686  0.0057219  -193.778  &lt; 2e-16 ***\nDESTIN_SZYSSZ04 -0.3748076  0.0051481   -72.805  &lt; 2e-16 ***\nDESTIN_SZYSSZ05 -1.7909654  0.0102064  -175.475  &lt; 2e-16 ***\nDESTIN_SZYSSZ06 -1.8519179  0.0099601  -185.933  &lt; 2e-16 ***\nDESTIN_SZYSSZ07 -0.9246626  0.0118101   -78.294  &lt; 2e-16 ***\nDESTIN_SZYSSZ08  0.4403129  0.0041268   106.697  &lt; 2e-16 ***\nDESTIN_SZYSSZ09  0.0267012  0.0041393     6.451 1.11e-10 ***\nlog(dist)       -0.6721961  0.0001353 -4969.566  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 60796037  on 14733  degrees of freedom\nResidual deviance: 20988409  on 14175  degrees of freedom\nAIC: 21081154\n\nNumber of Fisher Scoring iterations: 7\n\n\nSimilarly to examine how the constraints hold for destinations this time.\n\nCalcRSquared(dbcSIM$data$TRIPS, dbcSIM$fitted.values)\n\n[1] 0.5739638\n\n\nNotice that there is a relatively greater improvement in the R^2 value.\n\n\n8.9 Model comparison\nAnother useful model performance measure for continuous dependent variable is Root Mean Squared Error. In this sub-section, you will learn how to use compare_performance() of performance package\nFirst, a list named model_list will be created using the code chunk below.\n\nmodel_list &lt;- list(unconstrained=uncSIM,\n                   originConstrained=orcSIM,\n                   destinationConstrained=decSIM,\n                   doublyConstrained=dbcSIM)\n\nNext, to compute the RMSE of all the models in model_list file by using the code chunk below.\n\ncompare_performance(model_list,\n                    metrics = \"RMSE\")\n\n# Comparison of Model Performance Indices\n\nName                   | Model |     RMSE\n-----------------------------------------\nunconstrained          |   glm | 4288.012\noriginConstrained      |   glm | 3659.954\ndestinationConstrained |   glm | 3389.556\ndoublyConstrained      |   glm | 3252.297\n\n\nThe print above reveals that doubly constrained SIM is the best model among all the four SIMs because it has the smallest RMSE value of 1487.111.\n\n\n8.10 Visualising fitted values\nThis section covers visualizing observed versus fitted values. First, fitted values will be extracted from each model using the code chunk below.\n\ndf &lt;- as.data.frame(uncSIM$fitted.values) %&gt;%\n  round(digits = 0)\n\nNext, to join the values to SIM_data data frame.\n\nSIM_data &lt;- SIM_data %&gt;%\n  cbind(df) %&gt;%\n  rename(uncTRIPS = \"uncSIM$fitted.values\")\n\nRepeat the same step by for Origin Constrained SIM (i.e. orcSIM)\n\ndf &lt;- as.data.frame(orcSIM$fitted.values) %&gt;%\n  round(digits = 0)\n\n\nSIM_data &lt;- SIM_data %&gt;%\n  cbind(df) %&gt;%\n  rename(orcTRIPS = \"orcSIM$fitted.values\")\n\nOnce again, repeat the same step by for Destination Constrained SIM (i.e. decSIM)\n\ndf &lt;- as.data.frame(decSIM$fitted.values) %&gt;%\n  round(digits = 0)\n\n\nSIM_data &lt;- SIM_data %&gt;%\n  cbind(df) %&gt;%\n  rename(decTRIPS = \"decSIM$fitted.values\")\n\nFinally repeat the same step by for Doubly Constrained SIM (i.e. dbcSIM)\n\ndf &lt;- as.data.frame(dbcSIM$fitted.values) %&gt;%\n  round(digits = 0)\n\n\nSIM_data &lt;- SIM_data %&gt;%\n  cbind(df) %&gt;%\n  rename(dbcTRIPS = \"dbcSIM$fitted.values\")\n\n\nunc_p &lt;- ggplot(data = SIM_data,\n                aes(x = uncTRIPS,\n                    y = TRIPS)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\norc_p &lt;- ggplot(data = SIM_data,\n                aes(x = orcTRIPS,\n                    y = TRIPS)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\ndec_p &lt;- ggplot(data = SIM_data,\n                aes(x = decTRIPS,\n                    y = TRIPS)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\ndbc_p &lt;- ggplot(data = SIM_data,\n                aes(x = dbcTRIPS,\n                    y = TRIPS)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\nNow, to put all the graphs into a single visual for better comparison by using the code chunk below.\n\nggarrange(unc_p, orc_p, dec_p, dbc_p,\n          ncol = 2,\n          nrow = 2)\n\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/Take-home_Ex3b-HDBDataPrep.html",
    "href": "In-class_Ex/In-class_Ex08/Take-home_Ex3b-HDBDataPrep.html",
    "title": "Preparing HDB data",
    "section": "",
    "text": "pacman::p_load(tidyverse, sf, httr, jsonlite, rvest, tmap)\n\n\nresale &lt;- read_csv(\"data/HDB/rawdata/resale.csv\") %&gt;%\n  filter(month &gt;= \"2023-01\" & month &lt;= \"2024-09\")\n\nRows: 192234 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (8): month, town, flat_type, block, street_name, storey_range, flat_mode...\ndbl (3): floor_area_sqm, lease_commence_date, resale_price\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nresale_tidy &lt;- resale %&gt;%\n  mutate(address = paste(block,street_name)) %&gt;%\n  mutate(remaining_lease_yr = as.integer(\n    str_sub(remaining_lease, 0, 2)))%&gt;%\n  mutate(remaining_lease_mth = as.integer(\n    str_sub(remaining_lease, 9, 11)))\n\n\nresale_selected &lt;- resale_tidy %&gt;%\n  filter(month == \"2024-09\")\n\n\nadd_list &lt;- sort(unique(resale_selected$address))\n\n\nget_coords &lt;- function(add_list){\n  \n  # Create a data frame to store all retrieved coordinates\n  postal_coords &lt;- data.frame()\n    \n  for (i in add_list){\n    #print(i)\n\n    r &lt;- GET('https://www.onemap.gov.sg/api/common/elastic/search?',\n           query=list(searchVal=i,\n                     returnGeom='Y',\n                     getAddrDetails='Y'))\n    data &lt;- fromJSON(rawToChar(r$content))\n    found &lt;- data$found\n    res &lt;- data$results\n    \n    # Create a new data frame for each address\n    new_row &lt;- data.frame()\n    \n    # If single result, append \n    if (found == 1){\n      postal &lt;- res$POSTAL \n      lat &lt;- res$LATITUDE\n      lng &lt;- res$LONGITUDE\n      new_row &lt;- data.frame(address= i, \n                            postal = postal, \n                            latitude = lat, \n                            longitude = lng)\n    }\n    \n    # If multiple results, drop NIL and append top 1\n    else if (found &gt; 1){\n      # Remove those with NIL as postal\n      res_sub &lt;- res[res$POSTAL != \"NIL\", ]\n      \n      # Set as NA first if no Postal\n      if (nrow(res_sub) == 0) {\n          new_row &lt;- data.frame(address= i, \n                                postal = NA, \n                                latitude = NA, \n                                longitude = NA)\n      }\n      \n      else{\n        top1 &lt;- head(res_sub, n = 1)\n        postal &lt;- top1$POSTAL \n        lat &lt;- top1$LATITUDE\n        lng &lt;- top1$LONGITUDE\n        new_row &lt;- data.frame(address= i, \n                              postal = postal, \n                              latitude = lat, \n                              longitude = lng)\n      }\n    }\n\n    else {\n      new_row &lt;- data.frame(address= i, \n                            postal = NA, \n                            latitude = NA, \n                            longitude = NA)\n    }\n    \n    # Add the row\n    postal_coords &lt;- rbind(postal_coords, new_row)\n  }\n  return(postal_coords)\n}\n\n\ncoords &lt;- get_coords(add_list)\n\n\nwrite_rds(coords, \"data/HDB/rds/coords.rds\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/Take-home_Ex3b-HDBDataPrep.html#oct-u2024",
    "href": "In-class_Ex/In-class_Ex08/Take-home_Ex3b-HDBDataPrep.html#oct-u2024",
    "title": "Preparing HDB data",
    "section": "28 Oct u2024",
    "text": "28 Oct u2024\n\nEldercare in shaprefile format - in svy21 projection but 2009\n\neldercare &lt;- st_read(dsn = \"data/HDB/rawdata\",\n                      layer = \"ELDERCARE\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `ELDERCARE' from data source \n  `C:\\zjho008\\ISSS626-GAA\\In-class_Ex\\In-class_Ex08\\data\\HDB\\rawdata' \n  using driver `ESRI Shapefile'\nSimple feature collection with 133 features and 18 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 14481.92 ymin: 28218.43 xmax: 41665.14 ymax: 46804.9\nProjected CRS: SVY21"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/Take-home_Ex3b-HDBDataPrep.html#buffering",
    "href": "In-class_Ex/In-class_Ex08/Take-home_Ex3b-HDBDataPrep.html#buffering",
    "title": "Preparing HDB data",
    "section": "Buffering",
    "text": "Buffering\nst_buffer() of sf package is used to create a buffer of 1km around each eldercare feature.\n\nbuffer_1km &lt;- st_buffer(eldercare,\n                        dist = 1000) # 1000metres = 1km\n\n\nimport kml file - in wgs84 since retrieved from internet\n\nCHAS &lt;- st_read(\"data/HDB/rawdata/CHASClinics.kml\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MOH_CHAS_CLINICS' from data source \n  `C:\\zjho008\\ISSS626-GAA\\In-class_Ex\\In-class_Ex08\\data\\HDB\\rawdata\\CHASClinics.kml' \n  using driver `KML'\nSimple feature collection with 1193 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.5818 ymin: 1.016264 xmax: 103.9903 ymax: 1.456037\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\nCHAS #if spatstats then need to drop. but sf is okay.\n\nSimple feature collection with 1193 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 2.127126e-08 ymin: -5.585825e-07 xmax: 45475.65 ymax: 48626.7\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n     Name\n1   kml_1\n2   kml_2\n3   kml_3\n4   kml_4\n5   kml_5\n6   kml_6\n7   kml_7\n8   kml_8\n9   kml_9\n10 kml_10\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Description\n1                               &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HCI_CODE&lt;/th&gt; &lt;td&gt;15M0211&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;HCI_NAME&lt;/th&gt; &lt;td&gt;Acumed Medical Group&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LICENCE_TYPE&lt;/th&gt; &lt;td&gt;MC&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;HCI_TEL&lt;/th&gt; &lt;td&gt;68615755&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;POSTAL_CD&lt;/th&gt; &lt;td&gt;629117&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDR_TYPE&lt;/th&gt; &lt;td&gt;B&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;BLK_HSE_NO&lt;/th&gt; &lt;td&gt;1&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FLOOR_NO&lt;/th&gt; &lt;td&gt;01&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;UNIT_NO&lt;/th&gt; &lt;td&gt;23&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;STREET_NAME&lt;/th&gt; &lt;td&gt;JOO KOON CIRCLE&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;BUILDING_NAME&lt;/th&gt; &lt;td&gt;FAIRPRICE HUB&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;CLINIC_PROGRAMME_CODE&lt;/th&gt; &lt;td&gt;CDMP,CHAS&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;X_COORDINATE&lt;/th&gt; &lt;td&gt;10760.19030171&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;Y_COORDINATE&lt;/th&gt; &lt;td&gt;34206.12386783&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;781AF3FC7E4D0301&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20210926121846&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt;\n2  &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HCI_CODE&lt;/th&gt; &lt;td&gt;16M0004&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;HCI_NAME&lt;/th&gt; &lt;td&gt;Acumed Medical Group&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LICENCE_TYPE&lt;/th&gt; &lt;td&gt;MC&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;HCI_TEL&lt;/th&gt; &lt;td&gt;65701390&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;POSTAL_CD&lt;/th&gt; &lt;td&gt;637370&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDR_TYPE&lt;/th&gt; &lt;td&gt;B&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;BLK_HSE_NO&lt;/th&gt; &lt;td&gt;128&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FLOOR_NO&lt;/th&gt; &lt;td&gt;01&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;UNIT_NO&lt;/th&gt; &lt;td&gt;03&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;STREET_NAME&lt;/th&gt; &lt;td&gt;TUAS SOUTH AVENUE 3&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;BUILDING_NAME&lt;/th&gt; &lt;td&gt;JTC BIOMED ONE @ TUAS BIOMEDICAL PARK&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;CLINIC_PROGRAMME_CODE&lt;/th&gt; &lt;td&gt;CDMP,CHAS&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;X_COORDINATE&lt;/th&gt; &lt;td&gt;4985.53397365&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;Y_COORDINATE&lt;/th&gt; &lt;td&gt;30167.98804538&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;4132D1A643933D75&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20210926121846&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt;\n3                                   &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HCI_CODE&lt;/th&gt; &lt;td&gt;21M0229&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;HCI_NAME&lt;/th&gt; &lt;td&gt;Advantage Medical Clinic&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LICENCE_TYPE&lt;/th&gt; &lt;td&gt;MC&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;HCI_TEL&lt;/th&gt; &lt;td&gt;87840093&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;POSTAL_CD&lt;/th&gt; &lt;td&gt;268802&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDR_TYPE&lt;/th&gt; &lt;td&gt;B&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;BLK_HSE_NO&lt;/th&gt; &lt;td&gt;1&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FLOOR_NO&lt;/th&gt; &lt;td&gt;03&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;UNIT_NO&lt;/th&gt; &lt;td&gt;12&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;STREET_NAME&lt;/th&gt; &lt;td&gt;FIFTH AVENUE&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;BUILDING_NAME&lt;/th&gt; &lt;td&gt;GUTHRIE HOUSE&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;CLINIC_PROGRAMME_CODE&lt;/th&gt; &lt;td&gt;CHAS&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;X_COORDINATE&lt;/th&gt; &lt;td&gt;23812.58956922&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;Y_COORDINATE&lt;/th&gt; &lt;td&gt;34780.57533007&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;1429766D7056AA8D&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20210926121846&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt;\n4                          &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HCI_CODE&lt;/th&gt; &lt;td&gt;19M0160&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;HCI_NAME&lt;/th&gt; &lt;td&gt;Affinity Medical Clinic&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LICENCE_TYPE&lt;/th&gt; &lt;td&gt;MC&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;HCI_TEL&lt;/th&gt; &lt;td&gt;62808080&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;POSTAL_CD&lt;/th&gt; &lt;td&gt;550253&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDR_TYPE&lt;/th&gt; &lt;td&gt;A&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;BLK_HSE_NO&lt;/th&gt; &lt;td&gt;253&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FLOOR_NO&lt;/th&gt; &lt;td&gt;01&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;UNIT_NO&lt;/th&gt; &lt;td&gt;187&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;STREET_NAME&lt;/th&gt; &lt;td&gt;SERANGOON CENTRAL DRIVE&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;BUILDING_NAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;CLINIC_PROGRAMME_CODE&lt;/th&gt; &lt;td&gt;CDMP,CHAS,ISP&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;X_COORDINATE&lt;/th&gt; &lt;td&gt;32176.99089858&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;Y_COORDINATE&lt;/th&gt; &lt;td&gt;37348.34529089&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;25E32F8453AEABFD&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20210926121846&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt;\n5        &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HCI_CODE&lt;/th&gt; &lt;td&gt;9404401&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;HCI_NAME&lt;/th&gt; &lt;td&gt;Allergy, Arthritis & Rheumatism Clinic&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LICENCE_TYPE&lt;/th&gt; &lt;td&gt;MD&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;HCI_TEL&lt;/th&gt; &lt;td&gt;64749438&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;POSTAL_CD&lt;/th&gt; &lt;td&gt;217562&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDR_TYPE&lt;/th&gt; &lt;td&gt;B&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;BLK_HSE_NO&lt;/th&gt; &lt;td&gt;1&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FLOOR_NO&lt;/th&gt; &lt;td&gt;14&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;UNIT_NO&lt;/th&gt; &lt;td&gt;13&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;STREET_NAME&lt;/th&gt; &lt;td&gt;FARRER PARK STATION ROAD&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;BUILDING_NAME&lt;/th&gt; &lt;td&gt;CONNEXION&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;CLINIC_PROGRAMME_CODE&lt;/th&gt; &lt;td&gt;CDMP,CHAS&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;X_COORDINATE&lt;/th&gt; &lt;td&gt;30293.80179285&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;Y_COORDINATE&lt;/th&gt; &lt;td&gt;32752.14975386&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;E04B63460D9DF892&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20210926121846&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt;\n6                                        &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HCI_CODE&lt;/th&gt; &lt;td&gt;17M0228&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;HCI_NAME&lt;/th&gt; &lt;td&gt;Allhealth Family Clinic&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LICENCE_TYPE&lt;/th&gt; &lt;td&gt;MC&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;HCI_TEL&lt;/th&gt; &lt;td&gt;67026467&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;POSTAL_CD&lt;/th&gt; &lt;td&gt;523872&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDR_TYPE&lt;/th&gt; &lt;td&gt;A&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;BLK_HSE_NO&lt;/th&gt; &lt;td&gt;872C&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FLOOR_NO&lt;/th&gt; &lt;td&gt;01&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;UNIT_NO&lt;/th&gt; &lt;td&gt;01&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;STREET_NAME&lt;/th&gt; &lt;td&gt;TAMPINES STREET 86&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;BUILDING_NAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;CLINIC_PROGRAMME_CODE&lt;/th&gt; &lt;td&gt;CHAS&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;X_COORDINATE&lt;/th&gt; &lt;td&gt;38940.52504647&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;Y_COORDINATE&lt;/th&gt; &lt;td&gt;37479.79536068&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;5B0B49E22956F1B3&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20210926121846&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt;\n7                                          &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HCI_CODE&lt;/th&gt; &lt;td&gt;19M0341&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;HCI_NAME&lt;/th&gt; &lt;td&gt;Ally Health&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LICENCE_TYPE&lt;/th&gt; &lt;td&gt;MC&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;HCI_TEL&lt;/th&gt; &lt;td&gt;66977700&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;POSTAL_CD&lt;/th&gt; &lt;td&gt;140462&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDR_TYPE&lt;/th&gt; &lt;td&gt;A&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;BLK_HSE_NO&lt;/th&gt; &lt;td&gt;46-2&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FLOOR_NO&lt;/th&gt; &lt;td&gt;01&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;UNIT_NO&lt;/th&gt; &lt;td&gt;372&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;STREET_NAME&lt;/th&gt; &lt;td&gt;COMMONWEALTH DRIVE&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;BUILDING_NAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;CLINIC_PROGRAMME_CODE&lt;/th&gt; &lt;td&gt;CDMP,CHAS,ISP&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;X_COORDINATE&lt;/th&gt; &lt;td&gt;24094.68699586&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;Y_COORDINATE&lt;/th&gt; &lt;td&gt;31368.73817961&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;C5F9B14203C0367F&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20210926121846&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt;\n8       &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HCI_CODE&lt;/th&gt; &lt;td&gt;16M0043&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;HCI_NAME&lt;/th&gt; &lt;td&gt;Ang Mo Kio Family Medicine Clinic&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LICENCE_TYPE&lt;/th&gt; &lt;td&gt;MC&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;HCI_TEL&lt;/th&gt; &lt;td&gt;65541133&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;POSTAL_CD&lt;/th&gt; &lt;td&gt;569841&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDR_TYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;BLK_HSE_NO&lt;/th&gt; &lt;td&gt;4190&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FLOOR_NO&lt;/th&gt; &lt;td&gt;03&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;UNIT_NO&lt;/th&gt; &lt;td&gt;01&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;STREET_NAME&lt;/th&gt; &lt;td&gt;ANG MO KIO AVENUE 6&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;BUILDING_NAME&lt;/th&gt; &lt;td&gt;BROADWAY PLAZA&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;CLINIC_PROGRAMME_CODE&lt;/th&gt; &lt;td&gt;CDMP,CHAS,ISP&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;X_COORDINATE&lt;/th&gt; &lt;td&gt;29405.66118025&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;Y_COORDINATE&lt;/th&gt; &lt;td&gt;39327.37454678&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;4A712102C8E400A3&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20210926121846&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt;\n9                            &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HCI_CODE&lt;/th&gt; &lt;td&gt;16C0397&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;HCI_NAME&lt;/th&gt; &lt;td&gt;Anteh Dispensary Pte Ltd&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LICENCE_TYPE&lt;/th&gt; &lt;td&gt;MC&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;HCI_TEL&lt;/th&gt; &lt;td&gt;67440040&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;POSTAL_CD&lt;/th&gt; &lt;td&gt;398664&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDR_TYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;BLK_HSE_NO&lt;/th&gt; &lt;td&gt;1&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FLOOR_NO&lt;/th&gt; &lt;td&gt;01&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;UNIT_NO&lt;/th&gt; &lt;td&gt;02&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;STREET_NAME&lt;/th&gt; &lt;td&gt;LORONG 22 GEYLANG&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;BUILDING_NAME&lt;/th&gt; &lt;td&gt;GRANDVIEW SUITES&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;CLINIC_PROGRAMME_CODE&lt;/th&gt; &lt;td&gt;CHAS&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;X_COORDINATE&lt;/th&gt; &lt;td&gt;33468.48699051&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;Y_COORDINATE&lt;/th&gt; &lt;td&gt;32785.67660058&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;7E06EFB3781F029E&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20210926121846&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt;\n10        &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HCI_CODE&lt;/th&gt; &lt;td&gt;20M0227&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;HCI_NAME&lt;/th&gt; &lt;td&gt;Appletree Medical Centre&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LICENCE_TYPE&lt;/th&gt; &lt;td&gt;MC&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;HCI_TEL&lt;/th&gt; &lt;td&gt;64548361&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;POSTAL_CD&lt;/th&gt; &lt;td&gt;560416&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDR_TYPE&lt;/th&gt; &lt;td&gt;A&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;BLK_HSE_NO&lt;/th&gt; &lt;td&gt;416&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FLOOR_NO&lt;/th&gt; &lt;td&gt;01&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;UNIT_NO&lt;/th&gt; &lt;td&gt;997&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;STREET_NAME&lt;/th&gt; &lt;td&gt;ANG MO KIO AVENUE 10&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;BUILDING_NAME&lt;/th&gt; &lt;td&gt;TECK GHEE HEARTLANDS&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;CLINIC_PROGRAMME_CODE&lt;/th&gt; &lt;td&gt;CDMP,CHAS,ISP&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;X_COORDINATE&lt;/th&gt; &lt;td&gt;30424.4244873&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;Y_COORDINATE&lt;/th&gt; &lt;td&gt;38509.61595566&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;68380F0447C3CEAD&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20210926121846&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt;\n                        geometry\n1  POINT Z (10760.19 34206.12 0)\n2  POINT Z (4985.534 30167.99 0)\n3  POINT Z (23812.59 34780.58 0)\n4  POINT Z (32176.99 37348.35 0)\n5   POINT Z (30293.8 32752.15 0)\n6   POINT Z (38940.53 37479.8 0)\n7  POINT Z (24094.69 31368.74 0)\n8  POINT Z (29405.66 39327.37 0)\n9  POINT Z (33468.49 32785.68 0)\n10 POINT Z (30424.42 38509.62 0)\n\n\n\n\nVisualising Polygon then point (otherwise point will cover over)\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\ntm_shape(buffer_1km) + # 1km circle then counting the dots - CHAS clinics\n  tm_polygons() +\ntm_shape(CHAS) +\n  tm_dots()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/Take-home_Ex3b-HDBDataPrep.html#counting-points-point-in-polygon-count---a-boundary-is-required-done-by-creating-the-buffer",
    "href": "In-class_Ex/In-class_Ex08/Take-home_Ex3b-HDBDataPrep.html#counting-points-point-in-polygon-count---a-boundary-is-required-done-by-creating-the-buffer",
    "title": "Preparing HDB data",
    "section": "Counting Points (point in polygon count - a boundary is required done by creating the buffer)",
    "text": "Counting Points (point in polygon count - a boundary is required done by creating the buffer)\n\nbuffer_1km$pts_count &lt;- lengths( # pts_count is a new field created\n  st_intersects(buffer_1km, CHAS))\n\nNote one dot outside of SG - to fix or remove if possible."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/Take-home_Ex3b-HDBDataPrep.html#data-preparation",
    "href": "In-class_Ex/In-class_Ex08/Take-home_Ex3b-HDBDataPrep.html#data-preparation",
    "title": "Preparing HDB data",
    "section": "Data Preparation",
    "text": "Data Preparation\nProximity - data from data.gov.sg. they are in kml file - are in wgs84 and have to do st_transform.\nRetail site - shopping mall list - use the httr.\nOverlap is workable if building hedonic model. for geospatial then no even so if using gwr. - same blocks of buildings will have multiple transactions.\nThere is also the function of spatstat jitter. Look at in class ex 8 for spatial jitter"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html",
    "title": "Modelling Geographic of Accessibility",
    "section": "",
    "text": "Issue on accessibility of MRT transportation and utilisation (over/under). Education sector - combining of JCs Fast food chains - KFC,Pizza hut etc - delivery based on the service level and location of order.\nThe notion of distance - not just km/m etc, but in terms of continuous and network distance.\nBalancing between time and cost.\nConcept of distance friction or impedance.\npower value - 2, 2.5, 3 - short impedance, value already close to zero. for power function the demand can drop very quickly\nexponential - for activities that are less sharp in drop.\ndrop is relatively slower\nboth options can be utilised in real world scenario, certain activities have a slower drop.\nModified Area Unit\nAn abstract area not affected by the administrative boundary for calibration of model.\nHexagon preferred to square as square has dimension issues - bias from adjacent distances. Hexagons are the most circular-shaped polygon that can tessellate to form an evenly spaced grid.\n“Good” distance/radius for a hexagon. 250m Within a study area to avoid picking an individual house etc. To find appropriate area to use trial and error before finding an appropriate radius.\nTo find accessibility - finding shortest distance.\nThe Potential Model The classic model\n\nMass included in calculation (attractiveness of location)\n\nThe Modified Potential Formula"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#introduction",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#introduction",
    "title": "Modelling Geographic of Accessibility",
    "section": "",
    "text": "Issue on accessibility of MRT transportation and utilisation (over/under). Education sector - combining of JCs Fast food chains - KFC,Pizza hut etc - delivery based on the service level and location of order.\nThe notion of distance - not just km/m etc, but in terms of continuous and network distance.\nBalancing between time and cost.\nConcept of distance friction or impedance.\npower value - 2, 2.5, 3 - short impedance, value already close to zero. for power function the demand can drop very quickly\nexponential - for activities that are less sharp in drop.\ndrop is relatively slower\nboth options can be utilised in real world scenario, certain activities have a slower drop.\nModified Area Unit\nAn abstract area not affected by the administrative boundary for calibration of model.\nHexagon preferred to square as square has dimension issues - bias from adjacent distances. Hexagons are the most circular-shaped polygon that can tessellate to form an evenly spaced grid.\n“Good” distance/radius for a hexagon. 250m Within a study area to avoid picking an individual house etc. To find appropriate area to use trial and error before finding an appropriate radius.\nTo find accessibility - finding shortest distance.\nThe Potential Model The classic model\n\nMass included in calculation (attractiveness of location)\n\nThe Modified Potential Formula"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#getting-started",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#getting-started",
    "title": "Modelling Geographic of Accessibility",
    "section": "2 Getting Started",
    "text": "2 Getting Started\n\npacman::p_load(tmap, SpatialAcc, sf, \n               ggstatsplot, reshape2,\n               tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#importing-data",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#importing-data",
    "title": "Modelling Geographic of Accessibility",
    "section": "3 Importing Data",
    "text": "3 Importing Data"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#geospatial-data",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#geospatial-data",
    "title": "Modelling Geographic of Accessibility",
    "section": "4 Geospatial Data",
    "text": "4 Geospatial Data\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_NO_SEA_PL\") %&gt;% st_transform(crs = 3414)\n\nReading layer `MP14_SUBZONE_NO_SEA_PL' from data source \n  `C:\\zjho008\\ISSS626-GAA\\In-class_Ex\\In-class_Ex09\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\nhexagons &lt;- st_read(dsn = \"data/geospatial\", layer = \"hexagons\") %&gt;% st_transform(crs = 3414)\n\nReading layer `hexagons' from data source \n  `C:\\zjho008\\ISSS626-GAA\\In-class_Ex\\In-class_Ex09\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 3125 features and 6 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 21506.33 xmax: 50010.26 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\n\neldercare &lt;- st_read(dsn = \"data/geospatial\", layer = \"ELDERCARE\") %&gt;% st_transform(crs = 3414)\n\nReading layer `ELDERCARE' from data source \n  `C:\\zjho008\\ISSS626-GAA\\In-class_Ex\\In-class_Ex09\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 120 features and 19 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 14481.92 ymin: 28218.43 xmax: 41665.14 ymax: 46804.9\nProjected CRS: SVY21 / Singapore TM\n\nCHAS &lt;- st_read(\"data/rawdata/CHASClinics.kml\") %&gt;% st_transform(crs = 3414)\n\nReading layer `MOH_CHAS_CLINICS' from data source \n  `C:\\zjho008\\ISSS626-GAA\\In-class_Ex\\In-class_Ex09\\data\\rawdata\\CHASClinics.kml' \n  using driver `KML'\nSimple feature collection with 1193 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.5818 ymin: 1.016264 xmax: 103.9903 ymax: 1.456037\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\n4.1 Buffering for eldercare\n\nbuffer_1km &lt;- st_buffer(eldercare, \n                        dist = 1000)\n\n\n\n4.2 Visualising\nThe code chunk below is used to plot the newly created buffers and the CHAS clinics.\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\ntm_shape(buffer_1km) +\n  tm_polygons() +\ntm_shape(CHAS) +\n  tm_dots()\n\n\n\n\n\n\n\n4.3 Count Number of Points within a Distance\nLastly, the code chunk below is used to count the number of CHAS clinics with 1km of each eldercare centre.\n\nbuffer_1km$pts_count &lt;- lengths(\n  st_intersects(buffer_1km, CHAS))\n\n\n\n4.4 OD Matrix\n\nODMatrix &lt;- read_csv(\"data/aspatial/OD_Matrix.csv\",\n                     skip = 0)\n\nRows: 375000 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (6): origin_id, destination_id, entry_cost, network_cost, exit_cost, tot...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nr5r package - uses open street map data. - Using java library."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#data-cleaning-and-updating-attributes",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#data-cleaning-and-updating-attributes",
    "title": "Modelling Geographic of Accessibility",
    "section": "5 Data Cleaning and Updating Attributes",
    "text": "5 Data Cleaning and Updating Attributes\n\n5.1 Supply (Eldercare)\n\neldercare &lt;- eldercare %&gt;%\n  select(fid, ADDRESSPOS) %&gt;%\n  mutate(capacity = 100) # artificially include a capacity/ or do survey via web crawling (services + capacity of centre) Note some variables which are not useful for analysis hence the select() function used to select he \"fid\" variable\n\n\n\n5.2 Demand (CHAS)\n\nhexagons &lt;- hexagons %&gt;%\n  select(fid) %&gt;%\n  mutate(demand = 100) # artificially input each hexagon will give a demand of 100 - crawl HDB site for HDB and no. of floors\n\n\n\n5.3 OD Matrix\n\ndistmat &lt;- ODMatrix %&gt;%\n  select(origin_id, destination_id, total_cost) %&gt;%\n  spread(destination_id, total_cost) %&gt;% # destinations become columns\n  select(c(-c('origin_id')))\n\n3125 rows of 120 variables. each variable is representing the elder care now. No more spread function - but called pivot longer.\n\ndistmat_km &lt;- as.matrix(distmat/1000)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#computing-handsens-accessibility",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#computing-handsens-accessibility",
    "title": "Modelling Geographic of Accessibility",
    "section": "6 Computing Handsen’s Accessibility",
    "text": "6 Computing Handsen’s Accessibility\n\n6.1 The base code\n\nacc_Hansen &lt;- data.frame(ac(hexagons$demand,\n                            eldercare$capacity,\n                            distmat_km,\n                            #d0 = 50,\n                            power = 2, \n                            family = \"Hansen\"))\n\n\n\n6.2 Tidying the output\n\ncolnames(acc_Hansen) &lt;- \"accHansen\"\n\nacc_Hansen &lt;- as_tibble(acc_Hansen)\n\nhexagon_Hansen &lt;- bind_cols(hexagons, acc_Hansen)\n\n\n\n6.3 Combining the Code Chunk\n\nacc_Hansen &lt;- data.frame(ac(hexagons$demand,\n                            eldercare$capacity,\n                            distmat_km, \n                            #d0 = 50,\n                            power = 0.5, \n                            family = \"Hansen\"))\n\ncolnames(acc_Hansen) &lt;- \"accHansen\"\nacc_Hansen &lt;- as_tibble(acc_Hansen)\nhexagon_Hansen &lt;- bind_cols(hexagons, acc_Hansen)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#visualising-accessibility",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#visualising-accessibility",
    "title": "Modelling Geographic of Accessibility",
    "section": "7 Visualising Accessibility",
    "text": "7 Visualising Accessibility\n\nThe CodeThe Plot\n\n\n\nmapex &lt;- st_bbox(hexagons)\n\ntmap_mode(\"plot\")\ntm_shape(hexagon_Hansen,\n         bbox = mapex) + \n  tm_fill(col = \"accHansen\",\n          n = 10,\n          style = \"quantile\",\n          border.col = \"black\",\n          border.lwd = 1) +\ntm_shape(eldercare) +\n  tm_symbols(size = 0.1) +\n  tm_layout(main.title = \"Accessibility to eldercare: Hansen method\",\n            main.title.position = \"center\",\n            main.title.size = 2,\n            legend.outside = FALSE,\n            legend.height = 0.45, \n            legend.width = 3.0,\n            legend.format = list(digits = 6),\n            legend.position = c(\"right\", \"top\"),\n            frame = TRUE) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.5)\n\n\n\n\n\ntmap mode set to plotting"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#statistical-graphic",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#statistical-graphic",
    "title": "Modelling Geographic of Accessibility",
    "section": "8 Statistical Graphic",
    "text": "8 Statistical Graphic\n\nhexagon_Hansen &lt;- st_join(hexagon_Hansen, mpsz, \n                          join = st_intersects)\n\n\nThe CodeThe Plot\n\n\n\nggbetweenstats(\n  data = hexagon_Hansen,\n  x = REGION_N,\n  y = accHansen,\n  type = \"p\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPersonal Notes\n\n\n\nUsing random forest\nChange the default don’t need to use 500 trees, maybe 50 trees is okay. Reduce no. of trees -\nJust use the 3 room flat OR 4 room flats.\nSpatialML, use gwmodel, gwr"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#overview",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#overview",
    "title": "Take-home Exercise 3b: Geospatial Analytics",
    "section": "",
    "text": "For take-home exercise 3, it consists of 2 options: Take-home Exercise 3a: Modelling Geography of Financial Inclusion with Geographically Weighted Methods & Take-home Exercise 3b: Predicting HDB Resale Prices with Geographically Weighted Machine Learning Methods. The selected option for this take-home exercise will be 3b.\nHousing plays a crucial role in household wealth across the globe, with purchasing a home representing a significant investment for most individuals. Housing prices are influenced by a variety of factors. Some of these factors are global, such as the overall economic conditions of a country or the inflation rate, while others are specific to individual properties. These factors can be categorised into structural and locational components.\nStructural factors relate directly to the characteristics of the property, such as its size, amenities, and tenure.\nLocational factors pertain to the surrounding environment, including proximity to childcare centres, public transportation, and shopping facilities.\nTraditionally, predictive models for housing resale prices have been developed using the Ordinary Least Squares (OLS) method. However, this approach does not account for spatial autocorrelation and spatial heterogeneity present in geographic datasets, such as those related to housing transactions. When spatial autocorrelation is present, OLS estimates can produce biased, inconsistent, or inefficient results (Anselin 1998). To address this limitation, Geographically Weighted Models (GWMs) have been introduced, offering a more accurate approach to modelling and predicting housing resale prices. The steps involved will ultimately build a hedonic pricing models using this methods.\n\n\nFor this take-home exercise, the primary dataset should be the HDB Resale Flat Prices available on data.gov.sg The analysis should concentrate on one specific flat type: three-room, four-room, or five-room flats.\nThe following is a list of suggested predictors to consider, though students are encouraged to include any other relevant independent variables that may enhance the analysis.\n\nStructural factors\n\nArea of the unit\nFloor level\nRemaining lease\nAge of the unit\nMain Upgrading Program (MUP) completed (optional)\n\nLocational factors\n\nProximity to CBD\nProximity to eldercare\nProximity to foodcourt/hawker centres\nProximity to MRT\nProximity to park\nProximity to good primary school\nProximity to shopping mall\nProximity to supermarket\nNumbers of kindergartens within 350m\nNumbers of childcare centres within 350m\nNumbers of bus stop within 350m\nNumbers of primary school within 1km\n\n\nThe four-room flats will be the chosen flat type for analysis as it is one of the most common HDB BTO flat types, which offers a comfortable living space for young couples and families.\nAdditionally, in this take-home exercise, we are tasked with calibrating a predictive model to forecast HDB resale prices for the period of July to September 2024, using resale transaction data from 2023 as the basis for analysis."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#installing-and-loading-r-packages",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#installing-and-loading-r-packages",
    "title": "Take-home Exercise 3b: Geospatial Analytics",
    "section": "2 Installing and Loading R Packages",
    "text": "2 Installing and Loading R Packages\nThe code chunk below will ensure for a list of required R packages to be created, checked for installation, and installed if missing. Once installed, all packages will be loaded for use in the exercise.\n\npacman::p_load(tidyverse, sf, spdep, GWmodel, SpatialML, spatstat, units, matrixStats, ggpubr,\n               tmap, rsample, Metrics, httr, jsonlite, rvest, olsrr, corrplot, ggstatsplot)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex3b-HDBDataPrep.html",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex3b-HDBDataPrep.html",
    "title": "Preparing HDB data",
    "section": "",
    "text": "pacman::p_load(tidyverse, sf, httr, jsonlite, rvest)\n\n\nresale &lt;- read_csv(\"data/HDB/rawdata/resale.csv\") %&gt;%\n  filter(month &gt;= \"2023-01\" & month &lt;= \"2024-09\")\n\nRows: 193068 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (8): month, town, flat_type, block, street_name, storey_range, flat_mode...\ndbl (3): floor_area_sqm, lease_commence_date, resale_price\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nresale_tidy &lt;- resale %&gt;%\n  mutate(address = paste(block,street_name)) %&gt;%\n  mutate(remaining_lease_yr = as.integer(\n    str_sub(remaining_lease, 0, 2)))%&gt;%\n  mutate(remaining_lease_mth = as.integer(\n    str_sub(remaining_lease, 9, 11)))\n\n\nresale_selected &lt;- resale_tidy %&gt;%\n  filter(month == \"2024-09\")\n\n\nadd_list &lt;- sort(unique(resale_selected$address))\n\n\nget_coords &lt;- function(add_list){\n  \n  # Create a data frame to store all retrieved coordinates\n  postal_coords &lt;- data.frame()\n    \n  for (i in add_list){\n    #print(i)\n\n    r &lt;- GET('https://www.onemap.gov.sg/api/common/elastic/search?',\n           query=list(searchVal=i,\n                     returnGeom='Y',\n                     getAddrDetails='Y'))\n    data &lt;- fromJSON(rawToChar(r$content))\n    found &lt;- data$found\n    res &lt;- data$results\n    \n    # Create a new data frame for each address\n    new_row &lt;- data.frame()\n    \n    # If single result, append \n    if (found == 1){\n      postal &lt;- res$POSTAL \n      lat &lt;- res$LATITUDE\n      lng &lt;- res$LONGITUDE\n      new_row &lt;- data.frame(address= i, \n                            postal = postal, \n                            latitude = lat, \n                            longitude = lng)\n    }\n    \n    # If multiple results, drop NIL and append top 1\n    else if (found &gt; 1){\n      # Remove those with NIL as postal\n      res_sub &lt;- res[res$POSTAL != \"NIL\", ]\n      \n      # Set as NA first if no Postal\n      if (nrow(res_sub) == 0) {\n          new_row &lt;- data.frame(address= i, \n                                postal = NA, \n                                latitude = NA, \n                                longitude = NA)\n      }\n      \n      else{\n        top1 &lt;- head(res_sub, n = 1)\n        postal &lt;- top1$POSTAL \n        lat &lt;- top1$LATITUDE\n        lng &lt;- top1$LONGITUDE\n        new_row &lt;- data.frame(address= i, \n                              postal = postal, \n                              latitude = lat, \n                              longitude = lng)\n      }\n    }\n\n    else {\n      new_row &lt;- data.frame(address= i, \n                            postal = NA, \n                            latitude = NA, \n                            longitude = NA)\n    }\n    \n    # Add the row\n    postal_coords &lt;- rbind(postal_coords, new_row)\n  }\n  return(postal_coords)\n}\n\n\ncoords &lt;- get_coords(add_list)\n\n\nwrite_rds(coords, \"data/HDB/rds/coords.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#visualising-the-data",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#visualising-the-data",
    "title": "Take-home Exercise 3b: Geospatial Analytics",
    "section": "6 Visualising the Data",
    "text": "6 Visualising the Data\nIn this section we will do quick visualisations without much customisations done just to ensure that the data is appropriate before proceeding.\n\nmpszEldercareCHASChildcare CentreKindergartensParks (NEA)Hawker CentresSupermarketsBus StopsMRT Stations\n\n\n\ntm_shape(mpsz) +\n  tm_polygons(col = \"grey\")\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz) +\n  tm_polygons(col = \"grey\") +\n  tm_shape(eldercare) +\n  tm_dots(col = \"red\", size = 0.1)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz) +\n  tm_polygons(col = \"grey\") +\n  tm_shape(chas) +\n  tm_dots(col = \"red\")\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz) +\n  tm_polygons(col = \"grey\") +\n  tm_shape(childcare) +\n  tm_dots(col = \"red\")\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz) +\n  tm_polygons(col = \"grey\") +\n  tm_shape(kindergartens) +\n  tm_dots(col = \"red\", size = 0.08)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz) +\n  tm_polygons(col = \"grey\") +\n  tm_shape(parks) +\n  tm_dots(col = \"red\", size = 0.08)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz) +\n  tm_polygons(col = \"grey\") +\n  tm_shape(hawker_centre) +\n  tm_dots(col = \"red\", size = 0.1)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz) +\n  tm_polygons(col = \"grey\") +\n  tm_shape(supermarkets) +\n  tm_dots(col = \"red\", size = 0.08)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz) +\n  tm_polygons(col = \"grey\") +\n  tm_shape(bus_stops) +\n  tm_dots(col = \"red\", size = 0.005)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz) +\n  tm_polygons(col = \"grey\") +\n  tm_shape(MRT) +\n  tm_dots(col = \"red\", size = 0.1)\n\n\n\n\n\n\n\n\n\n\n\nBased on the above visualisations the data points look in place without any abnormalities."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#locational-factors-proximity-calculation",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#locational-factors-proximity-calculation",
    "title": "Take-home Exercise 3b: Geospatial Analytics",
    "section": "7 Locational Factors (Proximity Calculation)",
    "text": "7 Locational Factors (Proximity Calculation)\nNow to calculate the proximity of HDB flats to relevant facilities. The provided proximity function - credits streamlines this process by calculating the minimum distance from each feature in df1 to the nearest feature in df2 and assigning this distance to a new column specified by varname.\nThe following locational factors will be calculated in terms of proximity:\n-   Proximity to CBD (Raffles Place, Tanjong Pagar MRT & City Hall MRT)\n-   Proximity to eldercare\n-   Proximity to CHAS Clinics\n-   Proximity to supermarket\n-   Proximity to hawker centres\n-   Proximity to supermarket\n-   Proximity to MRT\n-   Numbers of kindergartens within 350m\n-   Numbers of childcare centres within 350m\n-   Numbers of bus stop within 350m\n\nproximity &lt;- function(df1, df2, varname) {\n  dist_matrix &lt;- st_distance(df1, df2) %&gt;%\n    drop_units()\n  \n  # Calculate minimum distance for each row\n  df1[,varname] &lt;- rowMins(dist_matrix)\n  \n  return(df1)\n}\n\n\ncbd &lt;- filter(MRT, STN_NAM_DE %in% c(\"RAFFLES PLACE MRT STATION\", \"TANJONG PAGAR MRT STATION\", \"CITY HALL MRT STATION\"))\nresale_tidy &lt;- proximity(resale_tidy, cbd, \"PROX_CBD\") %&gt;%\n  proximity(., eldercare, \"PROX_ELDERCARE\") %&gt;%\n  proximity(., chas, \"PROX_CHAS\") %&gt;%\n  proximity(., hawker_centre, \"PROX_HAWKER\") %&gt;%\n  proximity(., MRT, \"PROX_MRT\") %&gt;%\n  proximity(., parks, \"PROX_PARK\") %&gt;%\n  proximity(., childcare, \"PROX_CHILDCARE\") %&gt;%\n  proximity(., kindergartens, \"PROX_KINDERGARTEN\") %&gt;%\n  proximity(., supermarkets, \"PROX_SUPERMARKET\") %&gt;%\n  proximity(., bus_stops, \"PROX_BUS_STOP\")\n\nWe also need to calculate the number of facilities within a specific radius from the resale flats. The count_in_radius function accomplishes this by calculating the distance matrix between df1 and df2 using st_distance, identifying features within the specified radius, and summing these counts in a new column in df1 designated by varname.\n\ncount_in_radius &lt;- function(df1, df2, varname, radius) {\n  dist_matrix &lt;- st_distance(df1, df2) %&gt;%\n    drop_units() %&gt;%\n    as.data.frame()\n  df1[,varname] &lt;- rowSums(dist_matrix &lt;= radius)\n  return(df1)\n}\n\nThe code chunk below is used to calculate the locational factors within a 350m radius\n\nresale_tidy &lt;- count_in_radius(resale_tidy, kindergartens, \"NUM_KINDERGARTEN\", 350) %&gt;%\n  count_in_radius(., childcare, \"NUM_CHILDCARE\", 350) %&gt;%\n  count_in_radius(., bus_stops, \"NUM_BUS_STOP\", 350) %&gt;%\n  count_in_radius(., chas, \"NUM_CHAS\", 350)\n\nCalibrating predictive models are computationally intensive, especially when the random forest method is used. For quick prototyping, a smaller sample will be selected at random from the data by using the code chunk below.\nresale_tidy consists of 14733 observations and 23 variables.\nA sample of 5000 will be used.\n\nset.seed(1234)\n\nresale_tidy &lt;- resale_tidy %&gt;%\n  sample_n(5000)\n\n\n7.1 Checking of overlapping points\nThe code chunk below is used to check if there are overlapping point features.\n\noverlapping_points &lt;- resale_tidy %&gt;%\n  mutate(overlap = lengths(st_equals(., .)) &gt; 1)\n\n\nBased on the results, it is observed that there are already multiple overlaps hence, in the code code chunk below, st_jitter() of sf package is used to move the point features by 3 metres to avoid overlapping point features.\n\nMoving point features2nd layer checks\n\n\n\nresale_tidy &lt;- resale_tidy %&gt;%\n  st_jitter(amount = 3)\n\n\n\nThe code chunk is run again to check for overlapping points.\n\noverlapping_points &lt;- resale_tidy %&gt;%\n  mutate(overlap = lengths(st_equals(., .)) &gt; 1)\n\nThe results now show that there are no overlapping point features with no results shown when TRUE is selected for the overlap variable.\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWhen using GWmodel to calibrate explanatory or predictive models, it is very important to ensure that there are no overlapping point features\n\n\n\nwrite_rds(resale_tidy, \"data/HDB/rds/int_resale.rds\")\n\n\nresale_tidy &lt;- read_rds(\"data/HDB/rds/int_resale.rds\")\n\nColumns which are not needed for this analysis in this exercise will be dropped and the file is then saved as a RDS file for ease of retrieval without the need to run the above code chunks again.\n\nresale_tidy &lt;- resale_tidy %&gt;%\n  rename(\n    MONTH = month,\n    TOWN = town,\n    FLOOR_AREA_SQM = floor_area_sqm,\n    ADDRESS = address,\n    RESALE_PRICE = resale_price,\n    LEVEL = level,\n    REMAINING_LEASE = remaining_lease,\n    UNIT_AGE = unit_age\n  ) %&gt;%\n  select(MONTH, TOWN, ADDRESS, REMAINING_LEASE, FLOOR_AREA_SQM, UNIT_AGE, RESALE_PRICE, LEVEL,\n         PROX_CBD, PROX_ELDERCARE, PROX_CHAS, PROX_HAWKER, PROX_MRT, PROX_PARK, PROX_CHILDCARE,\n         PROX_KINDERGARTEN, PROX_SUPERMARKET, PROX_BUS_STOP, NUM_KINDERGARTEN, NUM_CHILDCARE, NUM_BUS_STOP, NUM_CHAS)\n\nwrite_rds(resale_tidy, \"data/HDB/rds/final_resale.rds\")\n\nCode chunk below is used for ease of retrieving the finalised resale_tidy data table\n\nresale_tidy &lt;- read_rds(\"data/HDB/rds/final_resale.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#exploratory-data-analysis-eda",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#exploratory-data-analysis-eda",
    "title": "Take-home Exercise 3b: Geospatial Analytics",
    "section": "8 Exploratory Data Analysis (EDA)",
    "text": "8 Exploratory Data Analysis (EDA)\nIn the section, it will make use of statistical graphics functions of ggplot2 package to perform EDA on resale_tidy\n\n8.1 EDA using statistical graphics\n\n8.1.1 Resale Price\n\nggplot(data = resale_tidy, aes(x = `RESALE_PRICE`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"salmon\")\n\n\n\n\n\n\n\n\nThe figure above reveals a right skewed distribution. This means that more 4-room resale units were transacted at relative lower prices ranging from $400,000 to $600,000 price range.\n\n\n8.1.2 Floor Area (SQM)\n\nggplot(data = resale_tidy, aes(x = `FLOOR_AREA_SQM`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"salmon\")\n\n\n\n\n\n\n\n\nIn terms of floor area, the figure above reveals a right skewed distribution. This means that 4-room resale units were within the 90 to 100 sqm floor area.\n\n\n8.1.3 Multiple Histogram Plots for Locational Factors\nThe code chunk below is used to create 12 histograms. Then, ggarrange() is used to organised the histograms into a 3 column by 4 row small multiple plot.\n\nAREA_SQM &lt;- ggplot(data = resale_tidy, aes(x= `FLOOR_AREA_SQM`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nAGE &lt;- ggplot(data = resale_tidy, aes(x= `UNIT_AGE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nREMAINING_LEASE &lt;- ggplot(data = resale_tidy, aes(x= `REMAINING_LEASE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_CBD &lt;- ggplot(data = resale_tidy, aes(x= `PROX_CBD`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_CHILDCARE &lt;- ggplot(data = resale_tidy, aes(x= `PROX_CHILDCARE`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_ELDERCARE &lt;- ggplot(data = resale_tidy, aes(x= `PROX_ELDERCARE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_HAWKER &lt;- ggplot(data = resale_tidy, aes(x = `PROX_HAWKER`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_KINDERGARTEN &lt;- ggplot(data = resale_tidy, aes(x = `PROX_KINDERGARTEN`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_MRT &lt;- ggplot(data = resale_tidy, aes(x= `PROX_MRT`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_PARK &lt;- ggplot(data = resale_tidy, aes(x= `PROX_PARK`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_BUS_STOP &lt;- ggplot(data = resale_tidy, aes(x= `PROX_BUS_STOP`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_SUPERMARKET &lt;- ggplot(data = resale_tidy, \n                               aes(x= `PROX_SUPERMARKET`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\n\nggarrange(AREA_SQM, AGE, REMAINING_LEASE, PROX_CBD, PROX_CHILDCARE,\n          PROX_ELDERCARE, PROX_HAWKER, PROX_KINDERGARTEN, PROX_MRT,\n          PROX_PARK, PROX_BUS_STOP, PROX_SUPERMARKET,  \n          ncol = 3, nrow = 4)\n\n\n\n\n\n\n\n\n\n\n\n8.2 Statistical Point Map\nWe can also reveal the geospatial pattern distribution of four-room HDB resale prices and unit age sold in Singapore. The map will be prepared by using tmap package.\nFirst, we will turn on the interactive mode of tmap by using the code chunk below.\n\ntmap_mode(\"view\")\n\n\nResale PriceUnit Age\n\n\n\ntm_shape(mpsz)+\n  tm_polygons() +\ntm_shape(resale_tidy) +  \n  tm_dots(col = \"RESALE_PRICE\",\n          alpha = 0.6,\n          style=\"quantile\") +\n  tm_view(set.zoom.limits = c(11,14))\n\n\n\n\n\nset.zoom.limits argument of tm_view() sets the minimum and maximum zoom level to 11 and 14 respectively.\n\n\n\ntm_shape(mpsz)+\n  tm_polygons() +\ntm_shape(resale_tidy) +  \n  tm_dots(col = \"UNIT_AGE\",\n          alpha = 0.6,\n          style=\"quantile\") +\n  tm_view(set.zoom.limits = c(11,14))\n\n\n\n\n\n\n\n\nBefore moving on to the next section, the code below will be used to turn R display into plot mode. This also helps to reduce rendering time.\n\ntmap_mode(\"plot\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#hdb-resale-data-aspatial",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#hdb-resale-data-aspatial",
    "title": "Take-home Exercise 3b: Geospatial Analytics",
    "section": "3 HDB resale Data (Aspatial)",
    "text": "3 HDB resale Data (Aspatial)\nThe following sections will consist of steps which import, process and wrangling of data.\nData used for this exercise is HDB Resale data: a list of HDB resale transacted prices in Singapore from Jan 2017 onwards. It is in csv format which can be downloaded from data.gov.sg.\n\nWhen first downloaded, the data was labelled as ResaleflatpricesbasedonregistrationdatefromJan2017onwards. Hence, it was subsequently renamed to resale for ease of referencing and to avoid unnecessary mistakes. Similar to what is required in the task of using HDB resale transaction records in 2023 to predict HDB resale prices between July-September 2024 the code chunk below filters for transaction records for the entirety of 2023 and July till September 2024. Based on the requirements of this exercise, I have decided to focus my study on four-room flats.\n\n\nresale &lt;- read_csv(\"data/HDB/rawdata/resale.csv\") %&gt;%\n  filter(month &gt;= \"2023-01\" & month &lt;= \"2023-12\" | month %in% c(\"2024-07\", \"2024-08\", \"2024-09\")) %&gt;%\n  filter(flat_type == \"4 ROOM\")\n\n\n\n\nresale data snipshot\n\n\nThe observations have been reduced to 14733 after reducing the area of study to soley four-room flats.\nThe code chunk below serves the functions of combining block and street_name variables to create a new and more complete variable address (excluding unit number) alongside remaining_lease_yr and remaining_lease_mth extracted from remaining_lease. This function will supplement our steps later on in creating the model.\n\nresale_tidy &lt;- resale %&gt;%\n  mutate(address = paste(block,street_name)) %&gt;%\n  mutate(remaining_lease_yr = as.integer(\n    str_sub(remaining_lease, 0, 2)))%&gt;%\n  mutate(remaining_lease_mth = as.integer(\n    str_sub(remaining_lease, 9, 11)))\n\nDue to the addresses having same street names, a list is created with unique addresses to reduce the number of records and for the list to be passed through for API ingestion in the following steps. The sort function is used to reorder the records so that records will be in order. In essence, the code chunk below sorts a list of unique addresses to avoid the issue of repeated geocoding.\n\nadd_list &lt;- sort(unique(resale_tidy$address))\n\nThe following code chunks are used to obtain the postal code of the addresses using geocoding by passing the entries through the onemap API. This code chunk is credited to Prof. Kam where a HTTP address is sent to the OneMap API.\n\nget_coords &lt;- function(add_list){\n  \n  # Create a data frame to store all retrieved coordinates\n  postal_coords &lt;- data.frame()\n    \n  for (i in add_list){\n    #print(i)\n\n    r &lt;- GET('https://www.onemap.gov.sg/api/common/elastic/search?',\n           query=list(searchVal=i,\n                     returnGeom='Y',\n                     getAddrDetails='Y'))\n    data &lt;- fromJSON(rawToChar(r$content))\n    found &lt;- data$found\n    res &lt;- data$results\n    \n    # Create a new data frame for each address\n    new_row &lt;- data.frame()\n    \n    # If single result, append \n    if (found == 1){\n      postal &lt;- res$POSTAL \n      lat &lt;- res$LATITUDE\n      lng &lt;- res$LONGITUDE\n      new_row &lt;- data.frame(address= i, \n                            postal = postal, \n                            latitude = lat, \n                            longitude = lng)\n    }\n    \n    # If multiple results, drop NIL and append top 1\n    else if (found &gt; 1){\n      # Remove those with NIL as postal\n      res_sub &lt;- res[res$POSTAL != \"NIL\", ]\n      \n      # Set as NA first if no Postal\n      if (nrow(res_sub) == 0) {\n          new_row &lt;- data.frame(address= i, \n                                postal = NA, \n                                latitude = NA, \n                                longitude = NA)\n      }\n      \n      else{\n        top1 &lt;- head(res_sub, n = 1)\n        postal &lt;- top1$POSTAL \n        lat &lt;- top1$LATITUDE\n        lng &lt;- top1$LONGITUDE\n        new_row &lt;- data.frame(address= i, \n                              postal = postal, \n                              latitude = lat, \n                              longitude = lng)\n      }\n    }\n\n    else {\n      new_row &lt;- data.frame(address= i, \n                            postal = NA, \n                            latitude = NA, \n                            longitude = NA)\n    }\n    \n    # Add the row\n    postal_coords &lt;- rbind(postal_coords, new_row)\n  }\n  return(postal_coords)\n}\n\nFollowing which, the get_coords() function is used to crawl the coordinates from the generated list\n\ncoords &lt;- get_coords(add_list)\n\n\nSaving RDS fileReading RDS File\n\n\nThe following code chunk will be used to save the results to avoid having to re-run the code chunks above which will take up additional time and resources.\n\nwrite_rds(coords, \"data/HDB/rds/coords.rds\")\n\n\n\n\ncoords &lt;- read_rds('data/HDB/rds/coords.rds')\n\n\n\n\n\n3.1 Setting CRS for HDB Resale Data\nThe code chunk below first creates an sf object before the EPSG code is set for Singapore which is 3414\n\nresale_tidy &lt;- resale_tidy %&gt;%\n  left_join(coords, by = c(\"address\" = \"address\")) %&gt;%\n  st_as_sf(coords = c(\"longitude\", \"latitude\"), crs = 4326) %&gt;%\n  st_transform(crs = 3414)\n\nwrite_rds(resale_tidy, \"data/HDB/rds/resale.rds\")\n\n\nresale_tidy &lt;- read_rds(\"data/HDB/rds/resale.rds\")\n\n\n\n3.2 Structural factors for HDB Resale units\n\nStructural factors\n\nArea of the unit\nFloor level\nRemaining lease\nAge of the unit\nMain Upgrading Program (MUP) completed (optional)\n\n\n\n3.2.1 Floor Level\nAs one of the structural factors the code chunk below is used to view the floor levels in resale_tidy using the unique() function\n\nunique(resale_tidy$storey_range)\n\n [1] \"07 TO 09\" \"10 TO 12\" \"01 TO 03\" \"04 TO 06\" \"16 TO 18\" \"25 TO 27\"\n [7] \"13 TO 15\" \"22 TO 24\" \"19 TO 21\" \"28 TO 30\" \"34 TO 36\" \"43 TO 45\"\n[13] \"31 TO 33\" \"46 TO 48\" \"40 TO 42\" \"37 TO 39\" \"49 TO 51\"\n\n\nAs the variable for storey_range is in string, transformation is done to mutate it as numeric. However, the storey_range as stated follows a range which will make it hard for analysis as the exact floor level is not stated. Hence, this numeric attribute will be transformed based on the median value as the chosen method ensuring that we have values to work with instead of a range. The code transforms the storey_range variable from a string representing a range into a numeric variable by calculating the median floor level for each range, enabling easier analysis.\n\nresale_tidy &lt;- resale_tidy %&gt;%\n  mutate(\n    level = (as.numeric(str_extract(storey_range, \"^[0-9]+\")) +\n                  as.numeric(str_extract(storey_range, \"[0-9]+$\"))) / 2\n  )\n\nCode chunk below is used to get a summary if the transformation is done correctly\n\nsummary(resale_tidy$level)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  2.000   5.000   8.000   9.246  11.000  50.000 \n\n\n\n\n3.2.2 Remaining Lease & Age of Unit\nWe will also do some data wrangling for remaining_lease_yr & remaining_lease_mth. The code processes the remaining_lease_yr and remaining_lease_mth variables to first handle missing values, calculate the remaining lease in decimal years, and derive the unit’s age based on a 99-year HDB lease. The original year and month variables are then removed for a cleaner dataset.\n\nresale_tidy &lt;- resale_tidy %&gt;%\n  mutate(\n\n# Replace NA in months with 0 as observed in resale_tidy\n\nremaining_lease_mth = if_else(is.na(remaining_lease_mth), 0, remaining_lease_mth),\n    \n# Calculate remaining lease in decimal years\n  remaining_lease = remaining_lease_yr + (remaining_lease_mth / 12),\n    \n# Age of unit calculation based on a HDB 99-year lease\n    unit_age = 99 - remaining_lease\n  ) %&gt;%\n  relocate(remaining_lease_yr, remaining_lease_mth, .after = last_col())"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#locational-factors-geospatial",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#locational-factors-geospatial",
    "title": "Take-home Exercise 3b: Geospatial Analytics",
    "section": "4 Locational factors (Geospatial)",
    "text": "4 Locational factors (Geospatial)\nThe following locational factors will be derived from their respective data sources such as from data.gov.sg for this exercise.\n\nLocational factors\n\nProximity to CBD\nProximity to elder care\nProximity to hawker centres\nProximity to MRT\nProximity to park\nProximity to CHAS Clinics\nProximity to good primary school\nProximity to supermarket\nNumbers of kindergartens within 350m\nNumbers of childcare centres within 350m\nNumbers of bus stop within 350m\n\n\nBased on the locational factors above, we will import these geospatial data into the R environment. Firstly the Master Plan Subzone boundary data\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\") %&gt;%\n  st_transform(3414)\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Take-home_Ex\\Take-home_Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\nThe extent of mpsz is shown by using st_bbox() of sf package.\n\nst_bbox(mpsz) #view extent\n\n     xmin      ymin      xmax      ymax \n 2667.538 15748.721 56396.440 50256.334 \n\n\n\n4.1 Eldercare\n\neldercare &lt;- st_read(dsn = \"data/geospatial\", layer = \"ELDERCARE\") %&gt;%\n  st_transform(3414)\n\nReading layer `ELDERCARE' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Take-home_Ex\\Take-home_Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 133 features and 18 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 14481.92 ymin: 28218.43 xmax: 41665.14 ymax: 46804.9\nProjected CRS: SVY21\n\n\n\n\n4.2 CHAS Clinics\n\nchas &lt;- st_read(\"data/geospatial/CHASClinics.kml\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MOH_CHAS_CLINICS' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Take-home_Ex\\Take-home_Ex03\\data\\geospatial\\CHASClinics.kml' \n  using driver `KML'\nSimple feature collection with 1193 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.5818 ymin: 1.016264 xmax: 103.9903 ymax: 1.456037\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\n\n4.3 Childcare Centres\n\nchildcare &lt;- st_read(\"data/geospatial/ChildCareServices.kml\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `CHILDCARE' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Take-home_Ex\\Take-home_Ex03\\data\\geospatial\\ChildCareServices.kml' \n  using driver `KML'\nSimple feature collection with 1925 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\n\n4.4 Kindergartens\n\nkindergartens &lt;- st_read(\"data/geospatial/Kindergartens.geojson\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `Kindergartens' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Take-home_Ex\\Take-home_Ex03\\data\\geospatial\\Kindergartens.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 448 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6887 ymin: 1.247759 xmax: 103.9717 ymax: 1.455452\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\n\n4.5 Parks\n\nparks &lt;- st_read(\"data/geospatial/Parks.geojson\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `Parks' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Take-home_Ex\\Take-home_Ex03\\data\\geospatial\\Parks.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 430 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6929 ymin: 1.214491 xmax: 104.0538 ymax: 1.462094\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\n\n4.6 Hawker Centres\n\nhawker_centre &lt;- st_read(\"data/geospatial/HawkerCentresGEOJSON.geojson\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `HawkerCentresGEOJSON' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Take-home_Ex\\Take-home_Ex03\\data\\geospatial\\HawkerCentresGEOJSON.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 125 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6974 ymin: 1.272716 xmax: 103.9882 ymax: 1.449017\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\n\n4.7 Supermarkets\n\nsupermarkets &lt;- st_read(\"data/geospatial/SupermarketsGEOJSON.geojson\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `SupermarketsGEOJSON' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Take-home_Ex\\Take-home_Ex03\\data\\geospatial\\SupermarketsGEOJSON.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 526 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6258 ymin: 1.24715 xmax: 104.0036 ymax: 1.461526\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\n\n4.8 Bus Stop Locations\n\nbus_stops &lt;- st_read(dsn = \"data/geospatial\", layer = \"BusStop\") %&gt;%\n  st_transform(crs = 3414) %&gt;%\n  filter(lengths(st_within(., mpsz)) &gt; 0)\n\nReading layer `BusStop' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Take-home_Ex\\Take-home_Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 5166 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48285.52 ymax: 52983.82\nProjected CRS: SVY21\n\n\n\n\n4.9 MRT Accessibility\n\nMRT &lt;- st_read(dsn = \"data/geospatial\", layer = \"RapidTransitSystemStation\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `RapidTransitSystemStation' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Take-home_Ex\\Take-home_Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 230 features and 5 fields (with 1 geometry empty)\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 6068.209 ymin: 27478.44 xmax: 45377.5 ymax: 47913.58\nProjected CRS: SVY21\n\nSys.setenv(OGR_GEOMETRY_ACCEPT_UNCLOSED_RING = \"NO\")\n\nMRT &lt;- MRT[!st_is_empty(MRT), ]\n\n# Convert Polygon to Point\nMRT &lt;- st_centroid(MRT)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#processing-geospatial-data",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#processing-geospatial-data",
    "title": "Take-home Exercise 3b: Geospatial Analytics",
    "section": "5 Processing Geospatial Data",
    "text": "5 Processing Geospatial Data\nIn the previous section, we have loaded the geospatial data of interest it was also observed that some of this data consisted of the Z dimension. We will proceed to remove them as well as drop and unnecessary columns to reduce computation time and ensure geometries are valid.\n\nchas &lt;- st_zm(chas)\nchildcare &lt;- st_zm(childcare)\nkindergartens &lt;- st_zm(kindergartens)\nparks &lt;- st_zm(parks)\nhawker_centre &lt;- st_zm(hawker_centre)\nsupermarkets &lt;- st_zm(supermarkets)\n\nThe code chunks below are used to remove columns not exactly needed to do analysis as the needed variables are generally the Name for identification and Geometry variables. Note that not all the columns selected are Column 1.\n\neldercare &lt;- eldercare %&gt;%\n  select(c(1))\n\nchas &lt;- chas %&gt;%\n  select(c(1))\n\nchildcare &lt;- childcare %&gt;%\n  select(c(1))\n\nkindergartens &lt;- kindergartens %&gt;%\n  select(c(1))\n\nparks &lt;- parks %&gt;%\n  select(c(1))\n\nhawker_centre &lt;- hawker_centre %&gt;%\n  select(c(1))\n\nsupermarkets &lt;- supermarkets %&gt;%\n  select(c(1))\n\nbus_stops &lt;- bus_stops %&gt;%\n  select(c(1))\n\nMRT &lt;- MRT %&gt;%\n  select(c(5))\n\nThe code chunk below is used to ensure geometries are valid.\n\nlength(which(st_is_valid(mpsz) == FALSE))\n\n[1] 9\n\nlength(which(st_is_valid(eldercare) == FALSE))\n\n[1] 0\n\nlength(which(st_is_valid(chas) == FALSE))\n\n[1] 0\n\nlength(which(st_is_valid(childcare) == FALSE))\n\n[1] 0\n\nlength(which(st_is_valid(kindergartens) == FALSE))\n\n[1] 0\n\nlength(which(st_is_valid(parks) == FALSE))\n\n[1] 0\n\nlength(which(st_is_valid(hawker_centre) == FALSE))\n\n[1] 0\n\nlength(which(st_is_valid(supermarkets) == FALSE))\n\n[1] 0\n\nlength(which(st_is_valid(bus_stops) == FALSE))\n\n[1] 0\n\nlength(which(st_is_valid(MRT) == FALSE))\n\n[1] 0\n\n\nmpsz has invalid 9 invalid geometries which we will fix using st_make_valid()\n\nFixing Invalid GeometryChecks\n\n\n\nmpsz &lt;- st_make_valid(mpsz)\nlength(which(st_is_valid(mpsz) == FALSE))\n\n[1] 0\n\n\n\n\nThe code chunk is ran again to do checks ensuring valid geometries\n\nlength(which(st_is_valid(mpsz) == FALSE))\n\n[1] 0\n\nlength(which(st_is_valid(eldercare) == FALSE))\n\n[1] 0\n\nlength(which(st_is_valid(chas) == FALSE))\n\n[1] 0\n\nlength(which(st_is_valid(childcare) == FALSE))\n\n[1] 0\n\nlength(which(st_is_valid(kindergartens) == FALSE))\n\n[1] 0\n\nlength(which(st_is_valid(parks) == FALSE))\n\n[1] 0\n\nlength(which(st_is_valid(hawker_centre) == FALSE))\n\n[1] 0\n\nlength(which(st_is_valid(supermarkets) == FALSE))\n\n[1] 0\n\nlength(which(st_is_valid(bus_stops) == FALSE))\n\n[1] 0\n\nlength(which(st_is_valid(MRT) == FALSE))\n\n[1] 0\n\n\nWe can see that they are all fixed."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#computing-correlation-matrix",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#computing-correlation-matrix",
    "title": "Take-home Exercise 3b: Geospatial Analytics",
    "section": "9 Computing Correlation Matrix",
    "text": "9 Computing Correlation Matrix\nBefore loading the predictors into a predictive model, it is always a good practice to use correlation matrix to examine if there is sign of multicollinearity.\n\nresale_tidy_nogeo &lt;- resale_tidy %&gt;%\n  st_drop_geometry()\ncorrplot::corrplot(cor(resale_tidy_nogeo[, 4:18]), \n                   diag = FALSE, \n                   order = \"AOE\",\n                   tl.pos = \"td\", \n                   tl.cex = 0.5, \n                   method = \"number\", \n                   type = \"upper\")\n\n\n\n\n\n\n\n\nThe correlation matrix above shows that all the correlation values are below 0.8 except UNIT_AGE and REMAINING_LEASE which is at -1.0 given that they are highly related since UNIT_AGE was derived with the 99 year lease deducted by REMAINING_LEASE. Hence, one of this variables will be dropped to ensure there is no high multicollinearity in the model.\nThe code chunk below uses ggcorrmat() function to compute the correlation matrix.\n\nNote that UNIT_AGE is not selected as it will be excluded in the subsequent model building section.\n\n\nresale_tidy_nogeo &lt;- resale_tidy %&gt;%\n  st_drop_geometry()\nggstatsplot::ggcorrmat(resale_tidy_nogeo[, c(4:5, 7:18)])"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#model-building",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#model-building",
    "title": "Take-home Exercise 3b: Geospatial Analytics",
    "section": "10 Model Building",
    "text": "10 Model Building\n\n10.1 Data Sampling\nThe entire data is split into training and test data sets with resale transaction records in 2023 as the training data and July-September (Q3) 2024 resale transaction records respectively.\nIf the data is in a one year period and training and test data has to be split the it can be done by using initial_split() of rsample package. rsample is one of the package of tidymodels.\n\nset.seed(1234)\n\nresale_train &lt;- resale_tidy %&gt;%\n  filter(str_sub(MONTH, 1, 4) == \"2023\")\n\nresale_test &lt;- resale_tidy %&gt;%\n  filter(str_sub(MONTH, 1, 4) == \"2024\")\n\n\n\n10.2 Building a Multiple Linear Regression\nThe code chunk below uses lm() to calibrate the multiple linear regression model.\n\nresale.mlr &lt;- lm(formula = RESALE_PRICE ~ FLOOR_AREA_SQM + LEVEL + REMAINING_LEASE +\n                     PROX_CBD + PROX_ELDERCARE + PROX_CHAS + PROX_HAWKER + PROX_MRT + PROX_PARK +\n                     PROX_CHILDCARE + PROX_KINDERGARTEN + PROX_SUPERMARKET + PROX_BUS_STOP + NUM_KINDERGARTEN +\n                     NUM_CHILDCARE + NUM_BUS_STOP + NUM_CHAS, \n                data = resale_train)\nols_regress(resale.mlr)\n\n                              Model Summary                                \n--------------------------------------------------------------------------\nR                           0.884       RMSE                    61822.812 \nR-Squared                   0.781       MSE                3840136076.103 \nAdj. R-Squared              0.780       Coef. Var                  10.638 \nPred R-Squared              0.778       AIC                     95262.990 \nMAE                     47560.585       SBC                     95381.722 \n--------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n AIC: Akaike Information Criteria \n SBC: Schwarz Bayesian Criteria \n\n                                    ANOVA                                      \n------------------------------------------------------------------------------\n                    Sum of                                                    \n                   Squares          DF       Mean Square       F         Sig. \n------------------------------------------------------------------------------\nRegression    5.205812e+13          17      3.062242e+12    797.431    0.0000 \nResidual      1.461556e+13        3806    3840136076.103                      \nTotal         6.667368e+13        3823                                        \n------------------------------------------------------------------------------\n\n                                           Parameter Estimates                                             \n----------------------------------------------------------------------------------------------------------\n            model          Beta    Std. Error    Std. Beta       t        Sig          lower        upper \n----------------------------------------------------------------------------------------------------------\n      (Intercept)    -42061.163     18317.692                  -2.296    0.022    -77974.600    -6147.725 \n   FLOOR_AREA_SQM      4229.999       155.882        0.219     27.136    0.000      3924.379     4535.619 \n            LEVEL      5817.233       172.053        0.285     33.811    0.000      5479.908     6154.558 \n  REMAINING_LEASE      5124.646        84.869        0.541     60.383    0.000      4958.253     5291.040 \n         PROX_CBD       -16.801         0.323       -0.534    -51.996    0.000       -17.435      -16.168 \n   PROX_ELDERCARE        -4.868         1.767       -0.023     -2.755    0.006        -8.332       -1.404 \n        PROX_CHAS        68.923        11.149        0.054      6.182    0.000        47.066       90.781 \n      PROX_HAWKER       -17.655         2.145       -0.069     -8.231    0.000       -21.860      -13.449 \n         PROX_MRT       -29.076         2.910       -0.079     -9.991    0.000       -34.782      -23.370 \n        PROX_PARK        -8.359         2.517       -0.028     -3.322    0.001       -13.293       -3.425 \n   PROX_CHILDCARE        14.435        15.630        0.007      0.924    0.356       -16.209       45.079 \nPROX_KINDERGARTEN       -36.522         7.372       -0.049     -4.954    0.000       -50.975      -22.070 \n PROX_SUPERMARKET        -2.209         7.360       -0.003     -0.300    0.764       -16.639       12.221 \n    PROX_BUS_STOP        15.268        20.027        0.006      0.762    0.446       -23.996       54.531 \n NUM_KINDERGARTEN      4192.419      1337.767        0.033      3.134    0.002      1569.611     6815.227 \n    NUM_CHILDCARE     -3376.015       533.873       -0.059     -6.324    0.000     -4422.719    -2329.311 \n     NUM_BUS_STOP       287.083       401.725        0.006      0.715    0.475      -500.534     1074.699 \n         NUM_CHAS      7300.079       527.443        0.125     13.841    0.000      6265.981     8334.177 \n----------------------------------------------------------------------------------------------------------\n\n\n\n\n\n\n\n\nResult Explanation\n\n\n\nSignificant Predictors of Resale Price:\n\nFloor Area (FLOOR_AREA_SQM):\n\nWith a positive and highly significant coefficient (p &lt; 0.001), floor area strongly predicts resale prices. This aligns with common knowledge that larger HDB flats typically command higher resale values due to the increased living space.\n\nLevel:\n\nThe level (floor) of the unit also shows a strong positive effect on resale prices (p &lt; 0.001). Higher floors are often associated with better views, increased privacy, and less noise, which generally adds value.\n\nRemaining Lease:\n\nA positive coefficient for remaining lease (p &lt; 0.001) suggests that resale prices tend to be higher for units with more years left on their lease, as these units offer longer occupancy potential before reaching the lease expiration.\n\nProximity to MRT (PROX_MRT):\n\nWhile proximity to the MRT has a significant negative coefficient, indicating that being closer to MRT stations tends to increase prices, the distance is inversely coded (i.e., closer proximity lowers distance values). This is consistent with the desirability of accessible public transport, especially in Singapore.\n\nProximity to Childcare (PROX_CHILDCARE) and Kindergartens (PROX_KINDERGARTEN):\n\nBoth proximity to childcare and kindergartens are significant (p &lt; 0.01), with negative coefficients, suggesting that families especially those with children value these amenities nearby.\n\nOther Amenities:\n\nSeveral other amenities like Proximity to Parks (PROX_PARK) and Supermarkets (PROX_SUPERMARKET) are also significant, though their impact on resale prices is smaller compared to factors like floor area and level.\nInsignificant Predictors:\n\nProximity to Eldercare (PROX_ELDERCARE) and Proximity to CHAS Clinics (PROX_CHAS):\n\nThese variables have relatively high p-values (p &gt; 0.05), indicating that they may not be significant predictors of resale price in this model. Their lack of significance could suggest that proximity to eldercare and CHAS clinics does not strongly impact the value of HDB resale flats, possibly due to varying demand based on demographics.\n\nProximity to Hawker Centres (PROX_HAWKER):\n\nAlthough hawker centres are important to residents for affordable food, this variable does not appear to be highly significant in affecting resale prices (p &gt; 0.05), perhaps because it is less exclusive or ubiquitous.\nModel Accuracy and Fit:\n\nR-Squared: The model explains about 77.9% of the variability in resale prices, which is a strong indication of model fit and suggests that the included predictors capture the majority of factors influencing resale prices.\nRMSE (Root Mean Square Error): The RMSE value of 63051.285 suggests the typical deviation between observed and predicted resale prices. While a lower RMSE would indicate better prediction, this value suggests a reasonable model fit given the complexities of housing prices.\nF-statistic: The model’s F-statistic is highly significant (p &lt; 0.001), supporting the overall model validity.\n\nObservations:\n\nModel Coefficients: The coefficients align with common real estate trends, with larger and higher-floor units being more valuable. Proximity to transport and family-oriented amenities also enhances resale value, reflecting a preference for accessible and family-friendly environments in Singapore.\nPossible Multicollinearity: Given the number of variables, there may be multicollinearity among location-based predictors (e.g., proximity to MRT, parks, childcare). This can sometimes inflate standard errors and affect the interpretability of each predictor. Further diagnostics, such as Variance Inflation Factor (VIF), could help in evaluating multicollinearity which is done in the next step.\n\n\n\n\n10.2.1 Checking for multicolinearity\nIn this section, it will introduce you an R package specially programmed for performing OLS regression. It is called olsrr. It provides a collection of very useful methods for building better multiple linear regression models:\n\nComprehensive Regression Output\nVariable Selection Procedures\nHeteroskedasticity Tests\nCollinearity Diagnostics\nModel Fit Assessment\nMeasures of Influence\nResidual Diagnostics\nVariable Contribution Assessment\n\nIn the code chunk below, the ols_vif_tol() of olsrr package is used to test if there are signs of multicollinearity.\n\nols_vif_tol(resale.mlr)\n\n           Variables Tolerance      VIF\n1     FLOOR_AREA_SQM 0.8827152 1.132868\n2              LEVEL 0.8133391 1.229499\n3    REMAINING_LEASE 0.7187548 1.391295\n4           PROX_CBD 0.5466303 1.829390\n5     PROX_ELDERCARE 0.8121368 1.231320\n6          PROX_CHAS 0.7485047 1.335997\n7        PROX_HAWKER 0.8146946 1.227454\n8           PROX_MRT 0.9323147 1.072599\n9          PROX_PARK 0.7834653 1.276381\n10    PROX_CHILDCARE 0.9057032 1.104114\n11 PROX_KINDERGARTEN 0.5976016 1.673356\n12  PROX_SUPERMARKET 0.7885493 1.268151\n13     PROX_BUS_STOP 0.8668546 1.153596\n14  NUM_KINDERGARTEN 0.5250241 1.904675\n15     NUM_CHILDCARE 0.6711662 1.489944\n16      NUM_BUS_STOP 0.7718257 1.295629\n17          NUM_CHAS 0.7061126 1.416205\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n0 to 5: variables are not correlated\n5 to 10: variables are correlated\nGreater than 10: variables are highly correlated\n\n\n\nBased on the results of the Variance Inflation Factors (VIF) none of the variables are greater than 5. Each of the independent variables are calculated with another independent variable to attain the values above.\nThe analysis shows that multicollinearity is not a concern in this model, as all variables have VIF values significantly below the commonly accepted threshold. This suggests that each predictor contributes independently to the model, without redundancy that would impair interpretation or predictive power.\nThis shows no need to eliminate the variables.\n\nnote that there could be binary variables in datasets like Y/N options (dummy variables) which have some signs of correlation which are from the variable of lease properties: LEASEHOLD_99YR vs FREEHOLD etc.\n\n\n\n10.2.2 Test for Non-Linearity\nIn multiple linear regression, it is important for us to test the assumption that linearity and additivity of the relationship between dependent and independent\nIn the code chunk below, the ols_plot_resid_fit() of olsrr package is used to perform linearity assumption test.\n\nols_plot_resid_fit(resale.mlr)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResult Explanation\n\n\n\nWhile most of the data points are scattered around the 0 line; the plot also indicates slight issues with both linearity and homoscedasticity. The widening funnel shape at higher fitted values suggests that the model may not fully capture the complexity of higher-priced units, potentially indicating a need for transformation (e.g., log-transformation) or a different modelling approach to improve fit.\n\n\n\n\n10.2.3 Test for Normality Assumption\nLastly, the code chunk below uses ols_plot_resid_hist() of olsrr package to perform normality assumption test.\n\nols_plot_resid_hist(resale.mlr)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResult Explanation\n\n\n\nThe residuals do not follow a perfectly normal distribution, as evidenced by the slightly skewed shape while it has a normal curve. This could impact the reliability of significance tests and confidence intervals, especially for large residual values. This suggests that the model might tend to underpredict for certain observations, leading to larger residuals on the positive side.\n\n\n\n\n\n10.3 Test for Spatial Autocorrelation\nThe hedonic model we are constructing incorporates geographically referenced attributes, making it essential to visualize the residuals of this pricing model.\nTo test for spatial autocorrelation, we need to convert condo_resale.sf from an sf dataframe into a SpatialPointsDataFrame.\nFirst, we will extract the residuals from the hedonic pricing model and save them as a new dataframe.\n\nmlr_res &lt;- as.data.frame(resale.mlr$residuals)\n\n# joining the newly created data frame with resale_train\n\nresale_res &lt;- cbind(resale_train,\n                    mlr_res) %&gt;%\n  rename(MLR_RES = resale.mlr.residuals)\n\nIn this step it will convert resale.res from simple feature object into a SpatialPointsDataFrame because spdep package can only process sp conformed spatial data objects.\nThe code chunk below will be used to perform the data conversion process.\n\nresale_sp &lt;- as_Spatial(resale_res)\nresale_sp\n\nclass       : SpatialPointsDataFrame \nfeatures    : 3824 \nextent      : 11656.47, 42446.44, 28217.48, 48684.45  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 23\nnames       :   MONTH,       TOWN,          ADDRESS,  REMAINING_LEASE, FLOOR_AREA_SQM,         UNIT_AGE, RESALE_PRICE, LEVEL,         PROX_CBD,       PROX_ELDERCARE,            PROX_CHAS,      PROX_HAWKER,         PROX_MRT,        PROX_PARK,       PROX_CHILDCARE, ... \nmin values  : 2023-01, ANG MO KIO,  10 CHAI CHEE RD,               46,             74, 3.66666666666667,       350000,     2, 311.741838971365, 0.000428110190953706, 7.28527615277263e-06, 39.5321340230547, 21.3638644944817, 77.0078791420734, 6.59828462646688e-05, ... \nmax values  : 2023-12,     YISHUN, 9A BOON TIONG RD, 95.3333333333333,            176,               53,      1500000,    47, 19126.5211737734,     3261.54359027314,     808.332738794272, 2777.29424402156, 2152.48536476722, 2398.40352003288,     547.386819517238, ... \n\n\n\nwrite_rds(resale_sp, \"data/HDB/rds/resale_sp.rds\")\n\n\nresale_sp &lt;- read_rds(\"data/HDB/rds/resale_sp.rds\")\n\nFollowing which, tmap package will be used to display the distribution of the residuals on an interactive map.\nThe code churn below will turn on the interactive mode of tmap.\n\ntmap_mode(\"view\")\n\n\ntm_shape(mpsz) +\n  tmap_options(check.and.fix = TRUE) +\n  tm_polygons(col = \"grey\",\n              alpha = 0.4) +\ntm_shape(resale_res) +  \n  tm_dots(col = \"MLR_RES\",\n          alpha = 0.6,\n          style = \"quantile\") +\n  tm_layout(main.title = \"Residuals Distribution\",     \n            main.title.position = \"center\",\n            main.title.size = 0.8) +\n  tm_view(set.zoom.limits = c(11,14))\n\n\n\n\n\nSwitching back to “plot” mode before continuing.\n\ntmap_mode(\"plot\")\n\nBased on the figure above it reveals that there are signs of spatial autocorrelation.\nTo proof that our observation is indeed true, the Moran’s I test will be performed. First, to compute the distance-based weight matrix by using dnearneigh() function of spdep.\n\nnb &lt;- dnearneigh(coordinates(resale_sp), 0, 2000, longlat = FALSE)\nsummary(nb)\n\nNeighbour list object:\nNumber of regions: 3824 \nNumber of nonzero links: 874036 \nPercentage nonzero weights: 5.977142 \nAverage number of links: 228.5659 \n2 disjoint connected subgraphs\nLink number distribution:\n\n  6  11  12  13  14  17  19  20  23  27  28  29  34  35  36  39  40  41  42  43 \n  1   5   1   3   1   1   1   5   2   1   1   1   2   5   1   2   7   3   8   8 \n 44  45  46  47  48  49  51  52  53  54  55  56  57  58  59  60  61  62  63  64 \n  2   1   1   1   4  13   2   4   2   7   1   3   1  14   8   5   8   2  12  14 \n 65  66  67  68  69  70  71  72  73  74  76  77  78  79  80  81  82  83  84  85 \n 36  13  13   9   3  15   6   8   6   4   6  11  10   6  13   6   4  17  16  13 \n 86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 \n 14   8  12  14  17  19  12  17  21  10   9  14   4   7  12  10   4   6   3   7 \n106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 \n  8  15  13  19   6   7  11  12   6  14   5  13  12  23  20  20  30  14  11  11 \n126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 \n  8  14  14  13   7  17  18  16   9  18  17  16  10  14  20  18  26  28  23  21 \n146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 \n 15  21  16  21   8  20  14  12  16  10  19  23   5  23  19  22  16  10   8  10 \n166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 \n  8  12   6  10  13  10   8   9   7  10   4   5   7   9   4  13   8   3   7   7 \n187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 \n  2   8  15  10  11  13  14  12  14  10   6   9  19  11   6  26  10  13  10  10 \n207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 \n 12   7  10  12  16  14  12   9  10   3   8   4   4   5  10   7   4   8   6  15 \n227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 \n 15  10  17   2   7   5   8  14   6   7   8  11  10  14  12   9  11  24  11  13 \n247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 \n 10   7   9  11  11  10   9   4   9  10  12   9   9  18   8  16  16   4   9  21 \n267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 \n 14  25  26  15  14  20  28  19  12  13  18   7  12  18  14   9  33   6   5  17 \n287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 \n 12   8  16  10   7   7  17  14  11  17  11  14   4   4   2   4   7   4  12   6 \n307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 \n  5   5   1   6   7   8   7   9   2   5   4   2   9   2   4   9  14  17   4   9 \n327 328 329 330 331 332 333 335 336 337 338 339 340 341 342 343 344 345 347 348 \n  2  13  14   3   3   3   4   3   5   5   2   4   2   2   3   1   6   1   2   2 \n349 350 352 353 354 355 356 357 358 360 361 362 364 365 366 367 368 371 372 373 \n  3   1   3   1   1   3   2   8   3   2   2   2   2   1   3   1   3   8   3   7 \n374 375 376 377 378 379 380 381 382 383 384 386 387 388 389 390 391 392 394 395 \n  3   7   4   6  12   8   3   3   4   4   4   9   1   6   2   1   4   2   1   8 \n396 400 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 418 420 421 \n  4   5   3   1   3   1   4   4   4   6  10   5   1   3   1   6   3   3   3   3 \n423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 439 441 442 443 444 \n  6   2   3   9   3   8   1   4   5   7   3   2   3   1   2   4   3   4   6   4 \n446 448 449 451 452 455 456 457 459 460 461 462 463 465 466 467 469 470 471 472 \n  3   5   2   3   4   3   3   2   4   6   5   3   3   2   3   2   1   1   5   1 \n473 474 475 476 477 479 481 482 484 486 487 488 489 491 492 493 494 495 496 497 \n  4   5   1   3   1   3   5   3   1   3   5   5   8   5   1   5   2   5   2   3 \n498 500 505 506 508 509 510 511 512 513 514 515 516 518 519 520 521 522 523 526 \n  2   6   1   2   5   1   2   4   2   5   3   2   5   2   4   3   1   2   3   3 \n527 528 529 530 531 534 535 536 538 539 540 541 542 543 544 545 546 548 549 550 \n  3   5   1   1   1   1   4   1   2   1   4   4   3   1   3   6   4   2   1   1 \n551 553 554 555 556 557 560 561 562 563 564 566 567 569 570 571 572 573 576 579 \n  1   1   3   5   2   3   2   2   6   5   2   7   2   1   3   4   2   2   1   2 \n581 593 594 595 598 601 604 \n  2   2   1   1   1   2   1 \n1 least connected region:\n1732 with 6 links\n1 most connected region:\n3263 with 604 links\n\n\nFollowing which, nb2listw() of spdep package will be used to convert the output neighbours lists (i.e. nb) into spatial weights.\n\nnb_lw &lt;- nb2listw(nb, style = 'W')\nsummary(nb_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 3824 \nNumber of nonzero links: 874036 \nPercentage nonzero weights: 5.977142 \nAverage number of links: 228.5659 \n2 disjoint connected subgraphs\nLink number distribution:\n\n  6  11  12  13  14  17  19  20  23  27  28  29  34  35  36  39  40  41  42  43 \n  1   5   1   3   1   1   1   5   2   1   1   1   2   5   1   2   7   3   8   8 \n 44  45  46  47  48  49  51  52  53  54  55  56  57  58  59  60  61  62  63  64 \n  2   1   1   1   4  13   2   4   2   7   1   3   1  14   8   5   8   2  12  14 \n 65  66  67  68  69  70  71  72  73  74  76  77  78  79  80  81  82  83  84  85 \n 36  13  13   9   3  15   6   8   6   4   6  11  10   6  13   6   4  17  16  13 \n 86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 \n 14   8  12  14  17  19  12  17  21  10   9  14   4   7  12  10   4   6   3   7 \n106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 \n  8  15  13  19   6   7  11  12   6  14   5  13  12  23  20  20  30  14  11  11 \n126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 \n  8  14  14  13   7  17  18  16   9  18  17  16  10  14  20  18  26  28  23  21 \n146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 \n 15  21  16  21   8  20  14  12  16  10  19  23   5  23  19  22  16  10   8  10 \n166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 \n  8  12   6  10  13  10   8   9   7  10   4   5   7   9   4  13   8   3   7   7 \n187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 \n  2   8  15  10  11  13  14  12  14  10   6   9  19  11   6  26  10  13  10  10 \n207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 \n 12   7  10  12  16  14  12   9  10   3   8   4   4   5  10   7   4   8   6  15 \n227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 \n 15  10  17   2   7   5   8  14   6   7   8  11  10  14  12   9  11  24  11  13 \n247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 \n 10   7   9  11  11  10   9   4   9  10  12   9   9  18   8  16  16   4   9  21 \n267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 \n 14  25  26  15  14  20  28  19  12  13  18   7  12  18  14   9  33   6   5  17 \n287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 \n 12   8  16  10   7   7  17  14  11  17  11  14   4   4   2   4   7   4  12   6 \n307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 \n  5   5   1   6   7   8   7   9   2   5   4   2   9   2   4   9  14  17   4   9 \n327 328 329 330 331 332 333 335 336 337 338 339 340 341 342 343 344 345 347 348 \n  2  13  14   3   3   3   4   3   5   5   2   4   2   2   3   1   6   1   2   2 \n349 350 352 353 354 355 356 357 358 360 361 362 364 365 366 367 368 371 372 373 \n  3   1   3   1   1   3   2   8   3   2   2   2   2   1   3   1   3   8   3   7 \n374 375 376 377 378 379 380 381 382 383 384 386 387 388 389 390 391 392 394 395 \n  3   7   4   6  12   8   3   3   4   4   4   9   1   6   2   1   4   2   1   8 \n396 400 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 418 420 421 \n  4   5   3   1   3   1   4   4   4   6  10   5   1   3   1   6   3   3   3   3 \n423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 439 441 442 443 444 \n  6   2   3   9   3   8   1   4   5   7   3   2   3   1   2   4   3   4   6   4 \n446 448 449 451 452 455 456 457 459 460 461 462 463 465 466 467 469 470 471 472 \n  3   5   2   3   4   3   3   2   4   6   5   3   3   2   3   2   1   1   5   1 \n473 474 475 476 477 479 481 482 484 486 487 488 489 491 492 493 494 495 496 497 \n  4   5   1   3   1   3   5   3   1   3   5   5   8   5   1   5   2   5   2   3 \n498 500 505 506 508 509 510 511 512 513 514 515 516 518 519 520 521 522 523 526 \n  2   6   1   2   5   1   2   4   2   5   3   2   5   2   4   3   1   2   3   3 \n527 528 529 530 531 534 535 536 538 539 540 541 542 543 544 545 546 548 549 550 \n  3   5   1   1   1   1   4   1   2   1   4   4   3   1   3   6   4   2   1   1 \n551 553 554 555 556 557 560 561 562 563 564 566 567 569 570 571 572 573 576 579 \n  1   1   3   5   2   3   2   2   6   5   2   7   2   1   3   4   2   2   1   2 \n581 593 594 595 598 601 604 \n  2   2   1   1   1   2   1 \n1 least connected region:\n1732 with 6 links\n1 most connected region:\n3263 with 604 links\n\nWeights style: W \nWeights constants summary:\n     n       nn   S0       S1       S2\nW 3824 14622976 3824 47.67099 15430.41\n\n\nLastly, lm.morantest() of spdep package will be used to perform Moran’s I test for residual spatial autocorrelation to validate if our inital observation if there are signs of spatial autocorrelation\n\nmoran_test &lt;-lm.morantest(resale.mlr, nb_lw)\n\n\n\n\n\n\n\nInterpretation of Moran’s I Test Results\n\n\n\nThe Moran’s I test for residual spatial autocorrelation was conducted using the lm.morantest() function. Here’s a breakdown of the results:\nMoran I Statistic:\nThe observed Moran’s I value is 0.299, which indicates a positive spatial autocorrelation in the residuals. This suggests that similar values tend to be spatially clustered, which is a sign of spatial dependence that hasn’t been fully captured by the regression model.\nSignificance (p-value): The p-value is extremely low (p-value &lt; 2.2e-16) which strongly rejects the null hypothesis of no spatial autocorrelation. This statistically confirms that there is significant spatial autocorrelation in the residuals of the model.\n\n\n\nwrite_rds(moran_test, \"data/HDB/rds/moran_resale_sp.rds\")\n\n\nmoran_test &lt;- read_rds(\"data/HDB/rds/moran_resale_sp.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#building-geographical-random-forest-model",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#building-geographical-random-forest-model",
    "title": "Take-home Exercise 3b: Geospatial Analytics",
    "section": "11 Building Geographical Random Forest Model",
    "text": "11 Building Geographical Random Forest Model\nTo prepare for calibrating the random forest model, we first need to generate coordinate data required by the SpatialML package. This can be accomplished by using st_coordinates() from the sf package. After extracting the coordinates, we will remove the geometry from resale_train using st_drop_geometry(), creating a non-spatial dataset ready for analysis.\n\ncoords_train &lt;- st_coordinates(resale_train)\ncoords_train &lt;- write_rds(coords_train, \"data/HDB/rds/coords_train.rds\") # writing output into rds for future use\ncoords_train &lt;- read_rds(\"data/HDB/rds/coords_train.rds\")\n\nUsing st_drop_geometry()\n\nresale_train_nogeo &lt;- resale_train %&gt;% \n  st_drop_geometry()\n\n\n11.1 Computing adaptive bandwidth\nbw.gwr() of GWmodel package will be used to determine the optimal bandwidth to be used for the Random Forest Model. An adaptive bandwidth will be applied to allow the bandwidth to adjust based on the density of data points, offering greater flexibility in regions with sparse data. Also, to determine the optimal bandwidth, we will use a cross-validation (CV) approach with the bw.gwr() function as well.\n\nbw_adaptive &lt;- bw.gwr(formula = RESALE_PRICE ~ FLOOR_AREA_SQM + LEVEL + REMAINING_LEASE +\n                     PROX_CBD + PROX_ELDERCARE + PROX_CHAS + PROX_HAWKER + PROX_MRT + PROX_PARK +\n                     PROX_CHILDCARE + PROX_KINDERGARTEN + PROX_SUPERMARKET + PROX_BUS_STOP + NUM_KINDERGARTEN +\n                     NUM_CHILDCARE + NUM_BUS_STOP + NUM_CHAS,\n                      data = resale_sp, \n                      approach = \"CV\", \n                      kernel = \"gaussian\", \n                      adaptive = TRUE, \n                      longlat = FALSE)\n\nTake a cup of tea and have a break, it will take a few minutes.\n          -----A kind suggestion from GWmodel development group\nAdaptive bandwidth: 2371 CV score: 1.368532e+13 \nAdaptive bandwidth: 1473 CV score: 1.288663e+13 \nAdaptive bandwidth: 918 CV score: 1.161493e+13 \nAdaptive bandwidth: 574 CV score: 1.015948e+13 \nAdaptive bandwidth: 363 CV score: 8.471624e+12 \nAdaptive bandwidth: 230 CV score: 7.183122e+12 \nAdaptive bandwidth: 151 CV score: 5.939131e+12 \nAdaptive bandwidth: 98 CV score: 5.153881e+12 \nAdaptive bandwidth: 70 CV score: 4.78133e+12 \nAdaptive bandwidth: 47 CV score: 4.624679e+12 \nAdaptive bandwidth: 39 CV score: 4.564377e+12 \nAdaptive bandwidth: 27 CV score: 8.95862e+12 \nAdaptive bandwidth: 39 CV score: 4.564377e+12 \n\n\nThe result shows that 64 neighbour points will be the optimal bandwidth to be used if adaptive bandwidth is used for this data set.\n\nwrite_rds(bw_adaptive, \"data/HDB/model/bw_adaptive.rds\")\n\n\nbw_adaptive &lt;- read_rds(\"data/HDB/model/bw_adaptive.rds\")\nbw_adaptive\n\n[1] 39\n\n\n\n\n11.2 Calibrating Random Forest Model\nWith the results from the adaptive bandwidth computed earlier on, this section will illustrate the calibration of a Geographically Weighted Random Forest Model using grf() of SpatialML package.\nCode chunk below is used to verify the variable names before proceeding.\n\nnames(resale_train_nogeo)\n\n [1] \"MONTH\"             \"TOWN\"              \"ADDRESS\"          \n [4] \"REMAINING_LEASE\"   \"FLOOR_AREA_SQM\"    \"UNIT_AGE\"         \n [7] \"RESALE_PRICE\"      \"LEVEL\"             \"PROX_CBD\"         \n[10] \"PROX_ELDERCARE\"    \"PROX_CHAS\"         \"PROX_HAWKER\"      \n[13] \"PROX_MRT\"          \"PROX_PARK\"         \"PROX_CHILDCARE\"   \n[16] \"PROX_KINDERGARTEN\" \"PROX_SUPERMARKET\"  \"PROX_BUS_STOP\"    \n[19] \"NUM_KINDERGARTEN\"  \"NUM_CHILDCARE\"     \"NUM_BUS_STOP\"     \n[22] \"NUM_CHAS\"         \n\nnames(resale_train)\n\n [1] \"MONTH\"             \"TOWN\"              \"ADDRESS\"          \n [4] \"REMAINING_LEASE\"   \"FLOOR_AREA_SQM\"    \"UNIT_AGE\"         \n [7] \"RESALE_PRICE\"      \"LEVEL\"             \"PROX_CBD\"         \n[10] \"PROX_ELDERCARE\"    \"PROX_CHAS\"         \"PROX_HAWKER\"      \n[13] \"PROX_MRT\"          \"PROX_PARK\"         \"PROX_CHILDCARE\"   \n[16] \"PROX_KINDERGARTEN\" \"PROX_SUPERMARKET\"  \"PROX_BUS_STOP\"    \n[19] \"NUM_KINDERGARTEN\"  \"NUM_CHILDCARE\"     \"NUM_BUS_STOP\"     \n[22] \"NUM_CHAS\"          \"geometry\"         \n\n\n\nstr(resale_train_nogeo)\n\ntibble [3,824 × 22] (S3: tbl_df/tbl/data.frame)\n $ MONTH            : chr [1:3824] \"2023-08\" \"2023-09\" \"2023-08\" \"2023-09\" ...\n $ TOWN             : chr [1:3824] \"TAMPINES\" \"JURONG WEST\" \"PUNGGOL\" \"KALLANG/WHAMPOA\" ...\n $ ADDRESS          : chr [1:3824] \"879A TAMPINES AVE 8\" \"681C JURONG WEST CTRL 1\" \"632A PUNGGOL DR\" \"2C UPP BOON KENG RD\" ...\n $ REMAINING_LEASE  : num [1:3824] 92.9 75.9 83.4 82.2 93.6 ...\n $ FLOOR_AREA_SQM   : num [1:3824] 93 95 93 90 93 93 93 105 102 92 ...\n $ UNIT_AGE         : num [1:3824] 6.08 23.08 15.58 16.83 5.42 ...\n $ RESALE_PRICE     : num [1:3824] 702888 525000 560000 880000 600000 ...\n $ LEVEL            : num [1:3824] 11 14 14 14 8 14 11 2 8 20 ...\n $ PROX_CBD         : num [1:3824] 10722 17409 13699 3085 17099 ...\n $ PROX_ELDERCARE   : num [1:3824] 453 792 1220 885 1859 ...\n $ PROX_CHAS        : num [1:3824] 74.6 157.3 230.9 104.2 59.3 ...\n $ PROX_HAWKER      : num [1:3824] 1203 893 1260 211 1016 ...\n $ PROX_MRT         : num [1:3824] 1254 667 199 197 360 ...\n $ PROX_PARK        : num [1:3824] 1591 789 1369 755 502 ...\n $ PROX_CHILDCARE   : num [1:3824] 74.6 49.3 160.6 99.8 55.5 ...\n $ PROX_KINDERGARTEN: num [1:3824] 304 285 419 146 327 ...\n $ PROX_SUPERMARKET : num [1:3824] 74.6 497.4 241.9 103.7 341.9 ...\n $ PROX_BUS_STOP    : num [1:3824] 73.1 170 140 28.6 124.7 ...\n $ NUM_KINDERGARTEN : num [1:3824] 1 1 0 1 1 1 1 0 1 0 ...\n $ NUM_CHILDCARE    : num [1:3824] 4 5 5 4 6 11 5 2 7 5 ...\n $ NUM_BUS_STOP     : num [1:3824] 10 11 7 9 9 7 8 6 11 4 ...\n $ NUM_CHAS         : num [1:3824] 1 1 4 5 5 2 4 0 3 3 ...\n\n\nThe code chunk below is used to calibrate a model to predict HDB four-room resale price by using random forest function of ranger package.\n\nset.seed(1234)\n\nrf &lt;- ranger(RESALE_PRICE ~ FLOOR_AREA_SQM + LEVEL + REMAINING_LEASE +\n             PROX_CBD + PROX_ELDERCARE + PROX_CHAS + PROX_HAWKER + PROX_MRT + PROX_PARK +\n             PROX_CHILDCARE + PROX_KINDERGARTEN + PROX_SUPERMARKET + PROX_BUS_STOP + NUM_KINDERGARTEN +\n             NUM_CHILDCARE + NUM_BUS_STOP + NUM_CHAS,\n             data = resale_train_nogeo)\nrf\n\nRanger result\n\nCall:\n ranger(RESALE_PRICE ~ FLOOR_AREA_SQM + LEVEL + REMAINING_LEASE +      PROX_CBD + PROX_ELDERCARE + PROX_CHAS + PROX_HAWKER + PROX_MRT +      PROX_PARK + PROX_CHILDCARE + PROX_KINDERGARTEN + PROX_SUPERMARKET +      PROX_BUS_STOP + NUM_KINDERGARTEN + NUM_CHILDCARE + NUM_BUS_STOP +      NUM_CHAS, data = resale_train_nogeo) \n\nType:                             Regression \nNumber of trees:                  500 \nSample size:                      3824 \nNumber of independent variables:  17 \nMtry:                             4 \nTarget node size:                 5 \nVariable importance mode:         none \nSplitrule:                        variance \nOOB prediction error (MSE):       1803594630 \nR squared (OOB):                  0.8965837 \n\n\n\nwrite_rds(rf, \"data/HDB/model/rf.rds\")\n\n\nrf &lt;- read_rds(\"data/HDB/model/rf.rds\")\nrf\n\nRanger result\n\nCall:\n ranger(RESALE_PRICE ~ FLOOR_AREA_SQM + LEVEL + REMAINING_LEASE +      PROX_CBD + PROX_ELDERCARE + PROX_CHAS + PROX_HAWKER + PROX_MRT +      PROX_PARK + PROX_CHILDCARE + PROX_KINDERGARTEN + PROX_SUPERMARKET +      PROX_BUS_STOP + NUM_KINDERGARTEN + NUM_CHILDCARE + NUM_BUS_STOP +      NUM_CHAS, data = resale_train_nogeo) \n\nType:                             Regression \nNumber of trees:                  500 \nSample size:                      3824 \nNumber of independent variables:  17 \nMtry:                             4 \nTarget node size:                 5 \nVariable importance mode:         none \nSplitrule:                        variance \nOOB prediction error (MSE):       1803594630 \nR squared (OOB):                  0.8965837 \n\n\nThe model output is also saved in the following code chunk below.\n\nNumber or trees (e.g., ntree = 50)\n200 is selected because from earlier experiments with 500 trees, the gain in accuracy was minimal (a slight improvement in R-squared and OOB MSE). Lower number of trees can be a good compromise for faster computation and reducing complexity.Ideally we should let the model run and determine the number of trees which might be up to 500.\nkernel = \"adaptive\"\nensures that the model adjusts spatial influence based on local data density\nverbose = TRUE is helpful for debugging and monitoring the model’s progress.\n\n\npacman::p_load(parallel, profvis)\n\n\nset.seed(1234)\n\ngwRF_adaptive &lt;- grf(formula = RESALE_PRICE ~ FLOOR_AREA_SQM + LEVEL + REMAINING_LEASE +\n                     PROX_CBD + PROX_ELDERCARE + PROX_CHAS + PROX_HAWKER + PROX_MRT + PROX_PARK +\n                     PROX_CHILDCARE + PROX_KINDERGARTEN + PROX_SUPERMARKET + PROX_BUS_STOP + NUM_KINDERGARTEN +\n                     NUM_CHILDCARE + NUM_BUS_STOP + NUM_CHAS,\n                     dframe = resale_train_nogeo, \n                     bw = bw_adaptive, # based on earlier computed adaptive bandwidth\n                     ntree = 200, \n                     kernel = \"adaptive\",\n                     verbose = TRUE,\n                     coords = coords_train)\n\nRanger result\n\nCall:\n ranger(RESALE_PRICE ~ FLOOR_AREA_SQM + LEVEL + REMAINING_LEASE +      PROX_CBD + PROX_ELDERCARE + PROX_CHAS + PROX_HAWKER + PROX_MRT +      PROX_PARK + PROX_CHILDCARE + PROX_KINDERGARTEN + PROX_SUPERMARKET +      PROX_BUS_STOP + NUM_KINDERGARTEN + NUM_CHILDCARE + NUM_BUS_STOP +      NUM_CHAS, data = resale_train_nogeo, num.trees = 200, mtry = 5,      importance = \"impurity\", num.threads = NULL, verbose = TRUE) \n\nType:                             Regression \nNumber of trees:                  200 \nSample size:                      3824 \nNumber of independent variables:  17 \nMtry:                             5 \nTarget node size:                 5 \nVariable importance mode:         impurity \nSplitrule:                        variance \nOOB prediction error (MSE):       1737145553 \nR squared (OOB):                  0.9003939 \n   FLOOR_AREA_SQM             LEVEL   REMAINING_LEASE          PROX_CBD \n     3.263165e+12      1.047779e+13      1.488454e+13      2.077840e+13 \n   PROX_ELDERCARE         PROX_CHAS       PROX_HAWKER          PROX_MRT \n     2.260927e+12      8.291013e+11      2.772082e+12      2.192365e+12 \n        PROX_PARK    PROX_CHILDCARE PROX_KINDERGARTEN  PROX_SUPERMARKET \n     1.863344e+12      7.977834e+11      1.113445e+12      1.092576e+12 \n    PROX_BUS_STOP  NUM_KINDERGARTEN     NUM_CHILDCARE      NUM_BUS_STOP \n     8.380639e+11      3.849591e+11      5.332950e+11      5.872851e+11 \n         NUM_CHAS \n     1.461604e+12 \n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n-402888.9  -21537.6    -488.3    -917.3   21066.1  649147.3 \n      Min.    1st Qu.     Median       Mean    3rd Qu.       Max. \n-114283.74   -3516.67     -56.18     -32.67    3518.50  103936.38 \n                        Min          Max        Mean         StD\nFLOOR_AREA_SQM            0 327369341307 18564730799 36283978234\nLEVEL             179517210 237066921698 17357244435 26558883550\nREMAINING_LEASE   476456004 610467337521 46169698946 77798113135\nPROX_CBD          159160269 398838028133 13601543671 29690681093\nPROX_ELDERCARE    229472032 538119933435 12116733479 26711034015\nPROX_CHAS         169045122 164752719384  7669699018 12780222753\nPROX_HAWKER       205849444 212345427516 11246287515 20680809603\nPROX_MRT          197451249 325520355339 11680829832 23418978745\nPROX_PARK         150692058 324539620889 12175408296 22684720379\nPROX_CHILDCARE    161726549 332142137300  9466247889 21304593306\nPROX_KINDERGARTEN 168923960 497657122214 11349619493 30649799599\nPROX_SUPERMARKET  173000086 226481570982  9960133501 20427808278\nPROX_BUS_STOP      97177838 221479676375  8236757119 20192427806\nNUM_KINDERGARTEN          0 107244057163  1587110186  4979233427\nNUM_CHILDCARE      15035261 203734234177  5476256383 14279107513\nNUM_BUS_STOP       34946054 304540033154  6539865575 19902376737\nNUM_CHAS                  0 262309235853  5966025174 16453101580\n\n\n\n\n\n\n\n\nResult Breakdown\n\n\n\nBased on the results and parameters, it can be observed that\nTop 5 Predictors by Importance The top six predictors, based on their importance scores, are as follows: 1. FLOOR_AREA_SQM: Interpretation: Floor area is the most important predictor in the model, which aligns with the general understanding that larger flats tend to have higher resale values. Geographical Implication: This factor is likely uniformly significant across areas, as floor area directly impacts the valuation irrespective of location.\n\nLEVEL: Interpretation: The floor level of the unit is also highly significant, likely due to the premium placed on higher floors for better views, privacy, and less noise.\nREMAINING_LEASE:\n\nInterpretation: The remaining lease length strongly influences resale value, as longer leases provide more value to buyers, especially in Singapore where HDB leases are finite.\n\nPROX_CBD:\n\nInterpretation: Proximity to the Central Business District (CBD) is a major driver of value, as it suggests better access to job opportunities, amenities, and transport options.\nSecondary\n\nPROX_HAWKER : Interpretation: Proximity to hawker centres, an important amenity in Singapore, significantly impacts HDB resale prices, as they offer affordable dining options.\nPROX_MRT:\n\nInterpretation: Proximity to MRT stations is another key factor, as convenient public transportation access is highly valued in Singapore’s urban environment.\n\nPROX_PARK and PROX_ELDERCARE also contribute, albeit to a lesser degree, highlighting the value of recreational spaces and proximity to eldercare facilities.\n\nThe top predictors identified by this geographically weighted random forest model, particularly are floor area, level, and remaining lease, aligning with general expectations in HDB pricing. Location-specific amenities (e.g., proximity to CBD, MRT, and hawker centres) further emphasize the premium placed on convenience and accessibility in Singapore’s real estate market. The high R-squared value and reasonable OOB MSE suggest a robust model that captures both structural and spatial elements effectively.\n\nLess influential variables:\n\nVariables like NUM_KINDERGARTEN, PROX_CHILDCARE, and NUM_BUS_STOP have lower importance values, suggesting they contribute less to resale price variation.\n\n\n\n\n\n\n\n\nModel Performance\n\n\n\n\nR-squared (Not OOB): 98.559% This indicates that the model explains 98.56% of the variance in the resale prices. This seems to be a good fit for the data, suggesting the model is effective at capturing key predictors.\n\n\n\n\n11.2.1 Saving the model output\nCode chunk below is used to save the results as an rds file.\n\nwrite_rds(gwRF_adaptive, \"data/HDB/model/gwRF_adaptive.rds\")\n\n\ngwRF_adaptive &lt;- read_rds(\"data/HDB/model/gwRF_adaptive.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#model-evaluation-predicting-using-test-data",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#model-evaluation-predicting-using-test-data",
    "title": "Take-home Exercise 3b: Geospatial Analytics",
    "section": "12 Model Evaluation (Predicting using test data)",
    "text": "12 Model Evaluation (Predicting using test data)\nTo begin, we will prepare the test dataset, consisting of transactions from (Q3) July to September 2024. Like the training data, the test data requires coordinate information for use with the SpatialML package. These coordinates can be extracted using st_coordinates() from the sf package. Afterwards, the geometry data will be removed from resale_test using st_drop_geometry(), resulting in an aspatial dataset ready for analysis.\n\ncoords_test &lt;- st_coordinates(resale_test)\ncoords_test &lt;- write_rds(coords_test, \"data/HDB/rds/coords_test.rds\")\n\nresale_test_nogeo &lt;- cbind(resale_test, coords_test) %&gt;%\n  st_drop_geometry()\n\n\n12.1 Predicting with the test data\nThe Multiple Linear Regression (MLR) will first be used to make predictions based on the test data using the function predict() with the results stored in the test dataset for model evaluation afterwards.\n\nresale_test$MLR_PREDICT &lt;- predict(object = resale.mlr, newdata = resale_test)\n\n\n\n12.2 Predicting with Geographically Weighted Random Forest\nNext, predict.grf() of spatialML package will be used to predict the resale value by using the resale_test data and gwRF_adaptive model calibrated earlier.\n\nresale_test$GWRF_PREDICT &lt;- predict.grf(gwRF_adaptive,\n                                          resale_test_nogeo, \n                                          x.var.name = \"X\",\n                                          y.var.name = \"Y\", \n                                          local.w = 1,\n                                          global.w = 0)\n\nBefore moving on the output is saved as an rds file for future usage\n\nGRF_pred &lt;- write_rds(resale_test, \"data/HDB/rds/resale_test_pred.rds\")\n\n\nGRF_pred &lt;- read_rds(\"data/HDB/rds/resale_test_pred.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#calculation-of-root-mean-square-error-rmse",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#calculation-of-root-mean-square-error-rmse",
    "title": "Take-home Exercise 3b: Geospatial Analytics",
    "section": "13 Calculation of Root Mean Square Error (RMSE)",
    "text": "13 Calculation of Root Mean Square Error (RMSE)\nThe root mean square error (RMSE) allows us to measure how far predicted values are from observed values in a regression analysis. In the code chunk below, rmse() of Metrics package is used to compute the RMSE.\nThe output of the predict.grf() is a vector of predicted values. It is converted into a data frame for further visualisation and analysis.\n\nGRF_pred_df &lt;- as.data.frame(GRF_pred)\n\n\n13.1 RMSE for Geographically Weighted Random Forest\n\nrmse_gwrf &lt;- rmse(resale_test$RESALE_PRICE, \n                  resale_test$GWRF_PREDICT)\n\nrmse_gwrf\n\n[1] 84847.19\n\n\n\n\n13.2 RMSE for Multiple Linear Regression\n\nrmse_mlr &lt;- rmse(resale_test$RESALE_PRICE,\n                 resale_test$MLR_PREDICT)\n\nrmse_mlr\n\n[1] 89310.01\n\n\n\n\n13.3 RMSE Results (Table)\nThe RMSE results for each model can then be stored as a table format for reference using the head() function.\n\nrmse_mlr &lt;- rmse(resale_test$RESALE_PRICE, resale_test$MLR_PREDICT)\nrmse_gwrf &lt;- rmse(resale_test$RESALE_PRICE, resale_test$GWRF_PREDICT)\n\nrmse &lt;- data.frame(\n  Model = c(\"Multiple Linear Regression\", \"Geographically Weighted Random Forest\"),\n  RMSE = c(rmse_mlr, rmse_gwrf)\n)\n\nhead(rmse)\n\n                                  Model     RMSE\n1            Multiple Linear Regression 89310.01\n2 Geographically Weighted Random Forest 84847.19\n\n\n\n\n13.4 Visualising and Analysing the Model Prediction Results\nAdditionally, a scatter plot can be used to visualise the actual resale price and the predicted resale price of both models by using the code chunk below.\n\n\n\n\n\n\nNote\n\n\n\nA better predictive model should have the scatter point close to the diagonal line. The scatter plot can be also used to detect if any outliers are in the model.\n\n\n\nplot_mlr &lt;- ggplot(data = resale_test,\n                   aes(x = MLR_PREDICT,\n                       y = RESALE_PRICE)) +\n  geom_point() +\n  ggtitle(\"Actual Resale Price vs Predicted Price (MLR)\")\n\nplot_gwrf &lt;- ggplot(data = resale_test,\n                    aes(x = GWRF_PREDICT,\n                        y = RESALE_PRICE)) +\n  geom_point() + \n  ggtitle(\"Actual Resale Price vs Predicted Price (GWRF)\")\n\nggarrange(plot_mlr, plot_gwrf, ncol = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSummary and Model Performance\n\n\n\nRMSE Comparison:\n\nThe RMSE for Multiple Linear Regression (MLR) is 89310.01, while for Geographically Weighted Random Forest (GWRF), it is 84847.19. The lower RMSE for GWRF indicates better predictive performance compared to MLR, suggesting that incorporating spatial information improves prediction accuracy.\n\nScatter Plot Analysis:\n\nBoth models show scatter points roughly aligned along the diagonal, indicating reasonable predictive capability. The GWRF model has a tighter clustering of points closer to the diagonal, implying better alignment between actual and predicted resale prices.\n\nModel Interpretation:\n\nThe GWRF model demonstrates superior performance due to its ability to account for spatial heterogeneity and relationships, as seen in the reduced RMSE and improved scatter alignment.\nThis aligns with the observed spatial autocorrelation in the dataset, highlighting the value of using a geographically weighted model.\n\nRecommendation:\n\nFor more reliable results for a model, the GWRF should be preferred for tasks requiring precise predictions of resale prices, especially in spatially non-uniform datasets with evident spatial autocorrelation."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#conclusion-from-results",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#conclusion-from-results",
    "title": "Take-home Exercise 3b: Geospatial Analytics",
    "section": "14 Conclusion from results",
    "text": "14 Conclusion from results\nThe objective of this exercise was to predict HDB resale prices effectively while accounting for spatial relationships in the data. By comparing the performance of Multiple Linear Regression (MLR) and Geographically Weighted Random Forest (GWRF) models, it was evident that the GWRF model outperformed the MLR model. This was reflected in the lower Root Mean Square Error (RMSE) achieved by the GWRF model, which stood at 84847.19 compared to 89310.01 for the MLR model. The improved accuracy of the GWRF model underscores the importance of addressing spatial heterogeneity when modelling geographically distributed data.\nThe dataset used in this exercise exhibited signs of spatial autocorrelation, necessitating the use of spatially-aware models. GWRF effectively leveraged spatial relationships to capture local variations in factors influencing resale prices. The use of an adaptive bandwidth further optimized the model by allowing the kernel to adjust dynamically based on data density, thereby enhancing its performance. Additionally, the analysis of variable importance highlighted that factors such as REMAINING_LEASE, proximity to the central business district (CBD), and FLOOR_AREA_SQM were the most influential drivers of resale prices. These insights underscore the importance of focusing on these attributes in future analyses or pricing strategies.\nVisual validation through scatter plots of predicted versus actual resale prices demonstrated that the GWRF model produced predictions that aligned more closely with observed values compared to the MLR model. The points in the GWRF scatter plot clustered nearer to the diagonal, further reinforcing its superior predictive capabilities. From a practical perspective, for scenarios involving non-uniform spatial data with evident spatial autocorrelation, the GWRF model proves to be a more robust and reliable choice compared to traditional regression techniques. Its ability to incorporate local variability and spatial relationships makes it particularly well-suited for predictive modelling of geographically distributed data.\nIn conclusion, this exercise demonstrates the importance of integrating spatial methodologies in real estate pricing. The findings highlight the value of geographically weighted modelling approaches in addressing spatial heterogeneity and improving prediction accuracy. Future analyses should continue to leverage spatially-aware models such as GWRF while refining bandwidth parameters and incorporating additional spatial covariates to further enhance performance. The generalizability of this approach should also be evaluated on other property types to assess its broader applicability."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#references",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#references",
    "title": "Take-home Exercise 3b: Geospatial Analytics",
    "section": "15 References",
    "text": "15 References\nKam, T.S. (2024). Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method\nKam, T.S. (2024). Geographically Weighted Predictive Models\nIS415 Megan Sim Take-Home Exercise 3(2021). Retrieved from https://is415-msty.netlify.app/posts/2021-10-25-take-home-exercise-3/"
  }
]