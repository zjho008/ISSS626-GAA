{
  "hash": "29e20eb55c1ba82efeac778e6f3503bc",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Hands-on Exercise 5a: Spatial Weights and Applications\"\nauthor: \"Ho Zi Jun\"\ndate: \"Sep 20, 2024\"\ndate-modified: \"last-modified\"\nnumber-sections: true\nexecute:\n  eval: true\n  echo: true\n  message: false\n  freeze: true\neditor: source\n---\n\n\n\n\n\n## Overview\n\nIn this hands-on exercise, we will learn how to compute Global Measures of Spatial Autocorrelation (GMSA) by using **spdep** package. By the end to this hands-on exercise, we will be able to:\n\n-   import geospatial data using appropriate function(s) of **sf** package,\n-   import csv file using appropriate function of **readr** package,\n-   perform relational join using appropriate join function of **dplyr** package,\n-   compute Global Spatial Autocorrelation (GSA) statistics by using appropriate functions of **spdep** package,\n    -   plot Moran scatterplot,\n    -   compute and plot spatial correlogram using appropriate function of **spdep** package.\n-   provide statistically correct interpretation of GSA statistics.\n\n## Getting Started\n\n### The Research Question\n\nIn the realm of spatial planning, achieving a balanced distribution of development across regions is crucial. Our analysis will determine the uniformity of development distribution within a specified area. If *uneven*, we will investigate potential spatial clustering and identify their locations.\n\nWe will specifically analyze the spatial distribution of GDP per capita within [Hunan Provice](https://en.wikipedia.org/wiki/Hunan), People Republic of China.\n\n### The Study Area and Data\n\nTwo data sets will be used in this hands-on exercise, they are:\n\n-   Hunan province administrative boundary layer at county level. This is a geospatial data set in ESRI shapefile format.\n-   Hunan_2012.csv: This csv file contains selected Hunan's local development indicators in 2012.\n\n### Setting the Analytical Toolls\n\nBefore we get started, we need to ensure that **spdep**, **sf**, **tmap** and **tidyverse** packages of R are currently installed in your R.\n\n-   sf is use for importing and handling geospatial data in R,\n-   tidyverse is mainly use for wrangling attribute data in R,\n-   spdep will be used to compute spatial weights, global and local spatial autocorrelation statistics, and\n-   tmap will be used to prepare cartographic quality chropleth map.\n\nThe code chunk below is used to perform the following tasks:\n\n-   creating a package list containing the necessary R packages,\n-   checking if the R packages in the package list have been installed in R,\n    -   if they have yet to be installed, RStudio will installed the missing packages,\n-   launching the packages into R environment.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(sf, spdep, tmap, tidyverse)\n```\n:::\n\n\n\n\n\n## Getting the Data Into R Environment\n\nIn this section, you will learn how to bring a geospatial data and its associated attribute table into R environment. The geospatial data is in ESRI shapefile format and the attribute table is in csv format.\n\n### Import shapefile into r environment\n\nImport the Hunan shapefile as an sf simple features object using the `st_read()` function from the sf package.\n\nThe code chunk below uses [`st_read()`](https://r-spatial.github.io/sf/reference/st_read.html) of **sf** package to import Hunan shapefile into R. The imported shapefile will be **simple features** Object of **sf**.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhunan <- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `Hunan' from data source \n  `C:\\zjho008\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex05\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n```\n\n\n:::\n:::\n\n\n\n\n\n### Import csv file into r environment\n\nNext, we will import *Hunan_2012.csv* into R by using [`read_csv()`](https://readr.tidyverse.org/reference/read_delim.html) of **readr** package. The output is R data frame class.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhunan2012 <- read_csv(\"data/aspatial/Hunan_2012.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n:::\n\n\n\n\n\n### Performing relational join (Data Merging)\n\nThe code chunk below will be used to update the attribute table of *hunan*'s SpatialPolygonsDataFrame with the attribute fields of *hunan2012* dataframe. This is performed by using [`left_join()`](https://dplyr.tidyverse.org/reference/mutate-joins.html) of **dplyr** package.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhunan <- left_join(hunan,hunan2012) %>%\n  select(1:4, 7, 15)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nJoining with `by = join_by(County)`\n```\n\n\n:::\n:::\n\n\n\n\n\n### Mapping Regional Indicators\n\nNow, we are going to prepare a basemap and a choropleth map showing the distribution of GDPPC 2012 by using `qtm()` of **tmap** package.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nequal <- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval classification\")\n\nquantile <- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\")\n\ntmap_arrange(equal, \n             quantile, \n             asp=1, \n             ncol=2)\n```\n\n::: {.cell-output-display}\n![](Hands-on_Ex05a_files/figure-html/unnamed-chunk-5-1.png){width=1152}\n:::\n:::\n\n\n\n\n\n## Calculating Global Spatial Autocorrelation\n\n### Global Measures of Spatial Autocorrelation\n\nIn this section, it will show how to compute global spatial autocorrelation statistics and to perform spatial complete randomness test for global spatial autocorrelation.\n\n### Computing Contiguity Spatial Weights\n\nBefore we can compute the global spatial autocorrelation statistics, we need to construct a spatial weights of the study area. The spatial weights is used to define the neighbourhood relationships between the geographical units (i.e. county) in the study area.\n\nIn the code chunk below, [`poly2nb()`](https://r-spatial.github.io/spdep/reference/poly2nb.html) of **spdep** package is used to compute contiguity weight matrices for the study area. This function builds a neighbours list based on regions with contiguous boundaries. If you look at the documentation you will see that you can pass a \"queen\" argument that takes TRUE or FALSE as options. If you do not specify this argument the default is set to TRUE, that is, if you don't specify queen = FALSE this function will return a list of first order neighbours using the Queen criteria.\n\nMore specifically, the code chunk below is used to compute Queen contiguity weight matrix.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwm_q <- poly2nb(hunan, \n                queen=TRUE)\nsummary(wm_q)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n```\n\n\n:::\n:::\n\n\n\n\n\nThe summary report above shows that there are *88 area units* in Hunan. The most connected area unit has 11 neighbours. There are two area units with only one neighbours.\n\n### Row-standardised weights matrix (Standardizing Weights)\n\nNext, we need to assign weights to each neighboring polygon. In our case, each neighboring polygon will be assigned equal weight (style=\"W\"). This is accomplished by assigning the fraction 1/(#ofneighbors) to each neighboring county then summing the weighted income values. While this is the most intuitive way to summaries the neighbors' values it has one drawback in that polygons along the edges of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data. For this example, we'll stick with the style=\"W\" option for simplicity's sake but note that other more robust options are available, notably style=\"B\".\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrswm_q <- nb2listw(wm_q, \n                   style=\"W\", \n                   zero.policy = TRUE)\nrswm_q\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n```\n\n\n:::\n:::\n\n\n\n\n\n::: callout-note\n### What can we learn from the code chunk above?\n\n-   The input of [`nb2listw()`](https://r-spatial.github.io/spdep/reference/nb2listw.html) must be an object of class **nb**. The syntax of the function has two major arguments, namely style and zero.poly.\n-   *style* can take values \"W\", \"B\", \"C\", \"U\", \"minmax\" and \"S\". B is the basic binary coding, W is row standardised (sums over all links to n), C is globally standardised (sums over all links to n), U is equal to C divided by the number of neighbours (sums over all links to unity), while S is the variance-stabilizing coding scheme proposed by Tiefelsdorf et al. 1999, p. 167-168 (sums over all links to n).\n-   If *zero policy* is set to TRUE, weights vectors of zero length are inserted for regions without neighbour in the neighbours list. These will in turn generate lag values of zero, equivalent to the sum of products of the zero row t(rep(0, length=length(neighbours))) %\\*% x, for arbitrary numerical vector x of length length(neighbours). The spatially lagged value of x for the zero-neighbour region will then be zero, which may (or may not) be a sensible choice.\n:::\n\n## Global Measures of Spatial Autocorrelation: Moran's I\n\nIn this section, you will learn how to perform Moran's I statistics testing by using [`moran.test()`](https://r-spatial.github.io/spdep/reference/moran.test.html) of **spdep**.\n\n### Maron's I test\n\nThe code chunk below performs Moran's I statistical testing using [`moran.test()`](https://r-spatial.github.io/spdep/reference/moran.test.html) of **spdep**.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmoran.test(hunan$GDPPC, \n           listw=rswm_q, \n           zero.policy = TRUE, \n           na.action=na.omit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tMoran I test under randomisation\n\ndata:  hunan$GDPPC  \nweights: rswm_q    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n```\n\n\n:::\n:::\n\n\n\n\n\n> Question: What statistical conclusion can you draw from the output above?\n\n### Computing Monte Carlo Moran's I (Permutation Testing)\n\nThe code chunk below performs permutation test for Moran's I statistic by using [`moran.mc()`](https://r-spatial.github.io/spdep/reference/moran.mc.html) of **spdep**. A total of 1000 simulation will be performed.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\nbperm= moran.mc(hunan$GDPPC, \n                listw=rswm_q, \n                nsim=999, \n                zero.policy = TRUE, \n                na.action=na.omit)\nbperm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tMonte-Carlo simulation of Moran I\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.30075, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n```\n\n\n:::\n:::\n\n\n\n\n\n> Question: What statistical conclustion can you draw fro mthe output above?\n\n### Visualising Monte Carlo Moran's I (Distribution Visualization)\n\nIt is always a good practice for us the examine the simulated Moran's I test statistics in greater detail. This can be achieved by plotting the distribution of the statistical values as a histogram by using the code chunk below.\n\nIn the code chunk below [`hist()`](https://www.rdocumentation.org/packages/graphics/versions/3.6.2/topics/hist) and [`abline()`](https://www.rdocumentation.org/packages/graphics/versions/3.6.2/topics/abline) of R Graphics are used.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(bperm$res[1:999])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.01504572\n```\n\n\n:::\n\n```{.r .cell-code}\nvar(bperm$res[1:999])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.004371574\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(bperm$res[1:999])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.18339 -0.06168 -0.02125 -0.01505  0.02611  0.27593 \n```\n\n\n:::\n\n```{.r .cell-code}\nhist(bperm$res, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I\")\nabline(v=0, \n       col=\"red\") \n```\n\n::: {.cell-output-display}\n![](Hands-on_Ex05a_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n\n\n\n> Question: What statistical observation can you draw fro mthe output above?\n\n> Challenge: Instead of using Base Graph to plot the values, plot the values by using ggplot2 package.\n\n## Global Measures of Spatial Autocorrelation: Geary's C (Statistical Testing)\n\nIn this section, you will learn how to perform Geary's C statistics testing by using appropriate functions of **spdep** package.\n\n### Geary's C test\n\nThe code chunk below performs Geary's C test for spatial autocorrelation by using [`geary.test()`](https://r-spatial.github.io/spdep/reference/geary.test.html) of **spdep**.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngeary.test(hunan$GDPPC, listw=rswm_q)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tGeary C test under randomisation\n\ndata:  hunan$GDPPC \nweights: rswm_q   \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364 \n```\n\n\n:::\n:::\n\n\n\n\n\n> Question: What statistical conclusion can you draw from the output above?\n\n### Computing Monte Carlo Geary's C\n\nThe code chunk below performs permutation test for Geary's C statistic by using [`geary.mc()`](https://r-spatial.github.io/spdep/reference/geary.mc.html) of **spdep**.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\nbperm=geary.mc(hunan$GDPPC, \n               listw=rswm_q, \n               nsim=999)\nbperm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tMonte-Carlo simulation of Geary C\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.69072, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n```\n\n\n:::\n:::\n\n\n\n\n\n> Question: What statistical conclusion can you draw from the output above?\n\n### Visualising the Monte Carlo Geary's C\n\nNext, we will plot a histogram to reveal the distribution of the simulated values by using the code chunk below.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(bperm$res[1:999])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1.004402\n```\n\n\n:::\n\n```{.r .cell-code}\nvar(bperm$res[1:999])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.007436493\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(bperm$res[1:999])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.7142  0.9502  1.0052  1.0044  1.0595  1.2722 \n```\n\n\n:::\n\n```{.r .cell-code}\nhist(bperm$res, freq=TRUE, breaks=20, xlab=\"Simulated Geary c\")\nabline(v=1, col=\"red\") \n```\n\n::: {.cell-output-display}\n![](Hands-on_Ex05a_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\n\n\n\n> Question: What statistical observation can you draw from the output?\n\n## Spatial Correlogram\n\nSpatial correlograms are great to examine patterns of spatial autocorrelation in your data or model residuals. They show how correlated are pairs of spatial observations when you increase the distance (lag) between them - they are plots of some index of autocorrelation (Moran's I or Geary's c) against distance.Although correlograms are not as fundamental as variograms (a keystone concept of geostatistics), they are very useful as an exploratory and descriptive tool. For this purpose they actually provide richer information than variograms.\n\n### Compute Moran's I correlogram\n\nIn the code chunk below, [`sp.correlogram()`](https://r-spatial.github.io/spdep/reference/sp.correlogram.html) of **spdep** package is used to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used in Moran's I. The **plot()** of base Graph is then used to plot the output.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nMI_corr <- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"I\", \n                          style=\"W\")\nplot(MI_corr)\n```\n\n::: {.cell-output-display}\n![](Hands-on_Ex05a_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n\n\n\nPlotting the output alone may not provide a comprehensive interpretation, as not all autocorrelation values carry statistical significance. Therefore, it's crucial to review the complete analysis report. The detailed results can be accessed by executing the following code chunk, which prints out the entire analysis:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprint(MI_corr)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSpatial correlogram for hunan$GDPPC \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (88)  0.3007500  -0.0114943  0.0043484           4.7351       2.189e-06 ***\n2 (88)  0.2060084  -0.0114943  0.0020962           4.7505       2.029e-06 ***\n3 (88)  0.0668273  -0.0114943  0.0014602           2.0496        0.040400 *  \n4 (88)  0.0299470  -0.0114943  0.0011717           1.2107        0.226015    \n5 (88) -0.1530471  -0.0114943  0.0012440          -4.0134       5.984e-05 ***\n6 (88) -0.1187070  -0.0114943  0.0016791          -2.6164        0.008886 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n\n\n> Question: What statistical observation can you draw from the plot above?\n\n:::callout-note\nFrom the output of the spatial correlogram for Hunan GDP per capita, which uses Moran's I method, we can observe several key statistical points:\n\n  1. **Lag 1 and Lag 2 Correlations**: The Moran's I values for the first and second lags (0.300750 and 0.206004 respectively) are positive and highly significant (p-value < 0.01, denoted by ***), indicating a strong positive spatial autocorrelation at these distances. This suggests that regions that are close together (up to two lags away) tend to have similar GDP per capita values.\n\n  2. **Significance of Autocorrelation**: The positive autocorrelation at Lag 1 and Lag 2 implies that areas with higher GDP per capita are clustered together, as are areas with lower GDP per capita.\n\n  3. **Lag 3 to Lag 6 Correlations**: The values gradually decrease and even become negative by Lag 6 (-0.118070). The negative value at Lag 6 is statistically significant (p-value < 0.05, denoted by **), indicating that regions further apart start to exhibit dissimilar GDP per capita values, a phenomenon known as negative spatial autocorrelation.\n\n  4. **Statistical Significance**: Lags 1, 2, 4, and 6 show statistically significant autocorrelation. Particularly, Lags 1 and 2 show strong and highly significant positive spatial autocorrelation, while Lags 4 and 6 show statistically significant but weaker negative autocorrelation.\n\nThese observations highlight the presence of spatial patterns in GDP per capita across Hunan, with nearby regions being more similar than those further apart, transitioning to dissimilarity at greater distances.\n:::\n\n### Compute Geary's C correlogram and plot\n\nIn the code chunk below, `sp.correlogram()` of **spdep** package is used to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used in Geary's C. The **plot()** of base Graph is then used to plot the output.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nGC_corr <- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"C\", \n                          style=\"W\")\nplot(GC_corr)\n```\n\n::: {.cell-output-display}\n![](Hands-on_Ex05a_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\n\n\n\nSimilar to the previous step, we will print out the analysis report by using the code chunk below.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprint(GC_corr)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSpatial correlogram for hunan$GDPPC \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided    \n1 (88) 0.6907223   1.0000000 0.0073364          -3.6108       0.0003052 ***\n2 (88) 0.7630197   1.0000000 0.0049126          -3.3811       0.0007220 ***\n3 (88) 0.9397299   1.0000000 0.0049005          -0.8610       0.3892612    \n4 (88) 1.0098462   1.0000000 0.0039631           0.1564       0.8757128    \n5 (88) 1.2008204   1.0000000 0.0035568           3.3673       0.0007592 ***\n6 (88) 1.0773386   1.0000000 0.0058042           1.0151       0.3100407    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::",
    "supporting": [
      "Hands-on_Ex05a_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}